{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f79d99ef",
   "metadata": {},
   "source": [
    "# Text To Speech Synthesis using Machine Learning\n",
    "\n",
    "## <i>Part A - Application Area Review</i>\n",
    "\n",
    "### Overview\n",
    "\n",
    "Speech synthesis is the process of generating speech by artificial means, usually by computer. It involves the production of sound to simulate human speech, which is referred to as low-level synthesis. High-level synthesis deals with the conversion of written text or symbols into an abstract representation of the desired acoustic signal, suitable for driving a low-level synthesis system. \n",
    "\n",
    "Text-to-speech (TTS) is a technology that converts written text into spoken words. It is a type of speech synthesis that uses deep learning models to generate human-like speech. TTS AI can be used in a variety of applications, including audiobooks, virtual assistants, and accessibility tools for people with visual impairments. These AI models are trained on large datasets of human speech, which allows them to learn the nuances of language and produce speech that is indistinguishable from human speech. They can also be customized to produce speech in different languages, accents, and styles.\n",
    "\n",
    "<b><u>Literature Review</u></b>\n",
    "\n",
    "The history of speech synthesis possibly dates back to the 12th century when people tried to build machines to synthesize human speech however, the first computer-based speech synthesis system was developed in the latter half of the 20th century. Early computer-based speech synthesis methods predominantly used articulatory approaches, formant synthesis, and concatenative synthesis. Since the 2010s, neural network-based speech synthesis has become the industry standard to achieving speech synthesis indistinguishable from real human voices (Tan et al., 2021). \n",
    "\n",
    "<b><i>Neural Speech Synthesis</b></i>\n",
    "\n",
    "The first neural tts model was proposed by Google's Deepmind (Oord et al., 2016). A modern tts model genrally consists of a few critical components starting with a text analysis process which converts written text into a series of linguistic features. An acoustic model then creates acoustic features based on the aforemention linguistic features. A vocoder then converts these acoustic features into waveforms (Kaur and Singh, 2022). A vocoder, short for voice encoder, is a crucial component responsible for converting linguistic features into a natural-sounding speech waveform. The term \"vocoder\" is often used broadly to refer to any system or algorithm that performs this transformation, and there are different types of vocoders with varying architectures. This review will be discussing three main approaches based on the types of vocoders used in neural tts.\n",
    "\n",
    "<b><i>Autoregressive Vocoders (MEL Inverters)</b></i>\n",
    "\n",
    "Auto-regressive vocoders are a type of vocoder used in text-to-speech (TTS) systems. Vocoder stands for \"voice encoder\" and is a crucial component in the process of converting text into speech. The main goal of a vocoder is to generate a natural-sounding and high-quality speech signal. In the context of auto-regressive vocoders, the term \"auto-regressive\" refers to the way the model generates the output waveform. These models predict one audio sample at a time based on the previous samples in a sequential manner. This sequential generation allows the model to capture dependencies and patterns in the audio waveform, leading to more natural-sounding speech. This is in contrast to non-auto-regressive models, where all samples are generated simultaneously and independently.\n",
    "\n",
    "One popular example of an auto-regressive vocoder is WaveNet (Oord et al., 2016), developed by DeepMind, WaveNet is a generative model for raw audio waveforms and uses dilated convolutions to capture long-range dependencies in the data. It has been used in various text-to-speech applications to generate high-quality and natural-sounding speech.\n",
    "\n",
    "<b><i>GAN Based Vocoders</b></i>\n",
    "\n",
    "A GAN is a type of generative model consisting of a generator and a discriminator, which are trained simultaneously through adversarial training. The generator aims to create realistic data, while the discriminator tries to distinguish between real and generated data. This process leads to the generator improving its ability to generate more realistic samples. GAN-based vocoders are able to generate high-quality speech from text inputs.\n",
    "\n",
    "Wave GAN proposed by Donahue, McAuley and Puckette is arguably the first attempt to solve the problem using GANs (Donahue, McAuley and Puckette, 2019).\n",
    "\n",
    "<b><i>Flow Based Vocoders</b></i>\n",
    "\n",
    "Flow-based vocoders are a type of vocoder used in text-to-speech (TTS) systems. They are part of a family of generative models called normalizing flow models. Normalizing flows are a class of generative models that learn to transform a simple probability distribution (e.g., Gaussian distribution) into a more complex distribution that matches the data distribution. In the context of audio generation, these models can be used to learn the complex mapping from a simple distribution to the distribution of audio samples. Flow-based models consist of a series of invertible transformations. These transformations are designed so that both the forward (sampling) and inverse (probability density estimation) processes are computationally tractable. \n",
    "\n",
    "One of the advantages of flow-based vocoders is that they can generate audio samples in parallel, making them more computationally efficient compared to auto-regressive models. Other advantages include efficient training and high-quality audio synthesis. Flow-based vocoders take as input the learned representation of the speech signal and generate the corresponding waveform in parallel\n",
    "\n",
    "An earlier example of a flow-based vocoder is the WaveGlow model (Prenger et al., 2018), which was introduced by NVIDIA. WaveGlow employs normalizing flows to model the conditional distribution of audio waveforms given linguistic features and other relevant information. \n",
    "\n",
    "<b><u>Implementation</u></b>\n",
    "\n",
    "For this implementation, Glow TTS (Kim et al., 2020) will be used through the api provided by the corqui.ai library\n",
    "\n",
    "<b><i>HLD</b></i>\n",
    "\n",
    "![TTS-HLD](TTS-HLD.png)\n",
    "\n",
    "<b><i>Dataset</b></i>\n",
    "\n",
    "The data requirements for the model calls for transcribed speech which have been divided into the audio files and its subsequent transcription. The audio files need to be in the .wav format as this is a lossless audio format which is required to prevent compression artifacts.\n",
    "\n",
    "For this use case the LJ Speech dataset will be used (Ito and Johnson, 2017). The raw format of the dataset is explained in the documentation for this dataset.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "By default the wav files are presented under a folder a such:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9307034",
   "metadata": {},
   "source": [
    "<i><b>/wavs<br>\n",
    " | - audio1.wav<br>\n",
    " | - audio2.wav<br>\n",
    " | - audio3.wav</i><b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdfd141",
   "metadata": {},
   "source": [
    "The required folder structure for the coqui api is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee5b62",
   "metadata": {},
   "source": [
    "<i><b>\"/Dataset\"<br>\n",
    "    |<br>\n",
    "    | -> metadata.csv<br>\n",
    "    | -> /wavs<br>\n",
    "        | -> audio1.wav<br>\n",
    "        | -> audio2.wav<br>\n",
    "        | ...</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb8283",
   "metadata": {},
   "source": [
    "The final formatting and processing is shown further in the implementation below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone coqui for implementation\n",
    "!git clone \"https://github.com/coqui-ai/TTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open repo and install dependencies\n",
    "%cd TTS\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing TTS.egg-info\\PKG-INFO\n",
      "writing dependency_links to TTS.egg-info\\dependency_links.txt\n",
      "writing entry points to TTS.egg-info\\entry_points.txt\n",
      "writing requirements to TTS.egg-info\\requires.txt\n",
      "writing top-level names to TTS.egg-info\\top_level.txt\n",
      "reading manifest file 'TTS.egg-info\\SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "adding license file 'LICENSE.txt'\n",
      "writing manifest file 'TTS.egg-info\\SOURCES.txt'\n",
      "installing library code to build\\bdist.win-amd64\\egg\n",
      "running install_lib\n",
      "running build_py\n",
      "running build_ext\n",
      "building 'TTS.tts.utils.monotonic_align.core' extension\n",
      "creating build\n",
      "creating build\\temp.win-amd64-cpython-310\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\TTS\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\TTS\\tts\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\TTS\\tts\\utils\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\TTS\\tts\\utils\\monotonic_align\n",
      "\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.38.33130\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -Ic:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\include -Ic:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\include -Ic:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.38.33130\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" /TcTTS/tts/utils/monotonic_align/core.c /Fobuild\\temp.win-amd64-cpython-310\\Release\\TTS/tts/utils/monotonic_align/core.obj\n",
      "core.c\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_1_7_deprecated_api.h(14) : Warning Msg: Using deprecated NumPy API, disable it with #define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\n",
      "TTS/tts/utils/monotonic_align/core.c(19507): warning C4244: '=': conversion from 'Py_ssize_t' to 'int', possible loss of data\n",
      "creating c:\\Users\\glsup\\Documents\\IIT\\Year 4\\FYP\\Applied AI\\TTS\\build\\lib.win-amd64-cpython-310\n",
      "creating c:\\Users\\glsup\\Documents\\IIT\\Year 4\\FYP\\Applied AI\\TTS\\build\\lib.win-amd64-cpython-310\\TTS\n",
      "creating c:\\Users\\glsup\\Documents\\IIT\\Year 4\\FYP\\Applied AI\\TTS\\build\\lib.win-amd64-cpython-310\\TTS\\tts\n",
      "creating c:\\Users\\glsup\\Documents\\IIT\\Year 4\\FYP\\Applied AI\\TTS\\build\\lib.win-amd64-cpython-310\\TTS\\tts\\utils\n",
      "creating c:\\Users\\glsup\\Documents\\IIT\\Year 4\\FYP\\Applied AI\\TTS\\build\\lib.win-amd64-cpython-310\\TTS\\tts\\utils\\monotonic_align\n",
      "\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.38.33130\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\libs /LIBPATH:c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310 /LIBPATH:c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.38.33130\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22621.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22621.0\\\\um\\x64\" /EXPORT:PyInit_core build\\temp.win-amd64-cpython-310\\Release\\TTS/tts/utils/monotonic_align/core.obj /OUT:build\\lib.win-amd64-cpython-310\\TTS\\tts\\utils\\monotonic_align\\core.cp310-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-310\\Release\\TTS/tts/utils/monotonic_align\\core.cp310-win_amd64.lib\n",
      "   Creating library build\\temp.win-amd64-cpython-310\\Release\\TTS/tts/utils/monotonic_align\\core.cp310-win_amd64.lib and object build\\temp.win-amd64-cpython-310\\Release\\TTS/tts/utils/monotonic_align\\core.cp310-win_amd64.exp\n",
      "Generating code\n",
      "Finished generating code\n",
      "creating build\\bdist.win-amd64\n",
      "creating build\\bdist.win-amd64\\egg\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\n",
      "copying temp_build\\TTS\\.models.json -> build\\bdist.win-amd64\\egg\\TTS\n",
      "copying temp_build\\TTS\\api.py -> build\\bdist.win-amd64\\egg\\TTS\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\collect_env_info.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\compute_attention_masks.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\compute_embeddings.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\compute_statistics.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\eval_encoder.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\extract_tts_spectrograms.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\find_unique_chars.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\find_unique_phonemes.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\remove_silence_using_vad.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\resample.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\synthesize.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\train_encoder.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\train_tts.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\train_vocoder.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\tune_wavegrad.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "copying temp_build\\TTS\\bin\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\bin\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\config\n",
      "copying temp_build\\TTS\\config\\shared_configs.py -> build\\bdist.win-amd64\\egg\\TTS\\config\n",
      "copying temp_build\\TTS\\config\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\config\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\demos\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\demos\\xtts_ft_demo\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\demos\\xtts_ft_demo\\utils\n",
      "copying temp_build\\TTS\\demos\\xtts_ft_demo\\utils\\formatter.py -> build\\bdist.win-amd64\\egg\\TTS\\demos\\xtts_ft_demo\\utils\n",
      "copying temp_build\\TTS\\demos\\xtts_ft_demo\\utils\\gpt_train.py -> build\\bdist.win-amd64\\egg\\TTS\\demos\\xtts_ft_demo\\utils\n",
      "copying temp_build\\TTS\\demos\\xtts_ft_demo\\xtts_demo.py -> build\\bdist.win-amd64\\egg\\TTS\\demos\\xtts_ft_demo\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\encoder\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\encoder\\configs\n",
      "copying temp_build\\TTS\\encoder\\configs\\base_encoder_config.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\configs\n",
      "copying temp_build\\TTS\\encoder\\configs\\emotion_encoder_config.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\configs\n",
      "copying temp_build\\TTS\\encoder\\configs\\speaker_encoder_config.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\configs\n",
      "copying temp_build\\TTS\\encoder\\dataset.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\n",
      "copying temp_build\\TTS\\encoder\\losses.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\encoder\\models\n",
      "copying temp_build\\TTS\\encoder\\models\\base_encoder.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\models\n",
      "copying temp_build\\TTS\\encoder\\models\\lstm.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\models\n",
      "copying temp_build\\TTS\\encoder\\models\\resnet.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\models\n",
      "copying temp_build\\TTS\\encoder\\README.md -> build\\bdist.win-amd64\\egg\\TTS\\encoder\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\n",
      "copying temp_build\\TTS\\encoder\\utils\\generic_utils.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\n",
      "copying temp_build\\TTS\\encoder\\utils\\prepare_voxceleb.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\n",
      "copying temp_build\\TTS\\encoder\\utils\\training.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\n",
      "copying temp_build\\TTS\\encoder\\utils\\visual.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\n",
      "copying temp_build\\TTS\\encoder\\utils\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\n",
      "copying temp_build\\TTS\\encoder\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\encoder\n",
      "copying temp_build\\TTS\\model.py -> build\\bdist.win-amd64\\egg\\TTS\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\server\n",
      "copying temp_build\\TTS\\server\\conf.json -> build\\bdist.win-amd64\\egg\\TTS\\server\n",
      "copying temp_build\\TTS\\server\\README.md -> build\\bdist.win-amd64\\egg\\TTS\\server\n",
      "copying temp_build\\TTS\\server\\server.py -> build\\bdist.win-amd64\\egg\\TTS\\server\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\server\\static\n",
      "copying temp_build\\TTS\\server\\static\\coqui-log-green-TTS.png -> build\\bdist.win-amd64\\egg\\TTS\\server\\static\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\server\\templates\n",
      "copying temp_build\\TTS\\server\\templates\\details.html -> build\\bdist.win-amd64\\egg\\TTS\\server\\templates\n",
      "copying temp_build\\TTS\\server\\templates\\index.html -> build\\bdist.win-amd64\\egg\\TTS\\server\\templates\n",
      "copying temp_build\\TTS\\server\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\server\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\align_tts_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\bark_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\delightful_tts_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\fastspeech2_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\fast_pitch_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\fast_speech_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\glow_tts_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\neuralhmm_tts_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\overflow_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\shared_configs.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\speedy_speech_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\tacotron2_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\tacotron_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\tortoise_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\vits_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\xtts_config.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "copying temp_build\\TTS\\tts\\configs\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\datasets\n",
      "copying temp_build\\TTS\\tts\\datasets\\dataset.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\datasets\n",
      "copying temp_build\\TTS\\tts\\datasets\\formatters.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\datasets\n",
      "copying temp_build\\TTS\\tts\\datasets\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\datasets\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\align_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\align_tts\\duration_predictor.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\align_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\align_tts\\mdn.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\align_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\align_tts\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\align_tts\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\hubert\n",
      "copying temp_build\\TTS\\tts\\layers\\bark\\hubert\\hubert_manager.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\hubert\n",
      "copying temp_build\\TTS\\tts\\layers\\bark\\hubert\\kmeans_hubert.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\hubert\n",
      "copying temp_build\\TTS\\tts\\layers\\bark\\hubert\\tokenizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\hubert\n",
      "copying temp_build\\TTS\\tts\\layers\\bark\\hubert\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\hubert\n",
      "copying temp_build\\TTS\\tts\\layers\\bark\\inference_funcs.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\n",
      "copying temp_build\\TTS\\tts\\layers\\bark\\load_model.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\n",
      "copying temp_build\\TTS\\tts\\layers\\bark\\model.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\n",
      "copying temp_build\\TTS\\tts\\layers\\bark\\model_fine.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\n",
      "copying temp_build\\TTS\\tts\\layers\\bark\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\acoustic_model.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\conformer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\conv_layers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\encoders.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\energy_adaptor.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\kernel_predictor.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\networks.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\phoneme_prosody_predictor.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\pitch_adaptor.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\variance_predictor.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\delightful_tts\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\feed_forward\n",
      "copying temp_build\\TTS\\tts\\layers\\feed_forward\\decoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\feed_forward\n",
      "copying temp_build\\TTS\\tts\\layers\\feed_forward\\duration_predictor.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\feed_forward\n",
      "copying temp_build\\TTS\\tts\\layers\\feed_forward\\encoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\feed_forward\n",
      "copying temp_build\\TTS\\tts\\layers\\feed_forward\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\feed_forward\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "copying temp_build\\TTS\\tts\\layers\\generic\\aligner.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "copying temp_build\\TTS\\tts\\layers\\generic\\gated_conv.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "copying temp_build\\TTS\\tts\\layers\\generic\\normalization.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "copying temp_build\\TTS\\tts\\layers\\generic\\pos_encoding.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "copying temp_build\\TTS\\tts\\layers\\generic\\res_conv_bn.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "copying temp_build\\TTS\\tts\\layers\\generic\\time_depth_sep_conv.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "copying temp_build\\TTS\\tts\\layers\\generic\\transformer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "copying temp_build\\TTS\\tts\\layers\\generic\\wavenet.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "copying temp_build\\TTS\\tts\\layers\\generic\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\glow_tts\\decoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\glow_tts\\duration_predictor.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\glow_tts\\encoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\glow_tts\\glow.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\glow_tts\\transformer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\glow_tts\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\n",
      "copying temp_build\\TTS\\tts\\layers\\losses.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\n",
      "copying temp_build\\TTS\\tts\\layers\\overflow\\common_layers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\n",
      "copying temp_build\\TTS\\tts\\layers\\overflow\\decoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\n",
      "copying temp_build\\TTS\\tts\\layers\\overflow\\neural_hmm.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\n",
      "copying temp_build\\TTS\\tts\\layers\\overflow\\plotting_utils.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\n",
      "copying temp_build\\TTS\\tts\\layers\\overflow\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\n",
      "copying temp_build\\TTS\\tts\\layers\\tacotron\\attentions.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\n",
      "copying temp_build\\TTS\\tts\\layers\\tacotron\\capacitron_layers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\n",
      "copying temp_build\\TTS\\tts\\layers\\tacotron\\common_layers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\n",
      "copying temp_build\\TTS\\tts\\layers\\tacotron\\gst_layers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\n",
      "copying temp_build\\TTS\\tts\\layers\\tacotron\\tacotron.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\n",
      "copying temp_build\\TTS\\tts\\layers\\tacotron\\tacotron2.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\n",
      "copying temp_build\\TTS\\tts\\layers\\tacotron\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\arch_utils.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\audio_utils.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\autoregressive.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\classifier.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\clvp.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\diffusion.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\diffusion_decoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\dpm_solver.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\random_latent_generator.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\tokenizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\transformer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\utils.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\vocoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\wav2vec_alignment.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "copying temp_build\\TTS\\tts\\layers\\tortoise\\xtransformers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\vits\n",
      "copying temp_build\\TTS\\tts\\layers\\vits\\discriminator.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\vits\n",
      "copying temp_build\\TTS\\tts\\layers\\vits\\networks.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\vits\n",
      "copying temp_build\\TTS\\tts\\layers\\vits\\stochastic_duration_predictor.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\vits\n",
      "copying temp_build\\TTS\\tts\\layers\\vits\\transforms.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\vits\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\dvae.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\gpt.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\gpt_inference.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\hifigan_decoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\latent_encoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\perceiver_encoder.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\stream_generator.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\tokenizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\trainer\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\trainer\\dataset.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\trainer\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\trainer\\gpt_trainer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\trainer\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\xtts_manager.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\xtts\\zh_num2words.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\n",
      "copying temp_build\\TTS\\tts\\layers\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\align_tts.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\bark.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\base_tacotron.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\base_tts.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\delightful_tts.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\forward_tts.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\glow_tts.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\neuralhmm_tts.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\overflow.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\tacotron.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\tacotron2.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\tortoise.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\vits.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\xtts.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "copying temp_build\\TTS\\tts\\models\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\models\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\assets\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\assets\\tortoise\n",
      "copying temp_build\\TTS\\tts\\utils\\assets\\tortoise\\tokenizer.json -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\assets\\tortoise\n",
      "copying temp_build\\TTS\\tts\\utils\\data.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "copying temp_build\\TTS\\tts\\utils\\fairseq.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "copying temp_build\\TTS\\tts\\utils\\helpers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "copying temp_build\\TTS\\tts\\utils\\languages.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "copying temp_build\\TTS\\tts\\utils\\managers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "copying temp_build\\TTS\\tts\\utils\\measures.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\monotonic_align\n",
      "copying temp_build\\TTS\\tts\\utils\\monotonic_align\\core.c -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\monotonic_align\n",
      "copying temp_build\\TTS\\tts\\utils\\monotonic_align\\core.pyx -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\monotonic_align\n",
      "copying temp_build\\TTS\\tts\\utils\\monotonic_align\\setup.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\monotonic_align\n",
      "copying temp_build\\TTS\\tts\\utils\\monotonic_align\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\monotonic_align\n",
      "copying temp_build\\TTS\\tts\\utils\\speakers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "copying temp_build\\TTS\\tts\\utils\\ssim.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "copying temp_build\\TTS\\tts\\utils\\synthesis.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\bangla\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\bangla\\phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\bangla\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\bangla\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\bangla\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\belarusian\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\belarusian\\phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\belarusian\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\belarusian\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\belarusian\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\characters.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\chinese_mandarin\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\chinese_mandarin\\numbers.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\chinese_mandarin\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\chinese_mandarin\\phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\chinese_mandarin\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\chinese_mandarin\\pinyinToPhonemes.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\chinese_mandarin\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\chinese_mandarin\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\chinese_mandarin\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\cleaners.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\cmudict.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\english\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\english\\abbreviations.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\english\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\english\\number_norm.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\english\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\english\\time_norm.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\english\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\english\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\english\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\french\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\french\\abbreviations.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\french\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\french\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\french\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\japanese\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\japanese\\phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\japanese\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\japanese\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\japanese\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\korean\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\korean\\korean.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\korean\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\korean\\ko_dictionary.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\korean\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\korean\\phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\korean\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\korean\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\korean\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\bangla_phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\base.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\belarusian_phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\espeak_wrapper.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\gruut_wrapper.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\ja_jp_phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\ko_kr_phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\multi_phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\zh_cn_phonemizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\phonemizers\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\punctuation.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\tokenizer.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\n",
      "copying temp_build\\TTS\\tts\\utils\\text\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\n",
      "copying temp_build\\TTS\\tts\\utils\\visual.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "copying temp_build\\TTS\\tts\\utils\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\n",
      "copying temp_build\\TTS\\tts\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\tts\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\utils\\audio\n",
      "copying temp_build\\TTS\\utils\\audio\\numpy_transforms.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\\audio\n",
      "copying temp_build\\TTS\\utils\\audio\\processor.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\\audio\n",
      "copying temp_build\\TTS\\utils\\audio\\torch_transforms.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\\audio\n",
      "copying temp_build\\TTS\\utils\\audio\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\\audio\n",
      "copying temp_build\\TTS\\utils\\callbacks.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\capacitron_optimizer.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\distribute.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\download.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\downloaders.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\generic_utils.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\io.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\manage.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\radam.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\samplers.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\synthesizer.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\training.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\vad.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "copying temp_build\\TTS\\utils\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\utils\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vc\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vc\\configs\n",
      "copying temp_build\\TTS\\vc\\configs\\freevc_config.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\configs\n",
      "copying temp_build\\TTS\\vc\\configs\\shared_configs.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\configs\n",
      "copying temp_build\\TTS\\vc\\configs\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\configs\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vc\\models\n",
      "copying temp_build\\TTS\\vc\\models\\base_vc.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\models\n",
      "copying temp_build\\TTS\\vc\\models\\freevc.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\models\n",
      "copying temp_build\\TTS\\vc\\models\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\models\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\commons.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\mel_processing.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\modules.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\speaker_encoder\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\speaker_encoder\\audio.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\speaker_encoder\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\speaker_encoder\\hparams.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\speaker_encoder\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\speaker_encoder\\speaker_encoder.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\speaker_encoder\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\speaker_encoder\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\speaker_encoder\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\wavlm\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\wavlm\\config.json -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\wavlm\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\wavlm\\modules.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\wavlm\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\wavlm\\wavlm.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\wavlm\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\wavlm\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\wavlm\n",
      "copying temp_build\\TTS\\vc\\modules\\freevc\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\n",
      "copying temp_build\\TTS\\vc\\modules\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\n",
      "copying temp_build\\TTS\\VERSION -> build\\bdist.win-amd64\\egg\\TTS\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vocoder\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\fullband_melgan_config.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\hifigan_config.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\melgan_config.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\multiband_melgan_config.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\parallel_wavegan_config.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\shared_configs.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\univnet_config.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\wavegrad_config.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\wavernn_config.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "copying temp_build\\TTS\\vocoder\\configs\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\n",
      "copying temp_build\\TTS\\vocoder\\datasets\\gan_dataset.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\n",
      "copying temp_build\\TTS\\vocoder\\datasets\\preprocess.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\n",
      "copying temp_build\\TTS\\vocoder\\datasets\\wavegrad_dataset.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\n",
      "copying temp_build\\TTS\\vocoder\\datasets\\wavernn_dataset.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\n",
      "copying temp_build\\TTS\\vocoder\\datasets\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "copying temp_build\\TTS\\vocoder\\layers\\hifigan.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "copying temp_build\\TTS\\vocoder\\layers\\losses.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "copying temp_build\\TTS\\vocoder\\layers\\lvc_block.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "copying temp_build\\TTS\\vocoder\\layers\\melgan.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "copying temp_build\\TTS\\vocoder\\layers\\parallel_wavegan.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "copying temp_build\\TTS\\vocoder\\layers\\pqmf.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "copying temp_build\\TTS\\vocoder\\layers\\upsample.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "copying temp_build\\TTS\\vocoder\\layers\\wavegrad.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "copying temp_build\\TTS\\vocoder\\layers\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\base_vocoder.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\fullband_melgan_generator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\gan.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\hifigan_discriminator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\hifigan_generator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\melgan_discriminator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\melgan_generator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\melgan_multiscale_discriminator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\multiband_melgan_generator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\parallel_wavegan_discriminator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\parallel_wavegan_generator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\random_window_discriminator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\univnet_discriminator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\univnet_generator.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\wavegrad.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\wavernn.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\models\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\n",
      "copying temp_build\\TTS\\vocoder\\README.md -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\n",
      "creating build\\bdist.win-amd64\\egg\\TTS\\vocoder\\utils\n",
      "copying temp_build\\TTS\\vocoder\\utils\\distribution.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\utils\n",
      "copying temp_build\\TTS\\vocoder\\utils\\generic_utils.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\utils\n",
      "copying temp_build\\TTS\\vocoder\\utils\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\\utils\n",
      "copying temp_build\\TTS\\vocoder\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\\vocoder\n",
      "copying temp_build\\TTS\\__init__.py -> build\\bdist.win-amd64\\egg\\TTS\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\api.py to api.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\collect_env_info.py to collect_env_info.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\compute_attention_masks.py to compute_attention_masks.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\compute_embeddings.py to compute_embeddings.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\compute_statistics.py to compute_statistics.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\eval_encoder.py to eval_encoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\extract_tts_spectrograms.py to extract_tts_spectrograms.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\find_unique_chars.py to find_unique_chars.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\find_unique_phonemes.py to find_unique_phonemes.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\remove_silence_using_vad.py to remove_silence_using_vad.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\resample.py to resample.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\synthesize.py to synthesize.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\train_encoder.py to train_encoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\train_tts.py to train_tts.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\train_vocoder.py to train_vocoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\tune_wavegrad.py to tune_wavegrad.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\bin\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\config\\shared_configs.py to shared_configs.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\config\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\demos\\xtts_ft_demo\\utils\\formatter.py to formatter.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\demos\\xtts_ft_demo\\utils\\gpt_train.py to gpt_train.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\demos\\xtts_ft_demo\\xtts_demo.py to xtts_demo.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\configs\\base_encoder_config.py to base_encoder_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\configs\\emotion_encoder_config.py to emotion_encoder_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\configs\\speaker_encoder_config.py to speaker_encoder_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\dataset.py to dataset.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\losses.py to losses.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\models\\base_encoder.py to base_encoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\models\\lstm.py to lstm.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\models\\resnet.py to resnet.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\\generic_utils.py to generic_utils.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\\prepare_voxceleb.py to prepare_voxceleb.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\\training.py to training.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\\visual.py to visual.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\utils\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\encoder\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\model.py to model.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\server\\server.py to server.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\server\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\align_tts_config.py to align_tts_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\bark_config.py to bark_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\delightful_tts_config.py to delightful_tts_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\fastspeech2_config.py to fastspeech2_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\fast_pitch_config.py to fast_pitch_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\fast_speech_config.py to fast_speech_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\glow_tts_config.py to glow_tts_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\neuralhmm_tts_config.py to neuralhmm_tts_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\overflow_config.py to overflow_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\shared_configs.py to shared_configs.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\speedy_speech_config.py to speedy_speech_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\tacotron2_config.py to tacotron2_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\tacotron_config.py to tacotron_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\tortoise_config.py to tortoise_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\vits_config.py to vits_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\xtts_config.py to xtts_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\configs\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\datasets\\dataset.py to dataset.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\datasets\\formatters.py to formatters.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\datasets\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\align_tts\\duration_predictor.py to duration_predictor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\align_tts\\mdn.py to mdn.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\align_tts\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\hubert\\hubert_manager.py to hubert_manager.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\hubert\\kmeans_hubert.py to kmeans_hubert.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\hubert\\tokenizer.py to tokenizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\hubert\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\inference_funcs.py to inference_funcs.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\load_model.py to load_model.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\model.py to model.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\model_fine.py to model_fine.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\bark\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\acoustic_model.py to acoustic_model.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\conformer.py to conformer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\conv_layers.py to conv_layers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\encoders.py to encoders.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\energy_adaptor.py to energy_adaptor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\kernel_predictor.py to kernel_predictor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\networks.py to networks.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\phoneme_prosody_predictor.py to phoneme_prosody_predictor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\pitch_adaptor.py to pitch_adaptor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\variance_predictor.py to variance_predictor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\delightful_tts\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\feed_forward\\decoder.py to decoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\feed_forward\\duration_predictor.py to duration_predictor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\feed_forward\\encoder.py to encoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\feed_forward\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\\aligner.py to aligner.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\\gated_conv.py to gated_conv.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\\normalization.py to normalization.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\\pos_encoding.py to pos_encoding.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\\res_conv_bn.py to res_conv_bn.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\\time_depth_sep_conv.py to time_depth_sep_conv.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\\transformer.py to transformer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\\wavenet.py to wavenet.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\generic\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\\decoder.py to decoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\\duration_predictor.py to duration_predictor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\\encoder.py to encoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\\glow.py to glow.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\\transformer.py to transformer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\glow_tts\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\losses.py to losses.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\\common_layers.py to common_layers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\\decoder.py to decoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\\neural_hmm.py to neural_hmm.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\\plotting_utils.py to plotting_utils.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\overflow\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\\attentions.py to attentions.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\\capacitron_layers.py to capacitron_layers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\\common_layers.py to common_layers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\\gst_layers.py to gst_layers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\\tacotron.py to tacotron.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\\tacotron2.py to tacotron2.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tacotron\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\arch_utils.py to arch_utils.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\audio_utils.py to audio_utils.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\autoregressive.py to autoregressive.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\classifier.py to classifier.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\clvp.py to clvp.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\diffusion.py to diffusion.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\diffusion_decoder.py to diffusion_decoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\dpm_solver.py to dpm_solver.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\random_latent_generator.py to random_latent_generator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\tokenizer.py to tokenizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\transformer.py to transformer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\utils.py to utils.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\vocoder.py to vocoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\wav2vec_alignment.py to wav2vec_alignment.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\tortoise\\xtransformers.py to xtransformers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\vits\\discriminator.py to discriminator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\vits\\networks.py to networks.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\vits\\stochastic_duration_predictor.py to stochastic_duration_predictor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\vits\\transforms.py to transforms.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\dvae.py to dvae.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\gpt.py to gpt.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\gpt_inference.py to gpt_inference.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\hifigan_decoder.py to hifigan_decoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\latent_encoder.py to latent_encoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\perceiver_encoder.py to perceiver_encoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\stream_generator.py to stream_generator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\tokenizer.py to tokenizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\trainer\\dataset.py to dataset.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\trainer\\gpt_trainer.py to gpt_trainer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\xtts_manager.py to xtts_manager.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\xtts\\zh_num2words.py to zh_num2words.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\layers\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\align_tts.py to align_tts.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\bark.py to bark.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\base_tacotron.py to base_tacotron.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\base_tts.py to base_tts.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\delightful_tts.py to delightful_tts.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\forward_tts.py to forward_tts.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\glow_tts.py to glow_tts.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\neuralhmm_tts.py to neuralhmm_tts.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\overflow.py to overflow.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\tacotron.py to tacotron.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\tacotron2.py to tacotron2.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\tortoise.py to tortoise.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\vits.py to vits.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\xtts.py to xtts.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\models\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\data.py to data.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\fairseq.py to fairseq.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\helpers.py to helpers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\languages.py to languages.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\managers.py to managers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\measures.py to measures.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\monotonic_align\\setup.py to setup.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\monotonic_align\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\speakers.py to speakers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\ssim.py to ssim.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\synthesis.py to synthesis.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\bangla\\phonemizer.py to phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\bangla\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\belarusian\\phonemizer.py to phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\belarusian\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\characters.py to characters.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\chinese_mandarin\\numbers.py to numbers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\chinese_mandarin\\phonemizer.py to phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\chinese_mandarin\\pinyinToPhonemes.py to pinyinToPhonemes.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\chinese_mandarin\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\cleaners.py to cleaners.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\cmudict.py to cmudict.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\english\\abbreviations.py to abbreviations.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\english\\number_norm.py to number_norm.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\english\\time_norm.py to time_norm.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\english\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\french\\abbreviations.py to abbreviations.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\french\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\japanese\\phonemizer.py to phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\japanese\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\korean\\korean.py to korean.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\korean\\ko_dictionary.py to ko_dictionary.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\korean\\phonemizer.py to phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\korean\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\bangla_phonemizer.py to bangla_phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\base.py to base.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\belarusian_phonemizer.py to belarusian_phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\espeak_wrapper.py to espeak_wrapper.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\gruut_wrapper.py to gruut_wrapper.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\ja_jp_phonemizer.py to ja_jp_phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\ko_kr_phonemizer.py to ko_kr_phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\multi_phonemizer.py to multi_phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\zh_cn_phonemizer.py to zh_cn_phonemizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\phonemizers\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\punctuation.py to punctuation.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\tokenizer.py to tokenizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\text\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\visual.py to visual.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\utils\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\tts\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\audio\\numpy_transforms.py to numpy_transforms.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\audio\\processor.py to processor.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\audio\\torch_transforms.py to torch_transforms.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\audio\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\callbacks.py to callbacks.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\capacitron_optimizer.py to capacitron_optimizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\distribute.py to distribute.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\download.py to download.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\downloaders.py to downloaders.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\generic_utils.py to generic_utils.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\io.py to io.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\manage.py to manage.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\radam.py to radam.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\samplers.py to samplers.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\synthesizer.py to synthesizer.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\training.py to training.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\vad.py to vad.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\utils\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\configs\\freevc_config.py to freevc_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\configs\\shared_configs.py to shared_configs.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\configs\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\models\\base_vc.py to base_vc.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\models\\freevc.py to freevc.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\models\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\commons.py to commons.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\mel_processing.py to mel_processing.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\modules.py to modules.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\speaker_encoder\\audio.py to audio.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\speaker_encoder\\hparams.py to hparams.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\speaker_encoder\\speaker_encoder.py to speaker_encoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\speaker_encoder\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\wavlm\\modules.py to modules.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\wavlm\\wavlm.py to wavlm.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\wavlm\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\freevc\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vc\\modules\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\fullband_melgan_config.py to fullband_melgan_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\hifigan_config.py to hifigan_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\melgan_config.py to melgan_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\multiband_melgan_config.py to multiband_melgan_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\parallel_wavegan_config.py to parallel_wavegan_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\shared_configs.py to shared_configs.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\univnet_config.py to univnet_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\wavegrad_config.py to wavegrad_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\wavernn_config.py to wavernn_config.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\configs\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\\gan_dataset.py to gan_dataset.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\\preprocess.py to preprocess.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\\wavegrad_dataset.py to wavegrad_dataset.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\\wavernn_dataset.py to wavernn_dataset.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\datasets\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\\hifigan.py to hifigan.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\\losses.py to losses.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\\lvc_block.py to lvc_block.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\\melgan.py to melgan.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\\parallel_wavegan.py to parallel_wavegan.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\\pqmf.py to pqmf.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\\upsample.py to upsample.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\\wavegrad.py to wavegrad.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\layers\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\base_vocoder.py to base_vocoder.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\fullband_melgan_generator.py to fullband_melgan_generator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\gan.py to gan.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\hifigan_discriminator.py to hifigan_discriminator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\hifigan_generator.py to hifigan_generator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\melgan_discriminator.py to melgan_discriminator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\melgan_generator.py to melgan_generator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\melgan_multiscale_discriminator.py to melgan_multiscale_discriminator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\multiband_melgan_generator.py to multiband_melgan_generator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\parallel_wavegan_discriminator.py to parallel_wavegan_discriminator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\parallel_wavegan_generator.py to parallel_wavegan_generator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\random_window_discriminator.py to random_window_discriminator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\univnet_discriminator.py to univnet_discriminator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\univnet_generator.py to univnet_generator.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\wavegrad.py to wavegrad.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\wavernn.py to wavernn.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\models\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\utils\\distribution.py to distribution.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\utils\\generic_utils.py to generic_utils.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\utils\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\vocoder\\__init__.py to __init__.cpython-310.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\TTS\\__init__.py to __init__.cpython-310.pyc\n",
      "creating build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying TTS.egg-info\\PKG-INFO -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying TTS.egg-info\\SOURCES.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying TTS.egg-info\\dependency_links.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying TTS.egg-info\\entry_points.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying TTS.egg-info\\not-zip-safe -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying TTS.egg-info\\requires.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying TTS.egg-info\\top_level.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "creating dist\n",
      "creating 'dist\\TTS-0.22.0-py3.10-win-amd64.egg' and adding 'build\\bdist.win-amd64\\egg' to it\n",
      "removing 'build\\bdist.win-amd64\\egg' (and everything under it)\n",
      "Processing TTS-0.22.0-py3.10-win-amd64.egg\n",
      "creating c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\TTS-0.22.0-py3.10-win-amd64.egg\n",
      "Extracting TTS-0.22.0-py3.10-win-amd64.egg to c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Adding TTS 0.22.0 to easy-install.pth file\n",
      "Installing tts-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing tts.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing tts-server-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing tts-server.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Installed c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\tts-0.22.0-py3.10-win-amd64.egg\n",
      "Processing dependencies for TTS==0.22.0\n",
      "Searching for numba==0.58.1\n",
      "Best match: numba 0.58.1\n",
      "Adding numba 0.58.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for numpy==1.22.0\n",
      "Best match: numpy 1.22.0\n",
      "Adding numpy 1.22.0 to easy-install.pth file\n",
      "Installing f2py-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing f2py.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for spacy==3.7.2\n",
      "Best match: spacy 3.7.2\n",
      "Adding spacy 3.7.2 to easy-install.pth file\n",
      "Installing spacy-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing spacy.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for num2words==0.5.13\n",
      "Best match: num2words 0.5.13\n",
      "Adding num2words 0.5.13 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for Unidecode==1.3.7\n",
      "Best match: Unidecode 1.3.7\n",
      "Adding Unidecode 1.3.7 to easy-install.pth file\n",
      "Installing unidecode-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing unidecode.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for encodec==0.1.1\n",
      "Best match: encodec 0.1.1\n",
      "Adding encodec 0.1.1 to easy-install.pth file\n",
      "Installing encodec-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing encodec.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for transformers==4.36.2\n",
      "Best match: transformers 4.36.2\n",
      "Adding transformers 4.36.2 to easy-install.pth file\n",
      "Installing transformers-cli-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing transformers-cli.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for einops==0.7.0\n",
      "Best match: einops 0.7.0\n",
      "Adding einops 0.7.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for bnunicodenormalizer==0.1.6\n",
      "Best match: bnunicodenormalizer 0.1.6\n",
      "Adding bnunicodenormalizer 0.1.6 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for bnnumerizer==0.0.2\n",
      "Best match: bnnumerizer 0.0.2\n",
      "Adding bnnumerizer 0.0.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for bangla==0.0.2\n",
      "Best match: bangla 0.0.2\n",
      "Adding bangla 0.0.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for g2pkk==0.1.2\n",
      "Best match: g2pkk 0.1.2\n",
      "Adding g2pkk 0.1.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for nltk==3.8.1\n",
      "Best match: nltk 3.8.1\n",
      "Adding nltk 3.8.1 to easy-install.pth file\n",
      "Installing nltk-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing nltk.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for jamo==0.4.1\n",
      "Best match: jamo 0.4.1\n",
      "Adding jamo 0.4.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for gruut==2.2.3\n",
      "Best match: gruut 2.2.3\n",
      "Adding gruut 2.2.3 to easy-install.pth file\n",
      "Installing gruut-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing gruut.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for hangul-romanize==0.1.0\n",
      "Best match: hangul-romanize 0.1.0\n",
      "Adding hangul-romanize 0.1.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pypinyin==0.50.0\n",
      "Best match: pypinyin 0.50.0\n",
      "Adding pypinyin 0.50.0 to easy-install.pth file\n",
      "Installing pypinyin-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pypinyin.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for jieba==0.42.1\n",
      "Best match: jieba 0.42.1\n",
      "Adding jieba 0.42.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for coqpit==0.0.17\n",
      "Best match: coqpit 0.0.17\n",
      "Adding coqpit 0.0.17 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for trainer==0.0.36\n",
      "Best match: trainer 0.0.36\n",
      "Adding trainer 0.0.36 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for matplotlib==3.8.2\n",
      "Best match: matplotlib 3.8.2\n",
      "Adding matplotlib 3.8.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pandas==1.5.3\n",
      "Best match: pandas 1.5.3\n",
      "Adding pandas 1.5.3 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for umap-learn==0.5.5\n",
      "Best match: umap-learn 0.5.5\n",
      "Adding umap-learn 0.5.5 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pysbd==0.3.4\n",
      "Best match: pysbd 0.3.4\n",
      "Adding pysbd 0.3.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for flask==3.0.0\n",
      "Best match: flask 3.0.0\n",
      "Adding flask 3.0.0 to easy-install.pth file\n",
      "Installing flask-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing flask.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for mutagen==1.47.0\n",
      "Best match: mutagen 1.47.0\n",
      "Adding mutagen 1.47.0 to easy-install.pth file\n",
      "Installing mid3cp-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing mid3cp.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing mid3iconv-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing mid3iconv.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing mid3v2-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing mid3v2.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing moggsplit-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing moggsplit.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing mutagen-inspect-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing mutagen-inspect.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing mutagen-pony-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing mutagen-pony.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for packaging==23.2\n",
      "Best match: packaging 23.2\n",
      "Adding packaging 23.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for aiohttp==3.9.1\n",
      "Best match: aiohttp 3.9.1\n",
      "Adding aiohttp 3.9.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for fsspec==2023.12.2\n",
      "Best match: fsspec 2023.12.2\n",
      "Adding fsspec 2023.12.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for PyYAML==6.0.1\n",
      "Best match: PyYAML 6.0.1\n",
      "Adding PyYAML 6.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for anyascii==0.3.2\n",
      "Best match: anyascii 0.3.2\n",
      "Adding anyascii 0.3.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for tqdm==4.66.1\n",
      "Best match: tqdm 4.66.1\n",
      "Adding tqdm 4.66.1 to easy-install.pth file\n",
      "Installing tqdm-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing tqdm.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for inflect==7.0.0\n",
      "Best match: inflect 7.0.0\n",
      "Adding inflect 7.0.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for scikit-learn==1.3.2\n",
      "Best match: scikit-learn 1.3.2\n",
      "Adding scikit-learn 1.3.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for librosa==0.10.0\n",
      "Best match: librosa 0.10.0\n",
      "Adding librosa 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for soundfile==0.12.1\n",
      "Best match: soundfile 0.12.1\n",
      "Adding soundfile 0.12.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for torchaudio==2.1.0+cu118\n",
      "Best match: torchaudio 2.1.0+cu118\n",
      "Adding torchaudio 2.1.0+cu118 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for torch==2.1.0+cu118\n",
      "Best match: torch 2.1.0+cu118\n",
      "Adding torch 2.1.0+cu118 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing convert-caffe2-to-onnx.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing convert-onnx-to-caffe2-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing convert-onnx-to-caffe2.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing torchrun-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing torchrun.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for scipy==1.11.4\n",
      "Best match: scipy 1.11.4\n",
      "Adding scipy 1.11.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for Cython==3.0.7\n",
      "Best match: Cython 3.0.7\n",
      "Adding Cython 3.0.7 to easy-install.pth file\n",
      "Installing cygdb-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing cygdb.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing cython-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing cython.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing cythonize-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing cythonize.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for llvmlite==0.41.1\n",
      "Best match: llvmlite 0.41.1\n",
      "Adding llvmlite 0.41.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for SudachiDict-core==20230927\n",
      "Best match: SudachiDict-core 20230927\n",
      "Adding SudachiDict-core 20230927 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for SudachiPy==0.6.8\n",
      "Best match: SudachiPy 0.6.8\n",
      "Adding SudachiPy 0.6.8 to easy-install.pth file\n",
      "Installing sudachipy-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing sudachipy.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for langcodes==3.3.0\n",
      "Best match: langcodes 3.3.0\n",
      "Adding langcodes 3.3.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for setuptools==65.5.0\n",
      "Best match: setuptools 65.5.0\n",
      "Adding setuptools 65.5.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for Jinja2==3.1.2\n",
      "Best match: Jinja2 3.1.2\n",
      "Adding Jinja2 3.1.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pydantic==2.5.3\n",
      "Best match: pydantic 2.5.3\n",
      "Adding pydantic 2.5.3 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for requests==2.28.1\n",
      "Best match: requests 2.28.1\n",
      "Adding requests 2.28.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for smart-open==6.4.0\n",
      "Best match: smart-open 6.4.0\n",
      "Adding smart-open 6.4.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for typer==0.9.0\n",
      "Best match: typer 0.9.0\n",
      "Adding typer 0.9.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for weasel==0.3.4\n",
      "Best match: weasel 0.3.4\n",
      "Adding weasel 0.3.4 to easy-install.pth file\n",
      "Installing weasel-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing weasel.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for catalogue==2.0.10\n",
      "Best match: catalogue 2.0.10\n",
      "Adding catalogue 2.0.10 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for srsly==2.4.8\n",
      "Best match: srsly 2.4.8\n",
      "Adding srsly 2.4.8 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for wasabi==1.1.2\n",
      "Best match: wasabi 1.1.2\n",
      "Adding wasabi 1.1.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for thinc==8.2.2\n",
      "Best match: thinc 8.2.2\n",
      "Adding thinc 8.2.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for preshed==3.0.9\n",
      "Best match: preshed 3.0.9\n",
      "Adding preshed 3.0.9 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for cymem==2.0.8\n",
      "Best match: cymem 2.0.8\n",
      "Adding cymem 2.0.8 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for murmurhash==1.0.10\n",
      "Best match: murmurhash 1.0.10\n",
      "Adding murmurhash 1.0.10 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for spacy-loggers==1.0.5\n",
      "Best match: spacy-loggers 1.0.5\n",
      "Adding spacy-loggers 1.0.5 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for spacy-legacy==3.0.12\n",
      "Best match: spacy-legacy 3.0.12\n",
      "Adding spacy-legacy 3.0.12 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for docopt==0.6.2\n",
      "Best match: docopt 0.6.2\n",
      "Adding docopt 0.6.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for safetensors==0.4.1\n",
      "Best match: safetensors 0.4.1\n",
      "Adding safetensors 0.4.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for tokenizers==0.15.0\n",
      "Best match: tokenizers 0.15.0\n",
      "Adding tokenizers 0.15.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for regex==2023.12.25\n",
      "Best match: regex 2023.12.25\n",
      "Adding regex 2023.12.25 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for huggingface-hub==0.20.2\n",
      "Best match: huggingface-hub 0.20.2\n",
      "Adding huggingface-hub 0.20.2 to easy-install.pth file\n",
      "Installing huggingface-cli-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing huggingface-cli.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for filelock==3.9.0\n",
      "Best match: filelock 3.9.0\n",
      "Adding filelock 3.9.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for joblib==1.3.2\n",
      "Best match: joblib 1.3.2\n",
      "Adding joblib 1.3.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for click==8.1.7\n",
      "Best match: click 8.1.7\n",
      "Adding click 8.1.7 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for gruut-lang-es==2.0.0\n",
      "Best match: gruut-lang-es 2.0.0\n",
      "Adding gruut-lang-es 2.0.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for gruut-lang-fr==2.0.2\n",
      "Best match: gruut-lang-fr 2.0.2\n",
      "Adding gruut-lang-fr 2.0.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for gruut-lang-de==2.0.0\n",
      "Best match: gruut-lang-de 2.0.0\n",
      "Adding gruut-lang-de 2.0.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for python-crfsuite==0.9.10\n",
      "Best match: python-crfsuite 0.9.10\n",
      "Adding python-crfsuite 0.9.10 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for networkx==2.8.8\n",
      "Best match: networkx 2.8.8\n",
      "Adding networkx 2.8.8 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for jsonlines==1.2.0\n",
      "Best match: jsonlines 1.2.0\n",
      "Adding jsonlines 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for gruut-lang-en==2.0.0\n",
      "Best match: gruut-lang-en 2.0.0\n",
      "Adding gruut-lang-en 2.0.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for gruut-ipa==0.13.0\n",
      "Best match: gruut-ipa 0.13.0\n",
      "Adding gruut-ipa 0.13.0 to easy-install.pth file\n",
      "Installing gruut-ipa-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing gruut-ipa.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for dateparser==1.1.8\n",
      "Best match: dateparser 1.1.8\n",
      "Adding dateparser 1.1.8 to easy-install.pth file\n",
      "Installing dateparser-download-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing dateparser-download.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for Babel==2.14.0\n",
      "Best match: Babel 2.14.0\n",
      "Adding Babel 2.14.0 to easy-install.pth file\n",
      "Installing pybabel-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pybabel.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for tensorboard==2.15.1\n",
      "Best match: tensorboard 2.15.1\n",
      "Adding tensorboard 2.15.1 to easy-install.pth file\n",
      "Installing tensorboard-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing tensorboard.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for psutil==5.9.7\n",
      "Best match: psutil 5.9.7\n",
      "Adding psutil 5.9.7 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\roaming\\python\\python310\\site-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\roaming\\python\\python310\\site-packages\n",
      "Searching for pyparsing==3.1.1\n",
      "Best match: pyparsing 3.1.1\n",
      "Adding pyparsing 3.1.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for Pillow==9.3.0\n",
      "Best match: Pillow 9.3.0\n",
      "Adding Pillow 9.3.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for kiwisolver==1.4.5\n",
      "Best match: kiwisolver 1.4.5\n",
      "Adding kiwisolver 1.4.5 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for fonttools==4.47.0\n",
      "Best match: fonttools 4.47.0\n",
      "Adding fonttools 4.47.0 to easy-install.pth file\n",
      "Installing fonttools-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing fonttools.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyftmerge-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyftmerge.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyftsubset-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyftsubset.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing ttx-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing ttx.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for cycler==0.12.1\n",
      "Best match: cycler 0.12.1\n",
      "Adding cycler 0.12.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for contourpy==1.2.0\n",
      "Best match: contourpy 1.2.0\n",
      "Adding contourpy 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pytz==2023.3.post1\n",
      "Best match: pytz 2023.3.post1\n",
      "Adding pytz 2023.3.post1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pynndescent==0.5.11\n",
      "Best match: pynndescent 0.5.11\n",
      "Adding pynndescent 0.5.11 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for blinker==1.7.0\n",
      "Best match: blinker 1.7.0\n",
      "Adding blinker 1.7.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for itsdangerous==2.1.2\n",
      "Best match: itsdangerous 2.1.2\n",
      "Adding itsdangerous 2.1.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for werkzeug==3.0.1\n",
      "Best match: werkzeug 3.0.1\n",
      "Adding werkzeug 3.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for async-timeout==4.0.3\n",
      "Best match: async-timeout 4.0.3\n",
      "Adding async-timeout 4.0.3 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for aiosignal==1.3.1\n",
      "Best match: aiosignal 1.3.1\n",
      "Adding aiosignal 1.3.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for frozenlist==1.4.1\n",
      "Best match: frozenlist 1.4.1\n",
      "Adding frozenlist 1.4.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for yarl==1.9.4\n",
      "Best match: yarl 1.9.4\n",
      "Adding yarl 1.9.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for multidict==6.0.4\n",
      "Best match: multidict 6.0.4\n",
      "Adding multidict 6.0.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for attrs==23.2.0\n",
      "Best match: attrs 23.2.0\n",
      "Adding attrs 23.2.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for colorama==0.4.6\n",
      "Best match: colorama 0.4.6\n",
      "Adding colorama 0.4.6 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\roaming\\python\\python310\\site-packages\n",
      "Searching for typing-extensions==4.9.0\n",
      "Best match: typing-extensions 4.9.0\n",
      "Adding typing-extensions 4.9.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for threadpoolctl==3.2.0\n",
      "Best match: threadpoolctl 3.2.0\n",
      "Adding threadpoolctl 3.2.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for msgpack==1.0.7\n",
      "Best match: msgpack 1.0.7\n",
      "Adding msgpack 1.0.7 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for lazy-loader==0.3\n",
      "Best match: lazy-loader 0.3\n",
      "Adding lazy-loader 0.3 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for soxr==0.3.7\n",
      "Best match: soxr 0.3.7\n",
      "Adding soxr 0.3.7 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pooch==1.8.0\n",
      "Best match: pooch 1.8.0\n",
      "Adding pooch 1.8.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for decorator==5.1.1\n",
      "Best match: decorator 5.1.1\n",
      "Adding decorator 5.1.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\roaming\\python\\python310\\site-packages\n",
      "Searching for audioread==3.0.1\n",
      "Best match: audioread 3.0.1\n",
      "Adding audioread 3.0.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for cffi==1.16.0\n",
      "Best match: cffi 1.16.0\n",
      "Adding cffi 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for sympy==1.12\n",
      "Best match: sympy 1.12\n",
      "Adding sympy 1.12 to easy-install.pth file\n",
      "Installing isympy-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing isympy.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for MarkupSafe==2.1.2\n",
      "Best match: MarkupSafe 2.1.2\n",
      "Adding MarkupSafe 2.1.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pydantic-core==2.14.6\n",
      "Best match: pydantic-core 2.14.6\n",
      "Adding pydantic-core 2.14.6 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for annotated-types==0.6.0\n",
      "Best match: annotated-types 0.6.0\n",
      "Adding annotated-types 0.6.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for certifi==2022.12.7\n",
      "Best match: certifi 2022.12.7\n",
      "Adding certifi 2022.12.7 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for urllib3==1.26.13\n",
      "Best match: urllib3 1.26.13\n",
      "Adding urllib3 1.26.13 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for idna==3.4\n",
      "Best match: idna 3.4\n",
      "Adding idna 3.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for charset-normalizer==2.1.1\n",
      "Best match: charset-normalizer 2.1.1\n",
      "Adding charset-normalizer 2.1.1 to easy-install.pth file\n",
      "Installing normalizer-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing normalizer.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for cloudpathlib==0.16.0\n",
      "Best match: cloudpathlib 0.16.0\n",
      "Adding cloudpathlib 0.16.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for confection==0.1.4\n",
      "Best match: confection 0.1.4\n",
      "Adding confection 0.1.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for blis==0.7.11\n",
      "Best match: blis 0.7.11\n",
      "Adding blis 0.7.11 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\roaming\\python\\python310\\site-packages\n",
      "Searching for tzlocal==5.2\n",
      "Best match: tzlocal 5.2\n",
      "Adding tzlocal 5.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for tensorboard-data-server==0.7.2\n",
      "Best match: tensorboard-data-server 0.7.2\n",
      "Adding tensorboard-data-server 0.7.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for protobuf==4.23.4\n",
      "Best match: protobuf 4.23.4\n",
      "Adding protobuf 4.23.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for Markdown==3.5.1\n",
      "Best match: Markdown 3.5.1\n",
      "Adding Markdown 3.5.1 to easy-install.pth file\n",
      "Installing markdown_py-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing markdown_py.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for google-auth-oauthlib==1.2.0\n",
      "Best match: google-auth-oauthlib 1.2.0\n",
      "Adding google-auth-oauthlib 1.2.0 to easy-install.pth file\n",
      "Installing google-oauthlib-tool-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing google-oauthlib-tool.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for google-auth==2.26.1\n",
      "Best match: google-auth 2.26.1\n",
      "Adding google-auth 2.26.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for grpcio==1.60.0\n",
      "Best match: grpcio 1.60.0\n",
      "Adding grpcio 1.60.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for absl-py==2.0.0\n",
      "Best match: absl-py 2.0.0\n",
      "Adding absl-py 2.0.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for platformdirs==4.1.0\n",
      "Best match: platformdirs 4.1.0\n",
      "Adding platformdirs 4.1.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\roaming\\python\\python310\\site-packages\n",
      "Searching for pycparser==2.21\n",
      "Best match: pycparser 2.21\n",
      "Adding pycparser 2.21 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for mpmath==1.3.0\n",
      "Best match: mpmath 1.3.0\n",
      "Adding mpmath 1.3.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for tzdata==2023.4\n",
      "Best match: tzdata 2023.4\n",
      "Adding tzdata 2023.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for requests-oauthlib==1.3.1\n",
      "Best match: requests-oauthlib 1.3.1\n",
      "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for rsa==4.9\n",
      "Best match: rsa 4.9\n",
      "Adding rsa 4.9 to easy-install.pth file\n",
      "Installing pyrsa-decrypt-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-decrypt.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-encrypt-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-encrypt.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-keygen-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-keygen.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-priv2pub-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-priv2pub.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-sign-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-sign.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-verify-script.py script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "Installing pyrsa-verify.exe script to c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pyasn1-modules==0.3.0\n",
      "Best match: pyasn1-modules 0.3.0\n",
      "Adding pyasn1-modules 0.3.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for cachetools==5.3.2\n",
      "Best match: cachetools 5.3.2\n",
      "Adding cachetools 5.3.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for oauthlib==3.2.2\n",
      "Best match: oauthlib 3.2.2\n",
      "Adding oauthlib 3.2.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Searching for pyasn1==0.5.1\n",
      "Best match: pyasn1 0.5.1\n",
      "Adding pyasn1 0.5.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\glsup\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Finished processing dependencies for TTS==0.22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "warning: no previously-included files matching '*' found under directory 'tests'\n",
      "no previously-included directories found matching 'tests*'\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.monotonic_align' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.monotonic_align' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.monotonic_align' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.monotonic_align' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.bin' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.bin' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.bin' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.bin' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.config' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.config' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.config' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.config' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.demos.xtts_ft_demo' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.demos.xtts_ft_demo' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.demos.xtts_ft_demo' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.demos.xtts_ft_demo' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.demos.xtts_ft_demo.utils' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.demos.xtts_ft_demo.utils' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.demos.xtts_ft_demo.utils' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.demos.xtts_ft_demo.utils' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.encoder' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.encoder' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.encoder' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.encoder' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.encoder.configs' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.encoder.configs' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.encoder.configs' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.encoder.configs' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.encoder.models' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.encoder.models' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.encoder.models' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.encoder.models' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.encoder.utils' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.encoder.utils' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.encoder.utils' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.encoder.utils' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.server' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.server' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.server' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.server' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.server.static' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.server.static' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.server.static' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.server.static' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.server.templates' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.server.templates' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.server.templates' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.server.templates' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.configs' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.configs' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.configs' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.configs' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.datasets' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.datasets' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.datasets' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.datasets' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.align_tts' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.align_tts' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.align_tts' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.align_tts' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.bark' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.bark' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.bark' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.bark' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.bark.hubert' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.bark.hubert' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.bark.hubert' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.bark.hubert' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.delightful_tts' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.delightful_tts' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.delightful_tts' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.delightful_tts' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.feed_forward' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.feed_forward' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.feed_forward' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.feed_forward' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.generic' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.generic' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.generic' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.generic' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.glow_tts' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.glow_tts' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.glow_tts' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.glow_tts' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.overflow' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.overflow' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.overflow' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.overflow' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.tacotron' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.tacotron' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.tacotron' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.tacotron' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.tortoise' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.tortoise' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.tortoise' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.tortoise' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.vits' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.vits' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.vits' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.vits' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.xtts' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.xtts' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.xtts' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.xtts' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.layers.xtts.trainer' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.layers.xtts.trainer' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.layers.xtts.trainer' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.layers.xtts.trainer' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.models' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.models' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.models' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.models' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.assets.tortoise' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.assets.tortoise' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.assets.tortoise' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.assets.tortoise' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.text' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.text' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.text' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.text' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.text.bangla' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.text.bangla' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.text.bangla' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.text.bangla' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.text.belarusian' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.text.belarusian' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.text.belarusian' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.text.belarusian' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.text.chinese_mandarin' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.text.chinese_mandarin' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.text.chinese_mandarin' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.text.chinese_mandarin' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.text.english' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.text.english' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.text.english' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.text.english' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.text.french' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.text.french' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.text.french' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.text.french' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.text.japanese' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.text.japanese' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.text.japanese' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.text.japanese' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.text.korean' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.text.korean' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.text.korean' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.text.korean' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.tts.utils.text.phonemizers' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.tts.utils.text.phonemizers' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.tts.utils.text.phonemizers' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.tts.utils.text.phonemizers' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.utils' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.utils' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.utils' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.utils' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.utils.audio' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.utils.audio' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.utils.audio' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.utils.audio' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vc.configs' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vc.configs' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vc.configs' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vc.configs' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vc.models' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vc.models' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vc.models' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vc.models' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vc.modules' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vc.modules' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vc.modules' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vc.modules' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vc.modules.freevc' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vc.modules.freevc' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vc.modules.freevc' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vc.modules.freevc' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vc.modules.freevc.speaker_encoder' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vc.modules.freevc.speaker_encoder' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vc.modules.freevc.speaker_encoder' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vc.modules.freevc.speaker_encoder' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vc.modules.freevc.wavlm' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vc.modules.freevc.wavlm' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vc.modules.freevc.wavlm' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vc.modules.freevc.wavlm' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vocoder' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vocoder' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vocoder' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vocoder' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vocoder.configs' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vocoder.configs' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vocoder.configs' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vocoder.configs' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vocoder.datasets' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vocoder.datasets' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vocoder.datasets' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vocoder.datasets' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vocoder.layers' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vocoder.layers' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vocoder.layers' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vocoder.layers' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vocoder.models' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vocoder.models' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vocoder.models' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vocoder.models' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'TTS.vocoder.utils' as data is deprecated, please list it in `packages`.\n",
      "    !!\n",
      "\n",
      "\n",
      "    ############################\n",
      "    # Package would be ignored #\n",
      "    ############################\n",
      "    Python recognizes 'TTS.vocoder.utils' as an importable package,\n",
      "    but it is not listed in the `packages` configuration of setuptools.\n",
      "\n",
      "    'TTS.vocoder.utils' has been automatically added to the distribution only\n",
      "    because it may contain data files, but this behavior is likely to change\n",
      "    in future versions of setuptools (and therefore is considered deprecated).\n",
      "\n",
      "    Please make sure that 'TTS.vocoder.utils' is included as a package by using\n",
      "    the `packages` configuration field or the proper discovery methods\n",
      "    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "    instead of `find_packages(...)`/`find:`).\n",
      "\n",
      "    You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "    documentation page.\n",
      "\n",
      "\n",
      "!!\n",
      "\n",
      "  check.warn(importable)\n"
     ]
    }
   ],
   "source": [
    "# Install coqui tts\n",
    "!python setup.py install "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f226c8-4e55-48fa-937b-8415d539b17c",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "\n",
    "output_path = \"tts_train_dir\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b7019-3685-4b48-8917-c152e288d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "# Downloading the LJSpeech Dataset.\n",
    "import wget\n",
    "wget.download(\"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\", out = output_path)\n",
    "\n",
    "# Extract the Dataset (Extract manually using zip tool if not working on windows)\n",
    "!tar -xf $output_path/LJSpeech-1.1.tar.bz2 -C $output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76cd3ab5-6387-45f1-b488-24734cc1beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset config\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"LJSpeech-1.1/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5876e46-2aee-4bcf-b6b3-9e3c535c553f",
   "metadata": {},
   "source": [
    "Create model training config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config for glowtts\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "config = GlowTTSConfig(\n",
    "    batch_size=32,\n",
    "    eval_batch_size=16,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=100,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=25,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    "    save_step=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ed377-80b7-447b-bd92-106bffa777ee",
   "metadata": {},
   "source": [
    "Initialize audio processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\version.py:1: UserWarning: Module TTS was already imported from c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tts-0.22.0-py3.10-win-amd64.egg\\TTS\\__init__.py, but c:\\users\\glsup\\documents\\iit\\year 4\\fyp\\applied ai\\tts is being added to sys.path\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "from TTS.utils.audio import AudioProcessor\n",
    "ap = AudioProcessor.init_from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d461683-b05e-403f-815f-8007bda08c38",
   "metadata": {},
   "source": [
    "Initialize the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014879b7-f18d-44c0-b24a-e10f8002113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978",
   "metadata": {},
   "source": [
    "Load data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 13100 files in C:\\Users\\glsup\\Documents\\IIT\\Year 4\\FYP\\Applied AI\\TTS\\tts_train_dir\\LJSpeech-1.1\n"
     ]
    }
   ],
   "source": [
    "from TTS.tts.datasets import load_tts_samples\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac2ffe3e-ad0c-443e-800c-9b076ee811b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 12\n",
      " | > Num. of Torch Threads: 6\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "c:\\Users\\glsup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      " > Model has 28610257 parameters\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer, TrainerArgs\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b320831-dd83-429b-bb6a-473f9d49d321",
   "metadata": {},
   "source": [
    "Start training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: gruut\n",
      "| > Number of instances : 12969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 01:39:22) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Preprocessing samples\n",
      " | > Max text length: 188\n",
      " | > Min text length: 13\n",
      " | > Avg text length: 100.90014650319993\n",
      " | \n",
      " | > Max audio length: 222620\n",
      " | > Min audio length: 24476\n",
      " | > Avg audio length: 144962.21921505127\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:39:44 -- STEP: 0/406 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.7063  (1.706313133239746)\n",
      "     | > loader_time: 20.0685  (20.06854772567749)\n",
      "\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:39:53 -- STEP: 25/406 -- GLOBAL_STEP: 25\u001b[0m\n",
      "     | > loss: 3.9118354320526123  (3.841178210576375)\n",
      "     | > log_mle: 0.779578447341919  (0.7795685410499573)\n",
      "     | > loss_dur: 3.1322569847106934  (3.061609633763631)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.0007, device='cuda:0')  (tensor(11.1073, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3693  (0.3467982578277588)\n",
      "     | > loader_time: 0.003  (9.198145236968992)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:40:01 -- STEP: 50/406 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss: 3.9634480476379395  (3.827264612913132)\n",
      "     | > log_mle: 0.7784169316291809  (0.7809873387217522)\n",
      "     | > loss_dur: 3.1850311756134033  (3.046277266740799)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.2375, device='cuda:0')  (tensor(11.6132, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3536  (0.3467531108856201)\n",
      "     | > loader_time: 0.002  (4.600353808403015)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:40:11 -- STEP: 75/406 -- GLOBAL_STEP: 75\u001b[0m\n",
      "     | > loss: 3.9140472412109375  (3.8302598329690785)\n",
      "     | > log_mle: 0.7881894111633301  (0.7814970337427579)\n",
      "     | > loss_dur: 3.1258578300476074  (3.04876279097337)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.0698, device='cuda:0')  (tensor(11.7582, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4036  (0.35609417597452797)\n",
      "     | > loader_time: 0.003  (3.06782333691915)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:40:21 -- STEP: 100/406 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss: 3.8513498306274414  (3.824010297987196)\n",
      "     | > log_mle: 0.7864689230918884  (0.7817505538463593)\n",
      "     | > loss_dur: 3.064880847930908  (3.0422597381803724)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.1002, device='cuda:0')  (tensor(11.8094, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4307  (0.3671830439567567)\n",
      "     | > loader_time: 0.003  (2.301618177890778)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:40:31 -- STEP: 125/406 -- GLOBAL_STEP: 125\u001b[0m\n",
      "     | > loss: 3.8304672241210938  (3.8191151307976763)\n",
      "     | > log_mle: 0.785863995552063  (0.7817945122718811)\n",
      "     | > loss_dur: 3.0446033477783203  (3.037320618007494)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.9714, device='cuda:0')  (tensor(11.8331, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3713  (0.37475086593627943)\n",
      "     | > loader_time: 0.003  (1.8419511241912847)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:40:42 -- STEP: 150/406 -- GLOBAL_STEP: 150\u001b[0m\n",
      "     | > loss: 3.7906622886657715  (3.818763657978603)\n",
      "     | > log_mle: 0.7851244211196899  (0.7818458846637181)\n",
      "     | > loss_dur: 3.005537986755371  (3.0369177750178746)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.8666, device='cuda:0')  (tensor(11.8510, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4144  (0.38119219144185396)\n",
      "     | > loader_time: 0.004  (1.5355197302500407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:40:53 -- STEP: 175/406 -- GLOBAL_STEP: 175\u001b[0m\n",
      "     | > loss: 3.777631998062134  (3.8172629471981163)\n",
      "     | > log_mle: 0.7820014953613281  (0.7818611426786943)\n",
      "     | > loss_dur: 2.9956305027008057  (3.035401808131825)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.8210, device='cuda:0')  (tensor(11.8570, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4869  (0.3904748235430036)\n",
      "     | > loader_time: 0.004  (1.316670612607684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:41:05 -- STEP: 200/406 -- GLOBAL_STEP: 200\u001b[0m\n",
      "     | > loss: 3.7388715744018555  (3.816825837838022)\n",
      "     | > log_mle: 0.7852517366409302  (0.7818981725918619)\n",
      "     | > loss_dur: 2.953619956970215  (3.0349276693243725)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.7038, device='cuda:0')  (tensor(11.8590, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4904  (0.4017201840877533)\n",
      "     | > loader_time: 0.004  (1.1525471949577342)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:41:17 -- STEP: 225/406 -- GLOBAL_STEP: 225\u001b[0m\n",
      "     | > loss: 3.779106378555298  (3.8131591852321183)\n",
      "     | > log_mle: 0.7791734337806702  (0.7820113428803377)\n",
      "     | > loss_dur: 2.9999330043792725  (3.0311478459557817)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.7433, device='cuda:0')  (tensor(11.8512, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.54  (0.40968333350287545)\n",
      "     | > loader_time: 0.004  (1.024957934485542)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:41:30 -- STEP: 250/406 -- GLOBAL_STEP: 250\u001b[0m\n",
      "     | > loss: 3.8285553455352783  (3.8122161279122033)\n",
      "     | > log_mle: 0.784152090549469  (0.7821138453980286)\n",
      "     | > loss_dur: 3.044403314590454  (3.0301022867361698)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.7590, device='cuda:0')  (tensor(11.8450, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5711  (0.41966307830810545)\n",
      "     | > loader_time: 0.004  (0.9228745098114018)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:41:44 -- STEP: 275/406 -- GLOBAL_STEP: 275\u001b[0m\n",
      "     | > loss: 3.7346982955932617  (3.8114386090692483)\n",
      "     | > log_mle: 0.7848270535469055  (0.7819334659936293)\n",
      "     | > loss_dur: 2.949871301651001  (3.0295051484737754)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.5171, device='cuda:0')  (tensor(11.8384, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6316  (0.4316424473849209)\n",
      "     | > loader_time: 0.004  (0.8394135752591224)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:41:58 -- STEP: 300/406 -- GLOBAL_STEP: 300\u001b[0m\n",
      "     | > loss: 3.806678295135498  (3.809217022205221)\n",
      "     | > log_mle: 0.7798191905021667  (0.7818332293937945)\n",
      "     | > loss_dur: 3.0268590450286865  (3.027383796099958)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.7276, device='cuda:0')  (tensor(11.8258, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5207  (0.44192441066106153)\n",
      "     | > loader_time: 0.005  (0.769849441846212)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:42:13 -- STEP: 325/406 -- GLOBAL_STEP: 325\u001b[0m\n",
      "     | > loss: 3.7413673400878906  (3.8067292599450973)\n",
      "     | > log_mle: 0.7805867195129395  (0.7817103321590121)\n",
      "     | > loss_dur: 2.960780620574951  (3.0250189327058337)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.5297, device='cuda:0')  (tensor(11.8108, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6667  (0.45377863590533907)\n",
      "     | > loader_time: 0.005  (0.7110023344480075)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:42:28 -- STEP: 350/406 -- GLOBAL_STEP: 350\u001b[0m\n",
      "     | > loss: 3.7097063064575195  (3.80615959518096)\n",
      "     | > log_mle: 0.7782691121101379  (0.7816388261668822)\n",
      "     | > loss_dur: 2.9314372539520264  (3.024520775149851)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.4129, device='cuda:0')  (tensor(11.7962, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5599  (0.4643630783898489)\n",
      "     | > loader_time: 0.005  (0.6605710451943533)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:42:45 -- STEP: 375/406 -- GLOBAL_STEP: 375\u001b[0m\n",
      "     | > loss: 3.76682448387146  (3.8027005241341785)\n",
      "     | > log_mle: 0.7766730785369873  (0.7814725007096383)\n",
      "     | > loss_dur: 2.9901514053344727  (3.0212280293033555)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.4302, device='cuda:0')  (tensor(11.7749, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.682  (0.47643790435791006)\n",
      "     | > loader_time: 0.005  (0.6168772729237875)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:43:02 -- STEP: 400/406 -- GLOBAL_STEP: 400\u001b[0m\n",
      "     | > loss: 3.7223567962646484  (3.7991073608398436)\n",
      "     | > log_mle: 0.7781663537025452  (0.7814073623755039)\n",
      "     | > loss_dur: 2.944190502166748  (3.017700003354978)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.3763, device='cuda:0')  (tensor(11.7511, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7761  (0.49024773657321924)\n",
      "     | > loader_time: 0.005  (0.5786397331953048)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: gruut\n",
      "| > Number of instances : 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Preprocessing samples\n",
      " | > Max text length: 174\n",
      " | > Min text length: 20\n",
      " | > Avg text length: 100.76335877862596\n",
      " | \n",
      " | > Max audio length: 222620\n",
      " | > Min audio length: 34717\n",
      " | > Avg audio length: 144011.33587786258\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.24084347486495972 \u001b[0m(+0)\n",
      "     | > avg_loss: 3.781411349773407 \u001b[0m(+0)\n",
      "     | > avg_log_mle: 0.7778171598911285 \u001b[0m(+0)\n",
      "     | > avg_loss_dur: 3.003594160079956 \u001b[0m(+0)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_406.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 01:43:36) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:43:58 -- STEP: 19/406 -- GLOBAL_STEP: 425\u001b[0m\n",
      "     | > loss: 3.723463773727417  (3.7838783264160156)\n",
      "     | > log_mle: 0.7775536179542542  (0.7732453158027247)\n",
      "     | > loss_dur: 2.9459102153778076  (3.010633016887464)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.1189, device='cuda:0')  (tensor(11.1388, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.2642  (0.29437247075532613)\n",
      "     | > loader_time: 0.004  (0.013011794341237922)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:44:06 -- STEP: 44/406 -- GLOBAL_STEP: 450\u001b[0m\n",
      "     | > loss: 3.6200356483459473  (3.737544596195221)\n",
      "     | > log_mle: 0.7791191935539246  (0.7753556397828189)\n",
      "     | > loss_dur: 2.840916395187378  (2.9621889807961206)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.9072, device='cuda:0')  (tensor(11.1145, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.2853  (0.2877012707970359)\n",
      "     | > loader_time: 0.003  (0.007006130435250022)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:44:14 -- STEP: 69/406 -- GLOBAL_STEP: 475\u001b[0m\n",
      "     | > loss: 3.809757709503174  (3.732268164123314)\n",
      "     | > log_mle: 0.7839795351028442  (0.7760398353355519)\n",
      "     | > loss_dur: 3.02577805519104  (2.9562283391537876)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.2909, device='cuda:0')  (tensor(11.1184, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3483  (0.2988625609356423)\n",
      "     | > loader_time: 0.003  (0.005483001902483512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:44:22 -- STEP: 94/406 -- GLOBAL_STEP: 500\u001b[0m\n",
      "     | > loss: 3.67201566696167  (3.7249560203958065)\n",
      "     | > log_mle: 0.7778162360191345  (0.7761221699258114)\n",
      "     | > loss_dur: 2.8941993713378906  (2.948833858713191)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.9278, device='cuda:0')  (tensor(11.1067, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3823  (0.30876928694704736)\n",
      "     | > loader_time: 0.004  (0.00484458182720428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:44:31 -- STEP: 119/406 -- GLOBAL_STEP: 525\u001b[0m\n",
      "     | > loss: 3.7082109451293945  (3.715789416257073)\n",
      "     | > log_mle: 0.7742558121681213  (0.7761934139147526)\n",
      "     | > loss_dur: 2.933955192565918  (2.939596005848476)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.9737, device='cuda:0')  (tensor(11.0770, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4494  (0.31854852107392634)\n",
      "     | > loader_time: 0.004  (0.00450813269414822)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:44:41 -- STEP: 144/406 -- GLOBAL_STEP: 550\u001b[0m\n",
      "     | > loss: 3.666247606277466  (3.7147666646374597)\n",
      "     | > log_mle: 0.776285707950592  (0.7761212868822945)\n",
      "     | > loss_dur: 2.8899619579315186  (2.938645382722219)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8232, device='cuda:0')  (tensor(11.0594, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3667  (0.33062561353047687)\n",
      "     | > loader_time: 0.004  (0.004531777567333649)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:44:52 -- STEP: 169/406 -- GLOBAL_STEP: 575\u001b[0m\n",
      "     | > loss: 3.657158613204956  (3.710995617702868)\n",
      "     | > log_mle: 0.7840290665626526  (0.7760993235209989)\n",
      "     | > loss_dur: 2.8731296062469482  (2.934896299824912)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7283, device='cuda:0')  (tensor(11.0339, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4594  (0.3430333222157856)\n",
      "     | > loader_time: 0.004  (0.004441801612899151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:45:03 -- STEP: 194/406 -- GLOBAL_STEP: 600\u001b[0m\n",
      "     | > loss: 3.715963363647461  (3.709032318026749)\n",
      "     | > log_mle: 0.7782859206199646  (0.7759121422915113)\n",
      "     | > loss_dur: 2.9376773834228516  (2.933120179422123)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8155, device='cuda:0')  (tensor(11.0086, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4727  (0.3559591487510917)\n",
      "     | > loader_time: 0.004  (0.00442146640462974)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:45:14 -- STEP: 219/406 -- GLOBAL_STEP: 625\u001b[0m\n",
      "     | > loss: 3.6180641651153564  (3.703847022905742)\n",
      "     | > log_mle: 0.7779818177223206  (0.7758281764374475)\n",
      "     | > loss_dur: 2.8400824069976807  (2.9280188519116406)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6092, device='cuda:0')  (tensor(10.9754, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4934  (0.365329852387241)\n",
      "     | > loader_time: 0.004  (0.0043874690521797655)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:45:26 -- STEP: 244/406 -- GLOBAL_STEP: 650\u001b[0m\n",
      "     | > loss: 3.7158117294311523  (3.7020147560072725)\n",
      "     | > log_mle: 0.772338330745697  (0.7757743970781075)\n",
      "     | > loss_dur: 2.9434733390808105  (2.9262403630819476)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7776, device='cuda:0')  (tensor(10.9469, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4184  (0.37452424451953076)\n",
      "     | > loader_time: 0.005  (0.0043686638112928056)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:45:38 -- STEP: 269/406 -- GLOBAL_STEP: 675\u001b[0m\n",
      "     | > loss: 3.630181074142456  (3.698812493604355)\n",
      "     | > log_mle: 0.7778470516204834  (0.7755025753744472)\n",
      "     | > loss_dur: 2.8523340225219727  (2.9233099235477944)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4972, device='cuda:0')  (tensor(10.9154, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5625  (0.38590038487459205)\n",
      "     | > loader_time: 0.005  (0.004368197962253955)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:45:51 -- STEP: 294/406 -- GLOBAL_STEP: 700\u001b[0m\n",
      "     | > loss: 3.70029354095459  (3.695016147328072)\n",
      "     | > log_mle: 0.7720481157302856  (0.7752756111475887)\n",
      "     | > loss_dur: 2.9282455444335938  (2.9197405398297467)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.5998, device='cuda:0')  (tensor(10.8790, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4654  (0.395202215026025)\n",
      "     | > loader_time: 0.005  (0.004395053500220891)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:46:05 -- STEP: 319/406 -- GLOBAL_STEP: 725\u001b[0m\n",
      "     | > loss: 3.6479010581970215  (3.6918553080304664)\n",
      "     | > log_mle: 0.7675762176513672  (0.7750232787715228)\n",
      "     | > loss_dur: 2.8803248405456543  (2.9168320329959094)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4033, device='cuda:0')  (tensor(10.8453, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6466  (0.4083330085658728)\n",
      "     | > loader_time: 0.005  (0.00445849917899105)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:46:20 -- STEP: 344/406 -- GLOBAL_STEP: 750\u001b[0m\n",
      "     | > loss: 3.612114191055298  (3.6893801176270773)\n",
      "     | > log_mle: 0.7698540687561035  (0.7748079662059625)\n",
      "     | > loss_dur: 2.8422601222991943  (2.914572155059769)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2346, device='cuda:0')  (tensor(10.8101, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6226  (0.42108906770861426)\n",
      "     | > loader_time: 0.006  (0.004524355017861656)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:46:35 -- STEP: 369/406 -- GLOBAL_STEP: 775\u001b[0m\n",
      "     | > loss: 3.5848217010498047  (3.6854041423900985)\n",
      "     | > log_mle: 0.7675933837890625  (0.7745243839132104)\n",
      "     | > loss_dur: 2.817228317260742  (2.9108797625151417)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.1911, device='cuda:0')  (tensor(10.7720, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7397  (0.4346096787026258)\n",
      "     | > loader_time: 0.005  (0.004603003421773111)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:46:52 -- STEP: 394/406 -- GLOBAL_STEP: 800\u001b[0m\n",
      "     | > loss: 3.616975784301758  (3.6806668363851944)\n",
      "     | > log_mle: 0.7746894955635071  (0.7742964897664062)\n",
      "     | > loss_dur: 2.8422863483428955  (2.906370349946965)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.1125, device='cuda:0')  (tensor(10.7311, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6296  (0.44833435322427506)\n",
      "     | > loader_time: 0.005  (0.004638653721301084)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.002001941204071045 \u001b[0m(-0.23884153366088867)\n",
      "     | > avg_loss:\u001b[92m 3.639614850282669 \u001b[0m(-0.14179649949073792)\n",
      "     | > avg_log_mle:\u001b[92m 0.7682378441095352 \u001b[0m(-0.009579315781593323)\n",
      "     | > avg_loss_dur:\u001b[92m 2.8713770508766174 \u001b[0m(-0.13221710920333862)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_812.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 01:47:30) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:47:50 -- STEP: 13/406 -- GLOBAL_STEP: 825\u001b[0m\n",
      "     | > loss: 3.536174774169922  (3.631893799855159)\n",
      "     | > log_mle: 0.7574587464332581  (0.7639418565309964)\n",
      "     | > loss_dur: 2.7787160873413086  (2.8679519249842715)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.6915, device='cuda:0')  (tensor(9.8039, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.2742  (0.2766356101402869)\n",
      "     | > loader_time: 0.002  (0.02332907456618089)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:47:57 -- STEP: 38/406 -- GLOBAL_STEP: 850\u001b[0m\n",
      "     | > loss: 3.542876958847046  (3.591890573501587)\n",
      "     | > log_mle: 0.7667229771614075  (0.7661718616360113)\n",
      "     | > loss_dur: 2.776154041290283  (2.8257187040228593)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5841, device='cuda:0')  (tensor(9.7595, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.2933  (0.2752233116250289)\n",
      "     | > loader_time: 0.003  (0.009508936028731497)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:48:05 -- STEP: 63/406 -- GLOBAL_STEP: 875\u001b[0m\n",
      "     | > loss: 3.5524396896362305  (3.578998940331595)\n",
      "     | > log_mle: 0.7617985606193542  (0.7662386941531348)\n",
      "     | > loss_dur: 2.7906410694122314  (2.8127602509089886)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5088, device='cuda:0')  (tensor(9.7033, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3323  (0.2882456401037791)\n",
      "     | > loader_time: 0.004  (0.006831812480139356)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:48:14 -- STEP: 88/406 -- GLOBAL_STEP: 900\u001b[0m\n",
      "     | > loss: 3.4980907440185547  (3.5662695955146444)\n",
      "     | > log_mle: 0.7658230066299438  (0.7659903602166611)\n",
      "     | > loss_dur: 2.7322676181793213  (2.8002792325886805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3246, device='cuda:0')  (tensor(9.6248, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3673  (0.3051688075065612)\n",
      "     | > loader_time: 0.002  (0.005732606757770888)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:48:23 -- STEP: 113/406 -- GLOBAL_STEP: 925\u001b[0m\n",
      "     | > loss: 3.547825336456299  (3.5519427451412233)\n",
      "     | > log_mle: 0.7634968757629395  (0.765487319072791)\n",
      "     | > loss_dur: 2.7843284606933594  (2.786455422376109)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1625, device='cuda:0')  (tensor(9.5341, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3243  (0.3146012335751965)\n",
      "     | > loader_time: 0.003  (0.005155246869652674)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:48:32 -- STEP: 138/406 -- GLOBAL_STEP: 950\u001b[0m\n",
      "     | > loss: 3.554666757583618  (3.543267809826395)\n",
      "     | > log_mle: 0.7594256401062012  (0.7646852222041808)\n",
      "     | > loss_dur: 2.795241117477417  (2.7785825850307075)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.9944, device='cuda:0')  (tensor(9.4401, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4094  (0.32382778326670336)\n",
      "     | > loader_time: 0.003  (0.0048160794852436465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:48:42 -- STEP: 163/406 -- GLOBAL_STEP: 975\u001b[0m\n",
      "     | > loss: 3.4800639152526855  (3.5342777945512642)\n",
      "     | > log_mle: 0.758487343788147  (0.7638665017174798)\n",
      "     | > loss_dur: 2.721576690673828  (2.770411291005421)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7323, device='cuda:0')  (tensor(9.3422, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4334  (0.33365666061822635)\n",
      "     | > loader_time: 0.004  (0.004636216017366189)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:48:52 -- STEP: 188/406 -- GLOBAL_STEP: 1000\u001b[0m\n",
      "     | > loss: 3.5730764865875244  (3.5222506117313466)\n",
      "     | > log_mle: 0.7580640316009521  (0.7630402718452697)\n",
      "     | > loss_dur: 2.8150124549865723  (2.7592103367156184)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6436, device='cuda:0')  (tensor(9.2317, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3803  (0.3438103224368807)\n",
      "     | > loader_time: 0.003  (0.004488210728827945)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_1000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:49:05 -- STEP: 213/406 -- GLOBAL_STEP: 1025\u001b[0m\n",
      "     | > loss: 3.398702383041382  (3.509999497955394)\n",
      "     | > log_mle: 0.7530501484870911  (0.7621723189600197)\n",
      "     | > loss_dur: 2.6456522941589355  (2.747827178435707)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.1975, device='cuda:0')  (tensor(9.1183, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3964  (0.3549310176025535)\n",
      "     | > loader_time: 0.004  (0.004407789785537362)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:49:16 -- STEP: 238/406 -- GLOBAL_STEP: 1050\u001b[0m\n",
      "     | > loss: 3.471125602722168  (3.4991160410792888)\n",
      "     | > log_mle: 0.7543622255325317  (0.7613943076434255)\n",
      "     | > loss_dur: 2.7167632579803467  (2.7377217316827864)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0829, device='cuda:0')  (tensor(9.0061, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4064  (0.3639592883967553)\n",
      "     | > loader_time: 0.004  (0.004361132613751068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:49:30 -- STEP: 263/406 -- GLOBAL_STEP: 1075\u001b[0m\n",
      "     | > loss: 3.410452127456665  (3.489685762971073)\n",
      "     | > log_mle: 0.7508518099784851  (0.7603194704527184)\n",
      "     | > loss_dur: 2.659600257873535  (2.729366291611821)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.8385, device='cuda:0')  (tensor(8.8962, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5415  (0.3797463491389054)\n",
      "     | > loader_time: 0.006  (0.004395680735773008)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:49:42 -- STEP: 288/406 -- GLOBAL_STEP: 1100\u001b[0m\n",
      "     | > loss: 3.3440117835998535  (3.480642905665769)\n",
      "     | > log_mle: 0.7421865463256836  (0.7592027170790568)\n",
      "     | > loss_dur: 2.60182523727417  (2.721440186931028)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.5265, device='cuda:0')  (tensor(8.7857, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5075  (0.3901563800043531)\n",
      "     | > loader_time: 0.004  (0.00439290867911445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:49:56 -- STEP: 313/406 -- GLOBAL_STEP: 1125\u001b[0m\n",
      "     | > loss: 3.3414502143859863  (3.4719450588043506)\n",
      "     | > log_mle: 0.7437859773635864  (0.7581476285434758)\n",
      "     | > loss_dur: 2.5976641178131104  (2.713797426833132)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2925, device='cuda:0')  (tensor(8.6777, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6055  (0.4022472643623718)\n",
      "     | > loader_time: 0.007  (0.004396999225068019)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:50:10 -- STEP: 338/406 -- GLOBAL_STEP: 1150\u001b[0m\n",
      "     | > loss: 3.3641037940979004  (3.4637415684186497)\n",
      "     | > log_mle: 0.7417893409729004  (0.7569800689375612)\n",
      "     | > loss_dur: 2.622314453125  (2.7067614963068776)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.1655, device='cuda:0')  (tensor(8.5719, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5445  (0.4134668873611992)\n",
      "     | > loader_time: 0.005  (0.004418236264110321)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:50:24 -- STEP: 363/406 -- GLOBAL_STEP: 1175\u001b[0m\n",
      "     | > loss: 3.353428840637207  (3.4561233684707937)\n",
      "     | > log_mle: 0.7388495206832886  (0.7557893346163852)\n",
      "     | > loss_dur: 2.614579200744629  (2.700334032048208)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.0789, device='cuda:0')  (tensor(8.4703, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5245  (0.4238153009703665)\n",
      "     | > loader_time: 0.006  (0.004436562540774178)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:50:40 -- STEP: 388/406 -- GLOBAL_STEP: 1200\u001b[0m\n",
      "     | > loss: 3.3241448402404785  (3.4474029252209615)\n",
      "     | > log_mle: 0.7395153045654297  (0.7545940919020742)\n",
      "     | > loss_dur: 2.584629535675049  (2.6928088314754457)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.8825, device='cuda:0')  (tensor(8.3708, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.6986  (0.43569008898489253)\n",
      "     | > loader_time: 0.004  (0.004473153463343988)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0909835696220398 \u001b[0m(+0.08898162841796875)\n",
      "     | > avg_loss:\u001b[92m 3.2941380739212036 \u001b[0m(-0.34547677636146545)\n",
      "     | > avg_log_mle:\u001b[92m 0.7315764874219894 \u001b[0m(-0.036661356687545776)\n",
      "     | > avg_loss_dur:\u001b[92m 2.562561571598053 \u001b[0m(-0.30881547927856445)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_1218.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 01:51:14) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:51:32 -- STEP: 7/406 -- GLOBAL_STEP: 1225\u001b[0m\n",
      "     | > loss: 3.23187518119812  (3.336340461458479)\n",
      "     | > log_mle: 0.7339614033699036  (0.7318964004516602)\n",
      "     | > loss_dur: 2.4979138374328613  (2.6044440610068187)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.5844, device='cuda:0')  (tensor(6.7425, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.2492  (0.25465989112854004)\n",
      "     | > loader_time: 0.001  (0.03203518050057547)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:51:39 -- STEP: 32/406 -- GLOBAL_STEP: 1250\u001b[0m\n",
      "     | > loss: 3.356182336807251  (3.3082853630185127)\n",
      "     | > log_mle: 0.7315991520881653  (0.7331486362963915)\n",
      "     | > loss_dur: 2.6245832443237305  (2.5751367434859276)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.7344, device='cuda:0')  (tensor(6.6914, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.2562  (0.2583812400698663)\n",
      "     | > loader_time: 0.003  (0.008696526288986206)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:51:46 -- STEP: 57/406 -- GLOBAL_STEP: 1275\u001b[0m\n",
      "     | > loss: 3.2554545402526855  (3.294923184210794)\n",
      "     | > log_mle: 0.7288798093795776  (0.7320470224347031)\n",
      "     | > loss_dur: 2.5265748500823975  (2.5628761701416543)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.4285, device='cuda:0')  (tensor(6.6271, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3152  (0.27131050929688577)\n",
      "     | > loader_time: 0.003  (0.005953374661897358)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:51:54 -- STEP: 82/406 -- GLOBAL_STEP: 1300\u001b[0m\n",
      "     | > loss: 3.2117815017700195  (3.2870455340641302)\n",
      "     | > log_mle: 0.7243031859397888  (0.7301994663913075)\n",
      "     | > loss_dur: 2.487478256225586  (2.5568460720341375)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.3380, device='cuda:0')  (tensor(6.5805, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3593  (0.28445277853709894)\n",
      "     | > loader_time: 0.003  (0.0050172195201966825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:52:03 -- STEP: 107/406 -- GLOBAL_STEP: 1325\u001b[0m\n",
      "     | > loss: 3.1696882247924805  (3.2717083881948597)\n",
      "     | > log_mle: 0.7192655205726624  (0.7280808269420517)\n",
      "     | > loss_dur: 2.450422763824463  (2.543627562923967)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.2826, device='cuda:0')  (tensor(6.5274, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3828  (0.29739603818019983)\n",
      "     | > loader_time: 0.003  (0.004546555403237032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:52:12 -- STEP: 132/406 -- GLOBAL_STEP: 1350\u001b[0m\n",
      "     | > loss: 3.226691246032715  (3.261011611331593)\n",
      "     | > log_mle: 0.7089475393295288  (0.7257119078527797)\n",
      "     | > loss_dur: 2.5177438259124756  (2.535299703930364)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.2624, device='cuda:0')  (tensor(6.4848, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3293  (0.30825340205972857)\n",
      "     | > loader_time: 0.003  (0.004299693035356928)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:52:21 -- STEP: 157/406 -- GLOBAL_STEP: 1375\u001b[0m\n",
      "     | > loss: 3.2581255435943604  (3.253801919852093)\n",
      "     | > log_mle: 0.7106396555900574  (0.7235874154005839)\n",
      "     | > loss_dur: 2.547485828399658  (2.5302145071090405)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.2774, device='cuda:0')  (tensor(6.4497, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4213  (0.3195491581206111)\n",
      "     | > loader_time: 0.004  (0.004182402495365995)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:52:31 -- STEP: 182/406 -- GLOBAL_STEP: 1400\u001b[0m\n",
      "     | > loss: 3.183358669281006  (3.2433967695131405)\n",
      "     | > log_mle: 0.7003094553947449  (0.7213765687339908)\n",
      "     | > loss_dur: 2.483049154281616  (2.522020206346616)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.1604, device='cuda:0')  (tensor(6.4105, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.3687  (0.3311242572553866)\n",
      "     | > loader_time: 0.003  (0.004091868033775918)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:52:42 -- STEP: 207/406 -- GLOBAL_STEP: 1425\u001b[0m\n",
      "     | > loss: 3.1527717113494873  (3.233573869806557)\n",
      "     | > log_mle: 0.7001063823699951  (0.7193010970590196)\n",
      "     | > loss_dur: 2.452665328979492  (2.5142727785064403)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.1120, device='cuda:0')  (tensor(6.3752, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.473  (0.34242531297287515)\n",
      "     | > loader_time: 0.004  (0.004086044099595812)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:52:53 -- STEP: 232/406 -- GLOBAL_STEP: 1450\u001b[0m\n",
      "     | > loss: 3.1543772220611572  (3.222825807744059)\n",
      "     | > log_mle: 0.6926388144493103  (0.7172402138340062)\n",
      "     | > loss_dur: 2.461738348007202  (2.5055855964792184)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.1592, device='cuda:0')  (tensor(6.3422, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4104  (0.35245582769657013)\n",
      "     | > loader_time: 0.005  (0.004094396171898675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:53:05 -- STEP: 257/406 -- GLOBAL_STEP: 1475\u001b[0m\n",
      "     | > loss: 3.1036834716796875  (3.2137941655481836)\n",
      "     | > log_mle: 0.6926475763320923  (0.7151484542783596)\n",
      "     | > loss_dur: 2.4110360145568848  (2.4986457138209954)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.0203, device='cuda:0')  (tensor(6.3121, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5415  (0.36503766390136255)\n",
      "     | > loader_time: 0.005  (0.004112824391762103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:53:18 -- STEP: 282/406 -- GLOBAL_STEP: 1500\u001b[0m\n",
      "     | > loss: 3.09213924407959  (3.2033913871075246)\n",
      "     | > log_mle: 0.6907737255096436  (0.7129783446484423)\n",
      "     | > loss_dur: 2.4013655185699463  (2.490413044361358)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9842, device='cuda:0')  (tensor(6.2820, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.4474  (0.37584655589245747)\n",
      "     | > loader_time: 0.004  (0.004138631178132184)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:53:31 -- STEP: 307/406 -- GLOBAL_STEP: 1525\u001b[0m\n",
      "     | > loss: 3.0679683685302734  (3.194018335218151)\n",
      "     | > log_mle: 0.6848512887954712  (0.7108515207852912)\n",
      "     | > loss_dur: 2.383117198944092  (2.4831668134620983)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.9080, device='cuda:0')  (tensor(6.2543, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5995  (0.3873924347010809)\n",
      "     | > loader_time: 0.005  (0.004176544444180465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:53:45 -- STEP: 332/406 -- GLOBAL_STEP: 1550\u001b[0m\n",
      "     | > loss: 3.028698682785034  (3.1833391498370345)\n",
      "     | > log_mle: 0.6780343651771545  (0.7086805685097911)\n",
      "     | > loss_dur: 2.3506643772125244  (2.4746585818658398)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.8354, device='cuda:0')  (tensor(6.2258, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5205  (0.39953295150435114)\n",
      "     | > loader_time: 0.005  (0.004229843616485592)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:53:59 -- STEP: 357/406 -- GLOBAL_STEP: 1575\u001b[0m\n",
      "     | > loss: 2.98826265335083  (3.174461310651122)\n",
      "     | > log_mle: 0.680819571018219  (0.7064830086478334)\n",
      "     | > loss_dur: 2.307443141937256  (2.4679783031720093)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.7616, device='cuda:0')  (tensor(6.2001, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5325  (0.41125245722068127)\n",
      "     | > loader_time: 0.005  (0.004278493528606509)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:54:14 -- STEP: 382/406 -- GLOBAL_STEP: 1600\u001b[0m\n",
      "     | > loss: 3.029346466064453  (3.1632508726020134)\n",
      "     | > log_mle: 0.67342209815979  (0.7043416977552849)\n",
      "     | > loss_dur: 2.355924367904663  (2.458909176407061)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.8141, device='cuda:0')  (tensor(6.1722, device='cuda:0'))\n",
      "     | > current_lr: 7.5e-07 \n",
      "     | > step_time: 0.5525  (0.42304070083258666)\n",
      "     | > loader_time: 0.006  (0.004333869949061209)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09946548938751221 \u001b[0m(+0.008481919765472412)\n",
      "     | > avg_loss:\u001b[92m 2.901076912879944 \u001b[0m(-0.39306116104125977)\n",
      "     | > avg_log_mle:\u001b[92m 0.6676988452672958 \u001b[0m(-0.0638776421546936)\n",
      "     | > avg_loss_dur:\u001b[92m 2.233378052711487 \u001b[0m(-0.32918351888656616)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_1624.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 4/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 01:54:52) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:55:08 -- STEP: 1/406 -- GLOBAL_STEP: 1625\u001b[0m\n",
      "     | > loss: 3.0249855518341064  (3.0249855518341064)\n",
      "     | > log_mle: 0.6723716855049133  (0.6723716855049133)\n",
      "     | > loss_dur: 2.352613925933838  (2.352613925933838)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.7514, device='cuda:0')  (tensor(5.7514, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.2612  (0.26123547554016113)\n",
      "     | > loader_time: 0.002  (0.002003192901611328)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:55:15 -- STEP: 26/406 -- GLOBAL_STEP: 1650\u001b[0m\n",
      "     | > loss: 2.933049201965332  (2.949852384053744)\n",
      "     | > log_mle: 0.6720584630966187  (0.6741800078978906)\n",
      "     | > loss_dur: 2.260990619659424  (2.275672380740826)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.6672, device='cuda:0')  (tensor(5.6553, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.2642  (0.25700246370755714)\n",
      "     | > loader_time: 0.002  (0.011471986770629883)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:55:22 -- STEP: 51/406 -- GLOBAL_STEP: 1675\u001b[0m\n",
      "     | > loss: 2.8853020668029785  (2.9252138932545986)\n",
      "     | > log_mle: 0.6601368188858032  (0.6722594639834236)\n",
      "     | > loss_dur: 2.225165367126465  (2.252954445633234)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4792, device='cuda:0')  (tensor(5.6091, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3103  (0.27576015042323687)\n",
      "     | > loader_time: 0.003  (0.007183028202430873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:55:30 -- STEP: 76/406 -- GLOBAL_STEP: 1700\u001b[0m\n",
      "     | > loss: 2.871739625930786  (2.9139077443825574)\n",
      "     | > log_mle: 0.6682214736938477  (0.6693939260746303)\n",
      "     | > loss_dur: 2.2035181522369385  (2.2445138285034587)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4906, device='cuda:0')  (tensor(5.5825, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3093  (0.2901450144617181)\n",
      "     | > loader_time: 0.003  (0.005821093132621362)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:55:39 -- STEP: 101/406 -- GLOBAL_STEP: 1725\u001b[0m\n",
      "     | > loss: 2.8749375343322754  (2.897653718986134)\n",
      "     | > log_mle: 0.6515953540802002  (0.6662647765461761)\n",
      "     | > loss_dur: 2.223342180252075  (2.231388948931553)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4812, device='cuda:0')  (tensor(5.5507, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3243  (0.30154109709333654)\n",
      "     | > loader_time: 0.004  (0.005133355017935874)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:55:48 -- STEP: 126/406 -- GLOBAL_STEP: 1750\u001b[0m\n",
      "     | > loss: 2.7632789611816406  (2.8813434366195927)\n",
      "     | > log_mle: 0.6472362279891968  (0.6630198075657799)\n",
      "     | > loss_dur: 2.1160426139831543  (2.2183236356765508)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.3202, device='cuda:0')  (tensor(5.5183, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4154  (0.31231525019993844)\n",
      "     | > loader_time: 0.004  (0.0047900695649404365)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:55:58 -- STEP: 151/406 -- GLOBAL_STEP: 1775\u001b[0m\n",
      "     | > loss: 2.797645092010498  (2.8719509832116947)\n",
      "     | > log_mle: 0.6456283330917358  (0.6598287366873379)\n",
      "     | > loss_dur: 2.1520166397094727  (2.2121222508664165)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.3039, device='cuda:0')  (tensor(5.4950, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4294  (0.3244960513335979)\n",
      "     | > loader_time: 0.004  (0.004593591816377954)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:56:08 -- STEP: 176/406 -- GLOBAL_STEP: 1800\u001b[0m\n",
      "     | > loss: 2.7674667835235596  (2.85841894962571)\n",
      "     | > log_mle: 0.6361517906188965  (0.6567821367220443)\n",
      "     | > loss_dur: 2.131314992904663  (2.201636818322268)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.2540, device='cuda:0')  (tensor(5.4616, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3673  (0.3342831581830977)\n",
      "     | > loader_time: 0.003  (0.004441540349613535)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:56:19 -- STEP: 201/406 -- GLOBAL_STEP: 1825\u001b[0m\n",
      "     | > loss: 2.7107582092285156  (2.845595483163104)\n",
      "     | > log_mle: 0.636595606803894  (0.6537732203208392)\n",
      "     | > loss_dur: 2.074162721633911  (2.1918222702557753)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1394, device='cuda:0')  (tensor(5.4312, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.3843  (0.3461721050205514)\n",
      "     | > loader_time: 0.004  (0.004387097572212786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:56:29 -- STEP: 226/406 -- GLOBAL_STEP: 1850\u001b[0m\n",
      "     | > loss: 2.6957781314849854  (2.832614917670732)\n",
      "     | > log_mle: 0.621067225933075  (0.6507958672215454)\n",
      "     | > loss_dur: 2.0747108459472656  (2.1818190580975676)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0567, device='cuda:0')  (tensor(5.4011, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4014  (0.35485942595827885)\n",
      "     | > loader_time: 0.004  (0.004322540443555442)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:56:41 -- STEP: 251/406 -- GLOBAL_STEP: 1875\u001b[0m\n",
      "     | > loss: 2.7448368072509766  (2.822101256761894)\n",
      "     | > log_mle: 0.6184454560279846  (0.6478678809694085)\n",
      "     | > loss_dur: 2.1263914108276367  (2.1742333843413566)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1638, device='cuda:0')  (tensor(5.3746, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5175  (0.36591155310551)\n",
      "     | > loader_time: 0.004  (0.004310714296135768)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:56:53 -- STEP: 276/406 -- GLOBAL_STEP: 1900\u001b[0m\n",
      "     | > loss: 2.669126033782959  (2.8114257705384413)\n",
      "     | > log_mle: 0.6131166815757751  (0.6448109074347261)\n",
      "     | > loss_dur: 2.056009292602539  (2.1666148710941915)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0366, device='cuda:0')  (tensor(5.3494, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.4434  (0.37598053095997236)\n",
      "     | > loader_time: 0.004  (0.004304669905399929)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:57:06 -- STEP: 301/406 -- GLOBAL_STEP: 1925\u001b[0m\n",
      "     | > loss: 2.690577507019043  (2.8018670153380247)\n",
      "     | > log_mle: 0.6024758219718933  (0.6418732361144004)\n",
      "     | > loss_dur: 2.088101625442505  (2.1599937879365925)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9980, device='cuda:0')  (tensor(5.3263, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6055  (0.3866148288067788)\n",
      "     | > loader_time: 0.005  (0.004319575933918999)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:57:19 -- STEP: 326/406 -- GLOBAL_STEP: 1950\u001b[0m\n",
      "     | > loss: 2.643718957901001  (2.7920428850899466)\n",
      "     | > log_mle: 0.5994791388511658  (0.6389339888022721)\n",
      "     | > loss_dur: 2.0442397594451904  (2.1531089025041057)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9849, device='cuda:0')  (tensor(5.3042, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5135  (0.39796686318754393)\n",
      "     | > loader_time: 0.005  (0.004362893982167621)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:57:34 -- STEP: 351/406 -- GLOBAL_STEP: 1975\u001b[0m\n",
      "     | > loss: 2.6510934829711914  (2.7847584761106066)\n",
      "     | > log_mle: 0.5963805913925171  (0.6359088505774824)\n",
      "     | > loss_dur: 2.0547127723693848  (2.1488496299482804)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9719, device='cuda:0')  (tensor(5.2861, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.6486  (0.4103480655583219)\n",
      "     | > loader_time: 0.005  (0.004400055632631999)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:57:49 -- STEP: 376/406 -- GLOBAL_STEP: 2000\u001b[0m\n",
      "     | > loss: 2.6319658756256104  (2.7757525482076293)\n",
      "     | > log_mle: 0.592233419418335  (0.6329059443892318)\n",
      "     | > loss_dur: 2.0397324562072754  (2.142846607464424)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9392, device='cuda:0')  (tensor(5.2672, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.5685  (0.4222833926373337)\n",
      "     | > loader_time: 0.005  (0.004461554770774024)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_2000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:58:08 -- STEP: 401/406 -- GLOBAL_STEP: 2025\u001b[0m\n",
      "     | > loss: 2.6308393478393555  (2.767592762473814)\n",
      "     | > log_mle: 0.584530234336853  (0.6299898062560924)\n",
      "     | > loss_dur: 2.046309232711792  (2.13760295919052)\n",
      "     | > amp_scaler: 16384.0  (16424.8578553616)\n",
      "     | > grad_norm: tensor(4.9919, device='cuda:0')  (tensor(5.2381, device='cuda:0'))\n",
      "     | > current_lr: 1e-06 \n",
      "     | > step_time: 0.7165  (0.43703524251828446)\n",
      "     | > loader_time: 0.005  (0.004520376424242428)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0876196026802063 \u001b[0m(-0.011845886707305908)\n",
      "     | > avg_loss:\u001b[92m 2.5464749932289124 \u001b[0m(-0.3546019196510315)\n",
      "     | > avg_log_mle:\u001b[92m 0.5837729647755623 \u001b[0m(-0.08392588049173355)\n",
      "     | > avg_loss_dur:\u001b[92m 1.962702065706253 \u001b[0m(-0.27067598700523376)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_2030.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 5/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 01:58:34) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:58:55 -- STEP: 20/406 -- GLOBAL_STEP: 2050\u001b[0m\n",
      "     | > loss: 2.547940731048584  (2.647366034984589)\n",
      "     | > log_mle: 0.6065177917480469  (0.5986100941896438)\n",
      "     | > loss_dur: 1.941422939300537  (2.048755943775177)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8655, device='cuda:0')  (tensor(4.9877, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.2612  (0.25768359899520876)\n",
      "     | > loader_time: 0.002  (0.012461650371551513)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:59:02 -- STEP: 45/406 -- GLOBAL_STEP: 2075\u001b[0m\n",
      "     | > loss: 2.589796304702759  (2.61516924434238)\n",
      "     | > log_mle: 0.594369649887085  (0.5959393488036261)\n",
      "     | > loss_dur: 1.9954266548156738  (2.019229883617825)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9342, device='cuda:0')  (tensor(4.9561, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3253  (0.26673079066806366)\n",
      "     | > loader_time: 0.003  (0.00682882202996148)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:59:10 -- STEP: 70/406 -- GLOBAL_STEP: 2100\u001b[0m\n",
      "     | > loss: 2.5788559913635254  (2.607761219569615)\n",
      "     | > log_mle: 0.5747090578079224  (0.5912000298500062)\n",
      "     | > loss_dur: 2.0041470527648926  (2.0165611880166208)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9482, device='cuda:0')  (tensor(4.9504, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.2803  (0.27896742820739745)\n",
      "     | > loader_time: 0.002  (0.005362204142979213)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:59:18 -- STEP: 95/406 -- GLOBAL_STEP: 2125\u001b[0m\n",
      "     | > loss: 2.485250473022461  (2.595499016109267)\n",
      "     | > log_mle: 0.5729883909225464  (0.5866546273231504)\n",
      "     | > loss_dur: 1.912261962890625  (2.008844390668369)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8134, device='cuda:0')  (tensor(4.9430, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3023  (0.2917174063230815)\n",
      "     | > loader_time: 0.004  (0.004720200990375721)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:59:27 -- STEP: 120/406 -- GLOBAL_STEP: 2150\u001b[0m\n",
      "     | > loss: 2.534609317779541  (2.5844831228256235)\n",
      "     | > log_mle: 0.5579077005386353  (0.5823694005608558)\n",
      "     | > loss_dur: 1.9767016172409058  (2.002113724748295)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8986, device='cuda:0')  (tensor(4.9360, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3223  (0.3030661265055338)\n",
      "     | > loader_time: 0.004  (0.004437472422917685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:59:36 -- STEP: 145/406 -- GLOBAL_STEP: 2175\u001b[0m\n",
      "     | > loss: 2.4615819454193115  (2.577003327731431)\n",
      "     | > log_mle: 0.5571813583374023  (0.5779273324999316)\n",
      "     | > loss_dur: 1.9044005870819092  (1.999075994820432)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8396, device='cuda:0')  (tensor(4.9352, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3523  (0.3151890212091906)\n",
      "     | > loader_time: 0.003  (0.004231507202674603)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:59:46 -- STEP: 170/406 -- GLOBAL_STEP: 2200\u001b[0m\n",
      "     | > loss: 2.50687575340271  (2.567769035171062)\n",
      "     | > log_mle: 0.5462837815284729  (0.574091383639504)\n",
      "     | > loss_dur: 1.9605919122695923  (1.9936776511809418)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8776, device='cuda:0')  (tensor(4.9284, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3513  (0.3252889338661643)\n",
      "     | > loader_time: 0.004  (0.004150882889242732)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 01:59:56 -- STEP: 195/406 -- GLOBAL_STEP: 2225\u001b[0m\n",
      "     | > loss: 2.5053067207336426  (2.5582312804002036)\n",
      "     | > log_mle: 0.5523608922958374  (0.5702093106049758)\n",
      "     | > loss_dur: 1.9529459476470947  (1.9880219667385797)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9245, device='cuda:0')  (tensor(4.9198, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3823  (0.33707478718879896)\n",
      "     | > loader_time: 0.004  (0.004111491716825042)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:00:07 -- STEP: 220/406 -- GLOBAL_STEP: 2250\u001b[0m\n",
      "     | > loss: 2.4721360206604004  (2.5466490788893275)\n",
      "     | > log_mle: 0.5245931148529053  (0.56651440913027)\n",
      "     | > loss_dur: 1.9475427865982056  (1.980134663256733)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8432, device='cuda:0')  (tensor(4.9076, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.3994  (0.34738768122412944)\n",
      "     | > loader_time: 0.004  (0.004112891717390577)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:00:19 -- STEP: 245/406 -- GLOBAL_STEP: 2275\u001b[0m\n",
      "     | > loss: 2.427370071411133  (2.5366999470457747)\n",
      "     | > log_mle: 0.5350654721260071  (0.5628752024806278)\n",
      "     | > loss_dur: 1.892304539680481  (1.9738247394561776)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7463, device='cuda:0')  (tensor(4.8973, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5295  (0.3581656738203399)\n",
      "     | > loader_time: 0.004  (0.004134412687651964)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:00:31 -- STEP: 270/406 -- GLOBAL_STEP: 2300\u001b[0m\n",
      "     | > loss: 2.417696475982666  (2.525734116412976)\n",
      "     | > log_mle: 0.5234376192092896  (0.5593104159390487)\n",
      "     | > loss_dur: 1.894258737564087  (1.9664236965002846)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7286, device='cuda:0')  (tensor(4.8846, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4344  (0.36988369447213626)\n",
      "     | > loader_time: 0.005  (0.00417045575601083)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:00:44 -- STEP: 295/406 -- GLOBAL_STEP: 2325\u001b[0m\n",
      "     | > loss: 2.3805980682373047  (2.5151078822249087)\n",
      "     | > log_mle: 0.5181378126144409  (0.55580788446685)\n",
      "     | > loss_dur: 1.8624602556228638  (1.9592999927068169)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7073, device='cuda:0')  (tensor(4.8716, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5805  (0.38012453661126594)\n",
      "     | > loader_time: 0.004  (0.004193643796241888)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:00:57 -- STEP: 320/406 -- GLOBAL_STEP: 2350\u001b[0m\n",
      "     | > loss: 2.339339256286621  (2.503811335563662)\n",
      "     | > log_mle: 0.5174340605735779  (0.5524745350703598)\n",
      "     | > loss_dur: 1.821905255317688  (1.951336796954275)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6111, device='cuda:0')  (tensor(4.8574, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.4954  (0.39238100647926333)\n",
      "     | > loader_time: 0.005  (0.004275768250226975)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:01:11 -- STEP: 345/406 -- GLOBAL_STEP: 2375\u001b[0m\n",
      "     | > loss: 2.3551034927368164  (2.4938815959985736)\n",
      "     | > log_mle: 0.49591147899627686  (0.5490134929401286)\n",
      "     | > loss_dur: 1.85919189453125  (1.9448680998622514)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6789, device='cuda:0')  (tensor(4.8446, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.6356  (0.4048949172531349)\n",
      "     | > loader_time: 0.004  (0.004334382043368575)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:01:26 -- STEP: 370/406 -- GLOBAL_STEP: 2400\u001b[0m\n",
      "     | > loss: 2.2847886085510254  (2.482512247884599)\n",
      "     | > log_mle: 0.4888858497142792  (0.5456708734099928)\n",
      "     | > loss_dur: 1.7959028482437134  (1.9368413706083563)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5292, device='cuda:0')  (tensor(4.8295, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.5215  (0.4169296612610688)\n",
      "     | > loader_time: 0.005  (0.004406709928770323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:01:42 -- STEP: 395/406 -- GLOBAL_STEP: 2425\u001b[0m\n",
      "     | > loss: 2.290226459503174  (2.470998927007749)\n",
      "     | > log_mle: 0.4875706136226654  (0.5424974052966396)\n",
      "     | > loss_dur: 1.8026559352874756  (1.9285015193721922)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5670, device='cuda:0')  (tensor(4.8134, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-06 \n",
      "     | > step_time: 0.7257  (0.43037787026996854)\n",
      "     | > loader_time: 0.006  (0.004454689388033709)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08520257472991943 \u001b[0m(-0.0024170279502868652)\n",
      "     | > avg_loss:\u001b[92m 2.202168107032776 \u001b[0m(-0.3443068861961365)\n",
      "     | > avg_log_mle:\u001b[92m 0.4935902878642082 \u001b[0m(-0.09018267691135406)\n",
      "     | > avg_loss_dur:\u001b[92m 1.7085778564214706 \u001b[0m(-0.2541242092847824)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_2436.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 6/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:02:12) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:02:31 -- STEP: 14/406 -- GLOBAL_STEP: 2450\u001b[0m\n",
      "     | > loss: 2.2967848777770996  (2.324784210750035)\n",
      "     | > log_mle: 0.5000699758529663  (0.515927676643644)\n",
      "     | > loss_dur: 1.7967149019241333  (1.808856529848916)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5403, device='cuda:0')  (tensor(4.5831, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.2602  (0.25480266979762484)\n",
      "     | > loader_time: 0.002  (0.015085220336914062)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:02:38 -- STEP: 39/406 -- GLOBAL_STEP: 2475\u001b[0m\n",
      "     | > loss: 2.239612102508545  (2.273421030778151)\n",
      "     | > log_mle: 0.511914849281311  (0.513689296367841)\n",
      "     | > loss_dur: 1.7276971340179443  (1.7597317451085799)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4501, device='cuda:0')  (tensor(4.5101, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.2602  (0.26116100335732495)\n",
      "     | > loader_time: 0.003  (0.00698082263653095)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:02:45 -- STEP: 64/406 -- GLOBAL_STEP: 2500\u001b[0m\n",
      "     | > loss: 2.1179590225219727  (2.2495253235101695)\n",
      "     | > log_mle: 0.5103739500045776  (0.5091254832223056)\n",
      "     | > loss_dur: 1.607585072517395  (1.740399844944477)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2798, device='cuda:0')  (tensor(4.4718, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.2863  (0.27424952760338783)\n",
      "     | > loader_time: 0.003  (0.005223579704761505)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:02:54 -- STEP: 89/406 -- GLOBAL_STEP: 2525\u001b[0m\n",
      "     | > loss: 2.211353302001953  (2.233545185474868)\n",
      "     | > log_mle: 0.4910612404346466  (0.5041098092379194)\n",
      "     | > loss_dur: 1.720292091369629  (1.7294353769066628)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4435, device='cuda:0')  (tensor(4.4492, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.2973  (0.2873849038327679)\n",
      "     | > loader_time: 0.003  (0.004565916704327873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:03:03 -- STEP: 114/406 -- GLOBAL_STEP: 2550\u001b[0m\n",
      "     | > loss: 2.1423819065093994  (2.214883578451056)\n",
      "     | > log_mle: 0.4678684175014496  (0.4991915764515859)\n",
      "     | > loss_dur: 1.674513578414917  (1.7156920014766224)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2755, device='cuda:0')  (tensor(4.4229, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3823  (0.30178310160051325)\n",
      "     | > loader_time: 0.003  (0.0042318628545393025)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:03:12 -- STEP: 139/406 -- GLOBAL_STEP: 2575\u001b[0m\n",
      "     | > loss: 2.158010244369507  (2.201963501868488)\n",
      "     | > log_mle: 0.47170618176460266  (0.49463366497334804)\n",
      "     | > loss_dur: 1.6863040924072266  (1.7073298349654933)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3459, device='cuda:0')  (tensor(4.4065, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4074  (0.3122045462080044)\n",
      "     | > loader_time: 0.004  (0.004090038134897355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:03:21 -- STEP: 164/406 -- GLOBAL_STEP: 2600\u001b[0m\n",
      "     | > loss: 2.1186141967773438  (2.189697265625)\n",
      "     | > log_mle: 0.4741329848766327  (0.4907675632616368)\n",
      "     | > loss_dur: 1.6444813013076782  (1.6989297030902495)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2582, device='cuda:0')  (tensor(4.3906, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.3613  (0.3228176643208761)\n",
      "     | > loader_time: 0.004  (0.004015813513499935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:03:32 -- STEP: 189/406 -- GLOBAL_STEP: 2625\u001b[0m\n",
      "     | > loss: 2.123723030090332  (2.177842087215847)\n",
      "     | > log_mle: 0.45624297857284546  (0.48702677406331213)\n",
      "     | > loss_dur: 1.6674799919128418  (1.6908153181984313)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2736, device='cuda:0')  (tensor(4.3723, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4524  (0.3342507276585495)\n",
      "     | > loader_time: 0.003  (0.003961233865647089)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:03:43 -- STEP: 214/406 -- GLOBAL_STEP: 2650\u001b[0m\n",
      "     | > loss: 2.0491015911102295  (2.164875958567468)\n",
      "     | > log_mle: 0.4574293792247772  (0.48365926464027326)\n",
      "     | > loss_dur: 1.5916723012924194  (1.6812167017259334)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1793, device='cuda:0')  (tensor(4.3518, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5045  (0.34523881818646596)\n",
      "     | > loader_time: 0.004  (0.003966176621267731)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:03:54 -- STEP: 239/406 -- GLOBAL_STEP: 2675\u001b[0m\n",
      "     | > loss: 2.0734307765960693  (2.1534684033573424)\n",
      "     | > log_mle: 0.4384945333003998  (0.4803712187202405)\n",
      "     | > loss_dur: 1.6349362134933472  (1.673097191495377)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1943, device='cuda:0')  (tensor(4.3342, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5215  (0.35538559777966117)\n",
      "     | > loader_time: 0.004  (0.0039868414651399895)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:04:06 -- STEP: 264/406 -- GLOBAL_STEP: 2700\u001b[0m\n",
      "     | > loss: 2.047492504119873  (2.1423244273120705)\n",
      "     | > log_mle: 0.4484940767288208  (0.4772776981646364)\n",
      "     | > loss_dur: 1.5989984273910522  (1.6650467343402633)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1953, device='cuda:0')  (tensor(4.3172, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4334  (0.36774693294004973)\n",
      "     | > loader_time: 0.004  (0.0040301165797493686)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:04:18 -- STEP: 289/406 -- GLOBAL_STEP: 2725\u001b[0m\n",
      "     | > loss: 1.9710310697555542  (2.1316511961003077)\n",
      "     | > log_mle: 0.4420844316482544  (0.4742743179047396)\n",
      "     | > loss_dur: 1.5289466381072998  (1.6573768825267015)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0445, device='cuda:0')  (tensor(4.3003, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4434  (0.377708502706772)\n",
      "     | > loader_time: 0.004  (0.00406245789313399)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:04:32 -- STEP: 314/406 -- GLOBAL_STEP: 2750\u001b[0m\n",
      "     | > loss: 1.9499008655548096  (2.1214756073465773)\n",
      "     | > log_mle: 0.4327012002468109  (0.4715404611104613)\n",
      "     | > loss_dur: 1.5171996355056763  (1.6499351498427663)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0137, device='cuda:0')  (tensor(4.2838, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.4784  (0.39051584832987224)\n",
      "     | > loader_time: 0.004  (0.004115161622405814)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:04:46 -- STEP: 339/406 -- GLOBAL_STEP: 2775\u001b[0m\n",
      "     | > loss: 1.9669538736343384  (2.1118112144920325)\n",
      "     | > log_mle: 0.43313100934028625  (0.4687750559289195)\n",
      "     | > loss_dur: 1.5338228940963745  (1.6430361619037865)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0332, device='cuda:0')  (tensor(4.2687, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6506  (0.4023052084762439)\n",
      "     | > loader_time: 0.006  (0.004168947889389897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:05:01 -- STEP: 364/406 -- GLOBAL_STEP: 2800\u001b[0m\n",
      "     | > loss: 1.9696588516235352  (2.1024492612251864)\n",
      "     | > log_mle: 0.4341922700405121  (0.46603726939513135)\n",
      "     | > loss_dur: 1.5354665517807007  (1.6364119943681654)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0271, device='cuda:0')  (tensor(4.2534, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.6646  (0.41488943584672705)\n",
      "     | > loader_time: 0.006  (0.004248322366358163)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:05:16 -- STEP: 389/406 -- GLOBAL_STEP: 2825\u001b[0m\n",
      "     | > loss: 1.9337406158447266  (2.092222843501132)\n",
      "     | > log_mle: 0.416415274143219  (0.4635347979847141)\n",
      "     | > loss_dur: 1.5173254013061523  (1.6286880479680235)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9678, device='cuda:0')  (tensor(4.2363, device='cuda:0'))\n",
      "     | > current_lr: 1.5e-06 \n",
      "     | > step_time: 0.5935  (0.427662453492074)\n",
      "     | > loader_time: 0.007  (0.004302068970197272)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0922127366065979 \u001b[0m(+0.007010161876678467)\n",
      "     | > avg_loss:\u001b[92m 1.8463554829359055 \u001b[0m(-0.3558126240968704)\n",
      "     | > avg_log_mle:\u001b[92m 0.42787523940205574 \u001b[0m(-0.06571504846215248)\n",
      "     | > avg_loss_dur:\u001b[92m 1.41848024725914 \u001b[0m(-0.2900976091623306)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_2842.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 7/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:05:52) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:06:11 -- STEP: 8/406 -- GLOBAL_STEP: 2850\u001b[0m\n",
      "     | > loss: 1.9974758625030518  (1.9969639629125595)\n",
      "     | > log_mle: 0.45042163133621216  (0.45858363434672356)\n",
      "     | > loss_dur: 1.5470542907714844  (1.538380354642868)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0747, device='cuda:0')  (tensor(4.0158, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.2542  (0.2613624930381775)\n",
      "     | > loader_time: 0.002  (0.03127795457839966)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:06:18 -- STEP: 33/406 -- GLOBAL_STEP: 2875\u001b[0m\n",
      "     | > loss: 1.9501376152038574  (1.939283555204218)\n",
      "     | > log_mle: 0.4495512843132019  (0.4529453633409558)\n",
      "     | > loss_dur: 1.5005863904953003  (1.4863381999911685)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9499, device='cuda:0')  (tensor(3.9487, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.2843  (0.2684558088129217)\n",
      "     | > loader_time: 0.003  (0.009129567579789595)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:06:25 -- STEP: 58/406 -- GLOBAL_STEP: 2900\u001b[0m\n",
      "     | > loss: 1.9520868062973022  (1.9197556355903889)\n",
      "     | > log_mle: 0.43939873576164246  (0.44925654602461845)\n",
      "     | > loss_dur: 1.5126880407333374  (1.4704990921349361)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.0025, device='cuda:0')  (tensor(3.9172, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3203  (0.28025435990300673)\n",
      "     | > loader_time: 0.002  (0.006298924314564672)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:06:33 -- STEP: 83/406 -- GLOBAL_STEP: 2925\u001b[0m\n",
      "     | > loss: 1.9021703004837036  (1.9062981031027184)\n",
      "     | > log_mle: 0.42745932936668396  (0.4447681074400982)\n",
      "     | > loss_dur: 1.4747109413146973  (1.4615299960216843)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.9109, device='cuda:0')  (tensor(3.8942, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3563  (0.2920481210731598)\n",
      "     | > loader_time: 0.003  (0.005209681499435241)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:06:42 -- STEP: 108/406 -- GLOBAL_STEP: 2950\u001b[0m\n",
      "     | > loss: 1.8072714805603027  (1.8902467136029844)\n",
      "     | > log_mle: 0.42293086647987366  (0.4404111730831641)\n",
      "     | > loss_dur: 1.3843406438827515  (1.449835542175505)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7178, device='cuda:0')  (tensor(3.8691, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3213  (0.30343284209569293)\n",
      "     | > loader_time: 0.003  (0.0047265335365578)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:06:51 -- STEP: 133/406 -- GLOBAL_STEP: 2975\u001b[0m\n",
      "     | > loss: 1.8379546403884888  (1.879971446847557)\n",
      "     | > log_mle: 0.4138222932815552  (0.4361403268530853)\n",
      "     | > loss_dur: 1.4241323471069336  (1.4438311229074807)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7890, device='cuda:0')  (tensor(3.8545, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3693  (0.31633977782457395)\n",
      "     | > loader_time: 0.004  (0.004500378343395723)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:07:01 -- STEP: 158/406 -- GLOBAL_STEP: 3000\u001b[0m\n",
      "     | > loss: 1.8156282901763916  (1.8723318569267848)\n",
      "     | > log_mle: 0.40273886919021606  (0.4327082254841358)\n",
      "     | > loss_dur: 1.4128893613815308  (1.439623635026473)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7643, device='cuda:0')  (tensor(3.8433, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.3543  (0.3272337113754658)\n",
      "     | > loader_time: 0.004  (0.00436480739448644)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_3000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:07:14 -- STEP: 183/406 -- GLOBAL_STEP: 3025\u001b[0m\n",
      "     | > loss: 1.781383991241455  (1.8643065723565104)\n",
      "     | > log_mle: 0.40696316957473755  (0.4295437967842394)\n",
      "     | > loss_dur: 1.3744207620620728  (1.4347627788293558)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6694, device='cuda:0')  (tensor(3.8305, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4504  (0.34018855147023036)\n",
      "     | > loader_time: 0.004  (0.004244361418843925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:07:25 -- STEP: 208/406 -- GLOBAL_STEP: 3050\u001b[0m\n",
      "     | > loss: 1.7480841875076294  (1.8565070692163244)\n",
      "     | > log_mle: 0.3916863203048706  (0.42650633205014926)\n",
      "     | > loss_dur: 1.3563978672027588  (1.4300007401750638)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6423, device='cuda:0')  (tensor(3.8171, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4814  (0.350197698061283)\n",
      "     | > loader_time: 0.004  (0.0042009743360372715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:07:36 -- STEP: 233/406 -- GLOBAL_STEP: 3075\u001b[0m\n",
      "     | > loss: 1.799289584159851  (1.8485103845596311)\n",
      "     | > log_mle: 0.398923397064209  (0.42366474495936873)\n",
      "     | > loss_dur: 1.400366187095642  (1.4248456433095646)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6908, device='cuda:0')  (tensor(3.8040, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4254  (0.3585959156183727)\n",
      "     | > loader_time: 0.004  (0.0041712077390482485)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:07:48 -- STEP: 258/406 -- GLOBAL_STEP: 3100\u001b[0m\n",
      "     | > loss: 1.8169076442718506  (1.8420972856440283)\n",
      "     | > log_mle: 0.3975268602371216  (0.4210329542095347)\n",
      "     | > loss_dur: 1.419380784034729  (1.4210643343223157)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7429, device='cuda:0')  (tensor(3.7935, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4384  (0.3703440178272337)\n",
      "     | > loader_time: 0.005  (0.0041898599890775445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:08:00 -- STEP: 283/406 -- GLOBAL_STEP: 3125\u001b[0m\n",
      "     | > loss: 1.7513800859451294  (1.8348254951065925)\n",
      "     | > log_mle: 0.38717830181121826  (0.4184866599185727)\n",
      "     | > loss_dur: 1.3642017841339111  (1.4163388384525855)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6430, device='cuda:0')  (tensor(3.7816, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4474  (0.3807733286395933)\n",
      "     | > loader_time: 0.005  (0.004226420877679074)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:08:13 -- STEP: 308/406 -- GLOBAL_STEP: 3150\u001b[0m\n",
      "     | > loss: 1.7390761375427246  (1.8286832803255553)\n",
      "     | > log_mle: 0.38718342781066895  (0.41626877589272215)\n",
      "     | > loss_dur: 1.3518927097320557  (1.4124145078194608)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6371, device='cuda:0')  (tensor(3.7715, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4764  (0.39199178172396376)\n",
      "     | > loader_time: 0.005  (0.004266827137439276)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:08:27 -- STEP: 333/406 -- GLOBAL_STEP: 3175\u001b[0m\n",
      "     | > loss: 1.7828056812286377  (1.8221307606310457)\n",
      "     | > log_mle: 0.37921255826950073  (0.41405963960352604)\n",
      "     | > loss_dur: 1.4035930633544922  (1.408071124159896)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6829, device='cuda:0')  (tensor(3.7618, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.4774  (0.4027466430320396)\n",
      "     | > loader_time: 0.004  (0.004328207210735512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:08:41 -- STEP: 358/406 -- GLOBAL_STEP: 3200\u001b[0m\n",
      "     | > loss: 1.6658194065093994  (1.816530592947699)\n",
      "     | > log_mle: 0.3629645109176636  (0.4117317347053709)\n",
      "     | > loss_dur: 1.3028548955917358  (1.4047988609894695)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5232, device='cuda:0')  (tensor(3.7532, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.5145  (0.41420251963524846)\n",
      "     | > loader_time: 0.005  (0.004372627375512146)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:08:56 -- STEP: 383/406 -- GLOBAL_STEP: 3225\u001b[0m\n",
      "     | > loss: 1.740760326385498  (1.8098815707562799)\n",
      "     | > log_mle: 0.37955838441848755  (0.40966347093370503)\n",
      "     | > loss_dur: 1.3612018823623657  (1.4002181027016503)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6309, device='cuda:0')  (tensor(3.7421, device='cuda:0'))\n",
      "     | > current_lr: 1.75e-06 \n",
      "     | > step_time: 0.6666  (0.42622216563311943)\n",
      "     | > loader_time: 0.006  (0.004419083383624921)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.13149431347846985 \u001b[0m(+0.03928157687187195)\n",
      "     | > avg_loss:\u001b[92m 1.6319293677806854 \u001b[0m(-0.21442611515522003)\n",
      "     | > avg_log_mle:\u001b[92m 0.38179687410593033 \u001b[0m(-0.04607836529612541)\n",
      "     | > avg_loss_dur:\u001b[92m 1.2501325011253357 \u001b[0m(-0.16834774613380432)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_3248.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 8/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:09:36) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:09:53 -- STEP: 2/406 -- GLOBAL_STEP: 3250\u001b[0m\n",
      "     | > loss: 1.807051658630371  (1.7946394085884094)\n",
      "     | > log_mle: 0.4152819514274597  (0.409729927778244)\n",
      "     | > loss_dur: 1.3917697668075562  (1.3849095106124878)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6095, device='cuda:0')  (tensor(3.6702, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.2452  (0.26423943042755127)\n",
      "     | > loader_time: 0.001  (0.0010008811950683594)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:10:00 -- STEP: 27/406 -- GLOBAL_STEP: 3275\u001b[0m\n",
      "     | > loss: 1.645958423614502  (1.717879542598018)\n",
      "     | > log_mle: 0.41183561086654663  (0.40935300566531996)\n",
      "     | > loss_dur: 1.2341228723526  (1.3085265380364877)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4059, device='cuda:0')  (tensor(3.5566, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.2622  (0.2594206774676288)\n",
      "     | > loader_time: 0.002  (0.01316005212289316)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:10:08 -- STEP: 52/406 -- GLOBAL_STEP: 3300\u001b[0m\n",
      "     | > loss: 1.659852147102356  (1.6980416981073527)\n",
      "     | > log_mle: 0.39514803886413574  (0.40596027271105695)\n",
      "     | > loss_dur: 1.2647041082382202  (1.2920814339931197)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4433, device='cuda:0')  (tensor(3.5211, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.2773  (0.2722470989594093)\n",
      "     | > loader_time: 0.002  (0.007949540248283973)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:10:16 -- STEP: 77/406 -- GLOBAL_STEP: 3325\u001b[0m\n",
      "     | > loss: 1.676579236984253  (1.6870969208804043)\n",
      "     | > log_mle: 0.39836257696151733  (0.4014788451906921)\n",
      "     | > loss_dur: 1.2782167196273804  (1.2856180838176183)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4974, device='cuda:0')  (tensor(3.5052, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.3633  (0.28545386760265795)\n",
      "     | > loader_time: 0.004  (0.006278474609573166)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:10:24 -- STEP: 102/406 -- GLOBAL_STEP: 3350\u001b[0m\n",
      "     | > loss: 1.6429493427276611  (1.6743270450947332)\n",
      "     | > log_mle: 0.36584484577178955  (0.3969877271675595)\n",
      "     | > loss_dur: 1.2771044969558716  (1.2773393228942274)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4452, device='cuda:0')  (tensor(3.4833, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.3793  (0.29894779242721253)\n",
      "     | > loader_time: 0.003  (0.005495221007104013)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:10:33 -- STEP: 127/406 -- GLOBAL_STEP: 3375\u001b[0m\n",
      "     | > loss: 1.6277395486831665  (1.6636034362898098)\n",
      "     | > log_mle: 0.3719794750213623  (0.3929260765004345)\n",
      "     | > loss_dur: 1.2557600736618042  (1.2706773647173184)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4310, device='cuda:0')  (tensor(3.4668, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.3283  (0.3107545450916441)\n",
      "     | > loader_time: 0.003  (0.00507547723965382)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:10:43 -- STEP: 152/406 -- GLOBAL_STEP: 3400\u001b[0m\n",
      "     | > loss: 1.609358310699463  (1.6575667418931659)\n",
      "     | > log_mle: 0.36854082345962524  (0.38934150044071036)\n",
      "     | > loss_dur: 1.2408175468444824  (1.2682252447856104)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3593, device='cuda:0')  (tensor(3.4574, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.4804  (0.3247026612884119)\n",
      "     | > loader_time: 0.005  (0.004826746488872327)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:10:54 -- STEP: 177/406 -- GLOBAL_STEP: 3425\u001b[0m\n",
      "     | > loss: 1.6124002933502197  (1.650962071903681)\n",
      "     | > log_mle: 0.35517317056655884  (0.3862293418181142)\n",
      "     | > loss_dur: 1.2572271823883057  (1.2647327353051832)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4129, device='cuda:0')  (tensor(3.4457, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.4774  (0.3379508667746505)\n",
      "     | > loader_time: 0.004  (0.004693501413205247)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:11:05 -- STEP: 202/406 -- GLOBAL_STEP: 3450\u001b[0m\n",
      "     | > loss: 1.5864923000335693  (1.6442384294944232)\n",
      "     | > log_mle: 0.36188703775405884  (0.38332060525322886)\n",
      "     | > loss_dur: 1.2246053218841553  (1.2609178282246734)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3275, device='cuda:0')  (tensor(3.4331, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.424  (0.3524549939844868)\n",
      "     | > loader_time: 0.004  (0.004622969296899169)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:11:17 -- STEP: 227/406 -- GLOBAL_STEP: 3475\u001b[0m\n",
      "     | > loss: 1.5760143995285034  (1.6373374372852003)\n",
      "     | > log_mle: 0.37027692794799805  (0.380569903992346)\n",
      "     | > loss_dur: 1.2057374715805054  (1.2567675381505017)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2567, device='cuda:0')  (tensor(3.4215, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.4194  (0.36593271142060535)\n",
      "     | > loader_time: 0.005  (0.004607637548236591)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:11:30 -- STEP: 252/406 -- GLOBAL_STEP: 3500\u001b[0m\n",
      "     | > loss: 1.5972869396209717  (1.6320391169616153)\n",
      "     | > log_mle: 0.35058706998825073  (0.37795035434620705)\n",
      "     | > loss_dur: 1.2466999292373657  (1.2540887665180933)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3967, device='cuda:0')  (tensor(3.4121, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.4474  (0.3797413158038306)\n",
      "     | > loader_time: 0.005  (0.004611241439032173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:11:44 -- STEP: 277/406 -- GLOBAL_STEP: 3525\u001b[0m\n",
      "     | > loss: 1.5655487775802612  (1.6262013619557183)\n",
      "     | > log_mle: 0.35177385807037354  (0.37541994818281155)\n",
      "     | > loss_dur: 1.2137749195098877  (1.2507814177537222)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2875, device='cuda:0')  (tensor(3.4011, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5685  (0.39331712103062155)\n",
      "     | > loader_time: 0.005  (0.0046250372587128205)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:11:57 -- STEP: 302/406 -- GLOBAL_STEP: 3550\u001b[0m\n",
      "     | > loss: 1.5637441873550415  (1.620942981432605)\n",
      "     | > log_mle: 0.34294962882995605  (0.37314333061114024)\n",
      "     | > loss_dur: 1.2207945585250854  (1.2477996538806437)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2734, device='cuda:0')  (tensor(3.3908, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6066  (0.4052749943259536)\n",
      "     | > loader_time: 0.005  (0.004639871073084949)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:12:11 -- STEP: 327/406 -- GLOBAL_STEP: 3575\u001b[0m\n",
      "     | > loss: 1.5514568090438843  (1.6152525039258714)\n",
      "     | > log_mle: 0.34411656856536865  (0.3710151782276433)\n",
      "     | > loss_dur: 1.2073402404785156  (1.2442373296171887)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3227, device='cuda:0')  (tensor(3.3803, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5492  (0.4170216806802545)\n",
      "     | > loader_time: 0.005  (0.00467080442912717)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:12:26 -- STEP: 352/406 -- GLOBAL_STEP: 3600\u001b[0m\n",
      "     | > loss: 1.5349870920181274  (1.6111934611743144)\n",
      "     | > log_mle: 0.3422718048095703  (0.3687906684353946)\n",
      "     | > loss_dur: 1.1927152872085571  (1.2424027970568705)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2299, device='cuda:0')  (tensor(3.3725, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5435  (0.42925984954292123)\n",
      "     | > loader_time: 0.006  (0.004703040827404369)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:12:42 -- STEP: 377/406 -- GLOBAL_STEP: 3625\u001b[0m\n",
      "     | > loss: 1.5508787631988525  (1.6055658249387055)\n",
      "     | > log_mle: 0.3357875347137451  (0.3666072038029485)\n",
      "     | > loss_dur: 1.2150912284851074  (1.2389586256416787)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.2480, device='cuda:0')  (tensor(3.3614, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.6836  (0.4416112450769156)\n",
      "     | > loader_time: 0.006  (0.004752231213395097)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:12:59 -- STEP: 402/406 -- GLOBAL_STEP: 3650\u001b[0m\n",
      "     | > loss: 1.5001742839813232  (1.6000437869954462)\n",
      "     | > log_mle: 0.3261774182319641  (0.36455202629020544)\n",
      "     | > loss_dur: 1.1739968061447144  (1.2354917650792139)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1484, device='cuda:0')  (tensor(3.3503, device='cuda:0'))\n",
      "     | > current_lr: 2e-06 \n",
      "     | > step_time: 0.5661  (0.45532554773548944)\n",
      "     | > loader_time: 0.004  (0.004772876625630393)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0957115888595581 \u001b[0m(-0.03578272461891174)\n",
      "     | > avg_loss:\u001b[92m 1.4607172310352325 \u001b[0m(-0.17121213674545288)\n",
      "     | > avg_log_mle:\u001b[92m 0.3397323340177536 \u001b[0m(-0.04206454008817673)\n",
      "     | > avg_loss_dur:\u001b[92m 1.120984897017479 \u001b[0m(-0.12914760410785675)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_3654.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 9/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:13:27) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:13:49 -- STEP: 21/406 -- GLOBAL_STEP: 3675\u001b[0m\n",
      "     | > loss: 1.45303475856781  (1.5392749082474482)\n",
      "     | > log_mle: 0.3629891872406006  (0.3686551792281015)\n",
      "     | > loss_dur: 1.0900455713272095  (1.1706197318576632)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0086, device='cuda:0')  (tensor(3.1987, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.2963  (0.2687677769433884)\n",
      "     | > loader_time: 0.003  (0.014966045107160295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:13:56 -- STEP: 46/406 -- GLOBAL_STEP: 3700\u001b[0m\n",
      "     | > loss: 1.5018861293792725  (1.5146283274111543)\n",
      "     | > log_mle: 0.3599849343299866  (0.3665861046832541)\n",
      "     | > loss_dur: 1.1419012546539307  (1.1480422227279)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1513, device='cuda:0')  (tensor(3.1491, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.3133  (0.281298912089804)\n",
      "     | > loader_time: 0.003  (0.008159611536108927)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:14:05 -- STEP: 71/406 -- GLOBAL_STEP: 3725\u001b[0m\n",
      "     | > loss: 1.4985122680664062  (1.505898089476035)\n",
      "     | > log_mle: 0.35283786058425903  (0.3612478115189243)\n",
      "     | > loss_dur: 1.1456743478775024  (1.1446502796361142)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1964, device='cuda:0')  (tensor(3.1343, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.3653  (0.2939570991086289)\n",
      "     | > loader_time: 0.002  (0.006259129080973879)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:14:13 -- STEP: 96/406 -- GLOBAL_STEP: 3750\u001b[0m\n",
      "     | > loss: 1.4933829307556152  (1.4959862654407818)\n",
      "     | > log_mle: 0.3421473503112793  (0.3564852265020211)\n",
      "     | > loss_dur: 1.151235580444336  (1.1395010401805248)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1388, device='cuda:0')  (tensor(3.1166, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.3843  (0.3067786519726117)\n",
      "     | > loader_time: 0.003  (0.005463168025016785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:14:23 -- STEP: 121/406 -- GLOBAL_STEP: 3775\u001b[0m\n",
      "     | > loss: 1.472718358039856  (1.4877768794367137)\n",
      "     | > log_mle: 0.33813047409057617  (0.3524516840611607)\n",
      "     | > loss_dur: 1.1345878839492798  (1.1353251983311559)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0551, device='cuda:0')  (tensor(3.1024, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4054  (0.3205225526793929)\n",
      "     | > loader_time: 0.003  (0.005020937643760492)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:14:32 -- STEP: 146/406 -- GLOBAL_STEP: 3800\u001b[0m\n",
      "     | > loss: 1.4505598545074463  (1.482383510021314)\n",
      "     | > log_mle: 0.33912545442581177  (0.3487086214431344)\n",
      "     | > loss_dur: 1.1114343404769897  (1.1336748910276866)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9913, device='cuda:0')  (tensor(3.0928, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4304  (0.3318562376989077)\n",
      "     | > loader_time: 0.003  (0.004750723708165835)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:14:43 -- STEP: 171/406 -- GLOBAL_STEP: 3825\u001b[0m\n",
      "     | > loss: 1.4132421016693115  (1.4772494668849032)\n",
      "     | > log_mle: 0.3246147036552429  (0.3456073019936769)\n",
      "     | > loss_dur: 1.0886274576187134  (1.131642166634053)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0154, device='cuda:0')  (tensor(3.0825, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4574  (0.34306013653850004)\n",
      "     | > loader_time: 0.004  (0.004612204624198333)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:14:54 -- STEP: 196/406 -- GLOBAL_STEP: 3850\u001b[0m\n",
      "     | > loss: 1.4252820014953613  (1.472787003127896)\n",
      "     | > log_mle: 0.3173918128013611  (0.3426334514301651)\n",
      "     | > loss_dur: 1.1078901290893555  (1.130153551393627)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0597, device='cuda:0')  (tensor(3.0730, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4924  (0.3562215116559242)\n",
      "     | > loader_time: 0.004  (0.004544766581788353)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:15:06 -- STEP: 221/406 -- GLOBAL_STEP: 3875\u001b[0m\n",
      "     | > loss: 1.443884253501892  (1.4674743494836453)\n",
      "     | > log_mle: 0.326615571975708  (0.3399917402418491)\n",
      "     | > loss_dur: 1.117268681526184  (1.1274826078932765)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9826, device='cuda:0')  (tensor(3.0606, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4224  (0.3669350848478429)\n",
      "     | > loader_time: 0.004  (0.004506180189313927)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:15:18 -- STEP: 246/406 -- GLOBAL_STEP: 3900\u001b[0m\n",
      "     | > loss: 1.3986239433288574  (1.4633579481907977)\n",
      "     | > log_mle: 0.31353938579559326  (0.3374273406296242)\n",
      "     | > loss_dur: 1.0850845575332642  (1.1259306078034699)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9474, device='cuda:0')  (tensor(3.0532, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4584  (0.37838431974736647)\n",
      "     | > loader_time: 0.005  (0.004483574774207134)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:15:31 -- STEP: 271/406 -- GLOBAL_STEP: 3925\u001b[0m\n",
      "     | > loss: 1.4226499795913696  (1.4593739487588187)\n",
      "     | > log_mle: 0.29659199714660645  (0.3350067277236179)\n",
      "     | > loss_dur: 1.1260579824447632  (1.1243672203753718)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9579, device='cuda:0')  (tensor(3.0444, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.4634  (0.39067956002436)\n",
      "     | > loader_time: 0.004  (0.0044725293163003915)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:15:44 -- STEP: 296/406 -- GLOBAL_STEP: 3950\u001b[0m\n",
      "     | > loss: 1.4372049570083618  (1.455632315696897)\n",
      "     | > log_mle: 0.30980002880096436  (0.3327827993276958)\n",
      "     | > loss_dur: 1.1274049282073975  (1.12284951717467)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9518, device='cuda:0')  (tensor(3.0353, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5125  (0.40179736791430287)\n",
      "     | > loader_time: 0.005  (0.0044971470897262125)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:15:58 -- STEP: 321/406 -- GLOBAL_STEP: 3975\u001b[0m\n",
      "     | > loss: 1.389716625213623  (1.4515943092720534)\n",
      "     | > log_mle: 0.3024929165840149  (0.33074750484335824)\n",
      "     | > loss_dur: 1.0872236490249634  (1.1208468051714322)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8934, device='cuda:0')  (tensor(3.0268, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5225  (0.4142079813829462)\n",
      "     | > loader_time: 0.005  (0.004530407557977691)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:16:13 -- STEP: 346/406 -- GLOBAL_STEP: 4000\u001b[0m\n",
      "     | > loss: 1.3947250843048096  (1.4486868402172373)\n",
      "     | > log_mle: 0.3064168691635132  (0.32857202484428544)\n",
      "     | > loss_dur: 1.0883082151412964  (1.1201148160620236)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8577, device='cuda:0')  (tensor(3.0210, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5455  (0.42614137023859616)\n",
      "     | > loader_time: 0.005  (0.004555977148816763)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_4000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:16:31 -- STEP: 371/406 -- GLOBAL_STEP: 4025\u001b[0m\n",
      "     | > loss: 1.3865835666656494  (1.4448711447959957)\n",
      "     | > log_mle: 0.2956082820892334  (0.326471569081844)\n",
      "     | > loss_dur: 1.090975284576416  (1.1183995769994277)\n",
      "     | > amp_scaler: 32768.0  (17002.264150943392)\n",
      "     | > grad_norm: tensor(2.8696, device='cuda:0')  (tensor(3.0129, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5645  (0.4378478051517207)\n",
      "     | > loader_time: 0.005  (0.004596973686526727)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:16:47 -- STEP: 396/406 -- GLOBAL_STEP: 4050\u001b[0m\n",
      "     | > loss: 1.375694990158081  (1.4409674574630422)\n",
      "     | > log_mle: 0.28183841705322266  (0.3245388245341754)\n",
      "     | > loss_dur: 1.0938565731048584  (1.116428633831968)\n",
      "     | > amp_scaler: 32768.0  (17997.575757575763)\n",
      "     | > grad_norm: tensor(2.9060, device='cuda:0')  (tensor(3.0052, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-06 \n",
      "     | > step_time: 0.5865  (0.45125327327034676)\n",
      "     | > loader_time: 0.005  (0.004637850655449762)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09295958280563354 \u001b[0m(-0.0027520060539245605)\n",
      "     | > avg_loss:\u001b[92m 1.3389358967542648 \u001b[0m(-0.12178133428096771)\n",
      "     | > avg_log_mle:\u001b[92m 0.3010505884885788 \u001b[0m(-0.038681745529174805)\n",
      "     | > avg_loss_dur:\u001b[92m 1.0378853231668472 \u001b[0m(-0.08309957385063171)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_4060.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 10/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:17:19) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:17:39 -- STEP: 15/406 -- GLOBAL_STEP: 4075\u001b[0m\n",
      "     | > loss: 1.3893070220947266  (1.412311593691508)\n",
      "     | > log_mle: 0.31886744499206543  (0.32883421977361044)\n",
      "     | > loss_dur: 1.0704395771026611  (1.0834773699442548)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8125, device='cuda:0')  (tensor(2.9211, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.2592  (0.25489794413248695)\n",
      "     | > loader_time: 0.002  (0.01801641782124837)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:17:46 -- STEP: 40/406 -- GLOBAL_STEP: 4100\u001b[0m\n",
      "     | > loss: 1.3391468524932861  (1.3841303825378417)\n",
      "     | > log_mle: 0.33697831630706787  (0.3284927666187286)\n",
      "     | > loss_dur: 1.0021685361862183  (1.0556376159191134)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6761, device='cuda:0')  (tensor(2.8416, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.3013  (0.2656911015510559)\n",
      "     | > loader_time: 0.003  (0.008082419633865356)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:17:54 -- STEP: 65/406 -- GLOBAL_STEP: 4125\u001b[0m\n",
      "     | > loss: 1.3802695274353027  (1.3743983122018668)\n",
      "     | > log_mle: 0.3146671652793884  (0.324019144131587)\n",
      "     | > loss_dur: 1.065602421760559  (1.0503791708212642)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8521, device='cuda:0')  (tensor(2.8181, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.3533  (0.28005422078646147)\n",
      "     | > loader_time: 0.003  (0.006020876077505259)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:18:03 -- STEP: 90/406 -- GLOBAL_STEP: 4150\u001b[0m\n",
      "     | > loss: 1.3442022800445557  (1.367396756013235)\n",
      "     | > log_mle: 0.30599814653396606  (0.31944083703888787)\n",
      "     | > loss_dur: 1.0382041931152344  (1.047955923610264)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7922, device='cuda:0')  (tensor(2.8073, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.3843  (0.29830417633056655)\n",
      "     | > loader_time: 0.004  (0.005204698774549696)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:18:12 -- STEP: 115/406 -- GLOBAL_STEP: 4175\u001b[0m\n",
      "     | > loss: 1.341113567352295  (1.3585138839224116)\n",
      "     | > log_mle: 0.30933451652526855  (0.31494015144265214)\n",
      "     | > loss_dur: 1.0317790508270264  (1.0435737397359761)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7575, device='cuda:0')  (tensor(2.7948, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.3333  (0.31272742022638755)\n",
      "     | > loader_time: 0.004  (0.004795615569404933)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:18:22 -- STEP: 140/406 -- GLOBAL_STEP: 4200\u001b[0m\n",
      "     | > loss: 1.3159937858581543  (1.353612330981664)\n",
      "     | > log_mle: 0.284498393535614  (0.3110653715474265)\n",
      "     | > loss_dur: 1.0314953327178955  (1.0425469641174587)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8057, device='cuda:0')  (tensor(2.7872, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.3603  (0.32750452756881726)\n",
      "     | > loader_time: 0.004  (0.004611318452017647)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:18:32 -- STEP: 165/406 -- GLOBAL_STEP: 4225\u001b[0m\n",
      "     | > loss: 1.310457706451416  (1.3492983803604592)\n",
      "     | > log_mle: 0.27930784225463867  (0.30792399644851703)\n",
      "     | > loss_dur: 1.0311498641967773  (1.0413743871631043)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6886, device='cuda:0')  (tensor(2.7803, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.3723  (0.3397872953703909)\n",
      "     | > loader_time: 0.004  (0.004507141402273467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:18:43 -- STEP: 190/406 -- GLOBAL_STEP: 4250\u001b[0m\n",
      "     | > loss: 1.328051209449768  (1.345349202030583)\n",
      "     | > log_mle: 0.27696681022644043  (0.30484786817902026)\n",
      "     | > loss_dur: 1.0510843992233276  (1.0405013360475237)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7924, device='cuda:0')  (tensor(2.7730, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.3964  (0.3519248021276374)\n",
      "     | > loader_time: 0.003  (0.004430369326942845)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:18:55 -- STEP: 215/406 -- GLOBAL_STEP: 4275\u001b[0m\n",
      "     | > loss: 1.2943544387817383  (1.3405162312263663)\n",
      "     | > log_mle: 0.27858400344848633  (0.30229884857355177)\n",
      "     | > loss_dur: 1.015770435333252  (1.0382173837617386)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6451, device='cuda:0')  (tensor(2.7632, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.4054  (0.363152990784756)\n",
      "     | > loader_time: 0.005  (0.004390051198560139)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:19:07 -- STEP: 240/406 -- GLOBAL_STEP: 4300\u001b[0m\n",
      "     | > loss: 1.2803876399993896  (1.3368319287896153)\n",
      "     | > log_mle: 0.26865845918655396  (0.29967769111196213)\n",
      "     | > loss_dur: 1.0117292404174805  (1.0371542389194166)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7345, device='cuda:0')  (tensor(2.7563, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5325  (0.3746610114971797)\n",
      "     | > loader_time: 0.005  (0.004391482472419741)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:19:19 -- STEP: 265/406 -- GLOBAL_STEP: 4325\u001b[0m\n",
      "     | > loss: 1.3032034635543823  (1.33340772772735)\n",
      "     | > log_mle: 0.26630961894989014  (0.29726345719031577)\n",
      "     | > loss_dur: 1.0368938446044922  (1.0361442725613428)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7136, device='cuda:0')  (tensor(2.7520, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.4394  (0.38645276393530503)\n",
      "     | > loader_time: 0.004  (0.004366224216965011)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:19:32 -- STEP: 290/406 -- GLOBAL_STEP: 4350\u001b[0m\n",
      "     | > loss: 1.2737390995025635  (1.3299289892459731)\n",
      "     | > log_mle: 0.2572675347328186  (0.29488778114318853)\n",
      "     | > loss_dur: 1.0164715051651  (1.0350412091304515)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6448, device='cuda:0')  (tensor(2.7449, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5945  (0.39676369140888085)\n",
      "     | > loader_time: 0.005  (0.004369467702405207)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:19:46 -- STEP: 315/406 -- GLOBAL_STEP: 4375\u001b[0m\n",
      "     | > loss: 1.2567994594573975  (1.3267666370149638)\n",
      "     | > log_mle: 0.2513921856880188  (0.2928416284303818)\n",
      "     | > loss_dur: 1.0054073333740234  (1.0339250085845824)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5855, device='cuda:0')  (tensor(2.7384, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5225  (0.40827545211428706)\n",
      "     | > loader_time: 0.005  (0.004413504070705838)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:20:00 -- STEP: 340/406 -- GLOBAL_STEP: 4400\u001b[0m\n",
      "     | > loss: 1.3121833801269531  (1.3239937235327324)\n",
      "     | > log_mle: 0.2669186592102051  (0.2908211776438883)\n",
      "     | > loss_dur: 1.045264720916748  (1.0331725455382295)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6940, device='cuda:0')  (tensor(2.7341, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5205  (0.41970459082547373)\n",
      "     | > loader_time: 0.005  (0.004445205716525808)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:20:15 -- STEP: 365/406 -- GLOBAL_STEP: 4425\u001b[0m\n",
      "     | > loss: 1.2232900857925415  (1.3208980916297597)\n",
      "     | > log_mle: 0.2631533741950989  (0.28870176942381154)\n",
      "     | > loss_dur: 0.9601367115974426  (1.0321963213894472)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4649, device='cuda:0')  (tensor(2.7275, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.5925  (0.43160829086826286)\n",
      "     | > loader_time: 0.005  (0.004489009021079706)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:20:31 -- STEP: 390/406 -- GLOBAL_STEP: 4450\u001b[0m\n",
      "     | > loss: 1.2575626373291016  (1.3173179690654466)\n",
      "     | > log_mle: 0.24949711561203003  (0.2867560317883126)\n",
      "     | > loss_dur: 1.0080655813217163  (1.0305619369714698)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5990, device='cuda:0')  (tensor(2.7220, device='cuda:0'))\n",
      "     | > current_lr: 2.4999999999999998e-06 \n",
      "     | > step_time: 0.7167  (0.4450091410905888)\n",
      "     | > loader_time: 0.005  (0.004552860137743828)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08670398592948914 \u001b[0m(-0.006255596876144409)\n",
      "     | > avg_loss:\u001b[92m 1.2304100692272186 \u001b[0m(-0.1085258275270462)\n",
      "     | > avg_log_mle:\u001b[92m 0.2629867419600487 \u001b[0m(-0.03806384652853012)\n",
      "     | > avg_loss_dur:\u001b[92m 0.9674233347177505 \u001b[0m(-0.07046198844909668)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_4466.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 11/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:21:07) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:21:26 -- STEP: 9/406 -- GLOBAL_STEP: 4475\u001b[0m\n",
      "     | > loss: 1.3058152198791504  (1.305922057893541)\n",
      "     | > log_mle: 0.29649990797042847  (0.2962461643748813)\n",
      "     | > loss_dur: 1.0093152523040771  (1.0096758802731831)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6617, device='cuda:0')  (tensor(2.7130, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.2582  (0.2646845446692573)\n",
      "     | > loader_time: 0.001  (0.027580738067626953)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:21:33 -- STEP: 34/406 -- GLOBAL_STEP: 4500\u001b[0m\n",
      "     | > loss: 1.2529594898223877  (1.2694314507877125)\n",
      "     | > log_mle: 0.3025243878364563  (0.29091251597684975)\n",
      "     | > loss_dur: 0.9504351019859314  (0.9785189313047072)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5617, device='cuda:0')  (tensor(2.5885, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.2732  (0.26995046699748315)\n",
      "     | > loader_time: 0.002  (0.00871424114002901)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:21:41 -- STEP: 59/406 -- GLOBAL_STEP: 4525\u001b[0m\n",
      "     | > loss: 1.2315356731414795  (1.2599981558524955)\n",
      "     | > log_mle: 0.2656465768814087  (0.28675924519361073)\n",
      "     | > loss_dur: 0.9658891558647156  (0.9732389056076438)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4250, device='cuda:0')  (tensor(2.5520, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.3343  (0.28559796284821076)\n",
      "     | > loader_time: 0.003  (0.006192276033304508)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:21:49 -- STEP: 84/406 -- GLOBAL_STEP: 4550\u001b[0m\n",
      "     | > loss: 1.2281348705291748  (1.2537218303907485)\n",
      "     | > log_mle: 0.27229130268096924  (0.28264188837437393)\n",
      "     | > loss_dur: 0.9558435082435608  (0.9710799427259535)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4525, device='cuda:0')  (tensor(2.5394, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.3043  (0.2980323774474008)\n",
      "     | > loader_time: 0.003  (0.005183307897476923)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:21:58 -- STEP: 109/406 -- GLOBAL_STEP: 4575\u001b[0m\n",
      "     | > loss: 1.2125728130340576  (1.2445733219111736)\n",
      "     | > log_mle: 0.25204265117645264  (0.27817292115010245)\n",
      "     | > loss_dur: 0.960530161857605  (0.9664004062293866)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4976, device='cuda:0')  (tensor(2.5255, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.3904  (0.3108234186784937)\n",
      "     | > loader_time: 0.003  (0.004701550947416813)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:22:07 -- STEP: 134/406 -- GLOBAL_STEP: 4600\u001b[0m\n",
      "     | > loss: 1.2301127910614014  (1.2389238014150026)\n",
      "     | > log_mle: 0.2545313239097595  (0.27403051995519373)\n",
      "     | > loss_dur: 0.9755814075469971  (0.9648932854631054)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4972, device='cuda:0')  (tensor(2.5199, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.4264  (0.3217323609252475)\n",
      "     | > loader_time: 0.004  (0.004511560966719443)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:22:17 -- STEP: 159/406 -- GLOBAL_STEP: 4625\u001b[0m\n",
      "     | > loss: 1.2020437717437744  (1.2355471691995303)\n",
      "     | > log_mle: 0.2534898519515991  (0.2707783980939371)\n",
      "     | > loss_dur: 0.9485538601875305  (0.9647687752291841)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4443, device='cuda:0')  (tensor(2.5153, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.3783  (0.3331074774640162)\n",
      "     | > loader_time: 0.004  (0.004393859479412343)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:22:28 -- STEP: 184/406 -- GLOBAL_STEP: 4650\u001b[0m\n",
      "     | > loss: 1.2533483505249023  (1.2319066712389826)\n",
      "     | > log_mle: 0.2311837077140808  (0.2676593758489775)\n",
      "     | > loss_dur: 1.0221645832061768  (0.9642472999251407)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6125, device='cuda:0')  (tensor(2.5103, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.3884  (0.34579769165619556)\n",
      "     | > loader_time: 0.004  (0.00433535161225692)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:22:39 -- STEP: 209/406 -- GLOBAL_STEP: 4675\u001b[0m\n",
      "     | > loss: 1.2258027791976929  (1.2281810735401348)\n",
      "     | > log_mle: 0.2349703311920166  (0.26487082670750217)\n",
      "     | > loss_dur: 0.9908324480056763  (0.9633102516808578)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6030, device='cuda:0')  (tensor(2.5073, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.3974  (0.35746332332848363)\n",
      "     | > loader_time: 0.004  (0.004290886472857168)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:22:51 -- STEP: 234/406 -- GLOBAL_STEP: 4700\u001b[0m\n",
      "     | > loss: 1.2083964347839355  (1.224094902348314)\n",
      "     | > log_mle: 0.23106133937835693  (0.2621266182161802)\n",
      "     | > loss_dur: 0.9773350954055786  (0.9619682889718276)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4262, device='cuda:0')  (tensor(2.5010, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5365  (0.36802221567202836)\n",
      "     | > loader_time: 0.004  (0.00428582969893757)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:23:04 -- STEP: 259/406 -- GLOBAL_STEP: 4725\u001b[0m\n",
      "     | > loss: 1.1847684383392334  (1.2211715843686721)\n",
      "     | > log_mle: 0.2213260531425476  (0.25957823259950125)\n",
      "     | > loss_dur: 0.963442325592041  (0.9615933572923815)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4590, device='cuda:0')  (tensor(2.5030, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5485  (0.3809289435162047)\n",
      "     | > loader_time: 0.005  (0.004293337751999784)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:23:16 -- STEP: 284/406 -- GLOBAL_STEP: 4750\u001b[0m\n",
      "     | > loss: 1.2034810781478882  (1.2179310208475083)\n",
      "     | > log_mle: 0.22757679224014282  (0.2571464808474122)\n",
      "     | > loss_dur: 0.9759042859077454  (0.960784545666735)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4580, device='cuda:0')  (tensor(2.4999, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5695  (0.39214131529902063)\n",
      "     | > loader_time: 0.005  (0.004324218756716016)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:23:30 -- STEP: 309/406 -- GLOBAL_STEP: 4775\u001b[0m\n",
      "     | > loss: 1.1574575901031494  (1.2151145757594917)\n",
      "     | > log_mle: 0.23146706819534302  (0.2550693763884138)\n",
      "     | > loss_dur: 0.9259905219078064  (0.9600452051579373)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4532, device='cuda:0')  (tensor(2.4936, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6456  (0.4043736997931519)\n",
      "     | > loader_time: 0.005  (0.004359800067148548)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:23:44 -- STEP: 334/406 -- GLOBAL_STEP: 4800\u001b[0m\n",
      "     | > loss: 1.2087844610214233  (1.2122295877176839)\n",
      "     | > log_mle: 0.22061902284622192  (0.2529817005831321)\n",
      "     | > loss_dur: 0.9881654381752014  (0.9592478923098056)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4930, device='cuda:0')  (tensor(2.4896, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.6576  (0.41585368239237147)\n",
      "     | > loader_time: 0.005  (0.004411049945625719)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:23:59 -- STEP: 359/406 -- GLOBAL_STEP: 4825\u001b[0m\n",
      "     | > loss: 1.1525788307189941  (1.2097783191622462)\n",
      "     | > log_mle: 0.22764700651168823  (0.25081370700368605)\n",
      "     | > loss_dur: 0.9249317646026611  (0.9589646163093014)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4682, device='cuda:0')  (tensor(2.4867, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5655  (0.4278118949082567)\n",
      "     | > loader_time: 0.007  (0.004463515241830132)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:24:15 -- STEP: 384/406 -- GLOBAL_STEP: 4850\u001b[0m\n",
      "     | > loss: 1.1389610767364502  (1.2064888834332421)\n",
      "     | > log_mle: 0.22725504636764526  (0.24882153576860788)\n",
      "     | > loss_dur: 0.9117059707641602  (0.9576673517003655)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3424, device='cuda:0')  (tensor(2.4833, device='cuda:0'))\n",
      "     | > current_lr: 2.75e-06 \n",
      "     | > step_time: 0.5785  (0.440616260593136)\n",
      "     | > loader_time: 0.005  (0.004509167745709422)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10572144389152527 \u001b[0m(+0.019017457962036133)\n",
      "     | > avg_loss:\u001b[92m 1.1316362917423248 \u001b[0m(-0.0987737774848938)\n",
      "     | > avg_log_mle:\u001b[92m 0.22369176894426346 \u001b[0m(-0.03929497301578522)\n",
      "     | > avg_loss_dur:\u001b[92m 0.9079445153474808 \u001b[0m(-0.059478819370269775)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_4872.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 12/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:24:58) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:25:16 -- STEP: 3/406 -- GLOBAL_STEP: 4875\u001b[0m\n",
      "     | > loss: 1.2441374063491821  (1.2217656373977661)\n",
      "     | > log_mle: 0.2526509761810303  (0.25191187858581543)\n",
      "     | > loss_dur: 0.9914864301681519  (0.9698537190755209)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3369, device='cuda:0')  (tensor(2.5013, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.2612  (0.27625107765197754)\n",
      "     | > loader_time: 0.2732  (0.09241716066996257)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:25:23 -- STEP: 28/406 -- GLOBAL_STEP: 4900\u001b[0m\n",
      "     | > loss: 1.1449253559112549  (1.1652132102421355)\n",
      "     | > log_mle: 0.2488000988960266  (0.25266188383102417)\n",
      "     | > loss_dur: 0.8961252570152283  (0.912551320024899)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2796, device='cuda:0')  (tensor(2.3797, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.2943  (0.28676028762544903)\n",
      "     | > loader_time: 0.003  (0.011689279760633196)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:25:31 -- STEP: 53/406 -- GLOBAL_STEP: 4925\u001b[0m\n",
      "     | > loss: 1.1275396347045898  (1.154867604093732)\n",
      "     | > log_mle: 0.24775731563568115  (0.24947333785722842)\n",
      "     | > loss_dur: 0.8797822594642639  (0.9053942549903438)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4936, device='cuda:0')  (tensor(2.3503, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.3283  (0.29532464495245025)\n",
      "     | > loader_time: 0.003  (0.00747858803227263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:25:39 -- STEP: 78/406 -- GLOBAL_STEP: 4950\u001b[0m\n",
      "     | > loss: 1.101688265800476  (1.1483109960189235)\n",
      "     | > log_mle: 0.2372722625732422  (0.24486392048689035)\n",
      "     | > loss_dur: 0.8644160032272339  (0.9034470640696012)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1496, device='cuda:0')  (tensor(2.3375, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.3123  (0.3057262714092549)\n",
      "     | > loader_time: 0.003  (0.006056816149980596)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:25:48 -- STEP: 103/406 -- GLOBAL_STEP: 4975\u001b[0m\n",
      "     | > loss: 1.1037956476211548  (1.1408614394734204)\n",
      "     | > log_mle: 0.19617557525634766  (0.23990606220023145)\n",
      "     | > loss_dur: 0.9076200723648071  (0.9009553697502729)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2420, device='cuda:0')  (tensor(2.3247, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.3233  (0.3171908392489535)\n",
      "     | > loader_time: 0.004  (0.005402981656268962)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:25:57 -- STEP: 128/406 -- GLOBAL_STEP: 5000\u001b[0m\n",
      "     | > loss: 1.1475343704223633  (1.1345879063010216)\n",
      "     | > log_mle: 0.2103545069694519  (0.23588546738028526)\n",
      "     | > loss_dur: 0.9371798634529114  (0.8987024333328009)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2816, device='cuda:0')  (tensor(2.3175, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4194  (0.32889233715832233)\n",
      "     | > loader_time: 0.004  (0.005035808309912682)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_5000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:26:10 -- STEP: 153/406 -- GLOBAL_STEP: 5025\u001b[0m\n",
      "     | > loss: 1.116961121559143  (1.1314098632413578)\n",
      "     | > log_mle: 0.21967679262161255  (0.23242463473401037)\n",
      "     | > loss_dur: 0.8972843289375305  (0.8989852230533276)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6126, device='cuda:0')  (tensor(2.3209, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.3743  (0.34079307512520185)\n",
      "     | > loader_time: 0.004  (0.0048605600992838545)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:26:21 -- STEP: 178/406 -- GLOBAL_STEP: 5050\u001b[0m\n",
      "     | > loss: 1.1031972169876099  (1.1278570722997865)\n",
      "     | > log_mle: 0.22153806686401367  (0.2293595520967848)\n",
      "     | > loss_dur: 0.8816591501235962  (0.8984975161847104)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2314, device='cuda:0')  (tensor(2.3222, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4864  (0.35232551044292654)\n",
      "     | > loader_time: 0.005  (0.004751429129182623)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:26:32 -- STEP: 203/406 -- GLOBAL_STEP: 5075\u001b[0m\n",
      "     | > loss: 1.1056694984436035  (1.1242370717043952)\n",
      "     | > log_mle: 0.2143632173538208  (0.22647109965385476)\n",
      "     | > loss_dur: 0.8913063406944275  (0.8977659694079695)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2599, device='cuda:0')  (tensor(2.3255, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4354  (0.3638229616757096)\n",
      "     | > loader_time: 0.004  (0.004664230816469992)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:26:44 -- STEP: 228/406 -- GLOBAL_STEP: 5100\u001b[0m\n",
      "     | > loss: 1.1073729991912842  (1.1202132973754622)\n",
      "     | > log_mle: 0.19256073236465454  (0.2236505903695759)\n",
      "     | > loss_dur: 0.9148122072219849  (0.8965627043916468)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4194, device='cuda:0')  (tensor(2.3353, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.5315  (0.3746647395585712)\n",
      "     | > loader_time: 0.005  (0.004640081472564162)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:26:56 -- STEP: 253/406 -- GLOBAL_STEP: 5125\u001b[0m\n",
      "     | > loss: 1.099778652191162  (1.117405469238523)\n",
      "     | > log_mle: 0.18228626251220703  (0.22104789758388232)\n",
      "     | > loss_dur: 0.9174923896789551  (0.8963575695343169)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4207, device='cuda:0')  (tensor(2.3370, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4414  (0.38633496299562714)\n",
      "     | > loader_time: 0.004  (0.004632571940365516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:27:09 -- STEP: 278/406 -- GLOBAL_STEP: 5150\u001b[0m\n",
      "     | > loss: 1.0615894794464111  (1.1140943431168155)\n",
      "     | > log_mle: 0.208737313747406  (0.2186457330374409)\n",
      "     | > loss_dur: 0.8528521656990051  (0.8954486081497277)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2038, device='cuda:0')  (tensor(2.3400, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.5905  (0.3983725009204672)\n",
      "     | > loader_time: 0.005  (0.004640803920279304)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:27:23 -- STEP: 303/406 -- GLOBAL_STEP: 5175\u001b[0m\n",
      "     | > loss: 1.0897150039672852  (1.1114524937305517)\n",
      "     | > log_mle: 0.19682073593139648  (0.21642894713398653)\n",
      "     | > loss_dur: 0.8928943276405334  (0.8950235450228451)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3589, device='cuda:0')  (tensor(2.3378, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.4784  (0.409870502578937)\n",
      "     | > loader_time: 0.005  (0.004657584841888732)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:27:38 -- STEP: 328/406 -- GLOBAL_STEP: 5200\u001b[0m\n",
      "     | > loss: 1.1041325330734253  (1.1081825512938388)\n",
      "     | > log_mle: 0.1886519193649292  (0.2143843541058099)\n",
      "     | > loss_dur: 0.9154806137084961  (0.8937981950073709)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5897, device='cuda:0')  (tensor(2.3374, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.6516  (0.4221302096436665)\n",
      "     | > loader_time: 0.005  (0.004705394186624666)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:27:53 -- STEP: 353/406 -- GLOBAL_STEP: 5225\u001b[0m\n",
      "     | > loss: 1.072314977645874  (1.1062020532807957)\n",
      "     | > log_mle: 0.17329192161560059  (0.2122197088708959)\n",
      "     | > loss_dur: 0.8990231156349182  (0.8939823423836794)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3078, device='cuda:0')  (tensor(2.3326, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.6916  (0.43445678000409627)\n",
      "     | > loader_time: 0.006  (0.004754917479777135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:28:08 -- STEP: 378/406 -- GLOBAL_STEP: 5250\u001b[0m\n",
      "     | > loss: 1.0660215616226196  (1.1029502916588363)\n",
      "     | > log_mle: 0.18820995092391968  (0.2101293900025585)\n",
      "     | > loss_dur: 0.8778116106987  (0.8928208999217504)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2064, device='cuda:0')  (tensor(2.3317, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.7156  (0.44713348307937556)\n",
      "     | > loader_time: 0.006  (0.004816421125300978)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:28:26 -- STEP: 403/406 -- GLOBAL_STEP: 5275\u001b[0m\n",
      "     | > loss: 1.0343437194824219  (1.0997653980704754)\n",
      "     | > log_mle: 0.17905795574188232  (0.208102500172466)\n",
      "     | > loss_dur: 0.8552858233451843  (0.8916628961231811)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1185, device='cuda:0')  (tensor(2.3276, device='cuda:0'))\n",
      "     | > current_lr: 3e-06 \n",
      "     | > step_time: 0.7519  (0.46125491677087843)\n",
      "     | > loader_time: 0.004  (0.0048628415422463265)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.11310294270515442 \u001b[0m(+0.00738149881362915)\n",
      "     | > avg_loss:\u001b[92m 1.0379213690757751 \u001b[0m(-0.09371492266654968)\n",
      "     | > avg_log_mle:\u001b[92m 0.18703021109104156 \u001b[0m(-0.03666155785322189)\n",
      "     | > avg_loss_dur:\u001b[92m 0.850891150534153 \u001b[0m(-0.05705336481332779)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_5278.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 13/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:28:55) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:29:19 -- STEP: 22/406 -- GLOBAL_STEP: 5300\u001b[0m\n",
      "     | > loss: 1.0076208114624023  (1.0669095570390874)\n",
      "     | > log_mle: 0.21412116289138794  (0.2146090350367806)\n",
      "     | > loss_dur: 0.7934997081756592  (0.8523005165837028)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0608, device='cuda:0')  (tensor(2.2001, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.3093  (0.2911732521924106)\n",
      "     | > loader_time: 0.003  (0.015104662288318981)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:29:28 -- STEP: 47/406 -- GLOBAL_STEP: 5325\u001b[0m\n",
      "     | > loss: 1.0827209949493408  (1.054830163083178)\n",
      "     | > log_mle: 0.1939343810081482  (0.2123933142804085)\n",
      "     | > loss_dur: 0.8887865543365479  (0.8424368488027695)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2385, device='cuda:0')  (tensor(2.1607, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.3363  (0.3091529227317647)\n",
      "     | > loader_time: 0.003  (0.008433179652437253)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:29:36 -- STEP: 72/406 -- GLOBAL_STEP: 5350\u001b[0m\n",
      "     | > loss: 1.0295460224151611  (1.0491315863198705)\n",
      "     | > log_mle: 0.20870840549468994  (0.20751937644349205)\n",
      "     | > loss_dur: 0.820837676525116  (0.8416122131877476)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0745, device='cuda:0')  (tensor(2.1577, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.3523  (0.32118033369382215)\n",
      "     | > loader_time: 0.003  (0.006589326593610976)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:29:46 -- STEP: 97/406 -- GLOBAL_STEP: 5375\u001b[0m\n",
      "     | > loss: 1.0134141445159912  (1.042152022578053)\n",
      "     | > log_mle: 0.18960249423980713  (0.20255311555469158)\n",
      "     | > loss_dur: 0.8238116502761841  (0.8395989088668037)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0579, device='cuda:0')  (tensor(2.1466, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.3483  (0.33357076546580516)\n",
      "     | > loader_time: 0.003  (0.005757786563991271)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:29:55 -- STEP: 122/406 -- GLOBAL_STEP: 5400\u001b[0m\n",
      "     | > loss: 0.9829180836677551  (1.0360283289776473)\n",
      "     | > log_mle: 0.19133204221725464  (0.19846493787452824)\n",
      "     | > loss_dur: 0.7915860414505005  (0.8375633925688072)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0663, device='cuda:0')  (tensor(2.1610, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.4014  (0.34319676141269867)\n",
      "     | > loader_time: 0.004  (0.00527522798444404)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:30:05 -- STEP: 147/406 -- GLOBAL_STEP: 5425\u001b[0m\n",
      "     | > loss: 1.0162338018417358  (1.032453039470984)\n",
      "     | > log_mle: 0.1769547462463379  (0.19459624679721135)\n",
      "     | > loss_dur: 0.839279055595398  (0.8378567951066151)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2380, device='cuda:0')  (tensor(2.1715, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.3723  (0.3524900390988305)\n",
      "     | > loader_time: 0.004  (0.0050044740949358275)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:30:16 -- STEP: 172/406 -- GLOBAL_STEP: 5450\u001b[0m\n",
      "     | > loss: 0.9962665438652039  (1.0286223389381584)\n",
      "     | > log_mle: 0.17406970262527466  (0.1914758623339409)\n",
      "     | > loss_dur: 0.8221968412399292  (0.8371464776438334)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1468, device='cuda:0')  (tensor(2.1785, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.4634  (0.3630039234494056)\n",
      "     | > loader_time: 0.004  (0.004876463912254156)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:30:28 -- STEP: 197/406 -- GLOBAL_STEP: 5475\u001b[0m\n",
      "     | > loss: 1.0046464204788208  (1.0254859131604879)\n",
      "     | > log_mle: 0.17092442512512207  (0.18849613279255514)\n",
      "     | > loss_dur: 0.8337219953536987  (0.836989780670495)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0982, device='cuda:0')  (tensor(2.1742, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.4914  (0.374370291753469)\n",
      "     | > loader_time: 0.004  (0.0047986180649191)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:30:39 -- STEP: 222/406 -- GLOBAL_STEP: 5500\u001b[0m\n",
      "     | > loss: 0.9721190929412842  (1.021456164282721)\n",
      "     | > log_mle: 0.1580289602279663  (0.18575416706703804)\n",
      "     | > loss_dur: 0.8140901327133179  (0.8357019969471938)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.5300, device='cuda:0')  (tensor(2.2030, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.5365  (0.3841234574446809)\n",
      "     | > loader_time: 0.005  (0.004749658945444468)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:30:52 -- STEP: 247/406 -- GLOBAL_STEP: 5525\u001b[0m\n",
      "     | > loss: 0.9708672165870667  (1.0184690715812958)\n",
      "     | > log_mle: 0.18032711744308472  (0.18324092090853794)\n",
      "     | > loss_dur: 0.7905400991439819  (0.8352281501901293)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0426, device='cuda:0')  (tensor(2.2129, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.5915  (0.39521303833254934)\n",
      "     | > loader_time: 0.005  (0.004743041297202168)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:31:05 -- STEP: 272/406 -- GLOBAL_STEP: 5550\u001b[0m\n",
      "     | > loss: 0.9746301770210266  (1.0155823443304086)\n",
      "     | > log_mle: 0.14946448802947998  (0.18070128099883304)\n",
      "     | > loss_dur: 0.8251656889915466  (0.834881063112441)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1893, device='cuda:0')  (tensor(2.2111, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.5945  (0.4067479415851482)\n",
      "     | > loader_time: 0.004  (0.0047339507762123555)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:31:18 -- STEP: 297/406 -- GLOBAL_STEP: 5575\u001b[0m\n",
      "     | > loss: 0.9741860032081604  (1.0129259997345377)\n",
      "     | > log_mle: 0.1569347381591797  (0.17856824438178578)\n",
      "     | > loss_dur: 0.8172512650489807  (0.8343577555534413)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9438, device='cuda:0')  (tensor(2.2136, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.4954  (0.41683969674287036)\n",
      "     | > loader_time: 0.004  (0.004736519020414513)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:31:33 -- STEP: 322/406 -- GLOBAL_STEP: 5600\u001b[0m\n",
      "     | > loss: 1.0029170513153076  (1.0099274545722863)\n",
      "     | > log_mle: 0.1463196873664856  (0.17652884107198774)\n",
      "     | > loss_dur: 0.856597363948822  (0.8333986135002989)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0942, device='cuda:0')  (tensor(2.2114, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.6316  (0.42907585786736546)\n",
      "     | > loader_time: 0.005  (0.004760437130187608)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:31:48 -- STEP: 347/406 -- GLOBAL_STEP: 5625\u001b[0m\n",
      "     | > loss: 0.9830415844917297  (1.0077360270689817)\n",
      "     | > log_mle: 0.13690787553787231  (0.1743863812441097)\n",
      "     | > loss_dur: 0.8461337089538574  (0.8333496456531008)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5182, device='cuda:0')  (tensor(2.2150, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.5665  (0.4404199844822074)\n",
      "     | > loader_time: 0.005  (0.004815524180959212)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:32:03 -- STEP: 372/406 -- GLOBAL_STEP: 5650\u001b[0m\n",
      "     | > loss: 0.9458961486816406  (1.0047415427623256)\n",
      "     | > log_mle: 0.15226495265960693  (0.17233637984721892)\n",
      "     | > loss_dur: 0.7936311960220337  (0.8324051625946517)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0344, device='cuda:0')  (tensor(2.2163, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.6946  (0.45225733005872354)\n",
      "     | > loader_time: 0.005  (0.004863198726407943)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:32:20 -- STEP: 397/406 -- GLOBAL_STEP: 5675\u001b[0m\n",
      "     | > loss: 0.9542595744132996  (1.0017838920994422)\n",
      "     | > log_mle: 0.1438448429107666  (0.17037527927523596)\n",
      "     | > loss_dur: 0.810414731502533  (0.8314086125239317)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9718, device='cuda:0')  (tensor(2.2213, device='cuda:0'))\n",
      "     | > current_lr: 3.25e-06 \n",
      "     | > step_time: 0.7696  (0.46564654799492605)\n",
      "     | > loader_time: 0.006  (0.004919996189530613)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09358477592468262 \u001b[0m(-0.019518166780471802)\n",
      "     | > avg_loss:\u001b[92m 0.9461042284965515 \u001b[0m(-0.09181714057922363)\n",
      "     | > avg_log_mle:\u001b[92m 0.1508675068616867 \u001b[0m(-0.03616270422935486)\n",
      "     | > avg_loss_dur:\u001b[92m 0.7952367216348648 \u001b[0m(-0.05565442889928818)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_5684.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 14/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:32:54) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:33:17 -- STEP: 16/406 -- GLOBAL_STEP: 5700\u001b[0m\n",
      "     | > loss: 0.9834875464439392  (0.9835832379758358)\n",
      "     | > log_mle: 0.17046916484832764  (0.17525842040777206)\n",
      "     | > loss_dur: 0.8130183815956116  (0.8083248175680637)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9928, device='cuda:0')  (tensor(2.0473, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.2672  (0.29013822972774506)\n",
      "     | > loader_time: 0.002  (0.029651939868927)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:33:25 -- STEP: 41/406 -- GLOBAL_STEP: 5725\u001b[0m\n",
      "     | > loss: 0.9383318424224854  (0.9621553246567889)\n",
      "     | > log_mle: 0.18135690689086914  (0.175178950879632)\n",
      "     | > loss_dur: 0.7569749355316162  (0.7869763737771569)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8232, device='cuda:0')  (tensor(1.9751, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.3263  (0.30373888480954053)\n",
      "     | > loader_time: 0.002  (0.012987625308153106)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:33:33 -- STEP: 66/406 -- GLOBAL_STEP: 5750\u001b[0m\n",
      "     | > loss: 0.9579308032989502  (0.9547702507539229)\n",
      "     | > log_mle: 0.1590636968612671  (0.1705925302072005)\n",
      "     | > loss_dur: 0.7988671064376831  (0.7841777205467224)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9583, device='cuda:0')  (tensor(1.9666, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.2983  (0.3175002336502075)\n",
      "     | > loader_time: 0.002  (0.00908406214280562)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:33:42 -- STEP: 91/406 -- GLOBAL_STEP: 5775\u001b[0m\n",
      "     | > loss: 0.9096824526786804  (0.9488337033397549)\n",
      "     | > log_mle: 0.13338744640350342  (0.16590483175529233)\n",
      "     | > loss_dur: 0.776295006275177  (0.7829288715844626)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8744, device='cuda:0')  (tensor(1.9770, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.3894  (0.32894686814192886)\n",
      "     | > loader_time: 0.004  (0.007413431838318542)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:33:52 -- STEP: 116/406 -- GLOBAL_STEP: 5800\u001b[0m\n",
      "     | > loss: 0.9236117005348206  (0.9422823822703855)\n",
      "     | > log_mle: 0.15344637632369995  (0.16163380649583095)\n",
      "     | > loss_dur: 0.7701653242111206  (0.7806485757745546)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7472, device='cuda:0')  (tensor(1.9658, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.3733  (0.33962721454686123)\n",
      "     | > loader_time: 0.002  (0.006523191928863525)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:34:02 -- STEP: 141/406 -- GLOBAL_STEP: 5825\u001b[0m\n",
      "     | > loss: 0.9349594712257385  (0.9384997732250403)\n",
      "     | > log_mle: 0.1376829743385315  (0.15773144005038217)\n",
      "     | > loss_dur: 0.797276496887207  (0.7807683331746582)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4594, device='cuda:0')  (tensor(1.9748, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4484  (0.35024702633526306)\n",
      "     | > loader_time: 0.004  (0.006033802708835466)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:34:13 -- STEP: 166/406 -- GLOBAL_STEP: 5850\u001b[0m\n",
      "     | > loss: 0.9117668867111206  (0.9349963758365217)\n",
      "     | > log_mle: 0.12317460775375366  (0.15461252037301126)\n",
      "     | > loss_dur: 0.7885922789573669  (0.7803838554635102)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8276, device='cuda:0')  (tensor(2.0397, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4634  (0.3603150112083159)\n",
      "     | > loader_time: 0.003  (0.005716003567339425)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:34:24 -- STEP: 191/406 -- GLOBAL_STEP: 5875\u001b[0m\n",
      "     | > loss: 0.8938965797424316  (0.9320604205131531)\n",
      "     | > log_mle: 0.12896162271499634  (0.1516542206884055)\n",
      "     | > loss_dur: 0.7649349570274353  (0.7804061998247473)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9219, device='cuda:0')  (tensor(2.0383, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4975  (0.3714838040436748)\n",
      "     | > loader_time: 0.005  (0.005512830474613849)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:34:36 -- STEP: 216/406 -- GLOBAL_STEP: 5900\u001b[0m\n",
      "     | > loss: 0.8922629356384277  (0.9285944945834301)\n",
      "     | > log_mle: 0.1199384331703186  (0.1491065166062779)\n",
      "     | > loss_dur: 0.7723245024681091  (0.779487977977152)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3941, device='cuda:0')  (tensor(2.0711, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.5205  (0.38193006647957684)\n",
      "     | > loader_time: 0.003  (0.005361288785934448)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:34:48 -- STEP: 241/406 -- GLOBAL_STEP: 5925\u001b[0m\n",
      "     | > loss: 0.8950905799865723  (0.925798706988576)\n",
      "     | > log_mle: 0.13564246892929077  (0.1465914692126864)\n",
      "     | > loss_dur: 0.7594481110572815  (0.7792072377758894)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9317, device='cuda:0')  (tensor(2.0943, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4494  (0.39203225824348154)\n",
      "     | > loader_time: 0.004  (0.0052785962449069836)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:35:01 -- STEP: 266/406 -- GLOBAL_STEP: 5950\u001b[0m\n",
      "     | > loss: 0.9058125019073486  (0.9231374344431368)\n",
      "     | > log_mle: 0.12880027294158936  (0.14423973421405134)\n",
      "     | > loss_dur: 0.7770122289657593  (0.7788977002290852)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0467, device='cuda:0')  (tensor(2.1079, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.5685  (0.40466436676512973)\n",
      "     | > loader_time: 0.005  (0.005215195784891458)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:35:14 -- STEP: 291/406 -- GLOBAL_STEP: 5975\u001b[0m\n",
      "     | > loss: 0.9173121452331543  (0.9204740354285617)\n",
      "     | > log_mle: 0.13384050130844116  (0.1420453776608628)\n",
      "     | > loss_dur: 0.7834716439247131  (0.7784286577676989)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7909, device='cuda:0')  (tensor(2.0969, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.4824  (0.41385341018335914)\n",
      "     | > loader_time: 0.007  (0.0051592182867305795)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:35:28 -- STEP: 316/406 -- GLOBAL_STEP: 6000\u001b[0m\n",
      "     | > loss: 0.8802127242088318  (0.9179937352862539)\n",
      "     | > log_mle: 0.11768472194671631  (0.14005046592483036)\n",
      "     | > loss_dur: 0.7625280022621155  (0.7779432693614237)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2265, device='cuda:0')  (tensor(2.0887, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.6216  (0.4242807988879045)\n",
      "     | > loader_time: 0.004  (0.005108951767788656)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_6000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:35:45 -- STEP: 341/406 -- GLOBAL_STEP: 6025\u001b[0m\n",
      "     | > loss: 0.8744915723800659  (0.9158899034223249)\n",
      "     | > log_mle: 0.09708279371261597  (0.13816456658399695)\n",
      "     | > loss_dur: 0.77740877866745  (0.777725336838328)\n",
      "     | > amp_scaler: 65536.0  (34113.313782991194)\n",
      "     | > grad_norm: tensor(2.7539, device='cuda:0')  (tensor(2.0907, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.5375  (0.43439446586318015)\n",
      "     | > loader_time: 0.004  (0.0050718917175471955)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:36:00 -- STEP: 366/406 -- GLOBAL_STEP: 6050\u001b[0m\n",
      "     | > loss: 0.8658768534660339  (0.9134888663643697)\n",
      "     | > log_mle: 0.10394954681396484  (0.13617729147275281)\n",
      "     | > loss_dur: 0.7619273066520691  (0.7773115748916168)\n",
      "     | > amp_scaler: 65536.0  (36259.67213114752)\n",
      "     | > grad_norm: tensor(2.6138, device='cuda:0')  (tensor(2.0982, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.5645  (0.4441820383071898)\n",
      "     | > loader_time: 0.005  (0.005061804922552055)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:36:16 -- STEP: 391/406 -- GLOBAL_STEP: 6075\u001b[0m\n",
      "     | > loss: 0.8624869585037231  (0.9107101657201567)\n",
      "     | > log_mle: 0.09578812122344971  (0.13431396935601966)\n",
      "     | > loss_dur: 0.7666988372802734  (0.776396196364137)\n",
      "     | > amp_scaler: 65536.0  (38131.56010230177)\n",
      "     | > grad_norm: tensor(2.6100, device='cuda:0')  (tensor(2.1019, device='cuda:0'))\n",
      "     | > current_lr: 3.5e-06 \n",
      "     | > step_time: 0.6996  (0.456353011338607)\n",
      "     | > loader_time: 0.007  (0.005083743263693417)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08920606970787048 \u001b[0m(-0.004378706216812134)\n",
      "     | > avg_loss:\u001b[92m 0.8636013269424438 \u001b[0m(-0.08250290155410767)\n",
      "     | > avg_log_mle:\u001b[92m 0.11762949079275131 \u001b[0m(-0.033238016068935394)\n",
      "     | > avg_loss_dur:\u001b[92m 0.7459718361496925 \u001b[0m(-0.04926488548517227)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_6090.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 15/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:36:53) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:37:11 -- STEP: 10/406 -- GLOBAL_STEP: 6100\u001b[0m\n",
      "     | > loss: 0.8977024555206299  (0.9095009088516235)\n",
      "     | > log_mle: 0.1420055627822876  (0.14518074989318847)\n",
      "     | > loss_dur: 0.7556968927383423  (0.7643201589584351)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8223, device='cuda:0')  (tensor(1.8486, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.2522  (0.25823416709899905)\n",
      "     | > loader_time: 0.002  (0.02212047576904297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:37:18 -- STEP: 35/406 -- GLOBAL_STEP: 6125\u001b[0m\n",
      "     | > loss: 0.8595852851867676  (0.8787720918655395)\n",
      "     | > log_mle: 0.12186503410339355  (0.14000569752284464)\n",
      "     | > loss_dur: 0.737720251083374  (0.738766394342695)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7366, device='cuda:0')  (tensor(1.7981, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.2632  (0.26289577484130866)\n",
      "     | > loader_time: 0.002  (0.007807145799909319)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:37:26 -- STEP: 60/406 -- GLOBAL_STEP: 6150\u001b[0m\n",
      "     | > loss: 0.8224397301673889  (0.8704059253136317)\n",
      "     | > log_mle: 0.12667936086654663  (0.13655446271101634)\n",
      "     | > loss_dur: 0.6957603693008423  (0.7338514626026154)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6450, device='cuda:0')  (tensor(1.7807, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.2833  (0.27706801891326904)\n",
      "     | > loader_time: 0.003  (0.005588626861572266)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:37:34 -- STEP: 85/406 -- GLOBAL_STEP: 6175\u001b[0m\n",
      "     | > loss: 0.8196309804916382  (0.8649620119263144)\n",
      "     | > log_mle: 0.1021605134010315  (0.13238435352549838)\n",
      "     | > loss_dur: 0.7174704670906067  (0.732577658400816)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1894, device='cuda:0')  (tensor(1.7943, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.3033  (0.28963931588565606)\n",
      "     | > loader_time: 0.003  (0.004792639788459329)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:37:43 -- STEP: 110/406 -- GLOBAL_STEP: 6200\u001b[0m\n",
      "     | > loss: 0.8531901836395264  (0.8580706672234969)\n",
      "     | > log_mle: 0.10107594728469849  (0.12820981740951545)\n",
      "     | > loss_dur: 0.7521142363548279  (0.7298608498139815)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9915, device='cuda:0')  (tensor(1.7847, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.3273  (0.30252009305086974)\n",
      "     | > loader_time: 0.003  (0.004404007304798473)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:37:52 -- STEP: 135/406 -- GLOBAL_STEP: 6225\u001b[0m\n",
      "     | > loss: 0.850649893283844  (0.8538950898029186)\n",
      "     | > log_mle: 0.10824567079544067  (0.12438943518532655)\n",
      "     | > loss_dur: 0.7424042224884033  (0.7295056546175921)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5858, device='cuda:0')  (tensor(1.8011, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.3393  (0.3130990434575962)\n",
      "     | > loader_time: 0.004  (0.0041964089428936984)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:38:01 -- STEP: 160/406 -- GLOBAL_STEP: 6250\u001b[0m\n",
      "     | > loss: 0.8273970484733582  (0.8509344968944788)\n",
      "     | > log_mle: 0.10408103466033936  (0.12130059301853187)\n",
      "     | > loss_dur: 0.7233160138130188  (0.729633903875947)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(3.0255, device='cuda:0')  (tensor(1.8778, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.4294  (0.3248574137687681)\n",
      "     | > loader_time: 0.004  (0.004078686237335203)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:38:12 -- STEP: 185/406 -- GLOBAL_STEP: 6275\u001b[0m\n",
      "     | > loss: 0.812745988368988  (0.848263286899876)\n",
      "     | > log_mle: 0.1019255518913269  (0.11839433554056535)\n",
      "     | > loss_dur: 0.7108204364776611  (0.7298689513593105)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.3287, device='cuda:0')  (tensor(1.9114, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.3964  (0.33664627075195286)\n",
      "     | > loader_time: 0.005  (0.00405228073532517)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:38:23 -- STEP: 210/406 -- GLOBAL_STEP: 6300\u001b[0m\n",
      "     | > loss: 0.8088927268981934  (0.8456052601337433)\n",
      "     | > log_mle: 0.10110390186309814  (0.11577296626000183)\n",
      "     | > loss_dur: 0.7077888250350952  (0.7298322938737414)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.5634, device='cuda:0')  (tensor(1.9665, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.3994  (0.3479350430624823)\n",
      "     | > loader_time: 0.004  (0.004036944253104074)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:38:34 -- STEP: 235/406 -- GLOBAL_STEP: 6325\u001b[0m\n",
      "     | > loss: 0.8375515937805176  (0.8428422240500755)\n",
      "     | > log_mle: 0.09117096662521362  (0.11312572499538995)\n",
      "     | > loss_dur: 0.746380627155304  (0.7297164990546854)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7309, device='cuda:0')  (tensor(2.0378, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.4064  (0.35838928628475086)\n",
      "     | > loader_time: 0.004  (0.00405470868374439)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:38:47 -- STEP: 260/406 -- GLOBAL_STEP: 6350\u001b[0m\n",
      "     | > loss: 0.7838547825813293  (0.8404795885086059)\n",
      "     | > log_mle: 0.08083349466323853  (0.11076541932729578)\n",
      "     | > loss_dur: 0.7030212879180908  (0.7297141691813102)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0772, device='cuda:0')  (tensor(2.0613, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.5355  (0.37123712392953706)\n",
      "     | > loader_time: 0.004  (0.004088278917165903)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:38:59 -- STEP: 285/406 -- GLOBAL_STEP: 6375\u001b[0m\n",
      "     | > loss: 0.8116294145584106  (0.8380184106659471)\n",
      "     | > log_mle: 0.08909738063812256  (0.10859360339348777)\n",
      "     | > loss_dur: 0.7225320339202881  (0.7294248072724593)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.2148, device='cuda:0')  (tensor(2.0566, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.4494  (0.3817326227823892)\n",
      "     | > loader_time: 0.005  (0.00412298001741108)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:39:13 -- STEP: 310/406 -- GLOBAL_STEP: 6400\u001b[0m\n",
      "     | > loss: 0.7801313400268555  (0.8359186510885912)\n",
      "     | > log_mle: 0.09242820739746094  (0.10672604806961551)\n",
      "     | > loss_dur: 0.6877031326293945  (0.7291926030189758)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0810, device='cuda:0')  (tensor(2.0400, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.6206  (0.39415651059919765)\n",
      "     | > loader_time: 0.005  (0.004161786263988863)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:39:26 -- STEP: 335/406 -- GLOBAL_STEP: 6425\u001b[0m\n",
      "     | > loss: 0.8251485824584961  (0.8339158634641274)\n",
      "     | > log_mle: 0.07297420501708984  (0.10485774883583411)\n",
      "     | > loss_dur: 0.7521743774414062  (0.7290581146282931)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6031, device='cuda:0')  (tensor(2.0466, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.4834  (0.40471848872170496)\n",
      "     | > loader_time: 0.005  (0.004218702173944725)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:39:41 -- STEP: 360/406 -- GLOBAL_STEP: 6450\u001b[0m\n",
      "     | > loss: 0.8006741404533386  (0.831997990608215)\n",
      "     | > log_mle: 0.0740315318107605  (0.10297127101156446)\n",
      "     | > loss_dur: 0.7266426086425781  (0.7290267195966502)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.3982, device='cuda:0')  (tensor(2.0491, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.5205  (0.4164436366822982)\n",
      "     | > loader_time: 0.005  (0.0042844023969438325)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:39:56 -- STEP: 385/406 -- GLOBAL_STEP: 6475\u001b[0m\n",
      "     | > loss: 0.7814167141914368  (0.8295083829334801)\n",
      "     | > log_mle: 0.08006465435028076  (0.10119594382001208)\n",
      "     | > loss_dur: 0.701352059841156  (0.7283124391134678)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6456, device='cuda:0')  (tensor(2.0548, device='cuda:0'))\n",
      "     | > current_lr: 3.7499999999999997e-06 \n",
      "     | > step_time: 0.7056  (0.4290846341616145)\n",
      "     | > loader_time: 0.005  (0.004344146282641919)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08870655298233032 \u001b[0m(-0.0004995167255401611)\n",
      "     | > avg_loss:\u001b[92m 0.7919284775853157 \u001b[0m(-0.07167284935712814)\n",
      "     | > avg_log_mle:\u001b[92m 0.08532623201608658 \u001b[0m(-0.032303258776664734)\n",
      "     | > avg_loss_dur:\u001b[92m 0.7066022455692291 \u001b[0m(-0.03936959058046341)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_6496.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 16/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:40:36) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:40:53 -- STEP: 4/406 -- GLOBAL_STEP: 6500\u001b[0m\n",
      "     | > loss: 0.878607451915741  (0.8551177084445953)\n",
      "     | > log_mle: 0.13197451829910278  (0.11334535479545593)\n",
      "     | > loss_dur: 0.7466329336166382  (0.7417723536491394)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6708, device='cuda:0')  (tensor(1.7375, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.2602  (0.25923454761505127)\n",
      "     | > loader_time: 0.001  (0.06105571985244751)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:41:00 -- STEP: 29/406 -- GLOBAL_STEP: 6525\u001b[0m\n",
      "     | > loss: 0.777092695236206  (0.800272563408161)\n",
      "     | > log_mle: 0.1077268123626709  (0.1080416646497003)\n",
      "     | > loss_dur: 0.6693658828735352  (0.6922308987584608)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6743, device='cuda:0')  (tensor(1.5935, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.2753  (0.26127160006556016)\n",
      "     | > loader_time: 0.002  (0.010009173689217403)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:41:07 -- STEP: 54/406 -- GLOBAL_STEP: 6550\u001b[0m\n",
      "     | > loss: 0.7633400559425354  (0.7931528555022346)\n",
      "     | > log_mle: 0.09708285331726074  (0.10516752357836123)\n",
      "     | > loss_dur: 0.6662572026252747  (0.6879853319238733)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4861, device='cuda:0')  (tensor(1.5739, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.2783  (0.2730069557825724)\n",
      "     | > loader_time: 0.003  (0.006561694321808992)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:41:15 -- STEP: 79/406 -- GLOBAL_STEP: 6575\u001b[0m\n",
      "     | > loss: 0.7710332274436951  (0.7878811163238331)\n",
      "     | > log_mle: 0.08330237865447998  (0.10078458318227454)\n",
      "     | > loss_dur: 0.6877308487892151  (0.6870965331415585)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5945, device='cuda:0')  (tensor(1.5967, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.3603  (0.2858669878561285)\n",
      "     | > loader_time: 0.004  (0.005372153052800819)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:41:24 -- STEP: 104/406 -- GLOBAL_STEP: 6600\u001b[0m\n",
      "     | > loss: 0.7595055103302002  (0.7823083801911426)\n",
      "     | > log_mle: 0.09263569116592407  (0.09640738597282997)\n",
      "     | > loss_dur: 0.6668698191642761  (0.6859009942183125)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7519, device='cuda:0')  (tensor(1.6378, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.3924  (0.2988384549434367)\n",
      "     | > loader_time: 0.003  (0.004831460806039661)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:41:33 -- STEP: 129/406 -- GLOBAL_STEP: 6625\u001b[0m\n",
      "     | > loss: 0.7646521329879761  (0.7776317975317784)\n",
      "     | > log_mle: 0.08366018533706665  (0.09281082208766493)\n",
      "     | > loss_dur: 0.6809919476509094  (0.6848209754441134)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9914, device='cuda:0')  (tensor(1.7030, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.4044  (0.3107859589332757)\n",
      "     | > loader_time: 0.004  (0.004539060962292573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:41:43 -- STEP: 154/406 -- GLOBAL_STEP: 6650\u001b[0m\n",
      "     | > loss: 0.749721348285675  (0.7751056551933286)\n",
      "     | > log_mle: 0.07689815759658813  (0.08978877593944601)\n",
      "     | > loss_dur: 0.6728231906890869  (0.6853168792538826)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0621, device='cuda:0')  (tensor(1.7803, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.4344  (0.3220519802787086)\n",
      "     | > loader_time: 0.003  (0.004387163496636724)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:41:53 -- STEP: 179/406 -- GLOBAL_STEP: 6675\u001b[0m\n",
      "     | > loss: 0.7558971643447876  (0.772958880030243)\n",
      "     | > log_mle: 0.067440927028656  (0.08716243172491063)\n",
      "     | > loss_dur: 0.6884562373161316  (0.6857964483053323)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7380, device='cuda:0')  (tensor(1.7974, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.3793  (0.33336955075823393)\n",
      "     | > loader_time: 0.004  (0.004311231261525072)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:42:04 -- STEP: 204/406 -- GLOBAL_STEP: 6700\u001b[0m\n",
      "     | > loss: 0.7472140789031982  (0.7707444046642266)\n",
      "     | > log_mle: 0.067848801612854  (0.08468029925636217)\n",
      "     | > loss_dur: 0.6793652772903442  (0.6860641054078643)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1677, device='cuda:0')  (tensor(1.8632, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.3984  (0.34506807023403707)\n",
      "     | > loader_time: 0.004  (0.0042440914640239635)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:42:15 -- STEP: 229/406 -- GLOBAL_STEP: 6725\u001b[0m\n",
      "     | > loss: 0.7348588705062866  (0.7678598579360929)\n",
      "     | > log_mle: 0.06886458396911621  (0.08215830445810177)\n",
      "     | > loss_dur: 0.6659942865371704  (0.685701553477991)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0364, device='cuda:0')  (tensor(1.9223, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.4134  (0.3556328288332345)\n",
      "     | > loader_time: 0.004  (0.004226557552554201)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:42:27 -- STEP: 254/406 -- GLOBAL_STEP: 6750\u001b[0m\n",
      "     | > loss: 0.7563470602035522  (0.7660684921140746)\n",
      "     | > log_mle: 0.0672956109046936  (0.07983985073923126)\n",
      "     | > loss_dur: 0.6890514492988586  (0.6862286413748432)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9618, device='cuda:0')  (tensor(1.9821, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.5405  (0.3679206239895559)\n",
      "     | > loader_time: 0.004  (0.0042400538452028284)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:42:40 -- STEP: 279/406 -- GLOBAL_STEP: 6775\u001b[0m\n",
      "     | > loss: 0.7641951441764832  (0.7638231178338383)\n",
      "     | > log_mle: 0.06288158893585205  (0.07779950800762382)\n",
      "     | > loss_dur: 0.7013135552406311  (0.6860236098262145)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.4070, device='cuda:0')  (tensor(1.9851, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.4454  (0.37939460986831297)\n",
      "     | > loader_time: 0.004  (0.004269081204595531)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:42:53 -- STEP: 304/406 -- GLOBAL_STEP: 6800\u001b[0m\n",
      "     | > loss: 0.7220597267150879  (0.7618063162816199)\n",
      "     | > log_mle: 0.05108553171157837  (0.07590929987399202)\n",
      "     | > loss_dur: 0.6709741950035095  (0.6858970164076277)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5844, device='cuda:0')  (tensor(1.9971, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.6045  (0.39120384109647677)\n",
      "     | > loader_time: 0.004  (0.004290033327905752)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:43:07 -- STEP: 329/406 -- GLOBAL_STEP: 6825\u001b[0m\n",
      "     | > loss: 0.7502676248550415  (0.7596460771053399)\n",
      "     | > log_mle: 0.06395727396011353  (0.07427346833208774)\n",
      "     | > loss_dur: 0.686310350894928  (0.6853726087732518)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7977, device='cuda:0')  (tensor(2.0054, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.4934  (0.40274559400726634)\n",
      "     | > loader_time: 0.004  (0.004326053665764061)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:43:21 -- STEP: 354/406 -- GLOBAL_STEP: 6850\u001b[0m\n",
      "     | > loss: 0.7330464720726013  (0.7581962697250024)\n",
      "     | > log_mle: 0.05180037021636963  (0.0724523714033224)\n",
      "     | > loss_dur: 0.6812461018562317  (0.6857438983216797)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.4927, device='cuda:0')  (tensor(2.0213, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.5215  (0.4146024130158508)\n",
      "     | > loader_time: 0.005  (0.004373968657800705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:43:36 -- STEP: 379/406 -- GLOBAL_STEP: 6875\u001b[0m\n",
      "     | > loss: 0.7171242237091064  (0.7559243420183189)\n",
      "     | > log_mle: 0.044860899448394775  (0.07066470416051417)\n",
      "     | > loss_dur: 0.6722633242607117  (0.6852596378578042)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9302, device='cuda:0')  (tensor(2.0237, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.5755  (0.42678060758082437)\n",
      "     | > loader_time: 0.005  (0.004420835927797179)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:43:53 -- STEP: 404/406 -- GLOBAL_STEP: 6900\u001b[0m\n",
      "     | > loss: 0.7399416565895081  (0.7537791304068993)\n",
      "     | > log_mle: 0.04453200101852417  (0.06896104007074148)\n",
      "     | > loss_dur: 0.6954096555709839  (0.6848180903361573)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7738, device='cuda:0')  (tensor(2.0221, device='cuda:0'))\n",
      "     | > current_lr: 4e-06 \n",
      "     | > step_time: 0.5637  (0.4403567402669702)\n",
      "     | > loader_time: 0.004  (0.004459441888450391)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09758874773979187 \u001b[0m(+0.008882194757461548)\n",
      "     | > avg_loss:\u001b[92m 0.7247252017259598 \u001b[0m(-0.06720327585935593)\n",
      "     | > avg_log_mle:\u001b[92m 0.05479784309864044 \u001b[0m(-0.030528388917446136)\n",
      "     | > avg_loss_dur:\u001b[92m 0.6699273586273193 \u001b[0m(-0.03667488694190979)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_6902.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 17/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:44:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:44:44 -- STEP: 23/406 -- GLOBAL_STEP: 6925\u001b[0m\n",
      "     | > loss: 0.7156050205230713  (0.734823781511058)\n",
      "     | > log_mle: 0.07909274101257324  (0.0798005047051803)\n",
      "     | > loss_dur: 0.636512279510498  (0.6550232768058777)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3602, device='cuda:0')  (tensor(1.4176, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.2662  (0.2605844165967858)\n",
      "     | > loader_time: 0.002  (0.01383861251499342)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:44:51 -- STEP: 48/406 -- GLOBAL_STEP: 6950\u001b[0m\n",
      "     | > loss: 0.7263138294219971  (0.726178461064895)\n",
      "     | > log_mle: 0.07038730382919312  (0.07766501481334369)\n",
      "     | > loss_dur: 0.655926525592804  (0.6485134462515515)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6785, device='cuda:0')  (tensor(1.3632, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3033  (0.26999506851037336)\n",
      "     | > loader_time: 0.002  (0.007882123192151388)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:44:59 -- STEP: 73/406 -- GLOBAL_STEP: 6975\u001b[0m\n",
      "     | > loss: 0.6858504414558411  (0.7203784593164104)\n",
      "     | > log_mle: 0.04634732007980347  (0.07294529758087576)\n",
      "     | > loss_dur: 0.6395031213760376  (0.6474331617355349)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.2790, device='cuda:0')  (tensor(1.4523, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3453  (0.28232476809253426)\n",
      "     | > loader_time: 0.003  (0.006156258387108372)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:45:08 -- STEP: 98/406 -- GLOBAL_STEP: 7000\u001b[0m\n",
      "     | > loss: 0.7125062942504883  (0.7152449123713435)\n",
      "     | > log_mle: 0.062283456325531006  (0.06865773517258314)\n",
      "     | > loss_dur: 0.6502228379249573  (0.6465871771987607)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9279, device='cuda:0')  (tensor(1.5160, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3813  (0.29586039757242016)\n",
      "     | > loader_time: 0.003  (0.005351803740676567)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_7000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:45:19 -- STEP: 123/406 -- GLOBAL_STEP: 7025\u001b[0m\n",
      "     | > loss: 0.7024732232093811  (0.7104705358908429)\n",
      "     | > log_mle: 0.04030752182006836  (0.06487448961754154)\n",
      "     | > loss_dur: 0.6621657013893127  (0.6455960462733015)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1015, device='cuda:0')  (tensor(1.6029, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3213  (0.308230973840729)\n",
      "     | > loader_time: 0.003  (0.0049150629741389566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:45:29 -- STEP: 148/406 -- GLOBAL_STEP: 7050\u001b[0m\n",
      "     | > loss: 0.6921795010566711  (0.7075445885593827)\n",
      "     | > log_mle: 0.0398215651512146  (0.061558387972213115)\n",
      "     | > loss_dur: 0.6523579359054565  (0.6459862005871699)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6040, device='cuda:0')  (tensor(1.6600, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3473  (0.3185931943558358)\n",
      "     | > loader_time: 0.004  (0.004646188503987079)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:45:39 -- STEP: 173/406 -- GLOBAL_STEP: 7075\u001b[0m\n",
      "     | > loss: 0.7024637460708618  (0.70522924241303)\n",
      "     | > log_mle: 0.04529792070388794  (0.058940200791882634)\n",
      "     | > loss_dur: 0.6571658253669739  (0.6462890416211478)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3767, device='cuda:0')  (tensor(1.6749, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3693  (0.32966912275104854)\n",
      "     | > loader_time: 0.005  (0.004524439056484684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:45:50 -- STEP: 198/406 -- GLOBAL_STEP: 7100\u001b[0m\n",
      "     | > loss: 0.6790466904640198  (0.7032585709986059)\n",
      "     | > log_mle: 0.03579360246658325  (0.05634538723964883)\n",
      "     | > loss_dur: 0.6432530879974365  (0.6469131837589575)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3139, device='cuda:0')  (tensor(1.6966, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3914  (0.3418068873761881)\n",
      "     | > loader_time: 0.003  (0.00442331607895668)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:46:01 -- STEP: 223/406 -- GLOBAL_STEP: 7125\u001b[0m\n",
      "     | > loss: 0.6784669160842896  (0.7006202334780328)\n",
      "     | > log_mle: 0.036805927753448486  (0.05400729660496048)\n",
      "     | > loss_dur: 0.6416609883308411  (0.6466129368730728)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.3533, device='cuda:0')  (tensor(1.7916, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.3954  (0.351917327786775)\n",
      "     | > loader_time: 0.004  (0.0043717948845149145)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:46:12 -- STEP: 248/406 -- GLOBAL_STEP: 7150\u001b[0m\n",
      "     | > loss: 0.6755514144897461  (0.6986447810646025)\n",
      "     | > log_mle: 0.03629666566848755  (0.05184187307473151)\n",
      "     | > loss_dur: 0.6392547488212585  (0.6468029079898714)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1303, device='cuda:0')  (tensor(1.8057, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.5275  (0.36360959852895436)\n",
      "     | > loader_time: 0.004  (0.004354873972554359)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:46:25 -- STEP: 273/406 -- GLOBAL_STEP: 7175\u001b[0m\n",
      "     | > loss: 0.6603690385818481  (0.6965385256232794)\n",
      "     | > log_mle: 0.02417171001434326  (0.04967444108956026)\n",
      "     | > loss_dur: 0.6361973285675049  (0.6468640845337196)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.1521, device='cuda:0')  (tensor(1.7957, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.4294  (0.3748249335166735)\n",
      "     | > loader_time: 0.004  (0.004355724041278544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:46:37 -- STEP: 298/406 -- GLOBAL_STEP: 7200\u001b[0m\n",
      "     | > loss: 0.6663705110549927  (0.6946384530739497)\n",
      "     | > log_mle: 0.037345945835113525  (0.047978521393449505)\n",
      "     | > loss_dur: 0.6290245652198792  (0.6466599316805001)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6046, device='cuda:0')  (tensor(1.8106, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.6025  (0.38568675758054577)\n",
      "     | > loader_time: 0.004  (0.004379939712934046)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:46:51 -- STEP: 323/406 -- GLOBAL_STEP: 7225\u001b[0m\n",
      "     | > loss: 0.6691678166389465  (0.692630261828656)\n",
      "     | > log_mle: 0.022977769374847412  (0.04627141365694924)\n",
      "     | > loss_dur: 0.6461900472640991  (0.6463588481717065)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.1867, device='cuda:0')  (tensor(1.8443, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.4774  (0.39731520174457563)\n",
      "     | > loader_time: 0.004  (0.004406612354904506)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:47:05 -- STEP: 348/406 -- GLOBAL_STEP: 7250\u001b[0m\n",
      "     | > loss: 0.6945098638534546  (0.6912033254730293)\n",
      "     | > log_mle: 0.033009886741638184  (0.044585366358702194)\n",
      "     | > loss_dur: 0.6614999771118164  (0.6466179591143266)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.2743, device='cuda:0')  (tensor(1.8521, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.6676  (0.4088634430677041)\n",
      "     | > loader_time: 0.006  (0.004446692165287061)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:47:20 -- STEP: 373/406 -- GLOBAL_STEP: 7275\u001b[0m\n",
      "     | > loss: 0.6586770415306091  (0.6891391147876874)\n",
      "     | > log_mle: 0.015251100063323975  (0.04287987915504391)\n",
      "     | > loss_dur: 0.6434259414672852  (0.6462592356326433)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3487, device='cuda:0')  (tensor(1.8509, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.5485  (0.4197706434745891)\n",
      "     | > loader_time: 0.005  (0.004486762806173942)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:47:36 -- STEP: 398/406 -- GLOBAL_STEP: 7300\u001b[0m\n",
      "     | > loss: 0.6500785946846008  (0.6871161321599282)\n",
      "     | > log_mle: 0.01164323091506958  (0.041284580476319936)\n",
      "     | > loss_dur: 0.6384353637695312  (0.6458315516836083)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.6751, device='cuda:0')  (tensor(1.8569, device='cuda:0'))\n",
      "     | > current_lr: 4.25e-06 \n",
      "     | > step_time: 0.7309  (0.4334664847982589)\n",
      "     | > loader_time: 0.005  (0.00453689290051484)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09333893656730652 \u001b[0m(-0.0042498111724853516)\n",
      "     | > avg_loss:\u001b[92m 0.6566437259316444 \u001b[0m(-0.06808147579431534)\n",
      "     | > avg_log_mle:\u001b[92m 0.02968115359544754 \u001b[0m(-0.0251166895031929)\n",
      "     | > avg_loss_dur:\u001b[92m 0.6269625723361969 \u001b[0m(-0.042964786291122437)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_7308.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 18/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:48:09) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:48:29 -- STEP: 17/406 -- GLOBAL_STEP: 7325\u001b[0m\n",
      "     | > loss: 0.6321688294410706  (0.6749047286370221)\n",
      "     | > log_mle: 0.052062273025512695  (0.05173885121065028)\n",
      "     | > loss_dur: 0.5801065564155579  (0.6231658774263719)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.1527, device='cuda:0')  (tensor(1.4018, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.2602  (0.25870557392344756)\n",
      "     | > loader_time: 0.002  (0.01607328302720014)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:48:36 -- STEP: 42/406 -- GLOBAL_STEP: 7350\u001b[0m\n",
      "     | > loss: 0.6454694867134094  (0.6640196541945139)\n",
      "     | > log_mle: 0.04030907154083252  (0.051582956597918554)\n",
      "     | > loss_dur: 0.6051604151725769  (0.6124366975965954)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6457, device='cuda:0')  (tensor(1.3462, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.2973  (0.2656698283695039)\n",
      "     | > loader_time: 0.002  (0.00781646796635219)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:48:44 -- STEP: 67/406 -- GLOBAL_STEP: 7375\u001b[0m\n",
      "     | > loss: 0.6370075941085815  (0.6586043727931692)\n",
      "     | > log_mle: 0.032121121883392334  (0.0474834193044634)\n",
      "     | > loss_dur: 0.6048864722251892  (0.6111209534887058)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5458, device='cuda:0')  (tensor(1.4534, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.3373  (0.2788352646044831)\n",
      "     | > loader_time: 0.003  (0.0058858643716840605)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:48:52 -- STEP: 92/406 -- GLOBAL_STEP: 7400\u001b[0m\n",
      "     | > loss: 0.6378582119941711  (0.6542816660974337)\n",
      "     | > log_mle: 0.01850605010986328  (0.04307889938354492)\n",
      "     | > loss_dur: 0.6193521618843079  (0.6112027667138886)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.0302, device='cuda:0')  (tensor(1.4611, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.3673  (0.29200427946837054)\n",
      "     | > loader_time: 0.003  (0.005047982153685197)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:49:01 -- STEP: 117/406 -- GLOBAL_STEP: 7425\u001b[0m\n",
      "     | > loss: 0.6451374888420105  (0.6499271993963127)\n",
      "     | > log_mle: 0.023403048515319824  (0.039419119174663834)\n",
      "     | > loss_dur: 0.6217344403266907  (0.6105080802216489)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9695, device='cuda:0')  (tensor(1.5659, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.3874  (0.3039768251598391)\n",
      "     | > loader_time: 0.003  (0.0046280979091285635)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:49:10 -- STEP: 142/406 -- GLOBAL_STEP: 7450\u001b[0m\n",
      "     | > loss: 0.6255434155464172  (0.6470930601509521)\n",
      "     | > log_mle: 0.015669643878936768  (0.03599671200967171)\n",
      "     | > loss_dur: 0.6098737716674805  (0.6110963481412806)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.3879, device='cuda:0')  (tensor(1.6890, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.3363  (0.3152438989827331)\n",
      "     | > loader_time: 0.004  (0.004475931046714244)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:49:20 -- STEP: 167/406 -- GLOBAL_STEP: 7475\u001b[0m\n",
      "     | > loss: 0.6103329062461853  (0.6444457419618159)\n",
      "     | > log_mle: 0.013308227062225342  (0.033397240196159514)\n",
      "     | > loss_dur: 0.59702467918396  (0.6110485017656565)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7274, device='cuda:0')  (tensor(1.8120, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.3583  (0.32646400485923893)\n",
      "     | > loader_time: 0.003  (0.00436329556082537)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:49:31 -- STEP: 192/406 -- GLOBAL_STEP: 7500\u001b[0m\n",
      "     | > loss: 0.6005508899688721  (0.6424658788988987)\n",
      "     | > log_mle: 0.013205230236053467  (0.030918217884997528)\n",
      "     | > loss_dur: 0.5873456597328186  (0.6115476610139018)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.6929, device='cuda:0')  (tensor(1.8252, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.4004  (0.3401733698944251)\n",
      "     | > loader_time: 0.004  (0.004311267286539077)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:49:43 -- STEP: 217/406 -- GLOBAL_STEP: 7525\u001b[0m\n",
      "     | > loss: 0.6085275411605835  (0.6403432683461273)\n",
      "     | > log_mle: 0.011905372142791748  (0.028765620449171636)\n",
      "     | > loss_dur: 0.5966221690177917  (0.6115776478969561)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0037, device='cuda:0')  (tensor(1.8403, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.4314  (0.353113152464414)\n",
      "     | > loader_time: 0.004  (0.00430350809053342)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:49:55 -- STEP: 242/406 -- GLOBAL_STEP: 7550\u001b[0m\n",
      "     | > loss: 0.6150338053703308  (0.6384050826395838)\n",
      "     | > log_mle: -0.009646058082580566  (0.02653763831154374)\n",
      "     | > loss_dur: 0.6246798634529114  (0.6118674443280406)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8311, device='cuda:0')  (tensor(1.8990, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.5675  (0.36692396766883284)\n",
      "     | > loader_time: 0.004  (0.004342849589576408)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:50:08 -- STEP: 267/406 -- GLOBAL_STEP: 7575\u001b[0m\n",
      "     | > loss: 0.6147089600563049  (0.6365293659520953)\n",
      "     | > log_mle: 0.002424776554107666  (0.024654709890987093)\n",
      "     | > loss_dur: 0.6122841835021973  (0.6118746560611086)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.4896, device='cuda:0')  (tensor(1.9245, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.4394  (0.3804014863146378)\n",
      "     | > loader_time: 0.005  (0.004363563623321192)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:50:21 -- STEP: 292/406 -- GLOBAL_STEP: 7600\u001b[0m\n",
      "     | > loss: 0.6365066170692444  (0.634785619092314)\n",
      "     | > log_mle: 0.010314762592315674  (0.022891258336093324)\n",
      "     | > loss_dur: 0.6261918544769287  (0.6118943607562213)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.5790, device='cuda:0')  (tensor(1.8845, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.5875  (0.39200653278664366)\n",
      "     | > loader_time: 0.005  (0.004391013759456272)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:50:35 -- STEP: 317/406 -- GLOBAL_STEP: 7625\u001b[0m\n",
      "     | > loss: 0.6174478530883789  (0.633112175795558)\n",
      "     | > log_mle: 0.008147776126861572  (0.021264191493627026)\n",
      "     | > loss_dur: 0.6093000769615173  (0.6118479843019311)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(3.1796, device='cuda:0')  (tensor(1.8955, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.5225  (0.40473963860833684)\n",
      "     | > loader_time: 0.004  (0.004426786952214289)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:50:49 -- STEP: 342/406 -- GLOBAL_STEP: 7650\u001b[0m\n",
      "     | > loss: 0.5916436910629272  (0.6316290374039211)\n",
      "     | > log_mle: -0.008376359939575195  (0.0197170443005032)\n",
      "     | > loss_dur: 0.6000200510025024  (0.6119119931034177)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.2864, device='cuda:0')  (tensor(1.9247, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.6626  (0.4167672012284485)\n",
      "     | > loader_time: 0.005  (0.004469023810492622)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:51:05 -- STEP: 367/406 -- GLOBAL_STEP: 7675\u001b[0m\n",
      "     | > loss: 0.5893959999084473  (0.6300458053801952)\n",
      "     | > log_mle: -0.0027907490730285645  (0.018088491313788802)\n",
      "     | > loss_dur: 0.5921867489814758  (0.6119573140664062)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(0.9584, device='cuda:0')  (tensor(1.8970, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.6906  (0.4289833999134864)\n",
      "     | > loader_time: 0.007  (0.004546413629516269)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:51:21 -- STEP: 392/406 -- GLOBAL_STEP: 7700\u001b[0m\n",
      "     | > loss: 0.604223906993866  (0.6282977881480241)\n",
      "     | > log_mle: -0.007126748561859131  (0.01656842855166416)\n",
      "     | > loss_dur: 0.6113506555557251  (0.6117293595963597)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.8876, device='cuda:0')  (tensor(1.8767, device='cuda:0'))\n",
      "     | > current_lr: 4.5e-06 \n",
      "     | > step_time: 0.5835  (0.4425445697745498)\n",
      "     | > loader_time: 0.006  (0.004611362608111635)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0893307626247406 \u001b[0m(-0.004008173942565918)\n",
      "     | > avg_loss:\u001b[92m 0.6009425222873688 \u001b[0m(-0.055701203644275665)\n",
      "     | > avg_log_mle:\u001b[92m 0.007007531821727753 \u001b[0m(-0.022673621773719788)\n",
      "     | > avg_loss_dur:\u001b[92m 0.593934990465641 \u001b[0m(-0.03302758187055588)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_7714.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 19/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:51:59) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:52:19 -- STEP: 11/406 -- GLOBAL_STEP: 7725\u001b[0m\n",
      "     | > loss: 0.5876972675323486  (0.6237106702544473)\n",
      "     | > log_mle: 0.026976585388183594  (0.0315362269228155)\n",
      "     | > loss_dur: 0.560720682144165  (0.5921744433316317)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.0388, device='cuda:0')  (tensor(1.3191, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.2702  (0.2772515253587203)\n",
      "     | > loader_time: 0.002  (0.020655285228382458)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:52:26 -- STEP: 36/406 -- GLOBAL_STEP: 7750\u001b[0m\n",
      "     | > loss: 0.604659914970398  (0.6117238932185702)\n",
      "     | > log_mle: 0.035567641258239746  (0.027824928363164265)\n",
      "     | > loss_dur: 0.5690922737121582  (0.583898964855406)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(0.9836, device='cuda:0')  (tensor(1.4437, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.3073  (0.27708471483654445)\n",
      "     | > loader_time: 0.003  (0.007896171675788032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:52:34 -- STEP: 61/406 -- GLOBAL_STEP: 7775\u001b[0m\n",
      "     | > loss: 0.5906785130500793  (0.6070032256548522)\n",
      "     | > log_mle: 0.015261709690093994  (0.024317551831730077)\n",
      "     | > loss_dur: 0.5754168033599854  (0.5826856738231221)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.1226, device='cuda:0')  (tensor(1.3670, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.3353  (0.29357790556110325)\n",
      "     | > loader_time: 0.003  (0.0059562354791359825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:52:43 -- STEP: 86/406 -- GLOBAL_STEP: 7800\u001b[0m\n",
      "     | > loss: 0.5847582817077637  (0.6024606948675111)\n",
      "     | > log_mle: 0.01292121410369873  (0.020393400691276372)\n",
      "     | > loss_dur: 0.5718370676040649  (0.5820672941762348)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(0.8738, device='cuda:0')  (tensor(1.4084, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.3894  (0.3092922970306042)\n",
      "     | > loader_time: 0.004  (0.005155859991561534)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:52:52 -- STEP: 111/406 -- GLOBAL_STEP: 7825\u001b[0m\n",
      "     | > loss: 0.5656834244728088  (0.5973872719584283)\n",
      "     | > log_mle: -0.007453024387359619  (0.016504368266543813)\n",
      "     | > loss_dur: 0.5731364488601685  (0.5808829036918847)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9666, device='cuda:0')  (tensor(1.5185, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.3363  (0.32100303323419255)\n",
      "     | > loader_time: 0.003  (0.004869259155548368)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:53:02 -- STEP: 136/406 -- GLOBAL_STEP: 7850\u001b[0m\n",
      "     | > loss: 0.6021756529808044  (0.5940108847092178)\n",
      "     | > log_mle: -0.006970822811126709  (0.013186071287183186)\n",
      "     | > loss_dur: 0.6091464757919312  (0.5808248134220347)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.0382, device='cuda:0')  (tensor(1.5421, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.4474  (0.33269167822950035)\n",
      "     | > loader_time: 0.003  (0.004636487540076759)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:53:12 -- STEP: 161/406 -- GLOBAL_STEP: 7875\u001b[0m\n",
      "     | > loss: 0.5848391056060791  (0.5916358410201457)\n",
      "     | > log_mle: 0.003274679183959961  (0.010645938956219207)\n",
      "     | > loss_dur: 0.5815644264221191  (0.5809899020639268)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(3.5318, device='cuda:0')  (tensor(1.6611, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.3703  (0.34363488084781263)\n",
      "     | > loader_time: 0.004  (0.0045009281324303665)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:53:23 -- STEP: 186/406 -- GLOBAL_STEP: 7900\u001b[0m\n",
      "     | > loss: 0.5692907571792603  (0.5900905048975379)\n",
      "     | > log_mle: -0.013400018215179443  (0.008132421842185392)\n",
      "     | > loss_dur: 0.5826907753944397  (0.5819580830553528)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.0355, device='cuda:0')  (tensor(1.7091, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.4954  (0.35680775104030515)\n",
      "     | > loader_time: 0.004  (0.004455583069914129)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:53:35 -- STEP: 211/406 -- GLOBAL_STEP: 7925\u001b[0m\n",
      "     | > loss: 0.5588746666908264  (0.5883742308164662)\n",
      "     | > log_mle: -0.02484273910522461  (0.0059490181258504355)\n",
      "     | > loss_dur: 0.583717405796051  (0.582425212690616)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.5243, device='cuda:0')  (tensor(1.7816, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.5155  (0.36836280641962593)\n",
      "     | > loader_time: 0.004  (0.004444707626415087)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:53:47 -- STEP: 236/406 -- GLOBAL_STEP: 7950\u001b[0m\n",
      "     | > loss: 0.5756784677505493  (0.5863408027058943)\n",
      "     | > log_mle: 0.00012087821960449219  (0.0037912971387475164)\n",
      "     | > loss_dur: 0.5755575895309448  (0.582549505567147)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.9195, device='cuda:0')  (tensor(1.8235, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.4394  (0.37948433221396777)\n",
      "     | > loader_time: 0.004  (0.004461586475372312)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:54:00 -- STEP: 261/406 -- GLOBAL_STEP: 7975\u001b[0m\n",
      "     | > loss: 0.5498611330986023  (0.5847641172536947)\n",
      "     | > log_mle: -0.014730453491210938  (0.0017441467763820316)\n",
      "     | > loss_dur: 0.5645915865898132  (0.5830199704773129)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.7231, device='cuda:0')  (tensor(1.8597, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.4534  (0.39242906588704213)\n",
      "     | > loader_time: 0.005  (0.004482895935175517)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:54:13 -- STEP: 286/406 -- GLOBAL_STEP: 8000\u001b[0m\n",
      "     | > loss: 0.546140193939209  (0.5829318347093944)\n",
      "     | > log_mle: -0.020466089248657227  (-3.5110470298291915e-05)\n",
      "     | > loss_dur: 0.5666062831878662  (0.5829669451796929)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(4.3346, device='cuda:0')  (tensor(1.8927, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.4985  (0.4035341856362939)\n",
      "     | > loader_time: 0.006  (0.004531984562640421)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_8000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:54:31 -- STEP: 311/406 -- GLOBAL_STEP: 8025\u001b[0m\n",
      "     | > loss: 0.5602729320526123  (0.5813453136149711)\n",
      "     | > log_mle: -0.02501809597015381  (-0.0015312628730700384)\n",
      "     | > loss_dur: 0.5852910280227661  (0.5828765764880414)\n",
      "     | > amp_scaler: 65536.0  (65746.72668810289)\n",
      "     | > grad_norm: tensor(2.0676, device='cuda:0')  (tensor(1.9632, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.4944  (0.4169764426743488)\n",
      "     | > loader_time: 0.006  (0.004586053431225742)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:54:46 -- STEP: 336/406 -- GLOBAL_STEP: 8050\u001b[0m\n",
      "     | > loss: 0.5666292309761047  (0.5798222346320039)\n",
      "     | > log_mle: -0.012689411640167236  (-0.0029625458021958714)\n",
      "     | > loss_dur: 0.579318642616272  (0.5827847804342002)\n",
      "     | > amp_scaler: 32768.0  (63488.0)\n",
      "     | > grad_norm: tensor(1.7912, device='cuda:0')  (tensor(1.9333, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.6836  (0.42880579403468555)\n",
      "     | > loader_time: 0.005  (0.00464696827388945)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:55:01 -- STEP: 361/406 -- GLOBAL_STEP: 8075\u001b[0m\n",
      "     | > loss: 0.5748628973960876  (0.5782995740792758)\n",
      "     | > log_mle: -0.01741349697113037  (-0.004488213240604986)\n",
      "     | > loss_dur: 0.592276394367218  (0.5827877873198817)\n",
      "     | > amp_scaler: 32768.0  (61360.57617728532)\n",
      "     | > grad_norm: tensor(1.3736, device='cuda:0')  (tensor(1.9238, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.7277  (0.44098470679940954)\n",
      "     | > loader_time: 0.006  (0.004696666368817359)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:55:18 -- STEP: 386/406 -- GLOBAL_STEP: 8100\u001b[0m\n",
      "     | > loss: 0.542436420917511  (0.5764093595156397)\n",
      "     | > log_mle: -0.023590087890625  (-0.005927609038476502)\n",
      "     | > loss_dur: 0.566026508808136  (0.5823369685541169)\n",
      "     | > amp_scaler: 32768.0  (59508.72538860104)\n",
      "     | > grad_norm: tensor(1.4072, device='cuda:0')  (tensor(1.8868, device='cuda:0'))\n",
      "     | > current_lr: 4.749999999999999e-06 \n",
      "     | > step_time: 0.7427  (0.4552421674827221)\n",
      "     | > loader_time: 0.006  (0.004778837910587924)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09733849763870239 \u001b[0m(+0.008007735013961792)\n",
      "     | > avg_loss:\u001b[92m 0.5406684949994087 \u001b[0m(-0.06027402728796005)\n",
      "     | > avg_log_mle:\u001b[92m -0.017666704952716827 \u001b[0m(-0.02467423677444458)\n",
      "     | > avg_loss_dur:\u001b[92m 0.5583351999521255 \u001b[0m(-0.03559979051351547)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_8120.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 20/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 02:56:02) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:56:21 -- STEP: 5/406 -- GLOBAL_STEP: 8125\u001b[0m\n",
      "     | > loss: 0.5784701704978943  (0.5907581090927124)\n",
      "     | > log_mle: 0.020710468292236328  (0.012583136558532715)\n",
      "     | > loss_dur: 0.557759702205658  (0.5781749725341797)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(0.8954, device='cuda:0')  (tensor(1.4307, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.2612  (0.2720466613769531)\n",
      "     | > loader_time: 0.002  (0.06065535545349121)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:56:28 -- STEP: 30/406 -- GLOBAL_STEP: 8150\u001b[0m\n",
      "     | > loss: 0.5221844911575317  (0.5526293873786926)\n",
      "     | > log_mle: -0.0019590258598327637  (0.006232321262359619)\n",
      "     | > loss_dur: 0.5241435170173645  (0.546397066116333)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.2421, device='cuda:0')  (tensor(1.3914, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.2712  (0.2822890202204386)\n",
      "     | > loader_time: 0.002  (0.011877902348836263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:56:36 -- STEP: 55/406 -- GLOBAL_STEP: 8175\u001b[0m\n",
      "     | > loss: 0.5363953709602356  (0.5496659994125368)\n",
      "     | > log_mle: -0.01423490047454834  (0.003622252290899103)\n",
      "     | > loss_dur: 0.5506302714347839  (0.5460437471216376)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.1699, device='cuda:0')  (tensor(1.4762, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3053  (0.29484887556596234)\n",
      "     | > loader_time: 0.002  (0.007589119130914866)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:56:44 -- STEP: 80/406 -- GLOBAL_STEP: 8200\u001b[0m\n",
      "     | > loss: 0.5385931134223938  (0.5456727392971519)\n",
      "     | > log_mle: 0.00037235021591186523  (3.106370568275452e-05)\n",
      "     | > loss_dur: 0.5382207632064819  (0.545641675591469)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.0624, device='cuda:0')  (tensor(1.5492, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3053  (0.3070031881332397)\n",
      "     | > loader_time: 0.003  (0.00615593492984772)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:56:53 -- STEP: 105/406 -- GLOBAL_STEP: 8225\u001b[0m\n",
      "     | > loss: 0.5104000568389893  (0.5416113649095811)\n",
      "     | > log_mle: -0.007429301738739014  (-0.003946944077809651)\n",
      "     | > loss_dur: 0.5178293585777283  (0.5455583089873907)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.2408, device='cuda:0')  (tensor(1.4767, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3333  (0.3200996603284562)\n",
      "     | > loader_time: 0.003  (0.005471972056797576)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:57:03 -- STEP: 130/406 -- GLOBAL_STEP: 8250\u001b[0m\n",
      "     | > loss: 0.5146433711051941  (0.5376645042346079)\n",
      "     | > log_mle: -0.02276700735092163  (-0.007216271987328163)\n",
      "     | > loss_dur: 0.5374103784561157  (0.5448807762219355)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7136, device='cuda:0')  (tensor(1.6071, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3363  (0.3322242021560668)\n",
      "     | > loader_time: 0.003  (0.005104970932006838)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:57:13 -- STEP: 155/406 -- GLOBAL_STEP: 8275\u001b[0m\n",
      "     | > loss: 0.5070869326591492  (0.5354918999056665)\n",
      "     | > log_mle: -0.019048750400543213  (-0.00985282274984544)\n",
      "     | > loss_dur: 0.5261356830596924  (0.5453447226555118)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8142, device='cuda:0')  (tensor(1.7146, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3733  (0.34314330008722105)\n",
      "     | > loader_time: 0.005  (0.00489509951683783)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:57:24 -- STEP: 180/406 -- GLOBAL_STEP: 8300\u001b[0m\n",
      "     | > loss: 0.5030272006988525  (0.5336856603622442)\n",
      "     | > log_mle: -0.02993142604827881  (-0.01220169828997718)\n",
      "     | > loss_dur: 0.5329586267471313  (0.545887358652221)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(0.9500, device='cuda:0')  (tensor(1.7098, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.4834  (0.35420996083153616)\n",
      "     | > loader_time: 0.004  (0.004788045088450115)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:57:35 -- STEP: 205/406 -- GLOBAL_STEP: 8325\u001b[0m\n",
      "     | > loss: 0.5146904587745667  (0.5318254453379941)\n",
      "     | > log_mle: -0.03974241018295288  (-0.014393044099575135)\n",
      "     | > loss_dur: 0.5544328689575195  (0.5462184894375688)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0722, device='cuda:0')  (tensor(1.7905, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.5135  (0.3662002516955864)\n",
      "     | > loader_time: 0.005  (0.004726604136025036)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:57:48 -- STEP: 230/406 -- GLOBAL_STEP: 8350\u001b[0m\n",
      "     | > loss: 0.5227331519126892  (0.529375965698906)\n",
      "     | > log_mle: -0.03184539079666138  (-0.016522437334060665)\n",
      "     | > loss_dur: 0.5545785427093506  (0.5458984030329669)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.0264, device='cuda:0')  (tensor(1.8219, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.4454  (0.3787459259447844)\n",
      "     | > loader_time: 0.004  (0.0047263850336489496)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:58:01 -- STEP: 255/406 -- GLOBAL_STEP: 8375\u001b[0m\n",
      "     | > loss: 0.5170692801475525  (0.5278102227285799)\n",
      "     | > log_mle: -0.03411823511123657  (-0.018471916049134497)\n",
      "     | > loss_dur: 0.5511875152587891  (0.5462821387777146)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2795, device='cuda:0')  (tensor(1.9104, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.4534  (0.391796127020144)\n",
      "     | > loader_time: 0.006  (0.0047379802255069535)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:58:14 -- STEP: 280/406 -- GLOBAL_STEP: 8400\u001b[0m\n",
      "     | > loss: 0.5064346194267273  (0.5257209151983263)\n",
      "     | > log_mle: -0.04524773359298706  (-0.02018891509090151)\n",
      "     | > loss_dur: 0.5516823530197144  (0.545909830289228)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3138, device='cuda:0')  (tensor(1.9080, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.4874  (0.40430673786572047)\n",
      "     | > loader_time: 0.005  (0.004754683801106048)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:58:28 -- STEP: 305/406 -- GLOBAL_STEP: 8425\u001b[0m\n",
      "     | > loss: 0.5098492503166199  (0.524144449194924)\n",
      "     | > log_mle: -0.036532700061798096  (-0.021701299753345425)\n",
      "     | > loss_dur: 0.546381950378418  (0.5458457489482695)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.1129, device='cuda:0')  (tensor(1.9913, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.5119  (0.4168287691522818)\n",
      "     | > loader_time: 0.006  (0.004762054662235451)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:58:43 -- STEP: 330/406 -- GLOBAL_STEP: 8450\u001b[0m\n",
      "     | > loss: 0.5164402723312378  (0.5223385390007136)\n",
      "     | > log_mle: -0.05248826742172241  (-0.023031983772913604)\n",
      "     | > loss_dur: 0.5689285397529602  (0.5453705227736274)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7168, device='cuda:0')  (tensor(2.0703, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.5105  (0.42865762349331027)\n",
      "     | > loader_time: 0.005  (0.004813807660883124)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:58:58 -- STEP: 355/406 -- GLOBAL_STEP: 8475\u001b[0m\n",
      "     | > loss: 0.4998363256454468  (0.5209138734239928)\n",
      "     | > log_mle: -0.051657676696777344  (-0.024501254860783958)\n",
      "     | > loss_dur: 0.5514940023422241  (0.545415128284777)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6126, device='cuda:0')  (tensor(2.0820, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.5635  (0.44128416827027234)\n",
      "     | > loader_time: 0.005  (0.004852642811519999)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:59:14 -- STEP: 380/406 -- GLOBAL_STEP: 8500\u001b[0m\n",
      "     | > loss: 0.49373090267181396  (0.5190762590420873)\n",
      "     | > log_mle: -0.04625403881072998  (-0.025944492848295905)\n",
      "     | > loss_dur: 0.539984941482544  (0.5450207518903837)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(0.8971, device='cuda:0')  (tensor(2.0704, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.6816  (0.45311724888651)\n",
      "     | > loader_time: 0.005  (0.004881113453915247)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 02:59:30 -- STEP: 405/406 -- GLOBAL_STEP: 8525\u001b[0m\n",
      "     | > loss: 0.47118210792541504  (0.5172162950774772)\n",
      "     | > log_mle: -0.04471015930175781  (-0.027305774629851908)\n",
      "     | > loss_dur: 0.5158922672271729  (0.5445220697073296)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.3280, device='cuda:0')  (tensor(2.0787, device='cuda:0'))\n",
      "     | > current_lr: 4.9999999999999996e-06 \n",
      "     | > step_time: 0.3123  (0.46497422677499284)\n",
      "     | > loader_time: 0.002  (0.004878863581904659)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0984644889831543 \u001b[0m(+0.0011259913444519043)\n",
      "     | > avg_loss:\u001b[92m 0.47931819781661034 \u001b[0m(-0.061350297182798386)\n",
      "     | > avg_log_mle:\u001b[92m -0.04057475924491882 \u001b[0m(-0.022908054292201996)\n",
      "     | > avg_loss_dur:\u001b[92m 0.5198929570615292 \u001b[0m(-0.03844224289059639)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_8526.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 21/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:00:00) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:00:23 -- STEP: 24/406 -- GLOBAL_STEP: 8550\u001b[0m\n",
      "     | > loss: 0.4741393029689789  (0.49011875440677005)\n",
      "     | > log_mle: -0.020028352737426758  (-0.01284764458735784)\n",
      "     | > loss_dur: 0.49416765570640564  (0.5029663989941279)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.6682, device='cuda:0')  (tensor(1.4663, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.2702  (0.2655326922734578)\n",
      "     | > loader_time: 0.002  (0.011677304903666178)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:00:30 -- STEP: 49/406 -- GLOBAL_STEP: 8575\u001b[0m\n",
      "     | > loss: 0.48780375719070435  (0.49000951039547824)\n",
      "     | > log_mle: -0.01865863800048828  (-0.014354138958210848)\n",
      "     | > loss_dur: 0.5064623951911926  (0.5043636493536893)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8926, device='cuda:0')  (tensor(1.5216, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.2783  (0.27898802562635777)\n",
      "     | > loader_time: 0.002  (0.006944996970040458)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:00:38 -- STEP: 74/406 -- GLOBAL_STEP: 8600\u001b[0m\n",
      "     | > loss: 0.48011553287506104  (0.4863722263961225)\n",
      "     | > log_mle: -0.04883229732513428  (-0.018882513046264652)\n",
      "     | > loss_dur: 0.5289478302001953  (0.5052547394423873)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9719, device='cuda:0')  (tensor(1.7902, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.3083  (0.2923329971932076)\n",
      "     | > loader_time: 0.002  (0.005518552419301626)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:00:47 -- STEP: 99/406 -- GLOBAL_STEP: 8625\u001b[0m\n",
      "     | > loss: 0.48398590087890625  (0.4837517605887519)\n",
      "     | > log_mle: -0.03124713897705078  (-0.02241450247138438)\n",
      "     | > loss_dur: 0.515233039855957  (0.5061662630601362)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.1912, device='cuda:0')  (tensor(1.7204, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.3173  (0.3056816260019936)\n",
      "     | > loader_time: 0.003  (0.004873109586311106)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:00:57 -- STEP: 124/406 -- GLOBAL_STEP: 8650\u001b[0m\n",
      "     | > loss: 0.4600090980529785  (0.4793763343364962)\n",
      "     | > log_mle: -0.041192591190338135  (-0.025798920662172382)\n",
      "     | > loss_dur: 0.5012016892433167  (0.5051752549986686)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.6600, device='cuda:0')  (tensor(1.7642, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4194  (0.3188298113884463)\n",
      "     | > loader_time: 0.004  (0.004592905121464879)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:01:06 -- STEP: 149/406 -- GLOBAL_STEP: 8675\u001b[0m\n",
      "     | > loss: 0.46113109588623047  (0.4777402483776912)\n",
      "     | > log_mle: -0.047780752182006836  (-0.028719499207183023)\n",
      "     | > loss_dur: 0.5089118480682373  (0.5064597475848742)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1955, device='cuda:0')  (tensor(1.9054, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4344  (0.3302931801584741)\n",
      "     | > loader_time: 0.003  (0.004399992475573645)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:01:17 -- STEP: 174/406 -- GLOBAL_STEP: 8700\u001b[0m\n",
      "     | > loss: 0.460956871509552  (0.4759356343540652)\n",
      "     | > log_mle: -0.045471131801605225  (-0.030886993325989827)\n",
      "     | > loss_dur: 0.5064280033111572  (0.5068226276800553)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.6211, device='cuda:0')  (tensor(1.9005, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4634  (0.34200017753688744)\n",
      "     | > loader_time: 0.005  (0.004314273253254502)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:01:28 -- STEP: 199/406 -- GLOBAL_STEP: 8725\u001b[0m\n",
      "     | > loss: 0.47437596321105957  (0.4745671097657189)\n",
      "     | > log_mle: -0.039409339427948  (-0.03306206985933697)\n",
      "     | > loss_dur: 0.5137853026390076  (0.5076291796250558)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.3737, device='cuda:0')  (tensor(2.0106, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4954  (0.35478442517956277)\n",
      "     | > loader_time: 0.004  (0.004275256065867048)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:01:39 -- STEP: 224/406 -- GLOBAL_STEP: 8750\u001b[0m\n",
      "     | > loss: 0.4418303370475769  (0.47229317096727236)\n",
      "     | > log_mle: -0.0472598671913147  (-0.03506278938480787)\n",
      "     | > loss_dur: 0.4890902042388916  (0.5073559603520799)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3392, device='cuda:0')  (tensor(2.1420, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4204  (0.36511275172233565)\n",
      "     | > loader_time: 0.004  (0.004249379038810724)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:01:52 -- STEP: 249/406 -- GLOBAL_STEP: 8775\u001b[0m\n",
      "     | > loss: 0.45170730352401733  (0.4705401898387924)\n",
      "     | > log_mle: -0.045759499073028564  (-0.03685985822754214)\n",
      "     | > loss_dur: 0.4974668025970459  (0.5074000480663342)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8072, device='cuda:0')  (tensor(2.2031, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4314  (0.37712152320218356)\n",
      "     | > loader_time: 0.004  (0.004256845956825341)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:02:04 -- STEP: 274/406 -- GLOBAL_STEP: 8800\u001b[0m\n",
      "     | > loss: 0.4456965923309326  (0.4688325436228383)\n",
      "     | > log_mle: -0.05858081579208374  (-0.03867180068997572)\n",
      "     | > loss_dur: 0.5042774081230164  (0.5075043443128137)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.2565, device='cuda:0')  (tensor(2.2574, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.4704  (0.38877635976693914)\n",
      "     | > loader_time: 0.005  (0.004273925384465789)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:02:18 -- STEP: 299/406 -- GLOBAL_STEP: 8825\u001b[0m\n",
      "     | > loss: 0.4493345022201538  (0.46712480430618974)\n",
      "     | > log_mle: -0.07432955503463745  (-0.04008178108910654)\n",
      "     | > loss_dur: 0.5236640572547913  (0.507206585395296)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6437, device='cuda:0')  (tensor(2.2640, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.6216  (0.4005074524959194)\n",
      "     | > loader_time: 0.005  (0.00431826920014958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:02:32 -- STEP: 324/406 -- GLOBAL_STEP: 8850\u001b[0m\n",
      "     | > loss: 0.41640380024909973  (0.4653095424543192)\n",
      "     | > log_mle: -0.05926024913787842  (-0.041384213316587766)\n",
      "     | > loss_dur: 0.47566404938697815  (0.5066937557709065)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.8363, device='cuda:0')  (tensor(2.2883, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.5185  (0.4122354049741488)\n",
      "     | > loader_time: 0.005  (0.004355772777839937)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:02:47 -- STEP: 349/406 -- GLOBAL_STEP: 8875\u001b[0m\n",
      "     | > loss: 0.46573132276535034  (0.46384292729946125)\n",
      "     | > log_mle: -0.057409465312957764  (-0.04270389496767762)\n",
      "     | > loss_dur: 0.5231407880783081  (0.5065468222671383)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.2429, device='cuda:0')  (tensor(2.3260, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.5335  (0.4243480407747636)\n",
      "     | > loader_time: 0.005  (0.004402239889675015)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:03:02 -- STEP: 374/406 -- GLOBAL_STEP: 8900\u001b[0m\n",
      "     | > loss: 0.41793882846832275  (0.46192336783689614)\n",
      "     | > log_mle: -0.060430824756622314  (-0.04408023430701887)\n",
      "     | > loss_dur: 0.47836965322494507  (0.5060036021439142)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9690, device='cuda:0')  (tensor(2.2825, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.7297  (0.4360295827376015)\n",
      "     | > loader_time: 0.005  (0.004458558750662566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:03:18 -- STEP: 399/406 -- GLOBAL_STEP: 8925\u001b[0m\n",
      "     | > loss: 0.4322691559791565  (0.4599872108987698)\n",
      "     | > log_mle: -0.06488406658172607  (-0.04536760674980951)\n",
      "     | > loss_dur: 0.49715322256088257  (0.5053548176485785)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.9268, device='cuda:0')  (tensor(2.2568, device='cuda:0'))\n",
      "     | > current_lr: 5.25e-06 \n",
      "     | > step_time: 0.5816  (0.4499265669581288)\n",
      "     | > loader_time: 0.005  (0.004502799576685237)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08833035826683044 \u001b[0m(-0.010134130716323853)\n",
      "     | > avg_loss:\u001b[92m 0.4183170609176159 \u001b[0m(-0.061001136898994446)\n",
      "     | > avg_log_mle:\u001b[92m -0.05630956590175629 \u001b[0m(-0.015734806656837463)\n",
      "     | > avg_loss_dur:\u001b[92m 0.4746266268193722 \u001b[0m(-0.04526633024215698)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_8932.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 22/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:03:52) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:04:13 -- STEP: 18/406 -- GLOBAL_STEP: 8950\u001b[0m\n",
      "     | > loss: 0.435850590467453  (0.43439245058430564)\n",
      "     | > log_mle: -0.026328086853027344  (-0.030817482206556533)\n",
      "     | > loss_dur: 0.46217867732048035  (0.4652099327908622)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.4735, device='cuda:0')  (tensor(1.3968, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.2712  (0.2625718514124553)\n",
      "     | > loader_time: 0.002  (0.015069246292114258)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:04:20 -- STEP: 43/406 -- GLOBAL_STEP: 8975\u001b[0m\n",
      "     | > loss: 0.4086185395717621  (0.4303513883158218)\n",
      "     | > log_mle: -0.027304768562316895  (-0.030941575072532475)\n",
      "     | > loss_dur: 0.435923308134079  (0.4612929633883543)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.1801, device='cuda:0')  (tensor(1.4567, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.3083  (0.2745051328525987)\n",
      "     | > loader_time: 0.003  (0.007704579552938771)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:04:28 -- STEP: 68/406 -- GLOBAL_STEP: 9000\u001b[0m\n",
      "     | > loss: 0.4259507656097412  (0.4287763343137853)\n",
      "     | > log_mle: -0.04802703857421875  (-0.03486215104075039)\n",
      "     | > loss_dur: 0.47397780418395996  (0.4636384853545357)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7337, device='cuda:0')  (tensor(1.5170, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.2993  (0.289203875205096)\n",
      "     | > loader_time: 0.002  (0.005887575009289909)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_9000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:04:39 -- STEP: 93/406 -- GLOBAL_STEP: 9025\u001b[0m\n",
      "     | > loss: 0.4024038016796112  (0.4255216602356203)\n",
      "     | > log_mle: -0.06625854969024658  (-0.038953520277495025)\n",
      "     | > loss_dur: 0.4686623513698578  (0.4644751805131153)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7008, device='cuda:0')  (tensor(1.6648, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.3603  (0.30495752570449663)\n",
      "     | > loader_time: 0.003  (0.005101324409566898)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:04:49 -- STEP: 118/406 -- GLOBAL_STEP: 9050\u001b[0m\n",
      "     | > loss: 0.4067821204662323  (0.42180259803594167)\n",
      "     | > log_mle: -0.05495542287826538  (-0.04205628926471128)\n",
      "     | > loss_dur: 0.4617375433444977  (0.463858887300653)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.1937, device='cuda:0')  (tensor(1.7443, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.3453  (0.31807947158813477)\n",
      "     | > loader_time: 0.003  (0.004707572823863918)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:04:58 -- STEP: 143/406 -- GLOBAL_STEP: 9075\u001b[0m\n",
      "     | > loss: 0.4188474416732788  (0.419786307569984)\n",
      "     | > log_mle: -0.06684017181396484  (-0.04513565351913025)\n",
      "     | > loss_dur: 0.48568761348724365  (0.4649219610891142)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4585, device='cuda:0')  (tensor(1.7723, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.4444  (0.3298750407212264)\n",
      "     | > loader_time: 0.004  (0.004514487473281113)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:05:09 -- STEP: 168/406 -- GLOBAL_STEP: 9100\u001b[0m\n",
      "     | > loss: 0.41170331835746765  (0.41820896842650007)\n",
      "     | > log_mle: -0.04864919185638428  (-0.047239637091046296)\n",
      "     | > loss_dur: 0.46035251021385193  (0.46544860551754635)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8510, device='cuda:0')  (tensor(1.8251, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.4074  (0.3404299247832526)\n",
      "     | > loader_time: 0.004  (0.004384848333540417)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:05:20 -- STEP: 193/406 -- GLOBAL_STEP: 9125\u001b[0m\n",
      "     | > loss: 0.41055795550346375  (0.41648911812144856)\n",
      "     | > log_mle: -0.06726568937301636  (-0.049488916915933094)\n",
      "     | > loss_dur: 0.4778236448764801  (0.46597803503738167)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.1975, device='cuda:0')  (tensor(1.9010, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.4804  (0.3532808642313272)\n",
      "     | > loader_time: 0.004  (0.004335456561548105)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:05:31 -- STEP: 218/406 -- GLOBAL_STEP: 9150\u001b[0m\n",
      "     | > loss: 0.40796834230422974  (0.4145964639722754)\n",
      "     | > log_mle: -0.0645369291305542  (-0.05130670540923373)\n",
      "     | > loss_dur: 0.47250527143478394  (0.4659031693815091)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7426, device='cuda:0')  (tensor(2.0473, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.4204  (0.36425411373103445)\n",
      "     | > loader_time: 0.004  (0.004311171146707798)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:05:43 -- STEP: 243/406 -- GLOBAL_STEP: 9175\u001b[0m\n",
      "     | > loss: 0.4109174907207489  (0.4128674339855649)\n",
      "     | > log_mle: -0.08126211166381836  (-0.05328010433495291)\n",
      "     | > loss_dur: 0.49217960238456726  (0.4661475383205178)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(7.9217, device='cuda:0')  (tensor(2.2116, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5695  (0.37563445538650336)\n",
      "     | > loader_time: 0.004  (0.004308360103717066)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:05:56 -- STEP: 268/406 -- GLOBAL_STEP: 9200\u001b[0m\n",
      "     | > loss: 0.3981541693210602  (0.411348669275419)\n",
      "     | > log_mle: -0.07528626918792725  (-0.05478931807759984)\n",
      "     | > loss_dur: 0.4734404385089874  (0.46613798735301887)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3656, device='cuda:0')  (tensor(2.2678, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5625  (0.38817817951316275)\n",
      "     | > loader_time: 0.004  (0.004339686080591002)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:06:09 -- STEP: 293/406 -- GLOBAL_STEP: 9225\u001b[0m\n",
      "     | > loss: 0.39639660716056824  (0.40972797781127296)\n",
      "     | > log_mle: -0.07722002267837524  (-0.05623744006043002)\n",
      "     | > loss_dur: 0.4736166298389435  (0.46596541787170304)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7526, device='cuda:0')  (tensor(2.3231, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.4934  (0.3990049256399631)\n",
      "     | > loader_time: 0.005  (0.004389581419908958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:06:23 -- STEP: 318/406 -- GLOBAL_STEP: 9250\u001b[0m\n",
      "     | > loss: 0.39653831720352173  (0.40821580551330383)\n",
      "     | > log_mle: -0.07071143388748169  (-0.05757108349470224)\n",
      "     | > loss_dur: 0.4672497510910034  (0.4657868890080062)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.1628, device='cuda:0')  (tensor(2.3210, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5075  (0.411308342555784)\n",
      "     | > loader_time: 0.005  (0.004434768508815165)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:06:37 -- STEP: 343/406 -- GLOBAL_STEP: 9275\u001b[0m\n",
      "     | > loss: 0.39280349016189575  (0.4066742788945967)\n",
      "     | > log_mle: -0.08448231220245361  (-0.058863801963127745)\n",
      "     | > loss_dur: 0.47728580236434937  (0.4655380808577246)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1587, device='cuda:0')  (tensor(2.3319, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5205  (0.4228804528539454)\n",
      "     | > loader_time: 0.005  (0.004458777758539941)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:06:53 -- STEP: 368/406 -- GLOBAL_STEP: 9300\u001b[0m\n",
      "     | > loss: 0.36780551075935364  (0.40506536626945355)\n",
      "     | > log_mle: -0.08750009536743164  (-0.06022305009157762)\n",
      "     | > loss_dur: 0.4553056061267853  (0.4652884163610313)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.3957, device='cuda:0')  (tensor(2.3013, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.5695  (0.4349419183057289)\n",
      "     | > loader_time: 0.005  (0.004514888576839284)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:07:09 -- STEP: 393/406 -- GLOBAL_STEP: 9325\u001b[0m\n",
      "     | > loss: 0.37174081802368164  (0.4033380653566985)\n",
      "     | > log_mle: -0.07906985282897949  (-0.06143874991637757)\n",
      "     | > loss_dur: 0.45081067085266113  (0.46477681527307624)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.1626, device='cuda:0')  (tensor(2.2656, device='cuda:0'))\n",
      "     | > current_lr: 5.5e-06 \n",
      "     | > step_time: 0.7177  (0.44840788962580186)\n",
      "     | > loader_time: 0.006  (0.0045587628245657074)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.1014673113822937 \u001b[0m(+0.013136953115463257)\n",
      "     | > avg_loss:\u001b[92m 0.35821766406297684 \u001b[0m(-0.06009939685463905)\n",
      "     | > avg_log_mle:\u001b[92m -0.07557686418294907 \u001b[0m(-0.01926729828119278)\n",
      "     | > avg_loss_dur:\u001b[92m 0.4337945282459259 \u001b[0m(-0.040832098573446274)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_9338.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 23/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:07:47) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:08:06 -- STEP: 12/406 -- GLOBAL_STEP: 9350\u001b[0m\n",
      "     | > loss: 0.3558562994003296  (0.38241059829791385)\n",
      "     | > log_mle: -0.054593443870544434  (-0.04473828275998434)\n",
      "     | > loss_dur: 0.410449743270874  (0.4271488810578982)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(0.9808, device='cuda:0')  (tensor(1.2310, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.2672  (0.26707559823989874)\n",
      "     | > loader_time: 0.002  (0.01935116449991862)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:08:13 -- STEP: 37/406 -- GLOBAL_STEP: 9375\u001b[0m\n",
      "     | > loss: 0.37492257356643677  (0.3798710123912708)\n",
      "     | > log_mle: -0.042792320251464844  (-0.04668464370675989)\n",
      "     | > loss_dur: 0.4177148938179016  (0.4265556560980307)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.2347, device='cuda:0')  (tensor(1.4250, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.2983  (0.2734644541869292)\n",
      "     | > loader_time: 0.003  (0.007926154781032252)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:08:21 -- STEP: 62/406 -- GLOBAL_STEP: 9400\u001b[0m\n",
      "     | > loss: 0.3777334690093994  (0.37918964845518904)\n",
      "     | > log_mle: -0.04149270057678223  (-0.049691432906735326)\n",
      "     | > loss_dur: 0.41922616958618164  (0.42888108136192443)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(0.8729, device='cuda:0')  (tensor(1.5399, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.3343  (0.29058629851187423)\n",
      "     | > loader_time: 0.003  (0.00577948554869621)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:08:30 -- STEP: 87/406 -- GLOBAL_STEP: 9425\u001b[0m\n",
      "     | > loss: 0.3461182117462158  (0.37650613058572513)\n",
      "     | > log_mle: -0.08099919557571411  (-0.05364293476630901)\n",
      "     | > loss_dur: 0.42711740732192993  (0.4301490653520343)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.5464, device='cuda:0')  (tensor(1.7096, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.3163  (0.30189472505416)\n",
      "     | > loader_time: 0.003  (0.00491251342598049)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:08:39 -- STEP: 112/406 -- GLOBAL_STEP: 9450\u001b[0m\n",
      "     | > loss: 0.34356075525283813  (0.37321938281612727)\n",
      "     | > log_mle: -0.07649362087249756  (-0.05707076245120594)\n",
      "     | > loss_dur: 0.4200543761253357  (0.4302901452673333)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.6592, device='cuda:0')  (tensor(1.9387, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.3914  (0.31461593295846674)\n",
      "     | > loader_time: 0.003  (0.0044862457684108166)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:08:48 -- STEP: 137/406 -- GLOBAL_STEP: 9475\u001b[0m\n",
      "     | > loss: 0.3957197070121765  (0.3712170854972226)\n",
      "     | > log_mle: -0.07004863023757935  (-0.05986355255990133)\n",
      "     | > loss_dur: 0.46576833724975586  (0.431080638057124)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3382, device='cuda:0')  (tensor(2.2075, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.3493  (0.32453547428994295)\n",
      "     | > loader_time: 0.003  (0.004252017849553239)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:08:58 -- STEP: 162/406 -- GLOBAL_STEP: 9500\u001b[0m\n",
      "     | > loss: 0.372454434633255  (0.369777512587147)\n",
      "     | > log_mle: -0.09306979179382324  (-0.06210312762378174)\n",
      "     | > loss_dur: 0.46552422642707825  (0.43188064021092876)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.4622, device='cuda:0')  (tensor(2.1878, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.4534  (0.33583572764455544)\n",
      "     | > loader_time: 0.004  (0.004145717915193533)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:09:09 -- STEP: 187/406 -- GLOBAL_STEP: 9525\u001b[0m\n",
      "     | > loss: 0.3466964662075043  (0.36805894062480826)\n",
      "     | > log_mle: -0.07916122674942017  (-0.0641422243041788)\n",
      "     | > loss_dur: 0.42585769295692444  (0.4322011649289871)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8081, device='cuda:0')  (tensor(2.2077, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.3833  (0.3476632074876264)\n",
      "     | > loader_time: 0.004  (0.004089240721840272)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:09:20 -- STEP: 212/406 -- GLOBAL_STEP: 9550\u001b[0m\n",
      "     | > loss: 0.3528006076812744  (0.36655679893381193)\n",
      "     | > log_mle: -0.08442580699920654  (-0.06596361016327483)\n",
      "     | > loss_dur: 0.43722641468048096  (0.4325204090970867)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.5316, device='cuda:0')  (tensor(2.3155, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.4084  (0.3588777094517113)\n",
      "     | > loader_time: 0.004  (0.004069692683669757)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:09:32 -- STEP: 237/406 -- GLOBAL_STEP: 9575\u001b[0m\n",
      "     | > loss: 0.33928170800209045  (0.36502646896909563)\n",
      "     | > log_mle: -0.08929800987243652  (-0.06777104119208296)\n",
      "     | > loss_dur: 0.428579717874527  (0.4327975101611785)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0914, device='cuda:0')  (tensor(2.3778, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5475  (0.36919595018217827)\n",
      "     | > loader_time: 0.004  (0.004088056741384516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:09:45 -- STEP: 262/406 -- GLOBAL_STEP: 9600\u001b[0m\n",
      "     | > loss: 0.353040874004364  (0.36370008217014427)\n",
      "     | > log_mle: -0.07164698839187622  (-0.06938875950019782)\n",
      "     | > loss_dur: 0.42468786239624023  (0.43308884167034206)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5785, device='cuda:0')  (tensor(2.4665, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5635  (0.382301285976672)\n",
      "     | > loader_time: 0.004  (0.004114391239544818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:09:57 -- STEP: 287/406 -- GLOBAL_STEP: 9625\u001b[0m\n",
      "     | > loss: 0.38839441537857056  (0.3622477623643775)\n",
      "     | > log_mle: -0.07945793867111206  (-0.07086917228399674)\n",
      "     | > loss_dur: 0.4678523540496826  (0.43311693464837414)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7984, device='cuda:0')  (tensor(2.4545, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5785  (0.3927921202124619)\n",
      "     | > loader_time: 0.005  (0.004146613310438417)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:10:11 -- STEP: 312/406 -- GLOBAL_STEP: 9650\u001b[0m\n",
      "     | > loss: 0.3669377863407135  (0.36094986313046556)\n",
      "     | > log_mle: -0.08192622661590576  (-0.0721103831743583)\n",
      "     | > loss_dur: 0.44886401295661926  (0.4330602463048237)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8825, device='cuda:0')  (tensor(2.4357, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5005  (0.40458524227142334)\n",
      "     | > loader_time: 0.005  (0.004189676963365997)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:10:25 -- STEP: 337/406 -- GLOBAL_STEP: 9675\u001b[0m\n",
      "     | > loss: 0.33457812666893005  (0.3597413587994676)\n",
      "     | > log_mle: -0.09244966506958008  (-0.07331120490320361)\n",
      "     | > loss_dur: 0.42702779173851013  (0.433052563702671)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.5952, device='cuda:0')  (tensor(2.4646, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.6526  (0.4160839747250611)\n",
      "     | > loader_time: 0.005  (0.004250101236632033)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:10:40 -- STEP: 362/406 -- GLOBAL_STEP: 9700\u001b[0m\n",
      "     | > loss: 0.3202776610851288  (0.35836190495701803)\n",
      "     | > log_mle: -0.09779739379882812  (-0.07458362362002802)\n",
      "     | > loss_dur: 0.4180750548839569  (0.43294552857704577)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2218, device='cuda:0')  (tensor(2.4773, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5585  (0.42737970892237037)\n",
      "     | > loader_time: 0.004  (0.004296683474798887)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:10:56 -- STEP: 387/406 -- GLOBAL_STEP: 9725\u001b[0m\n",
      "     | > loss: 0.3359685242176056  (0.3570273597111075)\n",
      "     | > log_mle: -0.0928727388381958  (-0.07573278128946784)\n",
      "     | > loss_dur: 0.4288412630558014  (0.4327601410005751)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7354, device='cuda:0')  (tensor(2.4785, device='cuda:0'))\n",
      "     | > current_lr: 5.75e-06 \n",
      "     | > step_time: 0.5685  (0.4400248108600153)\n",
      "     | > loader_time: 0.006  (0.004350153974784434)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09959086775779724 \u001b[0m(-0.00187644362449646)\n",
      "     | > avg_loss:\u001b[92m 0.32028960436582565 \u001b[0m(-0.037928059697151184)\n",
      "     | > avg_log_mle:\u001b[92m -0.08980894088745117 \u001b[0m(-0.014232076704502106)\n",
      "     | > avg_loss_dur:\u001b[92m 0.4100985452532768 \u001b[0m(-0.02369598299264908)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_9744.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 24/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:11:38) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:11:56 -- STEP: 6/406 -- GLOBAL_STEP: 9750\u001b[0m\n",
      "     | > loss: 0.33452045917510986  (0.35722456872463226)\n",
      "     | > log_mle: -0.05893176794052124  (-0.05585520466168722)\n",
      "     | > loss_dur: 0.3934522271156311  (0.41307977338631946)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(0.9314, device='cuda:0')  (tensor(1.1458, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.2602  (0.26507302125295)\n",
      "     | > loader_time: 0.002  (0.03670124212900797)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:12:02 -- STEP: 31/406 -- GLOBAL_STEP: 9775\u001b[0m\n",
      "     | > loss: 0.35297891497612  (0.34185206505560106)\n",
      "     | > log_mle: -0.05725473165512085  (-0.06034671298919186)\n",
      "     | > loss_dur: 0.41023364663124084  (0.4021987780447929)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(0.9958, device='cuda:0')  (tensor(1.3944, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.2672  (0.26934065357331305)\n",
      "     | > loader_time: 0.002  (0.008718344473069715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:12:10 -- STEP: 56/406 -- GLOBAL_STEP: 9800\u001b[0m\n",
      "     | > loss: 0.3414320945739746  (0.3402502786900316)\n",
      "     | > log_mle: -0.07085680961608887  (-0.06271560490131378)\n",
      "     | > loss_dur: 0.4122889041900635  (0.4029658835913454)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.2459, device='cuda:0')  (tensor(1.6773, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.3303  (0.28273816619600556)\n",
      "     | > loader_time: 0.003  (0.0059525370597839355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:12:18 -- STEP: 81/406 -- GLOBAL_STEP: 9825\u001b[0m\n",
      "     | > loss: 0.3225329518318176  (0.3373722161775754)\n",
      "     | > log_mle: -0.08022570610046387  (-0.06587839788860744)\n",
      "     | > loss_dur: 0.4027586579322815  (0.40325061406618284)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8560, device='cuda:0')  (tensor(1.9101, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.3673  (0.29823317939852484)\n",
      "     | > loader_time: 0.003  (0.004955765641765829)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:12:27 -- STEP: 106/406 -- GLOBAL_STEP: 9850\u001b[0m\n",
      "     | > loss: 0.30193355679512024  (0.3339417916986179)\n",
      "     | > log_mle: -0.07352060079574585  (-0.0694552395703658)\n",
      "     | > loss_dur: 0.3754541575908661  (0.4033970312689835)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7094, device='cuda:0')  (tensor(2.0593, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.3954  (0.31089495263009703)\n",
      "     | > loader_time: 0.003  (0.004533029952139223)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:12:37 -- STEP: 131/406 -- GLOBAL_STEP: 9875\u001b[0m\n",
      "     | > loss: 0.29387301206588745  (0.33109915802497003)\n",
      "     | > log_mle: -0.08360838890075684  (-0.07253144351580673)\n",
      "     | > loss_dur: 0.3774814009666443  (0.4036306015407766)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6772, device='cuda:0')  (tensor(2.2869, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.3393  (0.32189480948994176)\n",
      "     | > loader_time: 0.004  (0.0043174601693189785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:12:47 -- STEP: 156/406 -- GLOBAL_STEP: 9900\u001b[0m\n",
      "     | > loss: 0.31492576003074646  (0.3300827223903095)\n",
      "     | > log_mle: -0.09018898010253906  (-0.07486172364308286)\n",
      "     | > loss_dur: 0.4051147401332855  (0.4049444460333922)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1303, device='cuda:0')  (tensor(2.4051, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.3613  (0.33225625753402716)\n",
      "     | > loader_time: 0.004  (0.004209509262671838)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:12:57 -- STEP: 181/406 -- GLOBAL_STEP: 9925\u001b[0m\n",
      "     | > loss: 0.31810933351516724  (0.32888075297708674)\n",
      "     | > log_mle: -0.08707654476165771  (-0.07684889616887217)\n",
      "     | > loss_dur: 0.40518587827682495  (0.4057296491459588)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(6.1360, device='cuda:0')  (tensor(2.4818, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.4734  (0.34512493360108437)\n",
      "     | > loader_time: 0.004  (0.00416457850630112)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:13:08 -- STEP: 206/406 -- GLOBAL_STEP: 9950\u001b[0m\n",
      "     | > loss: 0.3243367373943329  (0.3275795574616459)\n",
      "     | > log_mle: -0.09107506275177002  (-0.07870981386564317)\n",
      "     | > loss_dur: 0.4154118001461029  (0.4062893713272891)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.2629, device='cuda:0')  (tensor(2.5570, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.3934  (0.35603144446622986)\n",
      "     | > loader_time: 0.004  (0.004149958925339779)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:13:20 -- STEP: 231/406 -- GLOBAL_STEP: 9975\u001b[0m\n",
      "     | > loss: 0.31746944785118103  (0.325932202659128)\n",
      "     | > log_mle: -0.10052859783172607  (-0.08055130408439808)\n",
      "     | > loss_dur: 0.4179980456829071  (0.40648350674352607)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2952, device='cuda:0')  (tensor(2.6550, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.5395  (0.3665746889073096)\n",
      "     | > loader_time: 0.004  (0.0041558556742482345)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:13:32 -- STEP: 256/406 -- GLOBAL_STEP: 10000\u001b[0m\n",
      "     | > loss: 0.296442449092865  (0.32484764489345247)\n",
      "     | > log_mle: -0.09785807132720947  (-0.08216545125469571)\n",
      "     | > loss_dur: 0.39430052042007446  (0.4070130961481482)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.0068, device='cuda:0')  (tensor(2.8774, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.5635  (0.37878084927797323)\n",
      "     | > loader_time: 0.004  (0.004168407060205934)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_10000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:13:50 -- STEP: 281/406 -- GLOBAL_STEP: 10025\u001b[0m\n",
      "     | > loss: 0.3100426197052002  (0.32340251858548336)\n",
      "     | > log_mle: -0.10779523849487305  (-0.08361365065455865)\n",
      "     | > loss_dur: 0.41783785820007324  (0.40701616924004197)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.5674, device='cuda:0')  (tensor(2.9092, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.5825  (0.39133884474051817)\n",
      "     | > loader_time: 0.006  (0.004203618209132943)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:14:03 -- STEP: 306/406 -- GLOBAL_STEP: 10050\u001b[0m\n",
      "     | > loss: 0.31484484672546387  (0.3223632986054701)\n",
      "     | > log_mle: -0.09736180305480957  (-0.08485808559492523)\n",
      "     | > loss_dur: 0.41220664978027344  (0.40722138420039533)\n",
      "     | > amp_scaler: 65536.0  (35230.95424836601)\n",
      "     | > grad_norm: tensor(2.1583, device='cuda:0')  (tensor(2.8505, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.4934  (0.4032366127749675)\n",
      "     | > loader_time: 0.005  (0.004255951619615741)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:14:18 -- STEP: 331/406 -- GLOBAL_STEP: 10075\u001b[0m\n",
      "     | > loss: 0.3011624217033386  (0.3211695877807017)\n",
      "     | > log_mle: -0.10054159164428711  (-0.08596406170248623)\n",
      "     | > loss_dur: 0.40170401334762573  (0.407133649483188)\n",
      "     | > amp_scaler: 65536.0  (37519.85498489428)\n",
      "     | > grad_norm: tensor(2.4565, device='cuda:0')  (tensor(2.8699, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.6426  (0.4151393711747)\n",
      "     | > loader_time: 0.004  (0.0042913212156727954)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:14:32 -- STEP: 356/406 -- GLOBAL_STEP: 10100\u001b[0m\n",
      "     | > loss: 0.32953763008117676  (0.320058626489023)\n",
      "     | > log_mle: -0.1084820032119751  (-0.08721193805169516)\n",
      "     | > loss_dur: 0.43801963329315186  (0.4072705645407183)\n",
      "     | > amp_scaler: 65536.0  (39487.280898876445)\n",
      "     | > grad_norm: tensor(2.9672, device='cuda:0')  (tensor(2.8307, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.6696  (0.42730192388041643)\n",
      "     | > loader_time: 0.004  (0.004338591286305632)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:14:48 -- STEP: 381/406 -- GLOBAL_STEP: 10125\u001b[0m\n",
      "     | > loss: 0.3049226403236389  (0.3188544744894573)\n",
      "     | > log_mle: -0.09729695320129395  (-0.0883911966964641)\n",
      "     | > loss_dur: 0.40221959352493286  (0.4072456711859214)\n",
      "     | > amp_scaler: 65536.0  (41196.514435695564)\n",
      "     | > grad_norm: tensor(1.9469, device='cuda:0')  (tensor(2.8354, device='cuda:0'))\n",
      "     | > current_lr: 6e-06 \n",
      "     | > step_time: 0.5615  (0.43982286716070707)\n",
      "     | > loader_time: 0.005  (0.004395434236901952)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10409426689147949 \u001b[0m(+0.004503399133682251)\n",
      "     | > avg_loss:\u001b[92m 0.2873619459569454 \u001b[0m(-0.032927658408880234)\n",
      "     | > avg_log_mle:\u001b[92m -0.10379251092672348 \u001b[0m(-0.013983570039272308)\n",
      "     | > avg_loss_dur:\u001b[92m 0.3911544568836689 \u001b[0m(-0.018944088369607925)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_10150.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 25/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:15:35) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:15:51 -- STEP: 0/406 -- GLOBAL_STEP: 10150\u001b[0m\n",
      "     | > loss: 0.35991838574409485  (0.35991838574409485)\n",
      "     | > log_mle: -0.055608391761779785  (-0.055608391761779785)\n",
      "     | > loss_dur: 0.41552677750587463  (0.41552677750587463)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(1.0347, device='cuda:0')  (tensor(1.0347, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.4584  (0.45841550827026367)\n",
      "     | > loader_time: 15.7311  (15.731133699417114)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:15:58 -- STEP: 25/406 -- GLOBAL_STEP: 10175\u001b[0m\n",
      "     | > loss: 0.31374701857566833  (0.3098384642601013)\n",
      "     | > log_mle: -0.07029128074645996  (-0.07231445550918579)\n",
      "     | > loss_dur: 0.3840382993221283  (0.3821529197692871)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0652, device='cuda:0')  (tensor(1.6658, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.3163  (0.26896440505981445)\n",
      "     | > loader_time: 0.002  (0.011770553588867187)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:16:05 -- STEP: 50/406 -- GLOBAL_STEP: 10200\u001b[0m\n",
      "     | > loss: 0.3227550685405731  (0.3086522197723387)\n",
      "     | > log_mle: -0.09472036361694336  (-0.07401565909385681)\n",
      "     | > loss_dur: 0.4174754321575165  (0.3826678788661957)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(3.5620, device='cuda:0')  (tensor(1.5938, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.3213  (0.2841982126235962)\n",
      "     | > loader_time: 0.003  (0.007126245498657227)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:16:14 -- STEP: 75/406 -- GLOBAL_STEP: 10225\u001b[0m\n",
      "     | > loss: 0.2964223325252533  (0.304717670281728)\n",
      "     | > log_mle: -0.09035110473632812  (-0.07793464740117394)\n",
      "     | > loss_dur: 0.3867734372615814  (0.38265231768290203)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.0938, device='cuda:0')  (tensor(1.7942, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.3573  (0.2953750896453858)\n",
      "     | > loader_time: 0.003  (0.005631513595581057)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:16:22 -- STEP: 100/406 -- GLOBAL_STEP: 10250\u001b[0m\n",
      "     | > loss: 0.308965802192688  (0.3028583833575248)\n",
      "     | > log_mle: -0.08320951461791992  (-0.08099631965160366)\n",
      "     | > loss_dur: 0.3921753168106079  (0.38385470300912855)\n",
      "     | > amp_scaler: 65536.0  (65536.0)\n",
      "     | > grad_norm: tensor(2.6296, device='cuda:0')  (tensor(1.8547, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.3944  (0.307699601650238)\n",
      "     | > loader_time: 0.003  (0.004984216690063479)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:16:32 -- STEP: 125/406 -- GLOBAL_STEP: 10275\u001b[0m\n",
      "     | > loss: 0.2676827609539032  (0.2990497341156006)\n",
      "     | > log_mle: -0.11227405071258545  (-0.08424020433425901)\n",
      "     | > loss_dur: 0.37995681166648865  (0.38328993844985965)\n",
      "     | > amp_scaler: 32768.0  (60817.408)\n",
      "     | > grad_norm: tensor(2.6809, device='cuda:0')  (tensor(2.0320, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.3353  (0.3204031467437744)\n",
      "     | > loader_time: 0.003  (0.00469997024536133)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:16:41 -- STEP: 150/406 -- GLOBAL_STEP: 10300\u001b[0m\n",
      "     | > loss: 0.27983739972114563  (0.2978968056042988)\n",
      "     | > log_mle: -0.0944674015045166  (-0.08666332284609472)\n",
      "     | > loss_dur: 0.37430480122566223  (0.3845601284503936)\n",
      "     | > amp_scaler: 32768.0  (56142.50666666664)\n",
      "     | > grad_norm: tensor(3.1612, device='cuda:0')  (tensor(2.0865, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.3683  (0.33134104887644444)\n",
      "     | > loader_time: 0.004  (0.0045105075836181655)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:16:52 -- STEP: 175/406 -- GLOBAL_STEP: 10325\u001b[0m\n",
      "     | > loss: 0.28959256410598755  (0.29693982022149207)\n",
      "     | > log_mle: -0.09760606288909912  (-0.08853527784347531)\n",
      "     | > loss_dur: 0.38719862699508667  (0.3854750980649675)\n",
      "     | > amp_scaler: 32768.0  (52803.29142857141)\n",
      "     | > grad_norm: tensor(4.1199, device='cuda:0')  (tensor(2.2148, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.4674  (0.34326039722987584)\n",
      "     | > loader_time: 0.004  (0.004398039409092493)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:17:03 -- STEP: 200/406 -- GLOBAL_STEP: 10350\u001b[0m\n",
      "     | > loss: 0.2761816084384918  (0.295303905159235)\n",
      "     | > log_mle: -0.10373973846435547  (-0.09045834690332409)\n",
      "     | > loss_dur: 0.3799213469028473  (0.38576225206255904)\n",
      "     | > amp_scaler: 32768.0  (50298.87999999998)\n",
      "     | > grad_norm: tensor(3.0492, device='cuda:0')  (tensor(2.2194, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.4924  (0.3557631742954254)\n",
      "     | > loader_time: 0.004  (0.004343711137771606)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:17:15 -- STEP: 225/406 -- GLOBAL_STEP: 10375\u001b[0m\n",
      "     | > loss: 0.2993030548095703  (0.2939490781890023)\n",
      "     | > log_mle: -0.10335290431976318  (-0.0921731607119242)\n",
      "     | > loss_dur: 0.4026559591293335  (0.38612223890092634)\n",
      "     | > amp_scaler: 32768.0  (48351.00444444443)\n",
      "     | > grad_norm: tensor(1.7494, device='cuda:0')  (tensor(2.3874, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5185  (0.3657500425974528)\n",
      "     | > loader_time: 0.005  (0.004328117370605468)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:17:27 -- STEP: 250/406 -- GLOBAL_STEP: 10400\u001b[0m\n",
      "     | > loss: 0.28297463059425354  (0.2931875381469728)\n",
      "     | > log_mle: -0.1245800256729126  (-0.09382289242744443)\n",
      "     | > loss_dur: 0.40755465626716614  (0.38701043057441703)\n",
      "     | > amp_scaler: 32768.0  (46792.70399999998)\n",
      "     | > grad_norm: tensor(14.7111, device='cuda:0')  (tensor(2.5479, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5525  (0.37761104393005374)\n",
      "     | > loader_time: 0.004  (0.0043316745758056625)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:17:40 -- STEP: 275/406 -- GLOBAL_STEP: 10425\u001b[0m\n",
      "     | > loss: 0.2886636257171631  (0.2918849283998664)\n",
      "     | > log_mle: -0.10124611854553223  (-0.09532227061011572)\n",
      "     | > loss_dur: 0.3899097442626953  (0.38720719900998196)\n",
      "     | > amp_scaler: 32768.0  (45517.7309090909)\n",
      "     | > grad_norm: tensor(2.5175, device='cuda:0')  (tensor(2.6133, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5715  (0.3895939107374712)\n",
      "     | > loader_time: 0.004  (0.004360064593228425)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:17:53 -- STEP: 300/406 -- GLOBAL_STEP: 10450\u001b[0m\n",
      "     | > loss: 0.28732043504714966  (0.2909037571152052)\n",
      "     | > log_mle: -0.09740984439849854  (-0.0965108865499496)\n",
      "     | > loss_dur: 0.3847302794456482  (0.3874146436651547)\n",
      "     | > amp_scaler: 32768.0  (44455.25333333332)\n",
      "     | > grad_norm: tensor(1.4833, device='cuda:0')  (tensor(2.5767, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.4614  (0.3997898554801941)\n",
      "     | > loader_time: 0.004  (0.004390378793080646)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:18:06 -- STEP: 325/406 -- GLOBAL_STEP: 10475\u001b[0m\n",
      "     | > loss: 0.29360952973365784  (0.28988750971280625)\n",
      "     | > log_mle: -0.10383403301239014  (-0.09764279750677252)\n",
      "     | > loss_dur: 0.397443562746048  (0.38753030721957876)\n",
      "     | > amp_scaler: 32768.0  (43556.23384615383)\n",
      "     | > grad_norm: tensor(8.7569, device='cuda:0')  (tensor(2.6612, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.6236  (0.4110380143385667)\n",
      "     | > loader_time: 0.004  (0.004422191473153917)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:18:21 -- STEP: 350/406 -- GLOBAL_STEP: 10500\u001b[0m\n",
      "     | > loss: 0.25781452655792236  (0.2889960230248315)\n",
      "     | > log_mle: -0.11836409568786621  (-0.0987677613326481)\n",
      "     | > loss_dur: 0.3761786222457886  (0.3877637843574797)\n",
      "     | > amp_scaler: 32768.0  (42785.6457142857)\n",
      "     | > grad_norm: tensor(6.0248, device='cuda:0')  (tensor(2.9536, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.5195  (0.42179745061056956)\n",
      "     | > loader_time: 0.005  (0.00446662902832031)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:18:36 -- STEP: 375/406 -- GLOBAL_STEP: 10525\u001b[0m\n",
      "     | > loss: 0.26119276881217957  (0.287938355922699)\n",
      "     | > log_mle: -0.1257261037826538  (-0.09994558954238887)\n",
      "     | > loss_dur: 0.3869188725948334  (0.387883945465088)\n",
      "     | > amp_scaler: 32768.0  (42117.80266666665)\n",
      "     | > grad_norm: tensor(7.8288, device='cuda:0')  (tensor(3.2097, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.6686  (0.4332815767923991)\n",
      "     | > loader_time: 0.005  (0.004521152496337886)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:18:52 -- STEP: 400/406 -- GLOBAL_STEP: 10550\u001b[0m\n",
      "     | > loss: 0.2786239683628082  (0.28686337068676954)\n",
      "     | > log_mle: -0.12221121788024902  (-0.10101611658930774)\n",
      "     | > loss_dur: 0.40083518624305725  (0.38787948727607735)\n",
      "     | > amp_scaler: 32768.0  (41533.43999999998)\n",
      "     | > grad_norm: tensor(1.5345, device='cuda:0')  (tensor(3.2626, device='cuda:0'))\n",
      "     | > current_lr: 6.2499999999999995e-06 \n",
      "     | > step_time: 0.7446  (0.4464730054140091)\n",
      "     | > loader_time: 0.005  (0.004556338787078851)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09425833821296692 \u001b[0m(-0.009835928678512573)\n",
      "     | > avg_loss:\u001b[92m 0.258976012468338 \u001b[0m(-0.028385933488607407)\n",
      "     | > avg_log_mle:\u001b[92m -0.11672815680503845 \u001b[0m(-0.012935645878314972)\n",
      "     | > avg_loss_dur:\u001b[92m 0.37570416927337646 \u001b[0m(-0.015450287610292435)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_10556.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 26/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:19:25) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:19:46 -- STEP: 19/406 -- GLOBAL_STEP: 10575\u001b[0m\n",
      "     | > loss: 0.27196207642555237  (0.27974255147733185)\n",
      "     | > log_mle: -0.07466793060302734  (-0.08399677590319984)\n",
      "     | > loss_dur: 0.3466300070285797  (0.3637393273805317)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0346, device='cuda:0')  (tensor(2.0280, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.2642  (0.25886656108655426)\n",
      "     | > loader_time: 0.003  (0.012537692722521332)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:19:53 -- STEP: 44/406 -- GLOBAL_STEP: 10600\u001b[0m\n",
      "     | > loss: 0.2860533893108368  (0.27906170893799165)\n",
      "     | > log_mle: -0.09219050407409668  (-0.0844221602786671)\n",
      "     | > loss_dur: 0.37824389338493347  (0.3634838692166589)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.2389, device='cuda:0')  (tensor(1.9625, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.2742  (0.26810687780380243)\n",
      "     | > loader_time: 0.003  (0.006756262345747514)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:20:01 -- STEP: 69/406 -- GLOBAL_STEP: 10625\u001b[0m\n",
      "     | > loss: 0.28000566363334656  (0.2780975090420764)\n",
      "     | > log_mle: -0.09789526462554932  (-0.08799811290658038)\n",
      "     | > loss_dur: 0.3779009282588959  (0.3660956219486568)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2013, device='cuda:0')  (tensor(2.4203, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.3443  (0.28279279971468274)\n",
      "     | > loader_time: 0.003  (0.005265806032263715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:20:10 -- STEP: 94/406 -- GLOBAL_STEP: 10650\u001b[0m\n",
      "     | > loss: 0.26448994874954224  (0.27568129275707504)\n",
      "     | > log_mle: -0.10672593116760254  (-0.09177561072593042)\n",
      "     | > loss_dur: 0.3712158799171448  (0.3674569034830053)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(6.0462, device='cuda:0')  (tensor(2.8401, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.3713  (0.2959813209290199)\n",
      "     | > loader_time: 0.003  (0.004631993618417297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:20:19 -- STEP: 119/406 -- GLOBAL_STEP: 10675\u001b[0m\n",
      "     | > loss: 0.2581542730331421  (0.27282232672226553)\n",
      "     | > log_mle: -0.11727702617645264  (-0.09462052683870333)\n",
      "     | > loss_dur: 0.3754312992095947  (0.3674428535609686)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4364, device='cuda:0')  (tensor(2.9342, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.4054  (0.30851949964250824)\n",
      "     | > loader_time: 0.004  (0.004340189845622088)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:20:28 -- STEP: 144/406 -- GLOBAL_STEP: 10700\u001b[0m\n",
      "     | > loss: 0.2618299126625061  (0.27154112793505214)\n",
      "     | > log_mle: -0.10385680198669434  (-0.09725747630000116)\n",
      "     | > loss_dur: 0.36568671464920044  (0.36879860423505306)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.1941, device='cuda:0')  (tensor(2.8854, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.3743  (0.31973113119602187)\n",
      "     | > loader_time: 0.004  (0.004184487793180681)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:20:38 -- STEP: 169/406 -- GLOBAL_STEP: 10725\u001b[0m\n",
      "     | > loss: 0.266884982585907  (0.27091775684667063)\n",
      "     | > log_mle: -0.10956370830535889  (-0.09911445576763718)\n",
      "     | > loss_dur: 0.37644869089126587  (0.3700322126143078)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8567, device='cuda:0')  (tensor(2.8247, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.4384  (0.3304685403609417)\n",
      "     | > loader_time: 0.004  (0.004116272785254486)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:20:49 -- STEP: 194/406 -- GLOBAL_STEP: 10750\u001b[0m\n",
      "     | > loss: 0.25884494185447693  (0.26922963544265527)\n",
      "     | > log_mle: -0.11193525791168213  (-0.10109125369602871)\n",
      "     | > loss_dur: 0.37078019976615906  (0.37032088913868383)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3759, device='cuda:0')  (tensor(2.8088, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.4604  (0.34285502827044606)\n",
      "     | > loader_time: 0.004  (0.004075974533238361)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:21:00 -- STEP: 219/406 -- GLOBAL_STEP: 10775\u001b[0m\n",
      "     | > loss: 0.24020391702651978  (0.2679257662328957)\n",
      "     | > log_mle: -0.11816263198852539  (-0.1026741900400484)\n",
      "     | > loss_dur: 0.35836654901504517  (0.3705999562729439)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.3602, device='cuda:0')  (tensor(2.8122, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.5445  (0.35385776545903447)\n",
      "     | > loader_time: 0.005  (0.004085956643161163)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:21:12 -- STEP: 244/406 -- GLOBAL_STEP: 10800\u001b[0m\n",
      "     | > loss: 0.23729771375656128  (0.2671953309022015)\n",
      "     | > log_mle: -0.117500901222229  (-0.10444534191342651)\n",
      "     | > loss_dur: 0.3547986149787903  (0.37164067281562774)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1156, device='cuda:0')  (tensor(2.7655, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.4184  (0.36497684971230926)\n",
      "     | > loader_time: 0.004  (0.004110303081449914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:21:24 -- STEP: 269/406 -- GLOBAL_STEP: 10825\u001b[0m\n",
      "     | > loss: 0.23558998107910156  (0.2661110256905895)\n",
      "     | > log_mle: -0.12436223030090332  (-0.10577496121807169)\n",
      "     | > loss_dur: 0.3599522113800049  (0.3718859869086609)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2129, device='cuda:0')  (tensor(2.8614, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.5475  (0.3775342078013934)\n",
      "     | > loader_time: 0.004  (0.004137586040567729)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:21:37 -- STEP: 294/406 -- GLOBAL_STEP: 10850\u001b[0m\n",
      "     | > loss: 0.26927778124809265  (0.2651571413489429)\n",
      "     | > log_mle: -0.1264129877090454  (-0.1070396054764183)\n",
      "     | > loss_dur: 0.39569076895713806  (0.37219674682536086)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.3868, device='cuda:0')  (tensor(2.8614, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.4674  (0.3877108632301798)\n",
      "     | > loader_time: 0.005  (0.004184040893502785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:21:51 -- STEP: 319/406 -- GLOBAL_STEP: 10875\u001b[0m\n",
      "     | > loss: 0.2484613060951233  (0.26430365078875306)\n",
      "     | > log_mle: -0.1238555908203125  (-0.10820370763073146)\n",
      "     | > loss_dur: 0.3723168969154358  (0.37250735841948396)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(6.5108, device='cuda:0')  (tensor(2.8874, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.6216  (0.40024584961535414)\n",
      "     | > loader_time: 0.005  (0.004220086579038804)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:22:05 -- STEP: 344/406 -- GLOBAL_STEP: 10900\u001b[0m\n",
      "     | > loss: 0.2606774568557739  (0.26352954084096997)\n",
      "     | > log_mle: -0.11729300022125244  (-0.10927431475977566)\n",
      "     | > loss_dur: 0.37797045707702637  (0.372803855600745)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.2365, device='cuda:0')  (tensor(2.9138, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.5465  (0.4115437262280043)\n",
      "     | > loader_time: 0.006  (0.004259623760400817)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:22:20 -- STEP: 369/406 -- GLOBAL_STEP: 10925\u001b[0m\n",
      "     | > loss: 0.26606348156929016  (0.26264062499612373)\n",
      "     | > log_mle: -0.11689257621765137  (-0.11042606879055984)\n",
      "     | > loss_dur: 0.38295605778694153  (0.37306669378668295)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5991, device='cuda:0')  (tensor(2.9076, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.7046  (0.42371671438863284)\n",
      "     | > loader_time: 0.005  (0.004320904491393547)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:22:36 -- STEP: 394/406 -- GLOBAL_STEP: 10950\u001b[0m\n",
      "     | > loss: 0.25196999311447144  (0.26167178411169134)\n",
      "     | > log_mle: -0.12362861633300781  (-0.11146153607949387)\n",
      "     | > loss_dur: 0.37559860944747925  (0.3731333201911847)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.6891, device='cuda:0')  (tensor(2.9703, device='cuda:0'))\n",
      "     | > current_lr: 6.5e-06 \n",
      "     | > step_time: 0.5795  (0.4365677355509724)\n",
      "     | > loader_time: 0.005  (0.004374419372093857)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10084134340286255 \u001b[0m(+0.00658300518989563)\n",
      "     | > avg_loss:\u001b[92m 0.2318580187857151 \u001b[0m(-0.02711799368262291)\n",
      "     | > avg_log_mle:\u001b[92m -0.12624713778495789 \u001b[0m(-0.009518980979919434)\n",
      "     | > avg_loss_dur:\u001b[92m 0.358105156570673 \u001b[0m(-0.017599012702703476)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_10962.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 27/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:23:13) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:23:33 -- STEP: 13/406 -- GLOBAL_STEP: 10975\u001b[0m\n",
      "     | > loss: 0.25125056505203247  (0.2531708593551929)\n",
      "     | > log_mle: -0.10353243350982666  (-0.09370346711232112)\n",
      "     | > loss_dur: 0.35478299856185913  (0.34687432646751404)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0480, device='cuda:0')  (tensor(1.7586, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.2722  (0.2583111066084642)\n",
      "     | > loader_time: 0.002  (0.016168887798602764)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:23:39 -- STEP: 38/406 -- GLOBAL_STEP: 11000\u001b[0m\n",
      "     | > loss: 0.2608155310153961  (0.2552978812079679)\n",
      "     | > log_mle: -0.10455513000488281  (-0.09472345364721196)\n",
      "     | > loss_dur: 0.36537066102027893  (0.35002133485518006)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8685, device='cuda:0')  (tensor(1.6976, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.2873  (0.2671107492948833)\n",
      "     | > loader_time: 0.003  (0.006927483960201866)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_11000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:23:49 -- STEP: 63/406 -- GLOBAL_STEP: 11025\u001b[0m\n",
      "     | > loss: 0.241074800491333  (0.25445197924735047)\n",
      "     | > log_mle: -0.1108008623123169  (-0.09745775328742133)\n",
      "     | > loss_dur: 0.3518756628036499  (0.35190973253477187)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2979, device='cuda:0')  (tensor(2.0811, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.2813  (0.28227392075553775)\n",
      "     | > loader_time: 0.003  (0.005147612284100245)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:23:58 -- STEP: 88/406 -- GLOBAL_STEP: 11050\u001b[0m\n",
      "     | > loss: 0.2560579776763916  (0.25228976830840105)\n",
      "     | > log_mle: -0.09779465198516846  (-0.10096918046474455)\n",
      "     | > loss_dur: 0.35385262966156006  (0.35325894877314573)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.5496, device='cuda:0')  (tensor(2.2045, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.3683  (0.29482568935914477)\n",
      "     | > loader_time: 0.003  (0.004515504295175724)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:24:06 -- STEP: 113/406 -- GLOBAL_STEP: 11075\u001b[0m\n",
      "     | > loss: 0.25340786576271057  (0.24896730179280308)\n",
      "     | > log_mle: -0.1198655366897583  (-0.10437806834161807)\n",
      "     | > loss_dur: 0.37327340245246887  (0.35334537013442113)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.5763, device='cuda:0')  (tensor(2.3469, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.3343  (0.30737734262922173)\n",
      "     | > loader_time: 0.003  (0.00421620259242775)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:24:16 -- STEP: 138/406 -- GLOBAL_STEP: 11100\u001b[0m\n",
      "     | > loss: 0.2605975866317749  (0.24809983523859494)\n",
      "     | > log_mle: -0.12504732608795166  (-0.10703822840815004)\n",
      "     | > loss_dur: 0.38564491271972656  (0.35513806364674505)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0775, device='cuda:0')  (tensor(2.4295, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.4144  (0.3181519646575486)\n",
      "     | > loader_time: 0.003  (0.004061638445094009)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:24:26 -- STEP: 163/406 -- GLOBAL_STEP: 11125\u001b[0m\n",
      "     | > loss: 0.2387351095676422  (0.24689122613953665)\n",
      "     | > log_mle: -0.12817370891571045  (-0.10908717904354163)\n",
      "     | > loss_dur: 0.36690881848335266  (0.3559784051830783)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2588, device='cuda:0')  (tensor(2.5392, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.4374  (0.32920141015316073)\n",
      "     | > loader_time: 0.004  (0.0039606284510138555)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:24:36 -- STEP: 188/406 -- GLOBAL_STEP: 11150\u001b[0m\n",
      "     | > loss: 0.25132042169570923  (0.24561337698647318)\n",
      "     | > log_mle: -0.14080774784088135  (-0.11102308301215474)\n",
      "     | > loss_dur: 0.3921281695365906  (0.3566364599986279)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.7478, device='cuda:0')  (tensor(2.6233, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.3874  (0.3415785140179574)\n",
      "     | > loader_time: 0.004  (0.003955659714150934)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:24:47 -- STEP: 213/406 -- GLOBAL_STEP: 11175\u001b[0m\n",
      "     | > loss: 0.24000343680381775  (0.24462541993794867)\n",
      "     | > log_mle: -0.13076865673065186  (-0.11258561342534883)\n",
      "     | > loss_dur: 0.3707720935344696  (0.3572110333632975)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.9748, device='cuda:0')  (tensor(2.6781, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.3984  (0.35276377145113524)\n",
      "     | > loader_time: 0.004  (0.003970644283742409)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:24:59 -- STEP: 238/406 -- GLOBAL_STEP: 11200\u001b[0m\n",
      "     | > loss: 0.22576728463172913  (0.24362452102809393)\n",
      "     | > log_mle: -0.13228726387023926  (-0.11426050973539591)\n",
      "     | > loss_dur: 0.3580545485019684  (0.3578850307634899)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9001, device='cuda:0')  (tensor(2.6638, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.4064  (0.3625959007679916)\n",
      "     | > loader_time: 0.004  (0.003990891600857259)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:25:11 -- STEP: 263/406 -- GLOBAL_STEP: 11225\u001b[0m\n",
      "     | > loss: 0.22480642795562744  (0.24271043455192798)\n",
      "     | > log_mle: -0.1328716278076172  (-0.11574864296858754)\n",
      "     | > loss_dur: 0.35767805576324463  (0.35845907752051553)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.7227, device='cuda:0')  (tensor(2.6814, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.5345  (0.3756280144811131)\n",
      "     | > loader_time: 0.004  (0.004022529369977939)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:25:24 -- STEP: 288/406 -- GLOBAL_STEP: 11250\u001b[0m\n",
      "     | > loss: 0.20529675483703613  (0.2414737989505132)\n",
      "     | > log_mle: -0.12623262405395508  (-0.11706992528504795)\n",
      "     | > loss_dur: 0.3315293788909912  (0.35854372423556113)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0415, device='cuda:0')  (tensor(2.7268, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.4944  (0.38584157410595155)\n",
      "     | > loader_time: 0.005  (0.004072999788655171)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:25:38 -- STEP: 313/406 -- GLOBAL_STEP: 11275\u001b[0m\n",
      "     | > loss: 0.24497246742248535  (0.2408091691545785)\n",
      "     | > log_mle: -0.13029634952545166  (-0.11820320846935431)\n",
      "     | > loss_dur: 0.375268816947937  (0.3590123776239328)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8815, device='cuda:0')  (tensor(2.7569, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.6045  (0.39803066345068583)\n",
      "     | > loader_time: 0.005  (0.004121807817453009)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:25:51 -- STEP: 338/406 -- GLOBAL_STEP: 11300\u001b[0m\n",
      "     | > loss: 0.21780475974082947  (0.24014225487525648)\n",
      "     | > log_mle: -0.1334679126739502  (-0.11924147429550894)\n",
      "     | > loss_dur: 0.35127267241477966  (0.35938372917076533)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.9500, device='cuda:0')  (tensor(2.7784, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.5225  (0.40916880277486933)\n",
      "     | > loader_time: 0.005  (0.004184112746334638)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:26:06 -- STEP: 363/406 -- GLOBAL_STEP: 11325\u001b[0m\n",
      "     | > loss: 0.20551767945289612  (0.23935903062833572)\n",
      "     | > log_mle: -0.1434311866760254  (-0.12038811638992351)\n",
      "     | > loss_dur: 0.3489488661289215  (0.35974714701825905)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.9545, device='cuda:0')  (tensor(2.8013, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.5305  (0.42044094442992813)\n",
      "     | > loader_time: 0.005  (0.0042461114153060685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:26:22 -- STEP: 388/406 -- GLOBAL_STEP: 11350\u001b[0m\n",
      "     | > loss: 0.22293055057525635  (0.23844574261264703)\n",
      "     | > log_mle: -0.13429546356201172  (-0.12136228121433061)\n",
      "     | > loss_dur: 0.35722601413726807  (0.3598080238269775)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.3010, device='cuda:0')  (tensor(2.7814, device='cuda:0'))\n",
      "     | > current_lr: 6.75e-06 \n",
      "     | > step_time: 0.7086  (0.4337610860460811)\n",
      "     | > loader_time: 0.005  (0.004323336266979727)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0935034453868866 \u001b[0m(-0.007337898015975952)\n",
      "     | > avg_loss:\u001b[92m 0.21456797048449516 \u001b[0m(-0.01729004830121994)\n",
      "     | > avg_log_mle:\u001b[92m -0.12940822541713715 \u001b[0m(-0.0031610876321792603)\n",
      "     | > avg_loss_dur:\u001b[92m 0.3439761959016323 \u001b[0m(-0.01412896066904068)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_11368.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 28/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:27:03) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:27:21 -- STEP: 7/406 -- GLOBAL_STEP: 11375\u001b[0m\n",
      "     | > loss: 0.2560102939605713  (0.2360346019268036)\n",
      "     | > log_mle: -0.0953068733215332  (-0.09970009326934814)\n",
      "     | > loss_dur: 0.3513171672821045  (0.33573469519615173)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.0866, device='cuda:0')  (tensor(1.3906, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.2572  (0.2613801956176758)\n",
      "     | > loader_time: 0.001  (0.03045616831098284)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:27:28 -- STEP: 32/406 -- GLOBAL_STEP: 11400\u001b[0m\n",
      "     | > loss: 0.21189814805984497  (0.2276481380686164)\n",
      "     | > log_mle: -0.10831797122955322  (-0.10450209304690361)\n",
      "     | > loss_dur: 0.3202161192893982  (0.33215023111552)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.3417, device='cuda:0')  (tensor(1.9257, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.2662  (0.2653034552931785)\n",
      "     | > loader_time: 0.002  (0.008319884538650511)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:27:35 -- STEP: 57/406 -- GLOBAL_STEP: 11425\u001b[0m\n",
      "     | > loss: 0.2331259548664093  (0.22911868545047023)\n",
      "     | > log_mle: -0.10809206962585449  (-0.10657594705882825)\n",
      "     | > loss_dur: 0.3412180244922638  (0.3356946325092985)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8590, device='cuda:0')  (tensor(2.3267, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.3213  (0.2773219869847882)\n",
      "     | > loader_time: 0.003  (0.005759460884228087)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:27:44 -- STEP: 82/406 -- GLOBAL_STEP: 11450\u001b[0m\n",
      "     | > loss: 0.2128608226776123  (0.22740614523247973)\n",
      "     | > log_mle: -0.1244126558303833  (-0.10968171823315503)\n",
      "     | > loss_dur: 0.3372734785079956  (0.3370878634656348)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8760, device='cuda:0')  (tensor(2.6352, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.3603  (0.2906785883554598)\n",
      "     | > loader_time: 0.002  (0.004833474391844213)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:27:52 -- STEP: 107/406 -- GLOBAL_STEP: 11475\u001b[0m\n",
      "     | > loss: 0.2097196877002716  (0.22504562696563862)\n",
      "     | > log_mle: -0.1213078498840332  (-0.11286306381225586)\n",
      "     | > loss_dur: 0.3310275375843048  (0.3379086907778945)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.4210, device='cuda:0')  (tensor(2.5878, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.3864  (0.3030415383454795)\n",
      "     | > loader_time: 0.003  (0.004396356154825086)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:28:01 -- STEP: 132/406 -- GLOBAL_STEP: 11500\u001b[0m\n",
      "     | > loss: 0.2059820592403412  (0.22366951473734595)\n",
      "     | > log_mle: -0.14047694206237793  (-0.11578435428214795)\n",
      "     | > loss_dur: 0.3464590013027191  (0.3394538690194939)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.3939, device='cuda:0')  (tensor(2.8201, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.3493  (0.3135878064415671)\n",
      "     | > loader_time: 0.004  (0.004253703536409321)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:28:11 -- STEP: 157/406 -- GLOBAL_STEP: 11525\u001b[0m\n",
      "     | > loss: 0.21811321377754211  (0.22340757281157622)\n",
      "     | > log_mle: -0.12861645221710205  (-0.11775828091202269)\n",
      "     | > loss_dur: 0.34672966599464417  (0.3411658537235989)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.9731, device='cuda:0')  (tensor(3.1238, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.4314  (0.32563330565288573)\n",
      "     | > loader_time: 0.004  (0.004150105130140948)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:28:22 -- STEP: 182/406 -- GLOBAL_STEP: 11550\u001b[0m\n",
      "     | > loss: 0.20899346470832825  (0.22233078489591787)\n",
      "     | > log_mle: -0.13403892517089844  (-0.11965588422921988)\n",
      "     | > loss_dur: 0.3430323898792267  (0.341986669125138)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3382, device='cuda:0')  (tensor(3.0996, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.3823  (0.3377682677992098)\n",
      "     | > loader_time: 0.005  (0.004107999277638866)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:28:33 -- STEP: 207/406 -- GLOBAL_STEP: 11575\u001b[0m\n",
      "     | > loss: 0.22199028730392456  (0.22139456292281404)\n",
      "     | > log_mle: -0.12550055980682373  (-0.12135791317852224)\n",
      "     | > loss_dur: 0.3474908471107483  (0.3427524761013364)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.2063, device='cuda:0')  (tensor(3.0373, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.4764  (0.34908513516043693)\n",
      "     | > loader_time: 0.004  (0.004090530284936876)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:28:44 -- STEP: 232/406 -- GLOBAL_STEP: 11600\u001b[0m\n",
      "     | > loss: 0.210661381483078  (0.2205302174492129)\n",
      "     | > log_mle: -0.14374315738677979  (-0.12317891573083811)\n",
      "     | > loss_dur: 0.3544045388698578  (0.34370913318005114)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.4119, device='cuda:0')  (tensor(3.1552, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.4084  (0.3588906053839059)\n",
      "     | > loader_time: 0.004  (0.0040897634522668235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:28:56 -- STEP: 257/406 -- GLOBAL_STEP: 11625\u001b[0m\n",
      "     | > loss: 0.22130250930786133  (0.21962574518608213)\n",
      "     | > log_mle: -0.13947832584381104  (-0.12469566053917436)\n",
      "     | > loss_dur: 0.36078083515167236  (0.3443214057252566)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.6630, device='cuda:0')  (tensor(3.1702, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.5515  (0.371547599710843)\n",
      "     | > loader_time: 0.005  (0.004128073903837092)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:29:09 -- STEP: 282/406 -- GLOBAL_STEP: 11650\u001b[0m\n",
      "     | > loss: 0.2032005786895752  (0.218440221450853)\n",
      "     | > log_mle: -0.14395833015441895  (-0.12605684107922488)\n",
      "     | > loss_dur: 0.34715890884399414  (0.34449706253007806)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.6495, device='cuda:0')  (tensor(3.1386, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.4614  (0.3824963527368315)\n",
      "     | > loader_time: 0.005  (0.004173823282228293)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:29:22 -- STEP: 307/406 -- GLOBAL_STEP: 11675\u001b[0m\n",
      "     | > loss: 0.20089229941368103  (0.21767380425906724)\n",
      "     | > log_mle: -0.13699793815612793  (-0.12719719728351794)\n",
      "     | > loss_dur: 0.33789023756980896  (0.34487100154258554)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9144, device='cuda:0')  (tensor(3.1059, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.6126  (0.3942734170037682)\n",
      "     | > loader_time: 0.004  (0.004208856762814599)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:29:36 -- STEP: 332/406 -- GLOBAL_STEP: 11700\u001b[0m\n",
      "     | > loss: 0.21135467290878296  (0.21712988650942422)\n",
      "     | > log_mle: -0.13635718822479248  (-0.12817987763738048)\n",
      "     | > loss_dur: 0.34771186113357544  (0.345309764146805)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.8624, device='cuda:0')  (tensor(3.1106, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.5195  (0.4056891906692321)\n",
      "     | > loader_time: 0.005  (0.004262738199119109)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:29:51 -- STEP: 357/406 -- GLOBAL_STEP: 11725\u001b[0m\n",
      "     | > loss: 0.21782907843589783  (0.21665625094699592)\n",
      "     | > log_mle: -0.1328955888748169  (-0.12927827915223705)\n",
      "     | > loss_dur: 0.3507246673107147  (0.34593453009923325)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.9012, device='cuda:0')  (tensor(3.2026, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.5445  (0.41766919608877484)\n",
      "     | > loader_time: 0.006  (0.004323079138576818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:30:06 -- STEP: 382/406 -- GLOBAL_STEP: 11750\u001b[0m\n",
      "     | > loss: 0.21678608655929565  (0.21576613094170055)\n",
      "     | > log_mle: -0.1422795057296753  (-0.13035063874659114)\n",
      "     | > loss_dur: 0.35906559228897095  (0.34611676968829197)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.5291, device='cuda:0')  (tensor(3.2065, device='cuda:0'))\n",
      "     | > current_lr: 7e-06 \n",
      "     | > step_time: 0.5545  (0.42969781191561235)\n",
      "     | > loader_time: 0.005  (0.004383374883242303)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0933351218700409 \u001b[0m(-0.00016832351684570312)\n",
      "     | > avg_loss:\u001b[92m 0.19441747665405273 \u001b[0m(-0.02015049383044243)\n",
      "     | > avg_log_mle:\u001b[92m -0.13397540152072906 \u001b[0m(-0.004567176103591919)\n",
      "     | > avg_loss_dur:\u001b[92m 0.3283928781747818 \u001b[0m(-0.01558331772685051)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_11774.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 29/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:30:52) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:31:08 -- STEP: 1/406 -- GLOBAL_STEP: 11775\u001b[0m\n",
      "     | > loss: 0.2146165370941162  (0.2146165370941162)\n",
      "     | > log_mle: -0.11213123798370361  (-0.11213123798370361)\n",
      "     | > loss_dur: 0.3267477750778198  (0.3267477750778198)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.3039, device='cuda:0')  (tensor(2.3039, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.2672  (0.2672426700592041)\n",
      "     | > loader_time: 0.002  (0.0020012855529785156)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:31:15 -- STEP: 26/406 -- GLOBAL_STEP: 11800\u001b[0m\n",
      "     | > loss: 0.20548659563064575  (0.20472211448045877)\n",
      "     | > log_mle: -0.11933302879333496  (-0.1134326641376202)\n",
      "     | > loss_dur: 0.3248196244239807  (0.31815477861807884)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9323, device='cuda:0')  (tensor(2.3572, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.2793  (0.2630851543866671)\n",
      "     | > loader_time: 0.002  (0.009008022455068734)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:31:22 -- STEP: 51/406 -- GLOBAL_STEP: 11825\u001b[0m\n",
      "     | > loss: 0.19884705543518066  (0.20781318171351565)\n",
      "     | > log_mle: -0.14115571975708008  (-0.1150815580405441)\n",
      "     | > loss_dur: 0.34000277519226074  (0.32289473975405975)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.1142, device='cuda:0')  (tensor(2.6059, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.3153  (0.27352304552115636)\n",
      "     | > loader_time: 0.002  (0.0057108495749679244)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:31:30 -- STEP: 76/406 -- GLOBAL_STEP: 11850\u001b[0m\n",
      "     | > loss: 0.2104431688785553  (0.20501987557662163)\n",
      "     | > log_mle: -0.11762690544128418  (-0.11810777846135591)\n",
      "     | > loss_dur: 0.3280700743198395  (0.3231276540379775)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.0263, device='cuda:0')  (tensor(3.1463, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.3013  (0.2849299186154416)\n",
      "     | > loader_time: 0.003  (0.0047277525851601035)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:31:38 -- STEP: 101/406 -- GLOBAL_STEP: 11875\u001b[0m\n",
      "     | > loss: 0.1895117461681366  (0.20425307957252653)\n",
      "     | > log_mle: -0.13572287559509277  (-0.12113989107679612)\n",
      "     | > loss_dur: 0.32523462176322937  (0.3253929706493226)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.7632, device='cuda:0')  (tensor(3.5931, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.3113  (0.2993809350646368)\n",
      "     | > loader_time: 0.003  (0.004330401373381658)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:31:47 -- STEP: 126/406 -- GLOBAL_STEP: 11900\u001b[0m\n",
      "     | > loss: 0.2026822865009308  (0.20169790822362144)\n",
      "     | > log_mle: -0.12709498405456543  (-0.12414921843816364)\n",
      "     | > loss_dur: 0.3297772705554962  (0.325847126661785)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.4413, device='cuda:0')  (tensor(3.5217, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.4044  (0.3117435413693625)\n",
      "     | > loader_time: 0.004  (0.004130478889223127)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:31:57 -- STEP: 151/406 -- GLOBAL_STEP: 11925\u001b[0m\n",
      "     | > loss: 0.2068348526954651  (0.20158619359629046)\n",
      "     | > log_mle: -0.13328254222869873  (-0.1264444905401066)\n",
      "     | > loss_dur: 0.3401173949241638  (0.32803068413639697)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4232, device='cuda:0')  (tensor(3.3115, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.4364  (0.3223126945116662)\n",
      "     | > loader_time: 0.004  (0.00402325510189233)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:32:07 -- STEP: 176/406 -- GLOBAL_STEP: 11950\u001b[0m\n",
      "     | > loss: 0.2059468924999237  (0.20070747133683078)\n",
      "     | > log_mle: -0.1344010829925537  (-0.12817646359855478)\n",
      "     | > loss_dur: 0.3403479754924774  (0.3288839349353856)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.6454, device='cuda:0')  (tensor(3.3237, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.3723  (0.3336440392515877)\n",
      "     | > loader_time: 0.004  (0.0039521807974035065)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:32:18 -- STEP: 201/406 -- GLOBAL_STEP: 11975\u001b[0m\n",
      "     | > loss: 0.19114673137664795  (0.1996240148793406)\n",
      "     | > log_mle: -0.1364990472793579  (-0.12997446902355742)\n",
      "     | > loss_dur: 0.32764577865600586  (0.329598483902898)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.7743, device='cuda:0')  (tensor(3.4230, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.3944  (0.34628162692435344)\n",
      "     | > loader_time: 0.003  (0.003953571936384357)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:32:29 -- STEP: 226/406 -- GLOBAL_STEP: 12000\u001b[0m\n",
      "     | > loss: 0.19643735885620117  (0.1989241515376927)\n",
      "     | > log_mle: -0.15187692642211914  (-0.13161860366838168)\n",
      "     | > loss_dur: 0.3483142852783203  (0.33054275520607435)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.4135, device='cuda:0')  (tensor(3.5656, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.4074  (0.3561880620179978)\n",
      "     | > loader_time: 0.005  (0.003981231588177971)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_12000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:32:46 -- STEP: 251/406 -- GLOBAL_STEP: 12025\u001b[0m\n",
      "     | > loss: 0.19845309853553772  (0.1984693646668438)\n",
      "     | > log_mle: -0.14176678657531738  (-0.13309603430835373)\n",
      "     | > loss_dur: 0.3402198851108551  (0.33156539897519755)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9237, device='cuda:0')  (tensor(3.6533, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.5265  (0.3691096581310865)\n",
      "     | > loader_time: 0.005  (0.004015395365863202)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:32:58 -- STEP: 276/406 -- GLOBAL_STEP: 12050\u001b[0m\n",
      "     | > loss: 0.18736281991004944  (0.19750901559988657)\n",
      "     | > log_mle: -0.14826393127441406  (-0.1344696857791016)\n",
      "     | > loss_dur: 0.3356267511844635  (0.3319787013789881)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.9973, device='cuda:0')  (tensor(3.6568, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.4534  (0.3800684956536776)\n",
      "     | > loader_time: 0.004  (0.0040505761685578675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:33:11 -- STEP: 301/406 -- GLOBAL_STEP: 12075\u001b[0m\n",
      "     | > loss: 0.20093172788619995  (0.19686625526592977)\n",
      "     | > log_mle: -0.16155076026916504  (-0.13557605450335536)\n",
      "     | > loss_dur: 0.362482488155365  (0.3324423097692847)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(8.7455, device='cuda:0')  (tensor(3.6374, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.6256  (0.39174328135493575)\n",
      "     | > loader_time: 0.004  (0.00410650101214944)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:33:25 -- STEP: 326/406 -- GLOBAL_STEP: 12100\u001b[0m\n",
      "     | > loss: 0.18375107645988464  (0.19634885327216306)\n",
      "     | > log_mle: -0.14219486713409424  (-0.1365445376905196)\n",
      "     | > loss_dur: 0.3259459435939789  (0.3328933909626821)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0099, device='cuda:0')  (tensor(3.6119, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.5215  (0.4032301332321635)\n",
      "     | > loader_time: 0.005  (0.004141578645062589)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:33:39 -- STEP: 351/406 -- GLOBAL_STEP: 12125\u001b[0m\n",
      "     | > loss: 0.2125183641910553  (0.19605179169239143)\n",
      "     | > log_mle: -0.1458531618118286  (-0.13759186328985756)\n",
      "     | > loss_dur: 0.3583715260028839  (0.33364365498224857)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0310, device='cuda:0')  (tensor(3.6605, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.6586  (0.4149256805409054)\n",
      "     | > loader_time: 0.005  (0.004183056008102544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:33:54 -- STEP: 376/406 -- GLOBAL_STEP: 12150\u001b[0m\n",
      "     | > loss: 0.19401589035987854  (0.19521576514903535)\n",
      "     | > log_mle: -0.14814519882202148  (-0.13868284479100665)\n",
      "     | > loss_dur: 0.3421610891819  (0.33389860994004167)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.5239, device='cuda:0')  (tensor(3.7050, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.5635  (0.4265646585758696)\n",
      "     | > loader_time: 0.005  (0.0042429794656469455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:34:11 -- STEP: 401/406 -- GLOBAL_STEP: 12175\u001b[0m\n",
      "     | > loss: 0.1782054901123047  (0.19445265253583094)\n",
      "     | > log_mle: -0.15400922298431396  (-0.13965815588125874)\n",
      "     | > loss_dur: 0.33221471309661865  (0.3341108084170894)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.5381, device='cuda:0')  (tensor(3.6507, device='cuda:0'))\n",
      "     | > current_lr: 7.25e-06 \n",
      "     | > step_time: 0.7233  (0.4405494200023927)\n",
      "     | > loader_time: 0.005  (0.004297939619221294)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08257526159286499 \u001b[0m(-0.010759860277175903)\n",
      "     | > avg_loss:\u001b[92m 0.16904421150684357 \u001b[0m(-0.025373265147209167)\n",
      "     | > avg_log_mle:\u001b[92m -0.14685951173305511 \u001b[0m(-0.01288411021232605)\n",
      "     | > avg_loss_dur:\u001b[92m 0.3159037232398987 \u001b[0m(-0.012489154934883118)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_12180.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 30/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:34:44) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:35:05 -- STEP: 20/406 -- GLOBAL_STEP: 12200\u001b[0m\n",
      "     | > loss: 0.19716331362724304  (0.17901242524385452)\n",
      "     | > log_mle: -0.10659754276275635  (-0.12067113518714905)\n",
      "     | > loss_dur: 0.3037608563899994  (0.2996835604310036)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.9791, device='cuda:0')  (tensor(2.1485, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.2622  (0.26063653230667116)\n",
      "     | > loader_time: 0.002  (0.014163076877593994)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:35:12 -- STEP: 45/406 -- GLOBAL_STEP: 12225\u001b[0m\n",
      "     | > loss: 0.19284740090370178  (0.18448133402400543)\n",
      "     | > log_mle: -0.11812615394592285  (-0.12143312295277914)\n",
      "     | > loss_dur: 0.31097355484962463  (0.3059144569767846)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.5338, device='cuda:0')  (tensor(2.2222, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.3133  (0.27082362704806867)\n",
      "     | > loader_time: 0.002  (0.007606988483005102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:35:20 -- STEP: 70/406 -- GLOBAL_STEP: 12250\u001b[0m\n",
      "     | > loss: 0.17535540461540222  (0.1832042425870895)\n",
      "     | > log_mle: -0.14235365390777588  (-0.1251805748258318)\n",
      "     | > loss_dur: 0.3177090585231781  (0.30838481741292134)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0655, device='cuda:0')  (tensor(2.5018, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.2843  (0.28381474699292875)\n",
      "     | > loader_time: 0.002  (0.005862501689365932)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:35:28 -- STEP: 95/406 -- GLOBAL_STEP: 12275\u001b[0m\n",
      "     | > loss: 0.18425923585891724  (0.1826009223335667)\n",
      "     | > log_mle: -0.13525569438934326  (-0.12876294412110986)\n",
      "     | > loss_dur: 0.3195149302482605  (0.3113638664546767)\n",
      "     | > amp_scaler: 65536.0  (38976.67368421053)\n",
      "     | > grad_norm: tensor(9.4409, device='cuda:0')  (tensor(2.9753, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.3173  (0.2967746307975369)\n",
      "     | > loader_time: 0.003  (0.00507831573486328)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:35:37 -- STEP: 120/406 -- GLOBAL_STEP: 12300\u001b[0m\n",
      "     | > loss: 0.16275817155838013  (0.18083610882361725)\n",
      "     | > log_mle: -0.14991414546966553  (-0.13165382643540713)\n",
      "     | > loss_dur: 0.31267231702804565  (0.3124899352590245)\n",
      "     | > amp_scaler: 65536.0  (44509.86666666667)\n",
      "     | > grad_norm: tensor(3.7294, device='cuda:0')  (tensor(3.2408, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.3353  (0.3086217502752941)\n",
      "     | > loader_time: 0.003  (0.0046876649061838764)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:35:47 -- STEP: 145/406 -- GLOBAL_STEP: 12325\u001b[0m\n",
      "     | > loss: 0.15762001276016235  (0.1804626394962442)\n",
      "     | > log_mle: -0.1376814842224121  (-0.13404672639123336)\n",
      "     | > loss_dur: 0.29530149698257446  (0.3145093658874778)\n",
      "     | > amp_scaler: 65536.0  (48135.062068965504)\n",
      "     | > grad_norm: tensor(2.0659, device='cuda:0')  (tensor(3.1805, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.3673  (0.3199455063918542)\n",
      "     | > loader_time: 0.003  (0.00450761893699909)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:35:57 -- STEP: 170/406 -- GLOBAL_STEP: 12350\u001b[0m\n",
      "     | > loss: 0.15777075290679932  (0.1803577610675026)\n",
      "     | > log_mle: -0.1475973129272461  (-0.13589610001620137)\n",
      "     | > loss_dur: 0.3053680658340454  (0.316253861083704)\n",
      "     | > amp_scaler: 65536.0  (50694.02352941177)\n",
      "     | > grad_norm: tensor(2.4825, device='cuda:0')  (tensor(3.0360, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.3653  (0.3309532950906191)\n",
      "     | > loader_time: 0.004  (0.004374600859249333)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:36:08 -- STEP: 195/406 -- GLOBAL_STEP: 12375\u001b[0m\n",
      "     | > loss: 0.17513343691825867  (0.1797653386226067)\n",
      "     | > log_mle: -0.13468027114868164  (-0.1377434021387346)\n",
      "     | > loss_dur: 0.3098137080669403  (0.3175087407613413)\n",
      "     | > amp_scaler: 65536.0  (52596.84102564103)\n",
      "     | > grad_norm: tensor(2.7380, device='cuda:0')  (tensor(3.1220, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.4074  (0.3435476877750494)\n",
      "     | > loader_time: 0.004  (0.004311632498716692)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:36:19 -- STEP: 220/406 -- GLOBAL_STEP: 12400\u001b[0m\n",
      "     | > loss: 0.1754714846611023  (0.17899724258617922)\n",
      "     | > log_mle: -0.17387008666992188  (-0.13940723213282516)\n",
      "     | > loss_dur: 0.34934157133102417  (0.31840447471900424)\n",
      "     | > amp_scaler: 65536.0  (54067.2)\n",
      "     | > grad_norm: tensor(11.7473, device='cuda:0')  (tensor(3.3228, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.4084  (0.3544717452742836)\n",
      "     | > loader_time: 0.004  (0.0042720838026566905)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:36:31 -- STEP: 245/406 -- GLOBAL_STEP: 12425\u001b[0m\n",
      "     | > loss: 0.1817781925201416  (0.17867030671664647)\n",
      "     | > log_mle: -0.14899563789367676  (-0.14094219305077393)\n",
      "     | > loss_dur: 0.33077383041381836  (0.3196124997674203)\n",
      "     | > amp_scaler: 32768.0  (54702.497959183675)\n",
      "     | > grad_norm: tensor(2.7560, device='cuda:0')  (tensor(3.5241, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.5405  (0.36531678413858215)\n",
      "     | > loader_time: 0.005  (0.004265110833304267)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:36:43 -- STEP: 270/406 -- GLOBAL_STEP: 12450\u001b[0m\n",
      "     | > loss: 0.17333224415779114  (0.17784533015003912)\n",
      "     | > log_mle: -0.15704452991485596  (-0.14218972170794464)\n",
      "     | > loss_dur: 0.3303767740726471  (0.32003505185798375)\n",
      "     | > amp_scaler: 32768.0  (52671.525925925926)\n",
      "     | > grad_norm: tensor(2.1216, device='cuda:0')  (tensor(3.6136, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.4524  (0.3775552087359958)\n",
      "     | > loader_time: 0.004  (0.004289082244590474)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:36:56 -- STEP: 295/406 -- GLOBAL_STEP: 12475\u001b[0m\n",
      "     | > loss: 0.16575607657432556  (0.17720769573066195)\n",
      "     | > log_mle: -0.1586620807647705  (-0.14337276765855705)\n",
      "     | > loss_dur: 0.32441815733909607  (0.3205804633892189)\n",
      "     | > amp_scaler: 32768.0  (50984.78644067797)\n",
      "     | > grad_norm: tensor(3.7637, device='cuda:0')  (tensor(3.6068, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.5905  (0.3883198730016158)\n",
      "     | > loader_time: 0.005  (0.004329328213707873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:37:10 -- STEP: 320/406 -- GLOBAL_STEP: 12500\u001b[0m\n",
      "     | > loss: 0.1879270076751709  (0.1769382914528251)\n",
      "     | > log_mle: -0.14664983749389648  (-0.14441106431186201)\n",
      "     | > loss_dur: 0.3345768451690674  (0.32134935576468704)\n",
      "     | > amp_scaler: 32768.0  (49561.60000000002)\n",
      "     | > grad_norm: tensor(2.6797, device='cuda:0')  (tensor(3.6017, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.4924  (0.4003583848476408)\n",
      "     | > loader_time: 0.004  (0.004350776970386505)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:37:24 -- STEP: 345/406 -- GLOBAL_STEP: 12525\u001b[0m\n",
      "     | > loss: 0.16275429725646973  (0.17667391170626107)\n",
      "     | > log_mle: -0.16753149032592773  (-0.1454233135002247)\n",
      "     | > loss_dur: 0.33028578758239746  (0.3220972252064857)\n",
      "     | > amp_scaler: 32768.0  (48344.67246376814)\n",
      "     | > grad_norm: tensor(4.2017, device='cuda:0')  (tensor(3.6603, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.6436  (0.4121085733607194)\n",
      "     | > loader_time: 0.005  (0.004383623427239018)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:37:39 -- STEP: 370/406 -- GLOBAL_STEP: 12550\u001b[0m\n",
      "     | > loss: 0.16007277369499207  (0.17611008302585499)\n",
      "     | > log_mle: -0.17480015754699707  (-0.14646576449677753)\n",
      "     | > loss_dur: 0.33487293124198914  (0.3225758475226324)\n",
      "     | > amp_scaler: 32768.0  (47292.19459459461)\n",
      "     | > grad_norm: tensor(7.8730, device='cuda:0')  (tensor(3.7258, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.5385  (0.42341517242225424)\n",
      "     | > loader_time: 0.004  (0.004433674425692174)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:37:55 -- STEP: 395/406 -- GLOBAL_STEP: 12575\u001b[0m\n",
      "     | > loss: 0.15738394856452942  (0.1754708628865737)\n",
      "     | > log_mle: -0.16862785816192627  (-0.14737224126163925)\n",
      "     | > loss_dur: 0.3260118067264557  (0.3228431041482126)\n",
      "     | > amp_scaler: 32768.0  (46372.94177215192)\n",
      "     | > grad_norm: tensor(9.9871, device='cuda:0')  (tensor(3.9125, device='cuda:0'))\n",
      "     | > current_lr: 7.499999999999999e-06 \n",
      "     | > step_time: 0.7387  (0.43687103186981574)\n",
      "     | > loader_time: 0.006  (0.004497661469857904)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.0828869640827179 \u001b[0m(+0.0003117024898529053)\n",
      "     | > avg_loss:\u001b[92m 0.15292615815997124 \u001b[0m(-0.01611805334687233)\n",
      "     | > avg_log_mle:\u001b[92m -0.154667928814888 \u001b[0m(-0.007808417081832886)\n",
      "     | > avg_loss_dur:\u001b[92m 0.30759408697485924 \u001b[0m(-0.008309636265039444)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_12586.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 31/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:38:32) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:38:52 -- STEP: 14/406 -- GLOBAL_STEP: 12600\u001b[0m\n",
      "     | > loss: 0.1816292703151703  (0.16118657376085008)\n",
      "     | > log_mle: -0.14457285404205322  (-0.1300624098096575)\n",
      "     | > loss_dur: 0.3262021243572235  (0.29124898357050766)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.7849, device='cuda:0')  (tensor(2.3550, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.2602  (0.25873492445264545)\n",
      "     | > loader_time: 0.002  (0.013083389827183314)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:38:59 -- STEP: 39/406 -- GLOBAL_STEP: 12625\u001b[0m\n",
      "     | > loss: 0.18907377123832703  (0.167677695170427)\n",
      "     | > log_mle: -0.1283738613128662  (-0.12955577556903547)\n",
      "     | > loss_dur: 0.31744763255119324  (0.29723347073946244)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.3835, device='cuda:0')  (tensor(2.3310, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.2632  (0.26511274851285493)\n",
      "     | > loader_time: 0.002  (0.006005262717222556)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:39:06 -- STEP: 64/406 -- GLOBAL_STEP: 12650\u001b[0m\n",
      "     | > loss: 0.15298053622245789  (0.1669960916042328)\n",
      "     | > log_mle: -0.13154077529907227  (-0.13210248015820975)\n",
      "     | > loss_dur: 0.28452131152153015  (0.2990985717624426)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.7549, device='cuda:0')  (tensor(2.5549, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.2883  (0.2793788053095342)\n",
      "     | > loader_time: 0.003  (0.004613433033227919)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:39:15 -- STEP: 89/406 -- GLOBAL_STEP: 12675\u001b[0m\n",
      "     | > loss: 0.17854717373847961  (0.16661131884274855)\n",
      "     | > log_mle: -0.13746273517608643  (-0.13548517896887954)\n",
      "     | > loss_dur: 0.31600990891456604  (0.3020964978116282)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.3244, device='cuda:0')  (tensor(2.9708, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.3003  (0.29273784026671)\n",
      "     | > loader_time: 0.003  (0.0041159217277269644)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:39:23 -- STEP: 114/406 -- GLOBAL_STEP: 12700\u001b[0m\n",
      "     | > loss: 0.14600712060928345  (0.16460266526330977)\n",
      "     | > log_mle: -0.1633291244506836  (-0.1389625386187904)\n",
      "     | > loss_dur: 0.30933624505996704  (0.3035652038821003)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(12.1128, device='cuda:0')  (tensor(3.3814, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.3964  (0.3056460723542331)\n",
      "     | > loader_time: 0.004  (0.003906892057050738)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:39:33 -- STEP: 139/406 -- GLOBAL_STEP: 12725\u001b[0m\n",
      "     | > loss: 0.15657716989517212  (0.16486446891757225)\n",
      "     | > log_mle: -0.15358436107635498  (-0.14128608497784287)\n",
      "     | > loss_dur: 0.3101615309715271  (0.3061505538954151)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4259, device='cuda:0')  (tensor(3.4299, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.4324  (0.31702178845302664)\n",
      "     | > loader_time: 0.004  (0.003809052405597494)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:39:43 -- STEP: 164/406 -- GLOBAL_STEP: 12750\u001b[0m\n",
      "     | > loss: 0.163173109292984  (0.16451382273580967)\n",
      "     | > log_mle: -0.1451871395111084  (-0.14313435481815803)\n",
      "     | > loss_dur: 0.3083602488040924  (0.3076481775539677)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.4548, device='cuda:0')  (tensor(3.3318, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.3733  (0.32844467570142066)\n",
      "     | > loader_time: 0.004  (0.00380209306391274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:39:53 -- STEP: 189/406 -- GLOBAL_STEP: 12775\u001b[0m\n",
      "     | > loss: 0.15339475870132446  (0.1639048709440484)\n",
      "     | > log_mle: -0.15788912773132324  (-0.1450475397564116)\n",
      "     | > loss_dur: 0.3112838864326477  (0.3089524107004598)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.0437, device='cuda:0')  (tensor(3.3665, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.4564  (0.3402243493095279)\n",
      "     | > loader_time: 0.004  (0.0038075598459395145)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:40:05 -- STEP: 214/406 -- GLOBAL_STEP: 12800\u001b[0m\n",
      "     | > loss: 0.15794947743415833  (0.1631635984527731)\n",
      "     | > log_mle: -0.15991592407226562  (-0.14654292013043557)\n",
      "     | > loss_dur: 0.31786540150642395  (0.30970651858320847)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.3575, device='cuda:0')  (tensor(3.4591, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.5105  (0.3520393861788458)\n",
      "     | > loader_time: 0.005  (0.003863161969407696)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:40:16 -- STEP: 239/406 -- GLOBAL_STEP: 12825\u001b[0m\n",
      "     | > loss: 0.1653570830821991  (0.1629571551807755)\n",
      "     | > log_mle: -0.16637647151947021  (-0.1481226353465763)\n",
      "     | > loss_dur: 0.3317335546016693  (0.31107979052735163)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.6589, device='cuda:0')  (tensor(3.6456, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.5405  (0.3636818171545054)\n",
      "     | > loader_time: 0.005  (0.0039071388324434285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:40:29 -- STEP: 264/406 -- GLOBAL_STEP: 12850\u001b[0m\n",
      "     | > loss: 0.16764932870864868  (0.1624394265765494)\n",
      "     | > log_mle: -0.15640032291412354  (-0.14943681205763967)\n",
      "     | > loss_dur: 0.3240496516227722  (0.31187623863418884)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2242, device='cuda:0')  (tensor(3.7154, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.4534  (0.37741479638851066)\n",
      "     | > loader_time: 0.004  (0.003942791259650028)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:40:42 -- STEP: 289/406 -- GLOBAL_STEP: 12875\u001b[0m\n",
      "     | > loss: 0.14502379298210144  (0.1615536992525147)\n",
      "     | > log_mle: -0.1568279266357422  (-0.15064317008615788)\n",
      "     | > loss_dur: 0.30185171961784363  (0.31219686933867247)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.2439, device='cuda:0')  (tensor(3.7386, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.4624  (0.3886990901920624)\n",
      "     | > loader_time: 0.004  (0.003993068186882045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:40:56 -- STEP: 314/406 -- GLOBAL_STEP: 12900\u001b[0m\n",
      "     | > loss: 0.1553584337234497  (0.16121516856038645)\n",
      "     | > log_mle: -0.1690521240234375  (-0.15172962853862987)\n",
      "     | > loss_dur: 0.3244105577468872  (0.31294479709901607)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.6069, device='cuda:0')  (tensor(3.8058, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.5075  (0.40192558203533213)\n",
      "     | > loader_time: 0.006  (0.0040608355953435215)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:41:11 -- STEP: 339/406 -- GLOBAL_STEP: 12925\u001b[0m\n",
      "     | > loss: 0.14187368750572205  (0.1610527310223706)\n",
      "     | > log_mle: -0.166526198387146  (-0.15264899892441303)\n",
      "     | > loss_dur: 0.30839988589286804  (0.3137017299467833)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.4073, device='cuda:0')  (tensor(3.7646, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.6786  (0.4145730505299077)\n",
      "     | > loader_time: 0.005  (0.0041289484254730105)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:41:25 -- STEP: 364/406 -- GLOBAL_STEP: 12950\u001b[0m\n",
      "     | > loss: 0.1518765687942505  (0.16064519787227713)\n",
      "     | > log_mle: -0.16893243789672852  (-0.1537200277978249)\n",
      "     | > loss_dur: 0.320809006690979  (0.3143652256701018)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(7.2337, device='cuda:0')  (tensor(3.8565, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.6796  (0.4264247175101397)\n",
      "     | > loader_time: 0.005  (0.004200057014004214)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:41:41 -- STEP: 389/406 -- GLOBAL_STEP: 12975\u001b[0m\n",
      "     | > loss: 0.14832019805908203  (0.1600550682808256)\n",
      "     | > log_mle: -0.1801280975341797  (-0.15464372377469196)\n",
      "     | > loss_dur: 0.3284482955932617  (0.31469879205551715)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.3100, device='cuda:0')  (tensor(4.0052, device='cuda:0'))\n",
      "     | > current_lr: 7.75e-06 \n",
      "     | > step_time: 0.5805  (0.4399178628749898)\n",
      "     | > loader_time: 0.005  (0.00426460905982167)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10071665048599243 \u001b[0m(+0.017829686403274536)\n",
      "     | > avg_loss:\u001b[92m 0.13531754538416862 \u001b[0m(-0.017608612775802612)\n",
      "     | > avg_log_mle:\u001b[92m -0.16251599788665771 \u001b[0m(-0.007848069071769714)\n",
      "     | > avg_loss_dur:\u001b[92m 0.29783354327082634 \u001b[0m(-0.009760543704032898)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_12992.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 32/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:42:24) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:42:42 -- STEP: 8/406 -- GLOBAL_STEP: 13000\u001b[0m\n",
      "     | > loss: 0.13566794991493225  (0.14962663128972054)\n",
      "     | > log_mle: -0.15053796768188477  (-0.13450969755649567)\n",
      "     | > loss_dur: 0.286205917596817  (0.2841363288462162)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0947, device='cuda:0')  (tensor(1.8430, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.2602  (0.3002726435661316)\n",
      "     | > loader_time: 0.001  (0.029151648283004764)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_13000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:42:51 -- STEP: 33/406 -- GLOBAL_STEP: 13025\u001b[0m\n",
      "     | > loss: 0.1697925329208374  (0.15057557234258362)\n",
      "     | > log_mle: -0.13376164436340332  (-0.13667429215980298)\n",
      "     | > loss_dur: 0.3035541772842407  (0.2872498645023866)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.3966, device='cuda:0')  (tensor(1.9012, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.2983  (0.27952648654128565)\n",
      "     | > loader_time: 0.002  (0.008674664930863813)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:42:59 -- STEP: 58/406 -- GLOBAL_STEP: 13050\u001b[0m\n",
      "     | > loss: 0.13878855109214783  (0.15384282454334458)\n",
      "     | > log_mle: -0.14233708381652832  (-0.13861591445988627)\n",
      "     | > loss_dur: 0.28112563490867615  (0.2924587390032307)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.7973, device='cuda:0')  (tensor(2.5775, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.3263  (0.2892971696524786)\n",
      "     | > loader_time: 0.003  (0.006040096282958984)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:43:07 -- STEP: 83/406 -- GLOBAL_STEP: 13075\u001b[0m\n",
      "     | > loss: 0.15721172094345093  (0.15201515444071903)\n",
      "     | > log_mle: -0.1508808135986328  (-0.14170272235410764)\n",
      "     | > loss_dur: 0.30809253454208374  (0.29371787679482647)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7217, device='cuda:0')  (tensor(2.8672, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.3663  (0.3020453338163445)\n",
      "     | > loader_time: 0.003  (0.005076962781239705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:43:16 -- STEP: 108/406 -- GLOBAL_STEP: 13100\u001b[0m\n",
      "     | > loss: 0.13021788001060486  (0.14950772416260508)\n",
      "     | > log_mle: -0.15278780460357666  (-0.14484185642666297)\n",
      "     | > loss_dur: 0.2830056846141815  (0.29434958058926775)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(6.5746, device='cuda:0')  (tensor(3.0314, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.3383  (0.3134883134453386)\n",
      "     | > loader_time: 0.003  (0.004633958692903873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:43:25 -- STEP: 133/406 -- GLOBAL_STEP: 13125\u001b[0m\n",
      "     | > loss: 0.14871209859848022  (0.14842001981753156)\n",
      "     | > log_mle: -0.1604098081588745  (-0.14772733261710724)\n",
      "     | > loss_dur: 0.30912190675735474  (0.2961473524346386)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.1186, device='cuda:0')  (tensor(3.2451, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.3493  (0.32421164046552853)\n",
      "     | > loader_time: 0.003  (0.004410094784614736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:43:35 -- STEP: 158/406 -- GLOBAL_STEP: 13150\u001b[0m\n",
      "     | > loss: 0.13540151715278625  (0.1484934073648875)\n",
      "     | > log_mle: -0.16962242126464844  (-0.14968760405914686)\n",
      "     | > loss_dur: 0.3050239384174347  (0.2981810114240343)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.5451, device='cuda:0')  (tensor(3.1595, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.3753  (0.3357288943061347)\n",
      "     | > loader_time: 0.004  (0.004282390015034736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:43:46 -- STEP: 183/406 -- GLOBAL_STEP: 13175\u001b[0m\n",
      "     | > loss: 0.1486562192440033  (0.1484555899282622)\n",
      "     | > log_mle: -0.16720712184906006  (-0.15145628569556058)\n",
      "     | > loss_dur: 0.31586334109306335  (0.2999118756238228)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0434, device='cuda:0')  (tensor(3.2289, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4804  (0.34868819466054124)\n",
      "     | > loader_time: 0.005  (0.004233330325350733)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:43:58 -- STEP: 208/406 -- GLOBAL_STEP: 13200\u001b[0m\n",
      "     | > loss: 0.1297999620437622  (0.14822312208035826)\n",
      "     | > log_mle: -0.17248046398162842  (-0.1530977659500561)\n",
      "     | > loss_dur: 0.3022804260253906  (0.3013208880304145)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0767, device='cuda:0')  (tensor(3.2973, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4995  (0.3599614730248086)\n",
      "     | > loader_time: 0.004  (0.004234553529666018)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:44:09 -- STEP: 233/406 -- GLOBAL_STEP: 13225\u001b[0m\n",
      "     | > loss: 0.1482236683368683  (0.14763003184815857)\n",
      "     | > log_mle: -0.17084944248199463  (-0.15480162606218842)\n",
      "     | > loss_dur: 0.3190731108188629  (0.3024316579103471)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(9.2434, device='cuda:0')  (tensor(3.5394, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4484  (0.3698035974870937)\n",
      "     | > loader_time: 0.004  (0.004248422614494615)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:44:22 -- STEP: 258/406 -- GLOBAL_STEP: 13250\u001b[0m\n",
      "     | > loss: 0.15430501103401184  (0.14731681086989348)\n",
      "     | > log_mle: -0.16649317741394043  (-0.15615859835646861)\n",
      "     | > loss_dur: 0.32079818844795227  (0.3034754092263622)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.6520, device='cuda:0')  (tensor(3.6970, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4564  (0.3830454867015514)\n",
      "     | > loader_time: 0.005  (0.004251839578613751)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:44:35 -- STEP: 283/406 -- GLOBAL_STEP: 13275\u001b[0m\n",
      "     | > loss: 0.15015587210655212  (0.14657416492174044)\n",
      "     | > log_mle: -0.16904056072235107  (-0.15737493889070647)\n",
      "     | > loss_dur: 0.3191964328289032  (0.303949103812447)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(6.9767, device='cuda:0')  (tensor(3.9545, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.4674  (0.3943015012639994)\n",
      "     | > loader_time: 0.004  (0.004286482982837687)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:44:48 -- STEP: 308/406 -- GLOBAL_STEP: 13300\u001b[0m\n",
      "     | > loss: 0.12671464681625366  (0.14624796657786743)\n",
      "     | > log_mle: -0.17349159717559814  (-0.15838630284581856)\n",
      "     | > loss_dur: 0.3002062439918518  (0.30463426942368604)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.4555, device='cuda:0')  (tensor(4.0901, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.5015  (0.4060667768701331)\n",
      "     | > loader_time: 0.005  (0.004331742014203749)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:45:03 -- STEP: 333/406 -- GLOBAL_STEP: 13325\u001b[0m\n",
      "     | > loss: 0.1368046998977661  (0.14601150266938018)\n",
      "     | > log_mle: -0.17796695232391357  (-0.15926080351477256)\n",
      "     | > loss_dur: 0.3147716522216797  (0.3052723061841529)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.4208, device='cuda:0')  (tensor(4.1426, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.5085  (0.4175442847403679)\n",
      "     | > loader_time: 0.005  (0.004376253924212295)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:45:18 -- STEP: 358/406 -- GLOBAL_STEP: 13350\u001b[0m\n",
      "     | > loss: 0.12031105160713196  (0.14581689908684298)\n",
      "     | > log_mle: -0.18966829776763916  (-0.16027418295098406)\n",
      "     | > loss_dur: 0.3099793493747711  (0.3060910820378273)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(8.5360, device='cuda:0')  (tensor(4.3809, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.5565  (0.42970021343763987)\n",
      "     | > loader_time: 0.006  (0.004428507895443024)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:45:33 -- STEP: 383/406 -- GLOBAL_STEP: 13375\u001b[0m\n",
      "     | > loss: 0.13593792915344238  (0.14534257118913593)\n",
      "     | > log_mle: -0.17340970039367676  (-0.16118003836499797)\n",
      "     | > loss_dur: 0.30934762954711914  (0.3065226095541341)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(9.6469, device='cuda:0')  (tensor(4.5003, device='cuda:0'))\n",
      "     | > current_lr: 8e-06 \n",
      "     | > step_time: 0.6986  (0.4424042919597178)\n",
      "     | > loader_time: 0.005  (0.0044765702738151815)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10384443402290344 \u001b[0m(+0.0031277835369110107)\n",
      "     | > avg_loss:\u001b[92m 0.12063578516244888 \u001b[0m(-0.014681760221719742)\n",
      "     | > avg_log_mle:\u001b[92m -0.1753344088792801 \u001b[0m(-0.012818410992622375)\n",
      "     | > avg_loss_dur:\u001b[92m 0.295970194041729 \u001b[0m(-0.0018633492290973663)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_13398.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 33/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:46:20) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:46:37 -- STEP: 2/406 -- GLOBAL_STEP: 13400\u001b[0m\n",
      "     | > loss: 0.08143094182014465  (0.10665355622768402)\n",
      "     | > log_mle: -0.154668927192688  (-0.14777177572250366)\n",
      "     | > loss_dur: 0.23609986901283264  (0.2544253319501877)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2485, device='cuda:0')  (tensor(1.8243, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.3103  (0.3287980556488037)\n",
      "     | > loader_time: 0.002  (0.0020012855529785156)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:46:44 -- STEP: 27/406 -- GLOBAL_STEP: 13425\u001b[0m\n",
      "     | > loss: 0.12269845604896545  (0.1315169212994752)\n",
      "     | > log_mle: -0.14163362979888916  (-0.14264564602463334)\n",
      "     | > loss_dur: 0.2643320858478546  (0.2741625673241086)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(1.7741, device='cuda:0')  (tensor(2.0528, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.2692  (0.2745085027482774)\n",
      "     | > loader_time: 0.003  (0.013160087444164135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:46:52 -- STEP: 52/406 -- GLOBAL_STEP: 13450\u001b[0m\n",
      "     | > loss: 0.1388375461101532  (0.1365534921105091)\n",
      "     | > log_mle: -0.1453484296798706  (-0.14419377767122715)\n",
      "     | > loss_dur: 0.2841859757900238  (0.2807472697817362)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6383, device='cuda:0')  (tensor(2.8069, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.2903  (0.28764580304806037)\n",
      "     | > loader_time: 0.002  (0.008007196279672474)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:47:00 -- STEP: 77/406 -- GLOBAL_STEP: 13475\u001b[0m\n",
      "     | > loss: 0.16513603925704956  (0.1363294054935505)\n",
      "     | > log_mle: -0.14757513999938965  (-0.1471281160007824)\n",
      "     | > loss_dur: 0.3127111792564392  (0.2834575214943328)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0673, device='cuda:0')  (tensor(3.1662, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.3683  (0.30027264743656296)\n",
      "     | > loader_time: 0.003  (0.0063823446050866855)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:47:09 -- STEP: 102/406 -- GLOBAL_STEP: 13500\u001b[0m\n",
      "     | > loss: 0.125352680683136  (0.13620504882990148)\n",
      "     | > log_mle: -0.17088031768798828  (-0.15032024126426835)\n",
      "     | > loss_dur: 0.29623299837112427  (0.2865252900941701)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.2387, device='cuda:0')  (tensor(3.2600, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.3874  (0.3125288579978196)\n",
      "     | > loader_time: 0.003  (0.005583475617801442)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:47:18 -- STEP: 127/406 -- GLOBAL_STEP: 13525\u001b[0m\n",
      "     | > loss: 0.13720491528511047  (0.1351438507320374)\n",
      "     | > log_mle: -0.16311287879943848  (-0.15319438900534554)\n",
      "     | > loss_dur: 0.30031779408454895  (0.28833823973738315)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.6936, device='cuda:0')  (tensor(3.4208, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.3353  (0.3226787424462988)\n",
      "     | > loader_time: 0.003  (0.005185818108986682)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:47:28 -- STEP: 152/406 -- GLOBAL_STEP: 13550\u001b[0m\n",
      "     | > loss: 0.1409725844860077  (0.1355226383005318)\n",
      "     | > log_mle: -0.16253578662872314  (-0.15537897850337776)\n",
      "     | > loss_dur: 0.30350837111473083  (0.29090161680390975)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1241, device='cuda:0')  (tensor(3.4746, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.4654  (0.33438246657973864)\n",
      "     | > loader_time: 0.004  (0.00493213377500835)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:47:39 -- STEP: 177/406 -- GLOBAL_STEP: 13575\u001b[0m\n",
      "     | > loss: 0.13058629631996155  (0.1353825584980054)\n",
      "     | > log_mle: -0.1803123950958252  (-0.15710705282997947)\n",
      "     | > loss_dur: 0.31089869141578674  (0.2924896113279852)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(6.1605, device='cuda:0')  (tensor(3.6446, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.4844  (0.34656880400275114)\n",
      "     | > loader_time: 0.004  (0.004772716996359957)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:47:50 -- STEP: 202/406 -- GLOBAL_STEP: 13600\u001b[0m\n",
      "     | > loss: 0.15485024452209473  (0.13531883651077142)\n",
      "     | > log_mle: -0.16228246688842773  (-0.1587085511424754)\n",
      "     | > loss_dur: 0.31713271141052246  (0.29402738765324715)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.5913, device='cuda:0')  (tensor(3.8432, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.4184  (0.35919733212725957)\n",
      "     | > loader_time: 0.004  (0.004697348811838882)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:48:02 -- STEP: 227/406 -- GLOBAL_STEP: 13625\u001b[0m\n",
      "     | > loss: 0.1516631543636322  (0.13477231975694048)\n",
      "     | > log_mle: -0.16220450401306152  (-0.16026083068175462)\n",
      "     | > loss_dur: 0.3138676583766937  (0.2950331504386954)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(8.5868, device='cuda:0')  (tensor(4.1705, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.4314  (0.36975413587124867)\n",
      "     | > loader_time: 0.004  (0.00464742719339379)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:48:15 -- STEP: 252/406 -- GLOBAL_STEP: 13650\u001b[0m\n",
      "     | > loss: 0.13904821872711182  (0.13438189041519913)\n",
      "     | > log_mle: -0.17556214332580566  (-0.16173467371198866)\n",
      "     | > loss_dur: 0.3146103620529175  (0.296116564127188)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.4323, device='cuda:0')  (tensor(4.3302, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.4534  (0.3822954438981556)\n",
      "     | > loader_time: 0.005  (0.004635177907489593)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:48:28 -- STEP: 277/406 -- GLOBAL_STEP: 13675\u001b[0m\n",
      "     | > loss: 0.11758866906166077  (0.1338236833307286)\n",
      "     | > log_mle: -0.17282366752624512  (-0.163029750762003)\n",
      "     | > loss_dur: 0.2904123365879059  (0.2968534340927318)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.4919, device='cuda:0')  (tensor(4.4880, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5635  (0.3945531018804558)\n",
      "     | > loader_time: 0.004  (0.004639598006375859)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:48:41 -- STEP: 302/406 -- GLOBAL_STEP: 13700\u001b[0m\n",
      "     | > loss: 0.12836003303527832  (0.13343614063515566)\n",
      "     | > log_mle: -0.1817702054977417  (-0.16410535100280058)\n",
      "     | > loss_dur: 0.31013023853302  (0.2975414916379563)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.1673, device='cuda:0')  (tensor(4.5554, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.6035  (0.40676329388523735)\n",
      "     | > loader_time: 0.005  (0.004679745396241446)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:48:56 -- STEP: 327/406 -- GLOBAL_STEP: 13725\u001b[0m\n",
      "     | > loss: 0.13039255142211914  (0.13320478158988708)\n",
      "     | > log_mle: -0.17784345149993896  (-0.1649892997304235)\n",
      "     | > loss_dur: 0.3082360029220581  (0.29819408132031067)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0679, device='cuda:0')  (tensor(4.4759, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5375  (0.41855120731785384)\n",
      "     | > loader_time: 0.005  (0.004719886575634691)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:49:10 -- STEP: 352/406 -- GLOBAL_STEP: 13750\u001b[0m\n",
      "     | > loss: 0.13526123762130737  (0.1330670486627654)\n",
      "     | > log_mle: -0.17313575744628906  (-0.16595365208658314)\n",
      "     | > loss_dur: 0.30839699506759644  (0.2990207007493485)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.8486, device='cuda:0')  (tensor(4.5477, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5245  (0.42994996702129185)\n",
      "     | > loader_time: 0.005  (0.004760028963739221)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:49:26 -- STEP: 377/406 -- GLOBAL_STEP: 13775\u001b[0m\n",
      "     | > loss: 0.139161616563797  (0.13261256554714881)\n",
      "     | > log_mle: -0.17884492874145508  (-0.16700744881870264)\n",
      "     | > loss_dur: 0.3180065453052521  (0.2996200143658515)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.4354, device='cuda:0')  (tensor(4.7157, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.6926  (0.44213079267850913)\n",
      "     | > loader_time: 0.005  (0.004808121081688675)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:49:43 -- STEP: 402/406 -- GLOBAL_STEP: 13800\u001b[0m\n",
      "     | > loss: 0.11909416317939758  (0.13205152260723402)\n",
      "     | > log_mle: -0.18731999397277832  (-0.16795853892369064)\n",
      "     | > loss_dur: 0.3064141571521759  (0.3000100615309247)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(8.9319, device='cuda:0')  (tensor(4.7785, device='cuda:0'))\n",
      "     | > current_lr: 8.25e-06 \n",
      "     | > step_time: 0.5716  (0.4564855774836753)\n",
      "     | > loader_time: 0.004  (0.0048352794267644906)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09771361947059631 \u001b[0m(-0.006130814552307129)\n",
      "     | > avg_loss:\u001b[92m 0.10916252434253693 \u001b[0m(-0.011473260819911957)\n",
      "     | > avg_log_mle:\u001b[92m -0.18080998957157135 \u001b[0m(-0.00547558069229126)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2899725139141083 \u001b[0m(-0.005997680127620697)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_13804.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 34/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:50:18) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:50:40 -- STEP: 21/406 -- GLOBAL_STEP: 13825\u001b[0m\n",
      "     | > loss: 0.13364753127098083  (0.11942124437718164)\n",
      "     | > log_mle: -0.1551816463470459  (-0.14927463304428829)\n",
      "     | > loss_dur: 0.28882917761802673  (0.26869587742146994)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.1516, device='cuda:0')  (tensor(2.4995, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.2652  (0.27405835333324613)\n",
      "     | > loader_time: 0.002  (0.011153028124854676)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:50:48 -- STEP: 46/406 -- GLOBAL_STEP: 13850\u001b[0m\n",
      "     | > loss: 0.10993734002113342  (0.12495514977237453)\n",
      "     | > log_mle: -0.15508532524108887  (-0.14964971853339157)\n",
      "     | > loss_dur: 0.2650226652622223  (0.274604868305766)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(2.2838, device='cuda:0')  (tensor(2.4306, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.3203  (0.28123362686323067)\n",
      "     | > loader_time: 0.002  (0.006310094957766323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:50:56 -- STEP: 71/406 -- GLOBAL_STEP: 13875\u001b[0m\n",
      "     | > loss: 0.1353449523448944  (0.1252476843729825)\n",
      "     | > log_mle: -0.1611189842224121  (-0.1530186240102204)\n",
      "     | > loss_dur: 0.2964639365673065  (0.27826630838320277)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(4.9612, device='cuda:0')  (tensor(3.4270, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.3723  (0.29619851246686035)\n",
      "     | > loader_time: 0.003  (0.005089141953159384)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:51:05 -- STEP: 96/406 -- GLOBAL_STEP: 13900\u001b[0m\n",
      "     | > loss: 0.12733125686645508  (0.12492003090058762)\n",
      "     | > log_mle: -0.16849613189697266  (-0.15637224415938064)\n",
      "     | > loss_dur: 0.29582738876342773  (0.28129227505996807)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(7.7444, device='cuda:0')  (tensor(4.7372, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.3994  (0.3134910191098847)\n",
      "     | > loader_time: 0.004  (0.00458741436402003)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:51:15 -- STEP: 121/406 -- GLOBAL_STEP: 13925\u001b[0m\n",
      "     | > loss: 0.12287530303001404  (0.1233695936350783)\n",
      "     | > log_mle: -0.16677439212799072  (-0.15906040727599596)\n",
      "     | > loss_dur: 0.28964969515800476  (0.282430000911074)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.3973, device='cuda:0')  (tensor(4.7862, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4264  (0.3270392122347492)\n",
      "     | > loader_time: 0.004  (0.004350936117251058)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:51:25 -- STEP: 146/406 -- GLOBAL_STEP: 13950\u001b[0m\n",
      "     | > loss: 0.12259498238563538  (0.12351231389258006)\n",
      "     | > log_mle: -0.16232514381408691  (-0.16126122295039974)\n",
      "     | > loss_dur: 0.2849201261997223  (0.2847735368429796)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.8848, device='cuda:0')  (tensor(4.7394, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4214  (0.3407670700386778)\n",
      "     | > loader_time: 0.004  (0.004291454406633769)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:51:36 -- STEP: 171/406 -- GLOBAL_STEP: 13975\u001b[0m\n",
      "     | > loss: 0.10572078824043274  (0.12344596042619115)\n",
      "     | > log_mle: -0.1756119728088379  (-0.16301061326300184)\n",
      "     | > loss_dur: 0.28133276104927063  (0.28645657368919286)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(6.4519, device='cuda:0')  (tensor(4.6959, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4514  (0.3516925301468162)\n",
      "     | > loader_time: 0.004  (0.004249353854976898)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:51:47 -- STEP: 196/406 -- GLOBAL_STEP: 14000\u001b[0m\n",
      "     | > loss: 0.11704587936401367  (0.12332459075414405)\n",
      "     | > log_mle: -0.17863035202026367  (-0.1647441064824862)\n",
      "     | > loss_dur: 0.29567623138427734  (0.28806869723663026)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.5526, device='cuda:0')  (tensor(4.7055, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4884  (0.3639570705744684)\n",
      "     | > loader_time: 0.003  (0.00424863732590967)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_14000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:52:03 -- STEP: 221/406 -- GLOBAL_STEP: 14025\u001b[0m\n",
      "     | > loss: 0.1320434808731079  (0.12292662701186012)\n",
      "     | > log_mle: -0.16961169242858887  (-0.16626612363357876)\n",
      "     | > loss_dur: 0.3016551733016968  (0.28919275064543876)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.4885, device='cuda:0')  (tensor(4.8270, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4284  (0.3745192132923937)\n",
      "     | > loader_time: 0.004  (0.004243556190939507)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:52:15 -- STEP: 246/406 -- GLOBAL_STEP: 14050\u001b[0m\n",
      "     | > loss: 0.12301367521286011  (0.12270027732219153)\n",
      "     | > log_mle: -0.17647826671600342  (-0.1677345410595094)\n",
      "     | > loss_dur: 0.2994919419288635  (0.2904348183817008)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.0404, device='cuda:0')  (tensor(4.8825, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4314  (0.3848396433078176)\n",
      "     | > loader_time: 0.004  (0.0042598441364319305)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:52:28 -- STEP: 271/406 -- GLOBAL_STEP: 14075\u001b[0m\n",
      "     | > loss: 0.10217902064323425  (0.12219602226991055)\n",
      "     | > log_mle: -0.1939682960510254  (-0.1689532625719189)\n",
      "     | > loss_dur: 0.29614731669425964  (0.29114928484182934)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.9629, device='cuda:0')  (tensor(4.9513, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.4644  (0.39654681339475056)\n",
      "     | > loader_time: 0.004  (0.0042804985468677895)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:52:41 -- STEP: 296/406 -- GLOBAL_STEP: 14100\u001b[0m\n",
      "     | > loss: 0.11995434761047363  (0.12183186547780359)\n",
      "     | > log_mle: -0.18218612670898438  (-0.17001765483134493)\n",
      "     | > loss_dur: 0.302140474319458  (0.2918495203091484)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(5.5540, device='cuda:0')  (tensor(4.9919, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.5185  (0.406820774078369)\n",
      "     | > loader_time: 0.005  (0.0043111983183267925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:52:55 -- STEP: 321/406 -- GLOBAL_STEP: 14125\u001b[0m\n",
      "     | > loss: 0.12106257677078247  (0.12161488608222142)\n",
      "     | > log_mle: -0.17789161205291748  (-0.1709977180415595)\n",
      "     | > loss_dur: 0.29895418882369995  (0.29261260412378093)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(3.4862, device='cuda:0')  (tensor(4.8552, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.5445  (0.41858759104648474)\n",
      "     | > loader_time: 0.005  (0.004358934093487223)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:53:10 -- STEP: 346/406 -- GLOBAL_STEP: 14150\u001b[0m\n",
      "     | > loss: 0.11405003070831299  (0.12145594188760471)\n",
      "     | > log_mle: -0.18077099323272705  (-0.1719734024450267)\n",
      "     | > loss_dur: 0.29482102394104004  (0.29342934433263135)\n",
      "     | > amp_scaler: 32768.0  (32768.0)\n",
      "     | > grad_norm: tensor(12.9214, device='cuda:0')  (tensor(4.8313, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.5335  (0.4299760305812592)\n",
      "     | > loader_time: 0.005  (0.004411338381684582)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:53:25 -- STEP: 371/406 -- GLOBAL_STEP: 14175\u001b[0m\n",
      "     | > loss: 0.11516669392585754  (0.12104497753545601)\n",
      "     | > log_mle: -0.19042658805847168  (-0.17299169992822197)\n",
      "     | > loss_dur: 0.3055932819843292  (0.29403667746367806)\n",
      "     | > amp_scaler: 16384.0  (31663.956873315365)\n",
      "     | > grad_norm: tensor(5.5636, device='cuda:0')  (tensor(5.0117, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.5873  (0.442315496845708)\n",
      "     | > loader_time: 0.005  (0.004489067108483324)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:53:42 -- STEP: 396/406 -- GLOBAL_STEP: 14200\u001b[0m\n",
      "     | > loss: 0.10327377915382385  (0.12041026018936225)\n",
      "     | > log_mle: -0.19942057132720947  (-0.1738723137161948)\n",
      "     | > loss_dur: 0.3026943504810333  (0.29428257390555707)\n",
      "     | > amp_scaler: 16384.0  (30699.31313131313)\n",
      "     | > grad_norm: tensor(5.9004, device='cuda:0')  (tensor(5.0669, device='cuda:0'))\n",
      "     | > current_lr: 8.5e-06 \n",
      "     | > step_time: 0.5865  (0.4569127222504278)\n",
      "     | > loader_time: 0.006  (0.004579727095786967)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.12648960947990417 \u001b[0m(+0.02877599000930786)\n",
      "     | > avg_loss:\u001b[92m 0.09710192680358887 \u001b[0m(-0.012060597538948059)\n",
      "     | > avg_log_mle:\u001b[92m -0.1848163604736328 \u001b[0m(-0.004006370902061462)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2819182872772217 \u001b[0m(-0.008054226636886597)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_14210.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 35/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:54:23) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:54:46 -- STEP: 15/406 -- GLOBAL_STEP: 14225\u001b[0m\n",
      "     | > loss: 0.09009189903736115  (0.10091473758220673)\n",
      "     | > log_mle: -0.15798676013946533  (-0.15639464060465494)\n",
      "     | > loss_dur: 0.24807865917682648  (0.2573093781868616)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1147, device='cuda:0')  (tensor(2.5201, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.2843  (0.27391544977823895)\n",
      "     | > loader_time: 0.003  (0.018950621287027996)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:54:54 -- STEP: 40/406 -- GLOBAL_STEP: 14250\u001b[0m\n",
      "     | > loss: 0.13016411662101746  (0.10985274724662304)\n",
      "     | > log_mle: -0.1476154327392578  (-0.1551757872104645)\n",
      "     | > loss_dur: 0.27777954936027527  (0.2650285344570874)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.0562, device='cuda:0')  (tensor(2.7322, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3153  (0.2862598419189453)\n",
      "     | > loader_time: 0.003  (0.008607804775238037)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:55:01 -- STEP: 65/406 -- GLOBAL_STEP: 14275\u001b[0m\n",
      "     | > loss: 0.11247262358665466  (0.11069108706254226)\n",
      "     | > log_mle: -0.168115496635437  (-0.15783898463616006)\n",
      "     | > loss_dur: 0.2805881202220917  (0.26853007169870224)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3591, device='cuda:0')  (tensor(3.1627, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3273  (0.292465485059298)\n",
      "     | > loader_time: 0.002  (0.006282659677358776)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:55:10 -- STEP: 90/406 -- GLOBAL_STEP: 14300\u001b[0m\n",
      "     | > loss: 0.09651550650596619  (0.11121596097946167)\n",
      "     | > log_mle: -0.17238187789916992  (-0.1611201259824965)\n",
      "     | > loss_dur: 0.2688973844051361  (0.27233608696195805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8394, device='cuda:0')  (tensor(3.5348, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3773  (0.3023691097895306)\n",
      "     | > loader_time: 0.004  (0.0053826067182752855)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:55:19 -- STEP: 115/406 -- GLOBAL_STEP: 14325\u001b[0m\n",
      "     | > loss: 0.1433497965335846  (0.11029080813345701)\n",
      "     | > log_mle: -0.1624966859817505  (-0.16445034379544465)\n",
      "     | > loss_dur: 0.3058464825153351  (0.2747411519289015)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5197, device='cuda:0')  (tensor(3.8357, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3413  (0.3156040461167047)\n",
      "     | > loader_time: 0.004  (0.004952237917029341)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:55:29 -- STEP: 140/406 -- GLOBAL_STEP: 14350\u001b[0m\n",
      "     | > loss: 0.10454463958740234  (0.11054651279534612)\n",
      "     | > log_mle: -0.18225181102752686  (-0.166845726115363)\n",
      "     | > loss_dur: 0.2867964506149292  (0.27739223891070913)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.6343, device='cuda:0')  (tensor(4.1497, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3453  (0.3266073192868915)\n",
      "     | > loader_time: 0.003  (0.004675633566720146)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:55:39 -- STEP: 165/406 -- GLOBAL_STEP: 14375\u001b[0m\n",
      "     | > loss: 0.10110503435134888  (0.11074845420591758)\n",
      "     | > log_mle: -0.18946027755737305  (-0.16862441048477633)\n",
      "     | > loss_dur: 0.2905653119087219  (0.279372864690694)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(14.6976, device='cuda:0')  (tensor(4.5558, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3623  (0.33707882418776997)\n",
      "     | > loader_time: 0.003  (0.004525293003429066)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:55:49 -- STEP: 190/406 -- GLOBAL_STEP: 14400\u001b[0m\n",
      "     | > loss: 0.1113971471786499  (0.11060475165906705)\n",
      "     | > log_mle: -0.186712384223938  (-0.17046785731064643)\n",
      "     | > loss_dur: 0.2981095314025879  (0.2810726089697136)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0194, device='cuda:0')  (tensor(4.6455, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3914  (0.3485928585654811)\n",
      "     | > loader_time: 0.004  (0.0044355630874633786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:56:01 -- STEP: 215/406 -- GLOBAL_STEP: 14425\u001b[0m\n",
      "     | > loss: 0.09527477622032166  (0.11004669506882513)\n",
      "     | > log_mle: -0.1873098611831665  (-0.17191014012625047)\n",
      "     | > loss_dur: 0.28258463740348816  (0.2819568351950757)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.0561, device='cuda:0')  (tensor(4.6879, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.3984  (0.3595753414686336)\n",
      "     | > loader_time: 0.004  (0.00438998355421909)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:56:12 -- STEP: 240/406 -- GLOBAL_STEP: 14450\u001b[0m\n",
      "     | > loss: 0.09035351872444153  (0.1098875201617678)\n",
      "     | > log_mle: -0.1950671672821045  (-0.17347879757483797)\n",
      "     | > loss_dur: 0.285420686006546  (0.2833663177366058)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4978, device='cuda:0')  (tensor(4.7760, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5305  (0.3703800270954768)\n",
      "     | > loader_time: 0.004  (0.004362276196479798)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:56:25 -- STEP: 265/406 -- GLOBAL_STEP: 14475\u001b[0m\n",
      "     | > loss: 0.11376222968101501  (0.10968982999054891)\n",
      "     | > log_mle: -0.1894930601119995  (-0.1746984391842248)\n",
      "     | > loss_dur: 0.3032552897930145  (0.28438826917477367)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3501, device='cuda:0')  (tensor(4.9540, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.4444  (0.382700259730501)\n",
      "     | > loader_time: 0.005  (0.004377559445938974)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:56:38 -- STEP: 290/406 -- GLOBAL_STEP: 14500\u001b[0m\n",
      "     | > loss: 0.08588337898254395  (0.10909770557592655)\n",
      "     | > log_mle: -0.1988767385482788  (-0.175863254892415)\n",
      "     | > loss_dur: 0.28476011753082275  (0.28496096046834146)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.4155, device='cuda:0')  (tensor(5.0401, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5965  (0.39346582231850463)\n",
      "     | > loader_time: 0.005  (0.004417806658251532)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:56:52 -- STEP: 315/406 -- GLOBAL_STEP: 14525\u001b[0m\n",
      "     | > loss: 0.0914422869682312  (0.10888298101841458)\n",
      "     | > log_mle: -0.199415922164917  (-0.17690893014272055)\n",
      "     | > loss_dur: 0.2908582091331482  (0.28579191116113495)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.3900, device='cuda:0')  (tensor(5.0429, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5275  (0.4055539002494207)\n",
      "     | > loader_time: 0.005  (0.00444530002654545)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:57:06 -- STEP: 340/406 -- GLOBAL_STEP: 14550\u001b[0m\n",
      "     | > loss: 0.11306282877922058  (0.10911736361244145)\n",
      "     | > log_mle: -0.17637395858764648  (-0.17769286176737617)\n",
      "     | > loss_dur: 0.28943678736686707  (0.28681022537981743)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3777, device='cuda:0')  (tensor(5.0806, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5125  (0.41705951129688934)\n",
      "     | > loader_time: 0.005  (0.004483481014476105)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:57:21 -- STEP: 365/406 -- GLOBAL_STEP: 14575\u001b[0m\n",
      "     | > loss: 0.08722779154777527  (0.10888123638825874)\n",
      "     | > log_mle: -0.19086158275604248  (-0.17872565739775356)\n",
      "     | > loss_dur: 0.27808937430381775  (0.28760689378601206)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7136, device='cuda:0')  (tensor(5.1125, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.5635  (0.42832720312353684)\n",
      "     | > loader_time: 0.006  (0.004521919929817935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:57:37 -- STEP: 390/406 -- GLOBAL_STEP: 14600\u001b[0m\n",
      "     | > loss: 0.09409090876579285  (0.10858161246929414)\n",
      "     | > log_mle: -0.20041728019714355  (-0.1796108536231212)\n",
      "     | > loss_dur: 0.2945081889629364  (0.28819246609241506)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.9219, device='cuda:0')  (tensor(5.2331, device='cuda:0'))\n",
      "     | > current_lr: 8.750000000000001e-06 \n",
      "     | > step_time: 0.7056  (0.4415243381108993)\n",
      "     | > loader_time: 0.005  (0.0045656962272448455)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08895754814147949 \u001b[0m(-0.03753206133842468)\n",
      "     | > avg_loss:\u001b[92m 0.08087543398141861 \u001b[0m(-0.016226492822170258)\n",
      "     | > avg_log_mle:\u001b[92m -0.19302383065223694 \u001b[0m(-0.008207470178604126)\n",
      "     | > avg_loss_dur:\u001b[92m 0.27389926463365555 \u001b[0m(-0.008019022643566132)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_14616.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 36/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 03:58:18) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:58:37 -- STEP: 9/406 -- GLOBAL_STEP: 14625\u001b[0m\n",
      "     | > loss: 0.12569066882133484  (0.09717064433627659)\n",
      "     | > log_mle: -0.16100776195526123  (-0.15944108698103163)\n",
      "     | > loss_dur: 0.28669843077659607  (0.2566117313173082)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.1488, device='cuda:0')  (tensor(2.1661, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.2542  (0.25956887669033474)\n",
      "     | > loader_time: 0.001  (0.022575934727986652)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:58:44 -- STEP: 34/406 -- GLOBAL_STEP: 14650\u001b[0m\n",
      "     | > loss: 0.1325153112411499  (0.09520744006423389)\n",
      "     | > log_mle: -0.14991521835327148  (-0.16100437851513133)\n",
      "     | > loss_dur: 0.2824305295944214  (0.2562118185793652)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.2054, device='cuda:0')  (tensor(2.2618, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.2652  (0.2633272689931533)\n",
      "     | > loader_time: 0.003  (0.007506721159991096)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:58:51 -- STEP: 59/406 -- GLOBAL_STEP: 14675\u001b[0m\n",
      "     | > loss: 0.09235429763793945  (0.09851497209678262)\n",
      "     | > log_mle: -0.17764484882354736  (-0.16347305653458935)\n",
      "     | > loss_dur: 0.2699991464614868  (0.26198802863137194)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7995, device='cuda:0')  (tensor(3.1071, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.3323  (0.27896504887079787)\n",
      "     | > loader_time: 0.003  (0.005445581371501341)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:58:59 -- STEP: 84/406 -- GLOBAL_STEP: 14700\u001b[0m\n",
      "     | > loss: 0.08839643001556396  (0.100040998842035)\n",
      "     | > log_mle: -0.18043553829193115  (-0.16636512960706443)\n",
      "     | > loss_dur: 0.2688319683074951  (0.2664061284490994)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4663, device='cuda:0')  (tensor(3.4838, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.3023  (0.2922295190039135)\n",
      "     | > loader_time: 0.003  (0.004694703079405287)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:59:08 -- STEP: 109/406 -- GLOBAL_STEP: 14725\u001b[0m\n",
      "     | > loss: 0.0861445963382721  (0.09906902799912547)\n",
      "     | > log_mle: -0.1885453462600708  (-0.16942293600204894)\n",
      "     | > loss_dur: 0.2746899425983429  (0.2684919640011744)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3690, device='cuda:0')  (tensor(3.8577, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.3894  (0.30530466508427884)\n",
      "     | > loader_time: 0.003  (0.004324998330632482)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:59:18 -- STEP: 134/406 -- GLOBAL_STEP: 14750\u001b[0m\n",
      "     | > loss: 0.10125032067298889  (0.09903319647063069)\n",
      "     | > log_mle: -0.18098998069763184  (-0.17208392673463968)\n",
      "     | > loss_dur: 0.2822403013706207  (0.2711171232052704)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.4242, device='cuda:0')  (tensor(4.1587, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.4164  (0.3164514107490653)\n",
      "     | > loader_time: 0.004  (0.004182906293157322)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:59:28 -- STEP: 159/406 -- GLOBAL_STEP: 14775\u001b[0m\n",
      "     | > loss: 0.0913098156452179  (0.09943723762935058)\n",
      "     | > log_mle: -0.18260955810546875  (-0.17392721491039925)\n",
      "     | > loss_dur: 0.27391937375068665  (0.27336445253975006)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1361, device='cuda:0')  (tensor(4.3529, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.3673  (0.32986547811976014)\n",
      "     | > loader_time: 0.004  (0.004104324856644158)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:59:38 -- STEP: 184/406 -- GLOBAL_STEP: 14800\u001b[0m\n",
      "     | > loss: 0.11852401494979858  (0.09948145978800625)\n",
      "     | > log_mle: -0.2015533447265625  (-0.17569723854894223)\n",
      "     | > loss_dur: 0.3200773596763611  (0.2751786983369487)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.8405, device='cuda:0')  (tensor(4.3148, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.3793  (0.34238144237062185)\n",
      "     | > loader_time: 0.004  (0.004047154084495876)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 03:59:50 -- STEP: 209/406 -- GLOBAL_STEP: 14825\u001b[0m\n",
      "     | > loss: 0.08819270133972168  (0.09923708645635812)\n",
      "     | > log_mle: -0.19707512855529785  (-0.17720205418801194)\n",
      "     | > loss_dur: 0.28526782989501953  (0.27643914064437036)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.7885, device='cuda:0')  (tensor(4.6824, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.3944  (0.3540103503961881)\n",
      "     | > loader_time: 0.004  (0.00403237570986223)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:00:01 -- STEP: 234/406 -- GLOBAL_STEP: 14850\u001b[0m\n",
      "     | > loss: 0.09635218977928162  (0.09888294740365099)\n",
      "     | > log_mle: -0.19951248168945312  (-0.17883805433909097)\n",
      "     | > loss_dur: 0.29586467146873474  (0.27772100174274217)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7624, device='cuda:0')  (tensor(4.7703, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5245  (0.36435638024256767)\n",
      "     | > loader_time: 0.005  (0.0040549630792731895)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:00:14 -- STEP: 259/406 -- GLOBAL_STEP: 14875\u001b[0m\n",
      "     | > loss: 0.08968734741210938  (0.09872564149869452)\n",
      "     | > log_mle: -0.2048872709274292  (-0.18015620699260226)\n",
      "     | > loss_dur: 0.2945746183395386  (0.278881848491297)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5019, device='cuda:0')  (tensor(4.7731, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5665  (0.3769753955045721)\n",
      "     | > loader_time: 0.005  (0.0040925331557579445)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:00:26 -- STEP: 284/406 -- GLOBAL_STEP: 14900\u001b[0m\n",
      "     | > loss: 0.09124797582626343  (0.09812876849736962)\n",
      "     | > log_mle: -0.199629545211792  (-0.1813232592293914)\n",
      "     | > loss_dur: 0.2908775210380554  (0.27945202772676114)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.9367, device='cuda:0')  (tensor(5.2565, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5645  (0.3881058206020946)\n",
      "     | > loader_time: 0.004  (0.004127015530223576)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:00:40 -- STEP: 309/406 -- GLOBAL_STEP: 14925\u001b[0m\n",
      "     | > loss: 0.09029582142829895  (0.09807488269211788)\n",
      "     | > log_mle: -0.19558918476104736  (-0.1822895405747743)\n",
      "     | > loss_dur: 0.2858850061893463  (0.28036442326689237)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0879, device='cuda:0')  (tensor(5.4106, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6336  (0.39984839016565604)\n",
      "     | > loader_time: 0.005  (0.004168862278021654)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:00:54 -- STEP: 334/406 -- GLOBAL_STEP: 14950\u001b[0m\n",
      "     | > loss: 0.09879019856452942  (0.09817527845769582)\n",
      "     | > log_mle: -0.20388007164001465  (-0.18311470247314346)\n",
      "     | > loss_dur: 0.30267027020454407  (0.2812899809308396)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.8043, device='cuda:0')  (tensor(5.4423, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.6446  (0.41085797012923)\n",
      "     | > loader_time: 0.005  (0.0042164404235200265)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:01:08 -- STEP: 359/406 -- GLOBAL_STEP: 14975\u001b[0m\n",
      "     | > loss: 0.09803968667984009  (0.09822340326222864)\n",
      "     | > log_mle: -0.1927776336669922  (-0.18405319621636)\n",
      "     | > loss_dur: 0.2908173203468323  (0.28227659947858896)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0025, device='cuda:0')  (tensor(5.5838, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5485  (0.422274655286316)\n",
      "     | > loader_time: 0.005  (0.004260188025684409)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:01:24 -- STEP: 384/406 -- GLOBAL_STEP: 15000\u001b[0m\n",
      "     | > loss: 0.08941388130187988  (0.09792297492579864)\n",
      "     | > log_mle: -0.19324755668640137  (-0.1849329269801576)\n",
      "     | > loss_dur: 0.28266143798828125  (0.2828559019059564)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4911, device='cuda:0')  (tensor(5.7686, device='cuda:0'))\n",
      "     | > current_lr: 9e-06 \n",
      "     | > step_time: 0.5725  (0.4345142015566428)\n",
      "     | > loader_time: 0.006  (0.004313868160049121)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_15000.pth\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.08970659971237183 \u001b[0m(+0.000749051570892334)\n",
      "     | > avg_loss:\u001b[92m 0.06781225837767124 \u001b[0m(-0.013063175603747368)\n",
      "     | > avg_log_mle:\u001b[92m -0.1995384395122528 \u001b[0m(-0.006514608860015869)\n",
      "     | > avg_loss_dur:\u001b[92m 0.26735069788992405 \u001b[0m(-0.006548566743731499)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_15022.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 37/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:02:15) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:02:32 -- STEP: 3/406 -- GLOBAL_STEP: 15025\u001b[0m\n",
      "     | > loss: 0.0768524557352066  (0.06957308451334636)\n",
      "     | > log_mle: -0.1691896915435791  (-0.17099463939666748)\n",
      "     | > loss_dur: 0.2460421472787857  (0.24056772391001383)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.8870, device='cuda:0')  (tensor(3.3424, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.2572  (0.28259023030598956)\n",
      "     | > loader_time: 0.2372  (0.08040618896484375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:02:38 -- STEP: 28/406 -- GLOBAL_STEP: 15050\u001b[0m\n",
      "     | > loss: 0.10918819904327393  (0.0844886228442192)\n",
      "     | > log_mle: -0.1648160219192505  (-0.16597772921834672)\n",
      "     | > loss_dur: 0.2740042209625244  (0.25046635206256596)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.7391, device='cuda:0')  (tensor(3.6031, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.2783  (0.26338224751608713)\n",
      "     | > loader_time: 0.002  (0.010223337582179479)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:02:46 -- STEP: 53/406 -- GLOBAL_STEP: 15075\u001b[0m\n",
      "     | > loss: 0.0840752124786377  (0.09035281246563173)\n",
      "     | > log_mle: -0.1649237871170044  (-0.16738512830914193)\n",
      "     | > loss_dur: 0.2489989995956421  (0.2577379407747736)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1901, device='cuda:0')  (tensor(3.8484, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.3173  (0.27598669843853646)\n",
      "     | > loader_time: 0.003  (0.006571783209746739)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:02:54 -- STEP: 78/406 -- GLOBAL_STEP: 15100\u001b[0m\n",
      "     | > loss: 0.10198214650154114  (0.09002011976180933)\n",
      "     | > log_mle: -0.17204999923706055  (-0.17035542390285394)\n",
      "     | > loss_dur: 0.2740321457386017  (0.2603755436646632)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(17.9317, device='cuda:0')  (tensor(4.5079, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.3053  (0.2885441963489239)\n",
      "     | > loader_time: 0.003  (0.0053252073434683)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:03:02 -- STEP: 103/406 -- GLOBAL_STEP: 15125\u001b[0m\n",
      "     | > loss: 0.06168261170387268  (0.08996320407367447)\n",
      "     | > log_mle: -0.20334315299987793  (-0.17370000510539824)\n",
      "     | > loss_dur: 0.2650257647037506  (0.26366320917907254)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.0959, device='cuda:0')  (tensor(5.4961, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.3123  (0.3019539268271435)\n",
      "     | > loader_time: 0.003  (0.004771179365880284)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:03:12 -- STEP: 128/406 -- GLOBAL_STEP: 15150\u001b[0m\n",
      "     | > loss: 0.09351962804794312  (0.08977298240642995)\n",
      "     | > log_mle: -0.192221999168396  (-0.17628281097859144)\n",
      "     | > loss_dur: 0.2857416272163391  (0.26605579338502117)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5734, device='cuda:0')  (tensor(5.2979, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.4134  (0.3145044185221193)\n",
      "     | > loader_time: 0.004  (0.004472708329558374)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:03:22 -- STEP: 153/406 -- GLOBAL_STEP: 15175\u001b[0m\n",
      "     | > loss: 0.09719479084014893  (0.0901420932579664)\n",
      "     | > log_mle: -0.18396854400634766  (-0.1782941958483527)\n",
      "     | > loss_dur: 0.2811633348464966  (0.26843628910631895)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5942, device='cuda:0')  (tensor(5.3435, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.3663  (0.3270879306045232)\n",
      "     | > loader_time: 0.004  (0.004317551656486163)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:03:32 -- STEP: 178/406 -- GLOBAL_STEP: 15200\u001b[0m\n",
      "     | > loss: 0.08796453475952148  (0.08984615092866877)\n",
      "     | > log_mle: -0.17801225185394287  (-0.17996421154965167)\n",
      "     | > loss_dur: 0.26597678661346436  (0.26981036247832046)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7198, device='cuda:0')  (tensor(5.3306, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.4694  (0.33852655700083506)\n",
      "     | > loader_time: 0.004  (0.004250942991020974)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:03:43 -- STEP: 203/406 -- GLOBAL_STEP: 15225\u001b[0m\n",
      "     | > loss: 0.10891565680503845  (0.08984815178833572)\n",
      "     | > log_mle: -0.18344736099243164  (-0.18157833374192556)\n",
      "     | > loss_dur: 0.2923630177974701  (0.2714264855302614)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2411, device='cuda:0')  (tensor(5.5214, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.3964  (0.3498645404289506)\n",
      "     | > loader_time: 0.004  (0.004215542318785719)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:03:54 -- STEP: 228/406 -- GLOBAL_STEP: 15250\u001b[0m\n",
      "     | > loss: 0.08092054724693298  (0.08966272677245893)\n",
      "     | > log_mle: -0.20337307453155518  (-0.18321075669506134)\n",
      "     | > loss_dur: 0.28429362177848816  (0.27287348346752044)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7367, device='cuda:0')  (tensor(5.7936, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.5165  (0.36044137310563445)\n",
      "     | > loader_time: 0.004  (0.004205487276378431)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:04:06 -- STEP: 253/406 -- GLOBAL_STEP: 15275\u001b[0m\n",
      "     | > loss: 0.08498629927635193  (0.08979137047477391)\n",
      "     | > log_mle: -0.21072840690612793  (-0.18465150250747736)\n",
      "     | > loss_dur: 0.29571470618247986  (0.2744428729822515)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.6754, device='cuda:0')  (tensor(5.8609, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.4324  (0.3725833987058856)\n",
      "     | > loader_time: 0.005  (0.004213236066192507)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:04:19 -- STEP: 278/406 -- GLOBAL_STEP: 15300\u001b[0m\n",
      "     | > loss: 0.0896655023097992  (0.0893640267334396)\n",
      "     | > log_mle: -0.18243122100830078  (-0.18577665605133384)\n",
      "     | > loss_dur: 0.2720967233181  (0.27514068278477366)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.1665, device='cuda:0')  (tensor(5.9603, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.5655  (0.3845938255460998)\n",
      "     | > loader_time: 0.004  (0.004234001790876869)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:04:32 -- STEP: 303/406 -- GLOBAL_STEP: 15325\u001b[0m\n",
      "     | > loss: 0.10651341080665588  (0.08929473682992135)\n",
      "     | > log_mle: -0.19733011722564697  (-0.18686333741291916)\n",
      "     | > loss_dur: 0.30384352803230286  (0.2761580742428407)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.5450, device='cuda:0')  (tensor(6.1261, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.4684  (0.3959734038551253)\n",
      "     | > loader_time: 0.005  (0.004267853085357364)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:04:46 -- STEP: 328/406 -- GLOBAL_STEP: 15350\u001b[0m\n",
      "     | > loss: 0.10222089290618896  (0.08920450962898209)\n",
      "     | > log_mle: -0.20191693305969238  (-0.1877330170898903)\n",
      "     | > loss_dur: 0.30413782596588135  (0.2769375267188725)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.7191, device='cuda:0')  (tensor(6.2460, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6296  (0.40795272952172795)\n",
      "     | > loader_time: 0.005  (0.004317902937168027)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:05:01 -- STEP: 353/406 -- GLOBAL_STEP: 15375\u001b[0m\n",
      "     | > loss: 0.08848837018013  (0.08926805169994362)\n",
      "     | > log_mle: -0.21108877658843994  (-0.1886748487483341)\n",
      "     | > loss_dur: 0.29957714676856995  (0.27794290044827796)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(18.0293, device='cuda:0')  (tensor(6.3280, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6816  (0.41994504415279726)\n",
      "     | > loader_time: 0.005  (0.004352348722074254)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:05:16 -- STEP: 378/406 -- GLOBAL_STEP: 15400\u001b[0m\n",
      "     | > loss: 0.09610754251480103  (0.08890550421974643)\n",
      "     | > log_mle: -0.19733595848083496  (-0.1896474228964912)\n",
      "     | > loss_dur: 0.293443500995636  (0.27855292711623775)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.6929, device='cuda:0')  (tensor(6.2915, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.6946  (0.43235553635491253)\n",
      "     | > loader_time: 0.005  (0.004400787530121977)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:05:33 -- STEP: 403/406 -- GLOBAL_STEP: 15425\u001b[0m\n",
      "     | > loss: 0.06058165431022644  (0.08843909163333047)\n",
      "     | > log_mle: -0.19808638095855713  (-0.19055206456196222)\n",
      "     | > loss_dur: 0.25866803526878357  (0.27899115619529274)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2580, device='cuda:0')  (tensor(6.2430, device='cuda:0'))\n",
      "     | > current_lr: 9.250000000000001e-06 \n",
      "     | > step_time: 0.7284  (0.4460801551714723)\n",
      "     | > loader_time: 0.004  (0.004453150273552603)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10421967506408691 \u001b[0m(+0.014513075351715088)\n",
      "     | > avg_loss:\u001b[92m 0.057283708825707436 \u001b[0m(-0.010528549551963806)\n",
      "     | > avg_log_mle:\u001b[92m -0.20418907701969147 \u001b[0m(-0.00465063750743866)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2614727858453989 \u001b[0m(-0.0058779120445251465)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_15428.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 38/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:06:06) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:06:28 -- STEP: 22/406 -- GLOBAL_STEP: 15450\u001b[0m\n",
      "     | > loss: 0.07836426794528961  (0.07018472931601784)\n",
      "     | > log_mle: -0.167641282081604  (-0.17118303342299027)\n",
      "     | > loss_dur: 0.24600555002689362  (0.24136776273900812)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.6602, device='cuda:0')  (tensor(2.8902, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.2612  (0.26005415482954547)\n",
      "     | > loader_time: 0.002  (0.010464158925143156)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:06:35 -- STEP: 47/406 -- GLOBAL_STEP: 15475\u001b[0m\n",
      "     | > loss: 0.0914696753025055  (0.07741489340650272)\n",
      "     | > log_mle: -0.18326354026794434  (-0.17174411327280897)\n",
      "     | > loss_dur: 0.27473321557044983  (0.2491590066793117)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.4587, device='cuda:0')  (tensor(3.0168, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.3093  (0.27148003273821897)\n",
      "     | > loader_time: 0.002  (0.00613372376624574)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:06:43 -- STEP: 72/406 -- GLOBAL_STEP: 15500\u001b[0m\n",
      "     | > loss: 0.08695453405380249  (0.07929585770600371)\n",
      "     | > log_mle: -0.17165207862854004  (-0.17481939494609833)\n",
      "     | > loss_dur: 0.25860661268234253  (0.25411525265210205)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.0866, device='cuda:0')  (tensor(4.0675, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.2963  (0.284883459409078)\n",
      "     | > loader_time: 0.003  (0.004865775505701701)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:06:52 -- STEP: 97/406 -- GLOBAL_STEP: 15525\u001b[0m\n",
      "     | > loss: 0.09005376696586609  (0.07983295312247322)\n",
      "     | > log_mle: -0.1815946102142334  (-0.17832904501059624)\n",
      "     | > loss_dur: 0.2716483771800995  (0.2581619981330694)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.5127, device='cuda:0')  (tensor(4.5169, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.3163  (0.2986421707979185)\n",
      "     | > loader_time: 0.003  (0.004344264256585504)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:07:01 -- STEP: 122/406 -- GLOBAL_STEP: 15550\u001b[0m\n",
      "     | > loss: 0.08129197359085083  (0.07932692815045839)\n",
      "     | > log_mle: -0.17905235290527344  (-0.1809105775395378)\n",
      "     | > loss_dur: 0.26034432649612427  (0.26023750568999593)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.8461, device='cuda:0')  (tensor(5.4617, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.4024  (0.3118486013568818)\n",
      "     | > loader_time: 0.003  (0.004143175531606206)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:07:11 -- STEP: 147/406 -- GLOBAL_STEP: 15575\u001b[0m\n",
      "     | > loss: 0.086518794298172  (0.07965354550452457)\n",
      "     | > log_mle: -0.1934647560119629  (-0.18314651161635007)\n",
      "     | > loss_dur: 0.2799835503101349  (0.26280005712087445)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7009, device='cuda:0')  (tensor(6.3605, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.3473  (0.32317773825457324)\n",
      "     | > loader_time: 0.003  (0.0039900273692851165)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:07:21 -- STEP: 172/406 -- GLOBAL_STEP: 15600\u001b[0m\n",
      "     | > loss: 0.08282220363616943  (0.07989201712053877)\n",
      "     | > log_mle: -0.19812703132629395  (-0.18489114281743077)\n",
      "     | > loss_dur: 0.2809492349624634  (0.26478315993796925)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.1225, device='cuda:0')  (tensor(6.2104, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.4554  (0.3350367462912273)\n",
      "     | > loader_time: 0.004  (0.003951233486796532)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:07:32 -- STEP: 197/406 -- GLOBAL_STEP: 15625\u001b[0m\n",
      "     | > loss: 0.07681509852409363  (0.07995745509409058)\n",
      "     | > log_mle: -0.19599688053131104  (-0.1865294905483421)\n",
      "     | > loss_dur: 0.27281197905540466  (0.2664869456424325)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.0201, device='cuda:0')  (tensor(6.6764, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.4724  (0.3476913386795123)\n",
      "     | > loader_time: 0.004  (0.00394769368437946)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:07:43 -- STEP: 222/406 -- GLOBAL_STEP: 15650\u001b[0m\n",
      "     | > loss: 0.07553982734680176  (0.07975203402944513)\n",
      "     | > log_mle: -0.20427823066711426  (-0.18804977498612968)\n",
      "     | > loss_dur: 0.279818058013916  (0.2678018090155747)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.8892, device='cuda:0')  (tensor(7.0273, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.5215  (0.35845611868677923)\n",
      "     | > loader_time: 0.004  (0.0039629882520383535)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:07:55 -- STEP: 247/406 -- GLOBAL_STEP: 15675\u001b[0m\n",
      "     | > loss: 0.09763705730438232  (0.07989884014071723)\n",
      "     | > log_mle: -0.18819403648376465  (-0.1894241537642383)\n",
      "     | > loss_dur: 0.285831093788147  (0.26932299390495534)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.7517, device='cuda:0')  (tensor(7.1866, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.5825  (0.3711791733498517)\n",
      "     | > loader_time: 0.005  (0.00401973145210791)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:08:08 -- STEP: 272/406 -- GLOBAL_STEP: 15700\u001b[0m\n",
      "     | > loss: 0.0537087619304657  (0.07936189740019686)\n",
      "     | > log_mle: -0.20794427394866943  (-0.190693369244828)\n",
      "     | > loss_dur: 0.26165303587913513  (0.2700552666450247)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.9299, device='cuda:0')  (tensor(7.2655, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.5555  (0.3831346850184834)\n",
      "     | > loader_time: 0.004  (0.004047695328207575)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:08:21 -- STEP: 297/406 -- GLOBAL_STEP: 15725\u001b[0m\n",
      "     | > loss: 0.06972610950469971  (0.07915522444127784)\n",
      "     | > log_mle: -0.20101606845855713  (-0.1916985343200992)\n",
      "     | > loss_dur: 0.27074217796325684  (0.2708537587613768)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.4567, device='cuda:0')  (tensor(7.3415, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.4824  (0.3937919509129894)\n",
      "     | > loader_time: 0.005  (0.004091127151592009)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:08:35 -- STEP: 322/406 -- GLOBAL_STEP: 15750\u001b[0m\n",
      "     | > loss: 0.0791521966457367  (0.07908102657113757)\n",
      "     | > log_mle: -0.20822858810424805  (-0.19265149431939455)\n",
      "     | > loss_dur: 0.28738078474998474  (0.2717325208905319)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.0813, device='cuda:0')  (tensor(7.3799, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.6146  (0.4064063137362464)\n",
      "     | > loader_time: 0.005  (0.0041464900378114684)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:08:49 -- STEP: 347/406 -- GLOBAL_STEP: 15775\u001b[0m\n",
      "     | > loss: 0.0773521363735199  (0.07922775875938044)\n",
      "     | > log_mle: -0.2153235673904419  (-0.19357017893612566)\n",
      "     | > loss_dur: 0.2926757037639618  (0.2727979376955058)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(15.6170, device='cuda:0')  (tensor(7.4188, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.5525  (0.417777082762045)\n",
      "     | > loader_time: 0.005  (0.004202507414804068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:09:04 -- STEP: 372/406 -- GLOBAL_STEP: 15800\u001b[0m\n",
      "     | > loss: 0.0833103358745575  (0.07913951055016571)\n",
      "     | > log_mle: -0.1978079080581665  (-0.19450493012705164)\n",
      "     | > loss_dur: 0.281118243932724  (0.27364444067721716)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0825, device='cuda:0')  (tensor(7.4915, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.6716  (0.429462564888821)\n",
      "     | > loader_time: 0.005  (0.004277920851143459)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:09:21 -- STEP: 397/406 -- GLOBAL_STEP: 15825\u001b[0m\n",
      "     | > loss: 0.06752869486808777  (0.07871622522772108)\n",
      "     | > log_mle: -0.2089691162109375  (-0.19537945868686712)\n",
      "     | > loss_dur: 0.27649781107902527  (0.27409568391458783)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.5850, device='cuda:0')  (tensor(7.5138, device='cuda:0'))\n",
      "     | > current_lr: 9.499999999999999e-06 \n",
      "     | > step_time: 0.7522  (0.4431166012281136)\n",
      "     | > loader_time: 0.005  (0.004346364691515715)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10659852623939514 \u001b[0m(+0.0023788511753082275)\n",
      "     | > avg_loss:\u001b[92m 0.04353928938508034 \u001b[0m(-0.013744419440627098)\n",
      "     | > avg_log_mle:\u001b[92m -0.21099351346492767 \u001b[0m(-0.006804436445236206)\n",
      "     | > avg_loss_dur:\u001b[92m 0.254532802850008 \u001b[0m(-0.006939982995390892)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_15834.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 39/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:09:58) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:10:18 -- STEP: 16/406 -- GLOBAL_STEP: 15850\u001b[0m\n",
      "     | > loss: 0.06680108606815338  (0.06118217762559652)\n",
      "     | > log_mle: -0.17952299118041992  (-0.17806492000818253)\n",
      "     | > loss_dur: 0.2463240772485733  (0.23924709763377905)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.1406, device='cuda:0')  (tensor(3.7394, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.2602  (0.26680411398410797)\n",
      "     | > loader_time: 0.002  (0.017266005277633667)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:10:25 -- STEP: 41/406 -- GLOBAL_STEP: 15875\u001b[0m\n",
      "     | > loss: 0.07184314727783203  (0.07003014007719549)\n",
      "     | > log_mle: -0.16872632503509521  (-0.17622538019971148)\n",
      "     | > loss_dur: 0.24056947231292725  (0.246255520276907)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.3064, device='cuda:0')  (tensor(3.8079, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.2642  (0.26848719759685236)\n",
      "     | > loader_time: 0.003  (0.008105382686708032)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:10:33 -- STEP: 66/406 -- GLOBAL_STEP: 15900\u001b[0m\n",
      "     | > loss: 0.09643727540969849  (0.07161114071354718)\n",
      "     | > log_mle: -0.1848534345626831  (-0.17904029831741794)\n",
      "     | > loss_dur: 0.2812907099723816  (0.25065143903096515)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.5926, device='cuda:0')  (tensor(4.3398, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.2823  (0.27970806035128515)\n",
      "     | > loader_time: 0.003  (0.00603618405082009)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:10:41 -- STEP: 91/406 -- GLOBAL_STEP: 15925\u001b[0m\n",
      "     | > loss: 0.06255075335502625  (0.07155947403593374)\n",
      "     | > log_mle: -0.20690488815307617  (-0.18244071976169124)\n",
      "     | > loss_dur: 0.2694556415081024  (0.254000193797625)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(18.8851, device='cuda:0')  (tensor(5.4302, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.3043  (0.2927049254323099)\n",
      "     | > loader_time: 0.004  (0.005191918257828597)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:10:50 -- STEP: 116/406 -- GLOBAL_STEP: 15950\u001b[0m\n",
      "     | > loss: 0.08424609899520874  (0.07120859417422062)\n",
      "     | > log_mle: -0.18446218967437744  (-0.18538524261836348)\n",
      "     | > loss_dur: 0.2687082886695862  (0.256593836792584)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.9471, device='cuda:0')  (tensor(6.1310, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.3273  (0.30418099000536164)\n",
      "     | > loader_time: 0.003  (0.004754650181737439)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:10:59 -- STEP: 141/406 -- GLOBAL_STEP: 15975\u001b[0m\n",
      "     | > loss: 0.07050314545631409  (0.07161437112388881)\n",
      "     | > log_mle: -0.2030414342880249  (-0.18780057058266714)\n",
      "     | > loss_dur: 0.273544579744339  (0.2594149417065559)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.3191, device='cuda:0')  (tensor(5.8646, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.4224  (0.31603131733887585)\n",
      "     | > loader_time: 0.003  (0.0045291920925708525)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:11:09 -- STEP: 166/406 -- GLOBAL_STEP: 16000\u001b[0m\n",
      "     | > loss: 0.05415844917297363  (0.07177937937429153)\n",
      "     | > log_mle: -0.2105696201324463  (-0.18949227160718063)\n",
      "     | > loss_dur: 0.2647280693054199  (0.2612716509814722)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.7831, device='cuda:0')  (tensor(6.0061, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.4444  (0.3268748421266856)\n",
      "     | > loader_time: 0.003  (0.004407816622630659)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_16000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:11:24 -- STEP: 191/406 -- GLOBAL_STEP: 16025\u001b[0m\n",
      "     | > loss: 0.06322047114372253  (0.07152983335612338)\n",
      "     | > log_mle: -0.20501577854156494  (-0.19116500597349634)\n",
      "     | > loss_dur: 0.2682362496852875  (0.2626948393296198)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.5897, device='cuda:0')  (tensor(6.2972, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.4674  (0.33933928374844713)\n",
      "     | > loader_time: 0.004  (0.004333955455200834)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:11:35 -- STEP: 216/406 -- GLOBAL_STEP: 16050\u001b[0m\n",
      "     | > loss: 0.07338717579841614  (0.07134618396284412)\n",
      "     | > log_mle: -0.21039259433746338  (-0.19248111214902663)\n",
      "     | > loss_dur: 0.2837797701358795  (0.2638272961118707)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.6188, device='cuda:0')  (tensor(6.9889, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.4924  (0.3503827220863767)\n",
      "     | > loader_time: 0.004  (0.004295732136125918)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:11:46 -- STEP: 241/406 -- GLOBAL_STEP: 16075\u001b[0m\n",
      "     | > loss: 0.08480063080787659  (0.07151621221506753)\n",
      "     | > log_mle: -0.1968752145767212  (-0.1938880934260198)\n",
      "     | > loss_dur: 0.2816758453845978  (0.2654043056410873)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.2403, device='cuda:0')  (tensor(7.2010, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.4144  (0.36141923552232175)\n",
      "     | > loader_time: 0.005  (0.004286204136258832)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:11:59 -- STEP: 266/406 -- GLOBAL_STEP: 16100\u001b[0m\n",
      "     | > loss: 0.07742530107498169  (0.07133888044303528)\n",
      "     | > log_mle: -0.20201075077056885  (-0.19506000486531652)\n",
      "     | > loss_dur: 0.27943605184555054  (0.2663988853083517)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.7566, device='cuda:0')  (tensor(7.2244, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.5455  (0.37396342234503965)\n",
      "     | > loader_time: 0.006  (0.004312327033595033)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:12:11 -- STEP: 291/406 -- GLOBAL_STEP: 16125\u001b[0m\n",
      "     | > loss: 0.07863935828208923  (0.07106835909725469)\n",
      "     | > log_mle: -0.19442343711853027  (-0.19612190280992964)\n",
      "     | > loss_dur: 0.2730627954006195  (0.26719026190718437)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.6111, device='cuda:0')  (tensor(7.3729, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.4784  (0.38426624950264743)\n",
      "     | > loader_time: 0.005  (0.004340846104310549)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:12:25 -- STEP: 316/406 -- GLOBAL_STEP: 16150\u001b[0m\n",
      "     | > loss: 0.08022403717041016  (0.07094620677489273)\n",
      "     | > log_mle: -0.2077622413635254  (-0.19713948346391516)\n",
      "     | > loss_dur: 0.28798627853393555  (0.2680856902388077)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.2350, device='cuda:0')  (tensor(7.4733, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.6256  (0.3965149612366399)\n",
      "     | > loader_time: 0.005  (0.0043743464011180245)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:12:39 -- STEP: 341/406 -- GLOBAL_STEP: 16175\u001b[0m\n",
      "     | > loss: 0.06762194633483887  (0.07124751753821057)\n",
      "     | > log_mle: -0.22682976722717285  (-0.19792975183805767)\n",
      "     | > loss_dur: 0.2944517135620117  (0.26917726937626807)\n",
      "     | > amp_scaler: 32768.0  (17585.173020527865)\n",
      "     | > grad_norm: tensor(9.6791, device='cuda:0')  (tensor(7.4777, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.5405  (0.40771905767603006)\n",
      "     | > loader_time: 0.005  (0.004408783926642184)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:12:53 -- STEP: 366/406 -- GLOBAL_STEP: 16200\u001b[0m\n",
      "     | > loss: 0.055286675691604614  (0.0710373954043363)\n",
      "     | > log_mle: -0.21860361099243164  (-0.19889530816364814)\n",
      "     | > loss_dur: 0.27389028668403625  (0.2699327035679844)\n",
      "     | > amp_scaler: 16384.0  (18308.896174863396)\n",
      "     | > grad_norm: tensor(15.5396, device='cuda:0')  (tensor(7.5631, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.5455  (0.4187981867399372)\n",
      "     | > loader_time: 0.006  (0.00444672537631676)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:13:09 -- STEP: 391/406 -- GLOBAL_STEP: 16225\u001b[0m\n",
      "     | > loss: 0.050503432750701904  (0.07088690249206477)\n",
      "     | > log_mle: -0.2207469940185547  (-0.19973334388049976)\n",
      "     | > loss_dur: 0.2712504267692566  (0.27062024637256443)\n",
      "     | > amp_scaler: 16384.0  (18185.820971867022)\n",
      "     | > grad_norm: tensor(8.4737, device='cuda:0')  (tensor(7.6629, device='cuda:0'))\n",
      "     | > current_lr: 9.75e-06 \n",
      "     | > step_time: 0.6906  (0.4322301475593196)\n",
      "     | > loader_time: 0.005  (0.004487507788421554)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09834069013595581 \u001b[0m(-0.008257836103439331)\n",
      "     | > avg_loss:\u001b[92m 0.038860177621245384 \u001b[0m(-0.004679111763834953)\n",
      "     | > avg_log_mle:\u001b[91m -0.21007287502288818 \u001b[0m(+0.0009206384420394897)\n",
      "     | > avg_loss_dur:\u001b[92m 0.24893305264413357 \u001b[0m(-0.005599750205874443)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_16240.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 40/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:13:50) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:14:08 -- STEP: 10/406 -- GLOBAL_STEP: 16250\u001b[0m\n",
      "     | > loss: 0.025256410241127014  (0.049345456063747406)\n",
      "     | > log_mle: -0.17980444431304932  (-0.1793515682220459)\n",
      "     | > loss_dur: 0.20506085455417633  (0.2286970242857933)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.2852, device='cuda:0')  (tensor(2.7298, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.2522  (0.2539301633834839)\n",
      "     | > loader_time: 0.002  (0.02001821994781494)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:14:15 -- STEP: 35/406 -- GLOBAL_STEP: 16275\u001b[0m\n",
      "     | > loss: 0.0500735342502594  (0.057752495578357155)\n",
      "     | > log_mle: -0.19861280918121338  (-0.18102295058114187)\n",
      "     | > loss_dur: 0.24868634343147278  (0.23877544615949903)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.1472, device='cuda:0')  (tensor(3.5011, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.2672  (0.260407372883388)\n",
      "     | > loader_time: 0.002  (0.0072069099971226284)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:14:22 -- STEP: 60/406 -- GLOBAL_STEP: 16300\u001b[0m\n",
      "     | > loss: 0.054469332098960876  (0.06207657555739085)\n",
      "     | > log_mle: -0.18582260608673096  (-0.18282087643941244)\n",
      "     | > loss_dur: 0.24029193818569183  (0.2448974519968033)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.8939, device='cuda:0')  (tensor(3.8747, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.2742  (0.27474896113077807)\n",
      "     | > loader_time: 0.002  (0.005255194505055746)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:14:30 -- STEP: 85/406 -- GLOBAL_STEP: 16325\u001b[0m\n",
      "     | > loss: 0.037092819809913635  (0.06278394337962656)\n",
      "     | > log_mle: -0.20871198177337646  (-0.18592836155610923)\n",
      "     | > loss_dur: 0.2458048015832901  (0.24871230493573582)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.3841, device='cuda:0')  (tensor(4.2472, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.2993  (0.28748419425066785)\n",
      "     | > loader_time: 0.002  (0.004486715092378503)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:14:39 -- STEP: 110/406 -- GLOBAL_STEP: 16350\u001b[0m\n",
      "     | > loss: 0.04790028929710388  (0.061945791000669666)\n",
      "     | > log_mle: -0.2146902084350586  (-0.18896272074092513)\n",
      "     | > loss_dur: 0.2625904977321625  (0.2509085117415948)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.8439, device='cuda:0')  (tensor(4.9376, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.3213  (0.30069996443661784)\n",
      "     | > loader_time: 0.003  (0.004185860807245428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:14:48 -- STEP: 135/406 -- GLOBAL_STEP: 16375\u001b[0m\n",
      "     | > loss: 0.07605138421058655  (0.06206932001643712)\n",
      "     | > log_mle: -0.2068164348602295  (-0.19157238183198147)\n",
      "     | > loss_dur: 0.28286781907081604  (0.2536417018484184)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5911, device='cuda:0')  (tensor(5.5254, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.3323  (0.31137868033515087)\n",
      "     | > loader_time: 0.004  (0.004070589277479382)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:14:58 -- STEP: 160/406 -- GLOBAL_STEP: 16400\u001b[0m\n",
      "     | > loss: 0.07547196745872498  (0.06245457082986833)\n",
      "     | > log_mle: -0.2054615020751953  (-0.19339602887630464)\n",
      "     | > loss_dur: 0.2809334695339203  (0.25585059970617285)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(15.1148, device='cuda:0')  (tensor(5.6479, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.4244  (0.32339955419301974)\n",
      "     | > loader_time: 0.004  (0.004047639667987822)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:15:08 -- STEP: 185/406 -- GLOBAL_STEP: 16425\u001b[0m\n",
      "     | > loss: 0.06963130831718445  (0.06236347749426558)\n",
      "     | > log_mle: -0.20669317245483398  (-0.19512230318945809)\n",
      "     | > loss_dur: 0.27632448077201843  (0.25748578068372363)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(14.1533, device='cuda:0')  (tensor(6.5089, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.3974  (0.33521507752908236)\n",
      "     | > loader_time: 0.004  (0.004003825058808195)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:15:19 -- STEP: 210/406 -- GLOBAL_STEP: 16450\u001b[0m\n",
      "     | > loss: 0.05529433488845825  (0.06235202011607942)\n",
      "     | > log_mle: -0.2049804925918579  (-0.19659085046677363)\n",
      "     | > loss_dur: 0.26027482748031616  (0.25894287058285304)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.4808, device='cuda:0')  (tensor(6.8212, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.3974  (0.3470507360640025)\n",
      "     | > loader_time: 0.004  (0.003999032293047222)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:15:31 -- STEP: 235/406 -- GLOBAL_STEP: 16475\u001b[0m\n",
      "     | > loss: 0.06590357422828674  (0.062315362818697664)\n",
      "     | > log_mle: -0.20888447761535645  (-0.19820861512042107)\n",
      "     | > loss_dur: 0.2747880518436432  (0.26052397793911863)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(13.2183, device='cuda:0')  (tensor(6.9088, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.4014  (0.3570837000583079)\n",
      "     | > loader_time: 0.004  (0.004012321918568709)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:15:43 -- STEP: 260/406 -- GLOBAL_STEP: 16500\u001b[0m\n",
      "     | > loss: 0.05824515223503113  (0.06236727971297044)\n",
      "     | > log_mle: -0.2154453992843628  (-0.19954453981839693)\n",
      "     | > loss_dur: 0.2736905515193939  (0.2619118195313674)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.4702, device='cuda:0')  (tensor(7.1976, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.5285  (0.37005708676118104)\n",
      "     | > loader_time: 0.004  (0.004034576966212343)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:15:56 -- STEP: 285/406 -- GLOBAL_STEP: 16525\u001b[0m\n",
      "     | > loss: 0.06865566968917847  (0.06188453843719081)\n",
      "     | > log_mle: -0.2069004774093628  (-0.20066603819529213)\n",
      "     | > loss_dur: 0.27555614709854126  (0.262550576632483)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.1255, device='cuda:0')  (tensor(7.4879, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.4544  (0.3807404007828025)\n",
      "     | > loader_time: 0.005  (0.004066949978209375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:16:09 -- STEP: 310/406 -- GLOBAL_STEP: 16550\u001b[0m\n",
      "     | > loss: 0.04886806011199951  (0.061853063394946436)\n",
      "     | > log_mle: -0.20549607276916504  (-0.20161688981517664)\n",
      "     | > loss_dur: 0.25436413288116455  (0.26346995321012306)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.7192, device='cuda:0')  (tensor(7.5354, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.6096  (0.3929422355467271)\n",
      "     | > loader_time: 0.005  (0.004181290441943747)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:16:23 -- STEP: 335/406 -- GLOBAL_STEP: 16575\u001b[0m\n",
      "     | > loss: 0.0910327136516571  (0.06194956462774704)\n",
      "     | > log_mle: -0.2152259349822998  (-0.20246009079378044)\n",
      "     | > loss_dur: 0.3062586486339569  (0.2644096554215275)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.8663, device='cuda:0')  (tensor(7.7166, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.4884  (0.4034663477940344)\n",
      "     | > loader_time: 0.006  (0.004233771651538444)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:16:37 -- STEP: 360/406 -- GLOBAL_STEP: 16600\u001b[0m\n",
      "     | > loss: 0.044486820697784424  (0.06193860818942388)\n",
      "     | > log_mle: -0.21817874908447266  (-0.20338614020082685)\n",
      "     | > loss_dur: 0.2626655697822571  (0.2653247483902507)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.5599, device='cuda:0')  (tensor(7.7865, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.5155  (0.414997660451465)\n",
      "     | > loader_time: 0.006  (0.004290056228637691)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:16:52 -- STEP: 385/406 -- GLOBAL_STEP: 16625\u001b[0m\n",
      "     | > loss: 0.06493079662322998  (0.06185040806795095)\n",
      "     | > log_mle: -0.2119807004928589  (-0.2042115220775852)\n",
      "     | > loss_dur: 0.27691149711608887  (0.2660619301455362)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1155, device='cuda:0')  (tensor(7.9377, device='cuda:0'))\n",
      "     | > current_lr: 9.999999999999999e-06 \n",
      "     | > step_time: 0.7076  (0.42774035466181753)\n",
      "     | > loader_time: 0.005  (0.004352032054554328)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08596557378768921 \u001b[0m(-0.012375116348266602)\n",
      "     | > avg_loss:\u001b[92m 0.027709510177373886 \u001b[0m(-0.011150667443871498)\n",
      "     | > avg_log_mle:\u001b[92m -0.21803490817546844 \u001b[0m(-0.007962033152580261)\n",
      "     | > avg_loss_dur:\u001b[92m 0.24574441835284233 \u001b[0m(-0.003188634291291237)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_16646.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 41/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:17:37) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:17:54 -- STEP: 4/406 -- GLOBAL_STEP: 16650\u001b[0m\n",
      "     | > loss: 0.08925580978393555  (0.043543703854084015)\n",
      "     | > log_mle: -0.16608047485351562  (-0.18533340096473694)\n",
      "     | > loss_dur: 0.25533628463745117  (0.22887710481882095)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3377, device='cuda:0')  (tensor(5.1401, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.2622  (0.2657410502433777)\n",
      "     | > loader_time: 0.002  (0.059804558753967285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:18:01 -- STEP: 29/406 -- GLOBAL_STEP: 16675\u001b[0m\n",
      "     | > loss: 0.06422469019889832  (0.04618643635305865)\n",
      "     | > log_mle: -0.18591439723968506  (-0.1857090818470922)\n",
      "     | > loss_dur: 0.2501390874385834  (0.23189551820015086)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.9077, device='cuda:0')  (tensor(4.0387, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.2763  (0.2618929599893504)\n",
      "     | > loader_time: 0.002  (0.009940114514581088)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:18:08 -- STEP: 54/406 -- GLOBAL_STEP: 16700\u001b[0m\n",
      "     | > loss: 0.054591238498687744  (0.051994429142386826)\n",
      "     | > log_mle: -0.19053196907043457  (-0.18681708750901402)\n",
      "     | > loss_dur: 0.24512320756912231  (0.23881151665140082)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.0662, device='cuda:0')  (tensor(4.2285, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.2813  (0.2730257334532562)\n",
      "     | > loader_time: 0.003  (0.00645027337250886)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:18:16 -- STEP: 79/406 -- GLOBAL_STEP: 16725\u001b[0m\n",
      "     | > loss: 0.07099968194961548  (0.053027912031246134)\n",
      "     | > log_mle: -0.20128726959228516  (-0.1896406849728355)\n",
      "     | > loss_dur: 0.27228695154190063  (0.24266859700408164)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4158, device='cuda:0')  (tensor(4.8480, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.3593  (0.2861248601841022)\n",
      "     | > loader_time: 0.003  (0.0052451574349705165)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:18:24 -- STEP: 104/406 -- GLOBAL_STEP: 16750\u001b[0m\n",
      "     | > loss: 0.053643837571144104  (0.05336363427340984)\n",
      "     | > log_mle: -0.19471848011016846  (-0.19276113578906426)\n",
      "     | > loss_dur: 0.24836231768131256  (0.2461247700624741)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0441, device='cuda:0')  (tensor(5.2760, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.3924  (0.2987361252307893)\n",
      "     | > loader_time: 0.003  (0.004677245250115027)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:18:34 -- STEP: 129/406 -- GLOBAL_STEP: 16775\u001b[0m\n",
      "     | > loss: 0.06845811009407043  (0.05322607739489208)\n",
      "     | > log_mle: -0.19651353359222412  (-0.1952572229296662)\n",
      "     | > loss_dur: 0.26497164368629456  (0.2484833003245583)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.7450, device='cuda:0')  (tensor(5.8834, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.4074  (0.3104628740355027)\n",
      "     | > loader_time: 0.003  (0.004399255264637081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:18:43 -- STEP: 154/406 -- GLOBAL_STEP: 16800\u001b[0m\n",
      "     | > loss: 0.052944839000701904  (0.05367554095271346)\n",
      "     | > log_mle: -0.20021069049835205  (-0.19721965356306595)\n",
      "     | > loss_dur: 0.25315552949905396  (0.2508951945157795)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4857, device='cuda:0')  (tensor(6.2244, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.4294  (0.32156721647683684)\n",
      "     | > loader_time: 0.004  (0.00425052178370488)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:18:53 -- STEP: 179/406 -- GLOBAL_STEP: 16825\u001b[0m\n",
      "     | > loss: 0.04516372084617615  (0.05371783898529394)\n",
      "     | > log_mle: -0.21425843238830566  (-0.1988635449436123)\n",
      "     | > loss_dur: 0.2594221532344818  (0.2525813839289065)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3983, device='cuda:0')  (tensor(6.5041, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.3763  (0.3327120842214404)\n",
      "     | > loader_time: 0.004  (0.0041600925296378525)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:19:04 -- STEP: 204/406 -- GLOBAL_STEP: 16850\u001b[0m\n",
      "     | > loss: 0.054863929748535156  (0.05398191840333097)\n",
      "     | > log_mle: -0.20952606201171875  (-0.20032473405202222)\n",
      "     | > loss_dur: 0.2643899917602539  (0.2543066524553535)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(13.9999, device='cuda:0')  (tensor(7.1449, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.3954  (0.3444077267366298)\n",
      "     | > loader_time: 0.004  (0.004116390265670475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:19:15 -- STEP: 229/406 -- GLOBAL_STEP: 16875\u001b[0m\n",
      "     | > loss: 0.05466008186340332  (0.05357545399509663)\n",
      "     | > log_mle: -0.2068694829940796  (-0.2018882124705085)\n",
      "     | > loss_dur: 0.2615295648574829  (0.25546366646560537)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.0737, device='cuda:0')  (tensor(7.5212, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.4104  (0.35491783337822136)\n",
      "     | > loader_time: 0.004  (0.004121558634995371)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:19:28 -- STEP: 254/406 -- GLOBAL_STEP: 16900\u001b[0m\n",
      "     | > loss: 0.05918186902999878  (0.05375264802082317)\n",
      "     | > log_mle: -0.20526278018951416  (-0.2032929461772047)\n",
      "     | > loss_dur: 0.26444464921951294  (0.2570455941980282)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.6985, device='cuda:0')  (tensor(7.4332, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.5365  (0.36763007622065513)\n",
      "     | > loader_time: 0.004  (0.004145411994513563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:19:40 -- STEP: 279/406 -- GLOBAL_STEP: 16925\u001b[0m\n",
      "     | > loss: 0.06687760353088379  (0.05351047191141328)\n",
      "     | > log_mle: -0.2075328826904297  (-0.2043770496135971)\n",
      "     | > loss_dur: 0.2744104862213135  (0.2578875215250107)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8965, device='cuda:0')  (tensor(7.6468, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.4454  (0.37912293061560637)\n",
      "     | > loader_time: 0.005  (0.004172168752198579)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:19:53 -- STEP: 304/406 -- GLOBAL_STEP: 16950\u001b[0m\n",
      "     | > loss: 0.034608930349349976  (0.05340831020944998)\n",
      "     | > log_mle: -0.22213256359100342  (-0.20547459862734135)\n",
      "     | > loss_dur: 0.2567414939403534  (0.25888290883679166)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.2425, device='cuda:0')  (tensor(7.7623, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.6045  (0.3908195393650156)\n",
      "     | > loader_time: 0.004  (0.004230719647909467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:20:07 -- STEP: 329/406 -- GLOBAL_STEP: 16975\u001b[0m\n",
      "     | > loss: 0.05688446760177612  (0.05348769183579188)\n",
      "     | > log_mle: -0.20811700820922852  (-0.20626855584988107)\n",
      "     | > loss_dur: 0.26500147581100464  (0.2597562476856733)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.6037, device='cuda:0')  (tensor(7.8548, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.4854  (0.4020314926796772)\n",
      "     | > loader_time: 0.004  (0.00427429581847959)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:20:21 -- STEP: 354/406 -- GLOBAL_STEP: 17000\u001b[0m\n",
      "     | > loss: 0.06049680709838867  (0.053609206093906694)\n",
      "     | > log_mle: -0.21596181392669678  (-0.20720585524025603)\n",
      "     | > loss_dur: 0.27645862102508545  (0.2608150613341631)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.6044, device='cuda:0')  (tensor(7.7965, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.5145  (0.4140561906631384)\n",
      "     | > loader_time: 0.006  (0.004334358172228108)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_17000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:20:42 -- STEP: 379/406 -- GLOBAL_STEP: 17025\u001b[0m\n",
      "     | > loss: 0.044505029916763306  (0.05336119340717951)\n",
      "     | > log_mle: -0.2252131700515747  (-0.20817465989759534)\n",
      "     | > loss_dur: 0.269718199968338  (0.26153585330477536)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1529, device='cuda:0')  (tensor(7.8521, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.5555  (0.42629882339437286)\n",
      "     | > loader_time: 0.005  (0.004373288091694775)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:20:58 -- STEP: 404/406 -- GLOBAL_STEP: 17050\u001b[0m\n",
      "     | > loss: 0.06448426842689514  (0.05312741695359203)\n",
      "     | > log_mle: -0.22041654586791992  (-0.20904840720762113)\n",
      "     | > loss_dur: 0.28490081429481506  (0.26217582416121377)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.1032, device='cuda:0')  (tensor(8.0431, device='cuda:0'))\n",
      "     | > current_lr: 1.025e-05 \n",
      "     | > step_time: 0.5605  (0.4393559163159664)\n",
      "     | > loader_time: 0.005  (0.004412344186612875)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09641984105110168 \u001b[0m(+0.010454267263412476)\n",
      "     | > avg_loss:\u001b[92m 0.021853448823094368 \u001b[0m(-0.005856061354279518)\n",
      "     | > avg_log_mle:\u001b[92m -0.22206337749958038 \u001b[0m(-0.0040284693241119385)\n",
      "     | > avg_loss_dur:\u001b[92m 0.24391682632267475 \u001b[0m(-0.0018275920301675797)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_17052.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 42/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:21:29) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:21:51 -- STEP: 23/406 -- GLOBAL_STEP: 17075\u001b[0m\n",
      "     | > loss: 0.058667317032814026  (0.03446588762428449)\n",
      "     | > log_mle: -0.18815088272094727  (-0.18989269111467444)\n",
      "     | > loss_dur: 0.2468181997537613  (0.22435857873895895)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.6040, device='cuda:0')  (tensor(5.5152, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.2632  (0.25692871342534607)\n",
      "     | > loader_time: 0.002  (0.01172017014544943)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:21:58 -- STEP: 48/406 -- GLOBAL_STEP: 17100\u001b[0m\n",
      "     | > loss: 0.06003132462501526  (0.04393004719167946)\n",
      "     | > log_mle: -0.19465839862823486  (-0.1903577819466591)\n",
      "     | > loss_dur: 0.2546897232532501  (0.23428782913833857)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.9771, device='cuda:0')  (tensor(5.1856, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.3013  (0.2677430510520935)\n",
      "     | > loader_time: 0.002  (0.006741851568222047)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:22:06 -- STEP: 73/406 -- GLOBAL_STEP: 17125\u001b[0m\n",
      "     | > loss: 0.030930787324905396  (0.04487778817954127)\n",
      "     | > log_mle: -0.21682798862457275  (-0.1935232600120649)\n",
      "     | > loss_dur: 0.24775877594947815  (0.23840104819160618)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.6553, device='cuda:0')  (tensor(5.3296, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.3453  (0.28070690207285415)\n",
      "     | > loader_time: 0.003  (0.005324200408099449)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:22:14 -- STEP: 98/406 -- GLOBAL_STEP: 17150\u001b[0m\n",
      "     | > loss: 0.04434257745742798  (0.04559147099451143)\n",
      "     | > log_mle: -0.19723069667816162  (-0.19669910474699373)\n",
      "     | > loss_dur: 0.2415732741355896  (0.24229057574150514)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.4794, device='cuda:0')  (tensor(5.5340, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.3813  (0.2941956933663814)\n",
      "     | > loader_time: 0.003  (0.004691075305549466)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:22:23 -- STEP: 123/406 -- GLOBAL_STEP: 17175\u001b[0m\n",
      "     | > loss: 0.05932989716529846  (0.04551227887471517)\n",
      "     | > log_mle: -0.2155437469482422  (-0.19934169354477552)\n",
      "     | > loss_dur: 0.27487364411354065  (0.24485397241949067)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.0489, device='cuda:0')  (tensor(6.8839, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.3253  (0.30613167499139055)\n",
      "     | > loader_time: 0.003  (0.004364141603795494)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:22:33 -- STEP: 148/406 -- GLOBAL_STEP: 17200\u001b[0m\n",
      "     | > loss: 0.04740113019943237  (0.04584075037289311)\n",
      "     | > log_mle: -0.21978998184204102  (-0.2015570329653251)\n",
      "     | > loss_dur: 0.2671911120414734  (0.24739778333821813)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.2140, device='cuda:0')  (tensor(7.4684, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.3503  (0.3171799585625932)\n",
      "     | > loader_time: 0.004  (0.004188229908814303)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:22:43 -- STEP: 173/406 -- GLOBAL_STEP: 17225\u001b[0m\n",
      "     | > loss: 0.05862456560134888  (0.04603587530251874)\n",
      "     | > log_mle: -0.2103055715560913  (-0.20319950580596932)\n",
      "     | > loss_dur: 0.2689301371574402  (0.24923538110848797)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.1499, device='cuda:0')  (tensor(7.6927, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.3693  (0.3286106048980889)\n",
      "     | > loader_time: 0.003  (0.00410366885234855)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:22:54 -- STEP: 198/406 -- GLOBAL_STEP: 17250\u001b[0m\n",
      "     | > loss: 0.030227914452552795  (0.045816867490007435)\n",
      "     | > log_mle: -0.2172412872314453  (-0.20485662872141064)\n",
      "     | > loss_dur: 0.2474692016839981  (0.25067349621141793)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.5329, device='cuda:0')  (tensor(7.8592, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.3914  (0.34100670766348784)\n",
      "     | > loader_time: 0.003  (0.0040505751214846225)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:23:05 -- STEP: 223/406 -- GLOBAL_STEP: 17275\u001b[0m\n",
      "     | > loss: 0.05167582631111145  (0.04592912687581752)\n",
      "     | > log_mle: -0.2140030860900879  (-0.20628374467516167)\n",
      "     | > loss_dur: 0.26567891240119934  (0.2522128715509791)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7688, device='cuda:0')  (tensor(7.9863, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.3974  (0.3515614896611782)\n",
      "     | > loader_time: 0.004  (0.004063227786076978)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:23:17 -- STEP: 248/406 -- GLOBAL_STEP: 17300\u001b[0m\n",
      "     | > loss: 0.034234046936035156  (0.0460519796657947)\n",
      "     | > log_mle: -0.2156202793121338  (-0.2075916182610297)\n",
      "     | > loss_dur: 0.24985432624816895  (0.2536435979268242)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(19.7265, device='cuda:0')  (tensor(8.9392, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.5285  (0.36344707396722603)\n",
      "     | > loader_time: 0.004  (0.004053142762953234)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:23:29 -- STEP: 273/406 -- GLOBAL_STEP: 17325\u001b[0m\n",
      "     | > loss: 0.02874290943145752  (0.04549594398164926)\n",
      "     | > log_mle: -0.22724533081054688  (-0.20885015014327057)\n",
      "     | > loss_dur: 0.2559882402420044  (0.2543460941249196)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.4478, device='cuda:0')  (tensor(9.2298, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.4344  (0.3748496286161652)\n",
      "     | > loader_time: 0.004  (0.004081607301593262)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:23:42 -- STEP: 298/406 -- GLOBAL_STEP: 17350\u001b[0m\n",
      "     | > loss: 0.04923787713050842  (0.045509073808289224)\n",
      "     | > log_mle: -0.20870065689086914  (-0.20973628639374808)\n",
      "     | > loss_dur: 0.25793853402137756  (0.25524536020203703)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3003, device='cuda:0')  (tensor(9.3699, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.6045  (0.3858665083878791)\n",
      "     | > loader_time: 0.004  (0.0041220924198227425)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:23:56 -- STEP: 323/406 -- GLOBAL_STEP: 17375\u001b[0m\n",
      "     | > loss: 0.041356027126312256  (0.045426926515050724)\n",
      "     | > log_mle: -0.22526216506958008  (-0.21068945905372455)\n",
      "     | > loss_dur: 0.26661819219589233  (0.256116385568775)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.1947, device='cuda:0')  (tensor(9.1628, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.4764  (0.3984881613645759)\n",
      "     | > loader_time: 0.005  (0.004171817295322475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:24:10 -- STEP: 348/406 -- GLOBAL_STEP: 17400\u001b[0m\n",
      "     | > loss: 0.050659745931625366  (0.04568120100717436)\n",
      "     | > log_mle: -0.21487891674041748  (-0.21153063301382394)\n",
      "     | > loss_dur: 0.26553866267204285  (0.2572118340209981)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.9979, device='cuda:0')  (tensor(9.0912, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.6636  (0.4097824315915161)\n",
      "     | > loader_time: 0.005  (0.004205755803776884)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:24:24 -- STEP: 373/406 -- GLOBAL_STEP: 17425\u001b[0m\n",
      "     | > loss: 0.023931413888931274  (0.045467273639290345)\n",
      "     | > log_mle: -0.22757601737976074  (-0.21248601333065903)\n",
      "     | > loss_dur: 0.251507431268692  (0.2579532869699492)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(16.8607, device='cuda:0')  (tensor(9.2455, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.5485  (0.42046972765679635)\n",
      "     | > loader_time: 0.006  (0.00426733014411006)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:24:40 -- STEP: 398/406 -- GLOBAL_STEP: 17450\u001b[0m\n",
      "     | > loss: 0.0357130765914917  (0.045180960740875374)\n",
      "     | > log_mle: -0.23177063465118408  (-0.21336932008589932)\n",
      "     | > loss_dur: 0.2674837112426758  (0.2585502808267746)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.9683, device='cuda:0')  (tensor(9.3871, device='cuda:0'))\n",
      "     | > current_lr: 1.05e-05 \n",
      "     | > step_time: 0.7256  (0.4338433754504025)\n",
      "     | > loader_time: 0.004  (0.004316141856974694)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08954963088035583 \u001b[0m(-0.00687021017074585)\n",
      "     | > avg_loss:\u001b[92m 0.011577365919947624 \u001b[0m(-0.010276082903146744)\n",
      "     | > avg_log_mle:\u001b[92m -0.2284374237060547 \u001b[0m(-0.006374046206474304)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2400147896260023 \u001b[0m(-0.0039020366966724396)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_17458.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 43/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:25:16) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:25:36 -- STEP: 17/406 -- GLOBAL_STEP: 17475\u001b[0m\n",
      "     | > loss: 0.02752549946308136  (0.019201665240175584)\n",
      "     | > log_mle: -0.19405245780944824  (-0.19609051592209759)\n",
      "     | > loss_dur: 0.2215779572725296  (0.2152921811622732)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(1.8563, device='cuda:0')  (tensor(4.2181, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.2592  (0.2574691772460937)\n",
      "     | > loader_time: 0.002  (0.010832954855526196)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:25:43 -- STEP: 42/406 -- GLOBAL_STEP: 17500\u001b[0m\n",
      "     | > loss: 0.038996219635009766  (0.03305749701602118)\n",
      "     | > log_mle: -0.20263099670410156  (-0.1943620244661967)\n",
      "     | > loss_dur: 0.24162721633911133  (0.2274195214822179)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(3.3663, device='cuda:0')  (tensor(4.5784, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.2943  (0.2643354336420695)\n",
      "     | > loader_time: 0.003  (0.00567166010538737)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:25:50 -- STEP: 67/406 -- GLOBAL_STEP: 17525\u001b[0m\n",
      "     | > loss: 0.044197916984558105  (0.036295735124331804)\n",
      "     | > log_mle: -0.2109208106994629  (-0.19705701763950176)\n",
      "     | > loss_dur: 0.255118727684021  (0.23335275276383358)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.6228, device='cuda:0')  (tensor(5.1668, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.3373  (0.27749091831605827)\n",
      "     | > loader_time: 0.002  (0.004511431081971126)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:25:59 -- STEP: 92/406 -- GLOBAL_STEP: 17550\u001b[0m\n",
      "     | > loss: 0.0430680513381958  (0.036892633399237755)\n",
      "     | > log_mle: -0.22082912921905518  (-0.20027843765590503)\n",
      "     | > loss_dur: 0.263897180557251  (0.23717107105514276)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.1748, device='cuda:0')  (tensor(7.1823, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.3593  (0.2908403303312218)\n",
      "     | > loader_time: 0.003  (0.004036128520965575)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:26:08 -- STEP: 117/406 -- GLOBAL_STEP: 17575\u001b[0m\n",
      "     | > loss: 0.04779168963432312  (0.037014906605084746)\n",
      "     | > log_mle: -0.21350789070129395  (-0.20299728100116438)\n",
      "     | > loss_dur: 0.26129958033561707  (0.2400121876062491)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.1659, device='cuda:0')  (tensor(8.1830, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.3934  (0.30356632949959533)\n",
      "     | > loader_time: 0.004  (0.0038837469541109517)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:26:17 -- STEP: 142/406 -- GLOBAL_STEP: 17600\u001b[0m\n",
      "     | > loss: 0.03826284408569336  (0.03756423399481977)\n",
      "     | > log_mle: -0.22127985954284668  (-0.20537802283193024)\n",
      "     | > loss_dur: 0.25954270362854004  (0.24294225682675)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7251, device='cuda:0')  (tensor(8.1219, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.3343  (0.31484230639229366)\n",
      "     | > loader_time: 0.004  (0.0038061645668996886)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:26:27 -- STEP: 167/406 -- GLOBAL_STEP: 17625\u001b[0m\n",
      "     | > loss: 0.03404119610786438  (0.038011325333646685)\n",
      "     | > log_mle: -0.220184326171875  (-0.20703941333793593)\n",
      "     | > loss_dur: 0.2542255222797394  (0.2450507386715826)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.8239, device='cuda:0')  (tensor(7.9456, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.3583  (0.325900778799)\n",
      "     | > loader_time: 0.004  (0.0037817840804596856)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:26:37 -- STEP: 192/406 -- GLOBAL_STEP: 17650\u001b[0m\n",
      "     | > loss: 0.02748417854309082  (0.03789166469747821)\n",
      "     | > log_mle: -0.22031843662261963  (-0.208714684471488)\n",
      "     | > loss_dur: 0.24780261516571045  (0.2466063491689662)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.1934, device='cuda:0')  (tensor(8.2897, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.3874  (0.33789538467923813)\n",
      "     | > loader_time: 0.004  (0.0037950351834297176)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:26:48 -- STEP: 217/406 -- GLOBAL_STEP: 17675\u001b[0m\n",
      "     | > loss: 0.04669320583343506  (0.037948579626149295)\n",
      "     | > log_mle: -0.2209862470626831  (-0.2100518886944116)\n",
      "     | > loss_dur: 0.26767945289611816  (0.24800046832056089)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.0983, device='cuda:0')  (tensor(8.4558, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.4054  (0.34907271016028635)\n",
      "     | > loader_time: 0.004  (0.003805252813523815)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:27:00 -- STEP: 242/406 -- GLOBAL_STEP: 17700\u001b[0m\n",
      "     | > loss: 0.02905169129371643  (0.03817843251730785)\n",
      "     | > log_mle: -0.23934447765350342  (-0.21153582669486684)\n",
      "     | > loss_dur: 0.26839616894721985  (0.2497142592121747)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(15.5671, device='cuda:0')  (tensor(8.7236, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.5405  (0.3598680535623851)\n",
      "     | > loader_time: 0.004  (0.003838152924845041)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:27:12 -- STEP: 267/406 -- GLOBAL_STEP: 17725\u001b[0m\n",
      "     | > loss: 0.0434393584728241  (0.038156604387340476)\n",
      "     | > log_mle: -0.2258213758468628  (-0.2126551473631841)\n",
      "     | > loss_dur: 0.2692607343196869  (0.2508117517505246)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(12.7783, device='cuda:0')  (tensor(8.7756, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.4274  (0.3721066164166741)\n",
      "     | > loader_time: 0.005  (0.003883634167217583)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:27:25 -- STEP: 292/406 -- GLOBAL_STEP: 17750\u001b[0m\n",
      "     | > loss: 0.05708998441696167  (0.03784712194784046)\n",
      "     | > log_mle: -0.22106146812438965  (-0.21367250199187293)\n",
      "     | > loss_dur: 0.2781514525413513  (0.2515196239397132)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2673, device='cuda:0')  (tensor(8.8858, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.5675  (0.3830371009160396)\n",
      "     | > loader_time: 0.005  (0.003928142051174216)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:27:39 -- STEP: 317/406 -- GLOBAL_STEP: 17775\u001b[0m\n",
      "     | > loss: 0.05620306730270386  (0.03796354918637862)\n",
      "     | > log_mle: -0.21893393993377686  (-0.21462672328347288)\n",
      "     | > loss_dur: 0.2751370072364807  (0.2525902724698513)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1505, device='cuda:0')  (tensor(9.2489, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.5075  (0.39527462559167553)\n",
      "     | > loader_time: 0.005  (0.003987739514853301)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:27:53 -- STEP: 342/406 -- GLOBAL_STEP: 17800\u001b[0m\n",
      "     | > loss: 0.03785771131515503  (0.038329432364444284)\n",
      "     | > log_mle: -0.23012757301330566  (-0.21541823141756114)\n",
      "     | > loss_dur: 0.2679852843284607  (0.2537476637820052)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.8627, device='cuda:0')  (tensor(9.4201, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.6476  (0.4068702682417042)\n",
      "     | > loader_time: 0.005  (0.0040620558443125255)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:28:07 -- STEP: 367/406 -- GLOBAL_STEP: 17825\u001b[0m\n",
      "     | > loss: 0.03973984718322754  (0.03821081349407943)\n",
      "     | > log_mle: -0.22433745861053467  (-0.2163404265281615)\n",
      "     | > loss_dur: 0.2640773057937622  (0.25455124002224067)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.9107, device='cuda:0')  (tensor(9.4944, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.6496  (0.41859612802718604)\n",
      "     | > loader_time: 0.006  (0.004128973230678967)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:28:23 -- STEP: 392/406 -- GLOBAL_STEP: 17850\u001b[0m\n",
      "     | > loss: 0.03661906719207764  (0.038132699130445105)\n",
      "     | > log_mle: -0.22865235805511475  (-0.21714537362663114)\n",
      "     | > loss_dur: 0.2652714252471924  (0.2552780727570759)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.4775, device='cuda:0')  (tensor(9.6742, device='cuda:0'))\n",
      "     | > current_lr: 1.075e-05 \n",
      "     | > step_time: 0.5645  (0.43110135562565893)\n",
      "     | > loader_time: 0.005  (0.004182258430792366)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09590494632720947 \u001b[0m(+0.006355315446853638)\n",
      "     | > avg_loss:\u001b[92m 0.0031199343502521515 \u001b[0m(-0.008457431569695473)\n",
      "     | > avg_log_mle:\u001b[92m -0.23498275876045227 \u001b[0m(-0.006545335054397583)\n",
      "     | > avg_loss_dur:\u001b[92m 0.23810269311070442 \u001b[0m(-0.0019120965152978897)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_17864.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 44/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:29:02) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:29:21 -- STEP: 11/406 -- GLOBAL_STEP: 17875\u001b[0m\n",
      "     | > loss: -0.029579252004623413  (0.014150133187120611)\n",
      "     | > log_mle: -0.19977307319641113  (-0.19764097170396286)\n",
      "     | > loss_dur: 0.17019382119178772  (0.21179110489108346)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.8550, device='cuda:0')  (tensor(4.0185, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.2562  (0.25595931573347613)\n",
      "     | > loader_time: 0.002  (0.0232030911879106)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:29:28 -- STEP: 36/406 -- GLOBAL_STEP: 17900\u001b[0m\n",
      "     | > loss: 0.04387393593788147  (0.02379032969474792)\n",
      "     | > log_mle: -0.19250965118408203  (-0.19857029451264274)\n",
      "     | > loss_dur: 0.2363835871219635  (0.22236062420739067)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(2.5400, device='cuda:0')  (tensor(3.5950, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.2883  (0.26246052318149143)\n",
      "     | > loader_time: 0.002  (0.00859114196565416)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:29:35 -- STEP: 61/406 -- GLOBAL_STEP: 17925\u001b[0m\n",
      "     | > loss: 0.049312442541122437  (0.02899211913835807)\n",
      "     | > log_mle: -0.20569396018981934  (-0.20014103905099337)\n",
      "     | > loss_dur: 0.2550064027309418  (0.22913315818935145)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.0379, device='cuda:0')  (tensor(6.5668, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.2913  (0.27572552493361174)\n",
      "     | > loader_time: 0.003  (0.0060383960848949)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:29:43 -- STEP: 86/406 -- GLOBAL_STEP: 17950\u001b[0m\n",
      "     | > loss: 0.045792222023010254  (0.030253536132879035)\n",
      "     | > log_mle: -0.20443594455718994  (-0.20279687920282058)\n",
      "     | > loss_dur: 0.2502281665802002  (0.23305041533569956)\n",
      "     | > amp_scaler: 8192.0  (15907.720930232557)\n",
      "     | > grad_norm: tensor(17.3313, device='cuda:0')  (tensor(8.4618, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.3593  (0.28837801966556276)\n",
      "     | > loader_time: 0.003  (0.005155851674634358)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:29:52 -- STEP: 111/406 -- GLOBAL_STEP: 17975\u001b[0m\n",
      "     | > loss: 0.01680511236190796  (0.03021285904420389)\n",
      "     | > log_mle: -0.2295151948928833  (-0.2057856213939083)\n",
      "     | > loss_dur: 0.24632030725479126  (0.23599848043811214)\n",
      "     | > amp_scaler: 8192.0  (14169.945945945947)\n",
      "     | > grad_norm: tensor(16.2670, device='cuda:0')  (tensor(10.0960, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.3363  (0.30078651453997624)\n",
      "     | > loader_time: 0.003  (0.004670940003953541)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:30:01 -- STEP: 136/406 -- GLOBAL_STEP: 18000\u001b[0m\n",
      "     | > loss: 0.045832037925720215  (0.030580798821414217)\n",
      "     | > log_mle: -0.22378814220428467  (-0.20817739297361937)\n",
      "     | > loss_dur: 0.2696201801300049  (0.23875819179503358)\n",
      "     | > amp_scaler: 8192.0  (13071.058823529413)\n",
      "     | > grad_norm: tensor(13.6689, device='cuda:0')  (tensor(10.6284, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.4184  (0.3125777665306539)\n",
      "     | > loader_time: 0.003  (0.004415871465907379)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_18000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:30:15 -- STEP: 161/406 -- GLOBAL_STEP: 18025\u001b[0m\n",
      "     | > loss: 0.052628934383392334  (0.03142340953305641)\n",
      "     | > log_mle: -0.20777273178100586  (-0.209746785785841)\n",
      "     | > loss_dur: 0.2604016661643982  (0.24117019531889733)\n",
      "     | > amp_scaler: 8192.0  (12313.440993788818)\n",
      "     | > grad_norm: tensor(14.1584, device='cuda:0')  (tensor(10.9044, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.3473  (0.324232116249037)\n",
      "     | > loader_time: 0.004  (0.004295928137642998)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:30:25 -- STEP: 186/406 -- GLOBAL_STEP: 18050\u001b[0m\n",
      "     | > loss: 0.031004101037979126  (0.031625625026482425)\n",
      "     | > log_mle: -0.22873735427856445  (-0.21152593371688685)\n",
      "     | > loss_dur: 0.2597414553165436  (0.2431515587433692)\n",
      "     | > amp_scaler: 8192.0  (11759.483870967742)\n",
      "     | > grad_norm: tensor(15.8236, device='cuda:0')  (tensor(11.0041, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.4714  (0.3374649375997562)\n",
      "     | > loader_time: 0.003  (0.0042028542487852075)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:30:36 -- STEP: 211/406 -- GLOBAL_STEP: 18075\u001b[0m\n",
      "     | > loss: 0.01840674877166748  (0.031760357002511425)\n",
      "     | > log_mle: -0.23741602897644043  (-0.21288065266270215)\n",
      "     | > loss_dur: 0.2558227777481079  (0.2446410096652135)\n",
      "     | > amp_scaler: 8192.0  (11336.796208530806)\n",
      "     | > grad_norm: tensor(18.7405, device='cuda:0')  (tensor(11.5542, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.4844  (0.3484655782509752)\n",
      "     | > loader_time: 0.004  (0.004165042633128962)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:30:48 -- STEP: 236/406 -- GLOBAL_STEP: 18100\u001b[0m\n",
      "     | > loss: 0.041640251874923706  (0.032052933222661624)\n",
      "     | > log_mle: -0.21342170238494873  (-0.21431412838273134)\n",
      "     | > loss_dur: 0.25506195425987244  (0.24636706160539287)\n",
      "     | > amp_scaler: 8192.0  (11003.661016949152)\n",
      "     | > grad_norm: tensor(6.1426, device='cuda:0')  (tensor(11.6407, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.4164  (0.35808983899779223)\n",
      "     | > loader_time: 0.004  (0.004152217153775495)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:31:00 -- STEP: 261/406 -- GLOBAL_STEP: 18125\u001b[0m\n",
      "     | > loss: 0.027851909399032593  (0.032067986512092826)\n",
      "     | > log_mle: -0.22585737705230713  (-0.21563023488640334)\n",
      "     | > loss_dur: 0.2537092864513397  (0.2476982213984961)\n",
      "     | > amp_scaler: 8192.0  (10734.344827586207)\n",
      "     | > grad_norm: tensor(11.7952, device='cuda:0')  (tensor(11.7998, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.4394  (0.37089024741074117)\n",
      "     | > loader_time: 0.005  (0.004168682171467168)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:31:12 -- STEP: 286/406 -- GLOBAL_STEP: 18150\u001b[0m\n",
      "     | > loss: 0.022366881370544434  (0.0318373254650123)\n",
      "     | > log_mle: -0.23034262657165527  (-0.21669527867457258)\n",
      "     | > loss_dur: 0.2527095079421997  (0.24853260413958475)\n",
      "     | > amp_scaler: 8192.0  (10512.111888111887)\n",
      "     | > grad_norm: tensor(6.3042, device='cuda:0')  (tensor(11.9855, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.4574  (0.38139686551127383)\n",
      "     | > loader_time: 0.004  (0.004203252859048914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:31:26 -- STEP: 311/406 -- GLOBAL_STEP: 18175\u001b[0m\n",
      "     | > loss: 0.02138689160346985  (0.031934963209836076)\n",
      "     | > log_mle: -0.23500168323516846  (-0.21762899417202572)\n",
      "     | > loss_dur: 0.2563885748386383  (0.24956395738186177)\n",
      "     | > amp_scaler: 8192.0  (10325.607717041798)\n",
      "     | > grad_norm: tensor(10.7801, device='cuda:0')  (tensor(11.6755, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.4674  (0.3936257738009143)\n",
      "     | > loader_time: 0.004  (0.004238683694428573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:31:40 -- STEP: 336/406 -- GLOBAL_STEP: 18200\u001b[0m\n",
      "     | > loss: 0.052144646644592285  (0.03237477437193906)\n",
      "     | > log_mle: -0.21930086612701416  (-0.21838756721644176)\n",
      "     | > loss_dur: 0.27144551277160645  (0.2507623415883807)\n",
      "     | > amp_scaler: 8192.0  (10166.857142857145)\n",
      "     | > grad_norm: tensor(10.5012, device='cuda:0')  (tensor(11.4846, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.6486  (0.4046157939093454)\n",
      "     | > loader_time: 0.005  (0.004280741725649158)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:31:54 -- STEP: 361/406 -- GLOBAL_STEP: 18225\u001b[0m\n",
      "     | > loss: 0.04652649164199829  (0.03231884811558555)\n",
      "     | > log_mle: -0.2256307601928711  (-0.21931897636265635)\n",
      "     | > loss_dur: 0.2721572518348694  (0.25163782447824173)\n",
      "     | > amp_scaler: 8192.0  (10030.094182825487)\n",
      "     | > grad_norm: tensor(10.7341, device='cuda:0')  (tensor(11.4621, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.6696  (0.41609378732802793)\n",
      "     | > loader_time: 0.005  (0.00433084575093024)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:32:09 -- STEP: 386/406 -- GLOBAL_STEP: 18250\u001b[0m\n",
      "     | > loss: 0.037132978439331055  (0.03219549222776929)\n",
      "     | > log_mle: -0.23165297508239746  (-0.22017305440853296)\n",
      "     | > loss_dur: 0.2687859535217285  (0.25236854663630204)\n",
      "     | > amp_scaler: 8192.0  (9911.04663212435)\n",
      "     | > grad_norm: tensor(7.7473, device='cuda:0')  (tensor(11.4421, device='cuda:0'))\n",
      "     | > current_lr: 1.1e-05 \n",
      "     | > step_time: 0.6986  (0.42861060280873986)\n",
      "     | > loader_time: 0.005  (0.0043926164893906385)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08733421564102173 \u001b[0m(-0.008570730686187744)\n",
      "     | > avg_loss:\u001b[92m 0.0030140429735183716 \u001b[0m(-0.00010589137673377991)\n",
      "     | > avg_log_mle:\u001b[91m -0.2314329743385315 \u001b[0m(+0.0035497844219207764)\n",
      "     | > avg_loss_dur:\u001b[92m 0.23444701731204987 \u001b[0m(-0.0036556757986545563)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_18270.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 45/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:32:53) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:33:10 -- STEP: 5/406 -- GLOBAL_STEP: 18275\u001b[0m\n",
      "     | > loss: 0.03183981776237488  (0.009802734851837159)\n",
      "     | > log_mle: -0.19150066375732422  (-0.20009136199951172)\n",
      "     | > loss_dur: 0.2233404815196991  (0.20989409685134888)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(1.9662, device='cuda:0')  (tensor(2.5492, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.2462  (0.2570329189300537)\n",
      "     | > loader_time: 0.002  (0.04404020309448242)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:33:17 -- STEP: 30/406 -- GLOBAL_STEP: 18300\u001b[0m\n",
      "     | > loss: 0.005365774035453796  (0.014821147918701172)\n",
      "     | > log_mle: -0.20751094818115234  (-0.20237433115641276)\n",
      "     | > loss_dur: 0.21287672221660614  (0.21719547907511394)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.3935, device='cuda:0')  (tensor(5.2216, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.2582  (0.2602697372436523)\n",
      "     | > loader_time: 0.003  (0.009041277567545573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:33:24 -- STEP: 55/406 -- GLOBAL_STEP: 18325\u001b[0m\n",
      "     | > loss: 0.0204075425863266  (0.02017529850656336)\n",
      "     | > log_mle: -0.2164607048034668  (-0.20340378934686834)\n",
      "     | > loss_dur: 0.2368682473897934  (0.2235790878534317)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.8029, device='cuda:0')  (tensor(5.5155, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.2763  (0.2713009704243054)\n",
      "     | > loader_time: 0.003  (0.005987028642134233)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:33:32 -- STEP: 80/406 -- GLOBAL_STEP: 18350\u001b[0m\n",
      "     | > loss: 0.04875226318836212  (0.02291982956230641)\n",
      "     | > log_mle: -0.201149582862854  (-0.20579085797071456)\n",
      "     | > loss_dur: 0.24990184605121613  (0.22871068753302098)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.6677, device='cuda:0')  (tensor(6.2637, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.2963  (0.2844208419322968)\n",
      "     | > loader_time: 0.003  (0.0050168603658676154)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:33:41 -- STEP: 105/406 -- GLOBAL_STEP: 18375\u001b[0m\n",
      "     | > loss: 0.024294763803482056  (0.023554556142716183)\n",
      "     | > log_mle: -0.21071195602416992  (-0.20897163095928373)\n",
      "     | > loss_dur: 0.23500671982765198  (0.23252618710199993)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.1536, device='cuda:0')  (tensor(7.6249, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.3163  (0.2974607808249338)\n",
      "     | > loader_time: 0.003  (0.004537312189737957)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:33:50 -- STEP: 130/406 -- GLOBAL_STEP: 18400\u001b[0m\n",
      "     | > loss: 0.008129969239234924  (0.023356472185024853)\n",
      "     | > log_mle: -0.22494447231292725  (-0.211545664530534)\n",
      "     | > loss_dur: 0.23307444155216217  (0.23490213671555885)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.1648, device='cuda:0')  (tensor(8.3768, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.3303  (0.309481114607591)\n",
      "     | > loader_time: 0.003  (0.004280746900118315)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:33:59 -- STEP: 155/406 -- GLOBAL_STEP: 18425\u001b[0m\n",
      "     | > loss: 0.037668853998184204  (0.02397866143334297)\n",
      "     | > log_mle: -0.21626508235931396  (-0.21347778535658318)\n",
      "     | > loss_dur: 0.25393393635749817  (0.23745644678992608)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.0968, device='cuda:0')  (tensor(8.2601, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.3573  (0.3207300232302759)\n",
      "     | > loader_time: 0.004  (0.004145631482524257)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:34:10 -- STEP: 180/406 -- GLOBAL_STEP: 18450\u001b[0m\n",
      "     | > loss: 0.025499612092971802  (0.024268963105148738)\n",
      "     | > log_mle: -0.2288278341293335  (-0.2151600387361315)\n",
      "     | > loss_dur: 0.2543274462223053  (0.2394290018412802)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.0864, device='cuda:0')  (tensor(8.5877, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.4674  (0.3325798961851334)\n",
      "     | > loader_time: 0.004  (0.004070242245992026)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:34:21 -- STEP: 205/406 -- GLOBAL_STEP: 18475\u001b[0m\n",
      "     | > loss: 0.02544298768043518  (0.02477243135615093)\n",
      "     | > log_mle: -0.238287091255188  (-0.21668612957000735)\n",
      "     | > loss_dur: 0.26373007893562317  (0.24145856092615825)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.6086, device='cuda:0')  (tensor(9.0464, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.4914  (0.34417116583847446)\n",
      "     | > loader_time: 0.004  (0.004057215481269652)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:34:32 -- STEP: 230/406 -- GLOBAL_STEP: 18500\u001b[0m\n",
      "     | > loss: 0.028413861989974976  (0.024760868108790853)\n",
      "     | > log_mle: -0.23067986965179443  (-0.2181428194046021)\n",
      "     | > loss_dur: 0.2590937316417694  (0.2429036875133929)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.1741, device='cuda:0')  (tensor(9.6084, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.4054  (0.3542391849600753)\n",
      "     | > loader_time: 0.004  (0.004055688692175825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:34:44 -- STEP: 255/406 -- GLOBAL_STEP: 18525\u001b[0m\n",
      "     | > loss: 0.02251341938972473  (0.024944615539382486)\n",
      "     | > log_mle: -0.22770869731903076  (-0.21953083674112958)\n",
      "     | > loss_dur: 0.2502221167087555  (0.24447545228051204)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.4155, device='cuda:0')  (tensor(10.0162, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.4324  (0.36663107685014334)\n",
      "     | > loader_time: 0.005  (0.004066260655721028)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:34:56 -- STEP: 280/406 -- GLOBAL_STEP: 18550\u001b[0m\n",
      "     | > loss: 0.017752379179000854  (0.02450431436300278)\n",
      "     | > log_mle: -0.2391742467880249  (-0.22066350621836528)\n",
      "     | > loss_dur: 0.25692662596702576  (0.24516782058136805)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.4580, device='cuda:0')  (tensor(10.1854, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.4524  (0.37813632403101266)\n",
      "     | > loader_time: 0.005  (0.004121423619134086)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:35:10 -- STEP: 305/406 -- GLOBAL_STEP: 18575\u001b[0m\n",
      "     | > loss: 0.031853318214416504  (0.024494936475988296)\n",
      "     | > log_mle: -0.23020386695861816  (-0.2217031877548968)\n",
      "     | > loss_dur: 0.26205718517303467  (0.2461981242308851)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.9760, device='cuda:0')  (tensor(10.3632, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.4774  (0.389832789780664)\n",
      "     | > loader_time: 0.004  (0.004167533311687534)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:35:23 -- STEP: 330/406 -- GLOBAL_STEP: 18600\u001b[0m\n",
      "     | > loss: 0.04008054733276367  (0.02474823160604997)\n",
      "     | > log_mle: -0.241918683052063  (-0.2224938699693391)\n",
      "     | > loss_dur: 0.28199923038482666  (0.24724210157538906)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.5118, device='cuda:0')  (tensor(10.4044, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.4824  (0.40124597766182674)\n",
      "     | > loader_time: 0.005  (0.004227887500416149)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:35:38 -- STEP: 355/406 -- GLOBAL_STEP: 18625\u001b[0m\n",
      "     | > loss: 0.01014697551727295  (0.024964826123815186)\n",
      "     | > log_mle: -0.24082529544830322  (-0.2233657806691989)\n",
      "     | > loss_dur: 0.25097227096557617  (0.2483306067930141)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.5560, device='cuda:0')  (tensor(10.2836, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.5435  (0.4130425036793027)\n",
      "     | > loader_time: 0.005  (0.004268503860688544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:35:53 -- STEP: 380/406 -- GLOBAL_STEP: 18650\u001b[0m\n",
      "     | > loss: 0.021318823099136353  (0.024773006258826506)\n",
      "     | > log_mle: -0.234269380569458  (-0.22424598053881997)\n",
      "     | > loss_dur: 0.25558820366859436  (0.24901898679764647)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.3878, device='cuda:0')  (tensor(10.1775, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.6696  (0.42540094601480616)\n",
      "     | > loader_time: 0.005  (0.0043169335315102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:36:09 -- STEP: 405/406 -- GLOBAL_STEP: 18675\u001b[0m\n",
      "     | > loss: -0.008193418383598328  (0.024386774095488183)\n",
      "     | > log_mle: -0.23301982879638672  (-0.225052821489028)\n",
      "     | > loss_dur: 0.2248264104127884  (0.24943959558451617)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.4694, device='cuda:0')  (tensor(10.4287, device='cuda:0'))\n",
      "     | > current_lr: 1.125e-05 \n",
      "     | > step_time: 0.3071  (0.43815642757180323)\n",
      "     | > loader_time: 0.003  (0.0043667981654037635)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10526347160339355 \u001b[0m(+0.017929255962371826)\n",
      "     | > avg_loss:\u001b[92m -0.01005832850933075 \u001b[0m(-0.013072371482849121)\n",
      "     | > avg_log_mle:\u001b[92m -0.2409280240535736 \u001b[0m(-0.009495049715042114)\n",
      "     | > avg_loss_dur:\u001b[92m 0.23086969554424286 \u001b[0m(-0.003577321767807007)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_18676.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 46/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:36:41) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:37:03 -- STEP: 24/406 -- GLOBAL_STEP: 18700\u001b[0m\n",
      "     | > loss: 0.0031748414039611816  (0.003921277821063995)\n",
      "     | > log_mle: -0.21376919746398926  (-0.20629058281580606)\n",
      "     | > loss_dur: 0.21694403886795044  (0.21021186063687006)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.9146, device='cuda:0')  (tensor(3.5626, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.2602  (0.2590268651644388)\n",
      "     | > loader_time: 0.002  (0.010259290536244707)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:37:10 -- STEP: 49/406 -- GLOBAL_STEP: 18725\u001b[0m\n",
      "     | > loss: 0.03207564353942871  (0.012645735728497408)\n",
      "     | > log_mle: -0.20959079265594482  (-0.20635023895575075)\n",
      "     | > loss_dur: 0.24166643619537354  (0.21899597468424817)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.1200, device='cuda:0')  (tensor(5.0721, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.2773  (0.2694895364800278)\n",
      "     | > loader_time: 0.002  (0.006250624753990949)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:37:18 -- STEP: 74/406 -- GLOBAL_STEP: 18750\u001b[0m\n",
      "     | > loss: 0.02444520592689514  (0.014022237143001041)\n",
      "     | > log_mle: -0.2364567518234253  (-0.20974252836124316)\n",
      "     | > loss_dur: 0.26090195775032043  (0.2237647655042442)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.1983, device='cuda:0')  (tensor(6.1918, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.2933  (0.2818639826130223)\n",
      "     | > loader_time: 0.002  (0.0050045735127217045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:37:26 -- STEP: 99/406 -- GLOBAL_STEP: 18775\u001b[0m\n",
      "     | > loss: 0.03227695822715759  (0.015880321763982675)\n",
      "     | > log_mle: -0.2182004451751709  (-0.2123670650250984)\n",
      "     | > loss_dur: 0.2504774034023285  (0.22824738678908107)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.5612, device='cuda:0')  (tensor(7.4617, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.3083  (0.2948535355654632)\n",
      "     | > loader_time: 0.003  (0.004488925741176412)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:37:35 -- STEP: 124/406 -- GLOBAL_STEP: 18800\u001b[0m\n",
      "     | > loss: 0.033517271280288696  (0.01649572447903694)\n",
      "     | > log_mle: -0.2275562286376953  (-0.2149997353553772)\n",
      "     | > loss_dur: 0.261073499917984  (0.23149545983441414)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.4656, device='cuda:0')  (tensor(8.5488, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.4004  (0.30715783180729045)\n",
      "     | > loader_time: 0.003  (0.004229678261664604)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:37:44 -- STEP: 149/406 -- GLOBAL_STEP: 18825\u001b[0m\n",
      "     | > loss: 0.02137163281440735  (0.016720717885350216)\n",
      "     | > log_mle: -0.2342243194580078  (-0.21717489325760195)\n",
      "     | > loss_dur: 0.25559595227241516  (0.23389561114295218)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.3737, device='cuda:0')  (tensor(8.1513, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.4194  (0.3177313116572848)\n",
      "     | > loader_time: 0.004  (0.004117877691384129)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:37:54 -- STEP: 174/406 -- GLOBAL_STEP: 18850\u001b[0m\n",
      "     | > loss: 0.024917632341384888  (0.017272030313809708)\n",
      "     | > log_mle: -0.22371351718902588  (-0.218598406890343)\n",
      "     | > loss_dur: 0.24863114953041077  (0.23587043720415268)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.5921, device='cuda:0')  (tensor(8.6735, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.4424  (0.3291262977424712)\n",
      "     | > loader_time: 0.005  (0.004061182339986162)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:38:05 -- STEP: 199/406 -- GLOBAL_STEP: 18875\u001b[0m\n",
      "     | > loss: 0.04578131437301636  (0.01753764318760915)\n",
      "     | > log_mle: -0.22188341617584229  (-0.22018807737072507)\n",
      "     | > loss_dur: 0.26766473054885864  (0.23772572055833424)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.5017, device='cuda:0')  (tensor(9.0593, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.4834  (0.34179260862532584)\n",
      "     | > loader_time: 0.004  (0.0040288402806574345)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:38:16 -- STEP: 224/406 -- GLOBAL_STEP: 18900\u001b[0m\n",
      "     | > loss: 0.01105150580406189  (0.017601423431187865)\n",
      "     | > log_mle: -0.23007988929748535  (-0.22164629293339594)\n",
      "     | > loss_dur: 0.24113139510154724  (0.2392477163645838)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.5468, device='cuda:0')  (tensor(9.4161, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.4094  (0.3517612037914141)\n",
      "     | > loader_time: 0.004  (0.0040260340486253975)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:38:28 -- STEP: 249/406 -- GLOBAL_STEP: 18925\u001b[0m\n",
      "     | > loss: 0.025602608919143677  (0.01788626581310747)\n",
      "     | > log_mle: -0.22599339485168457  (-0.22295289154512338)\n",
      "     | > loss_dur: 0.25159600377082825  (0.24083915735823083)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.3280, device='cuda:0')  (tensor(9.6578, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.4184  (0.3636071749001623)\n",
      "     | > loader_time: 0.004  (0.004051931411865723)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:38:41 -- STEP: 274/406 -- GLOBAL_STEP: 18950\u001b[0m\n",
      "     | > loss: 0.018974751234054565  (0.017600845463954615)\n",
      "     | > log_mle: -0.2374434471130371  (-0.2242337378272175)\n",
      "     | > loss_dur: 0.2564181983470917  (0.2418345832911721)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.4362, device='cuda:0')  (tensor(9.8537, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.4504  (0.37515808195963396)\n",
      "     | > loader_time: 0.005  (0.00409133677935078)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:38:54 -- STEP: 299/406 -- GLOBAL_STEP: 18975\u001b[0m\n",
      "     | > loss: -0.005422741174697876  (0.017654387249197042)\n",
      "     | > log_mle: -0.2575579881668091  (-0.22516106522601584)\n",
      "     | > loss_dur: 0.2521352469921112  (0.24281545247521288)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.6415, device='cuda:0')  (tensor(10.0150, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.6035  (0.38664194014558845)\n",
      "     | > loader_time: 0.005  (0.004140912888440796)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:39:07 -- STEP: 324/406 -- GLOBAL_STEP: 19000\u001b[0m\n",
      "     | > loss: 0.005529150366783142  (0.01780544966459273)\n",
      "     | > log_mle: -0.23658740520477295  (-0.22599219687191058)\n",
      "     | > loss_dur: 0.2421165555715561  (0.24379764653650332)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.7187, device='cuda:0')  (tensor(10.2464, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.5035  (0.398247324390176)\n",
      "     | > loader_time: 0.005  (0.004185912049846881)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_19000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:39:26 -- STEP: 349/406 -- GLOBAL_STEP: 19025\u001b[0m\n",
      "     | > loss: 0.043340474367141724  (0.018127467109685626)\n",
      "     | > log_mle: -0.23395085334777832  (-0.22680430630899773)\n",
      "     | > loss_dur: 0.27729132771492004  (0.24493177341868339)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.5967, device='cuda:0')  (tensor(10.4257, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.5095  (0.41056831518353576)\n",
      "     | > loader_time: 0.005  (0.004253143567410439)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:39:41 -- STEP: 374/406 -- GLOBAL_STEP: 19050\u001b[0m\n",
      "     | > loss: 0.0019263625144958496  (0.017853036801764026)\n",
      "     | > log_mle: -0.2385563850402832  (-0.22774174060413543)\n",
      "     | > loss_dur: 0.24048274755477905  (0.24559477740589947)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.6842, device='cuda:0')  (tensor(10.6561, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.6936  (0.42218614644545294)\n",
      "     | > loader_time: 0.007  (0.004314063704587552)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:39:57 -- STEP: 399/406 -- GLOBAL_STEP: 19075\u001b[0m\n",
      "     | > loss: 0.03365302085876465  (0.0176703367466317)\n",
      "     | > log_mle: -0.23944342136383057  (-0.22858059256895444)\n",
      "     | > loss_dur: 0.2730964422225952  (0.24625092931558615)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.0370, device='cuda:0')  (tensor(10.7377, device='cuda:0'))\n",
      "     | > current_lr: 1.15e-05 \n",
      "     | > step_time: 0.5601  (0.435570486207355)\n",
      "     | > loader_time: 0.005  (0.0043924559925433045)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09583747386932373 \u001b[0m(-0.009425997734069824)\n",
      "     | > avg_loss:\u001b[91m -0.0057894568890333176 \u001b[0m(+0.004268871620297432)\n",
      "     | > avg_log_mle:\u001b[91m -0.23463180661201477 \u001b[0m(+0.006296217441558838)\n",
      "     | > avg_loss_dur:\u001b[92m 0.22884234972298145 \u001b[0m(-0.002027345821261406)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 47/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:40:32) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:40:52 -- STEP: 18/406 -- GLOBAL_STEP: 19100\u001b[0m\n",
      "     | > loss: 0.02268625795841217  (-0.003444335526890225)\n",
      "     | > log_mle: -0.20167791843414307  (-0.2105354732937283)\n",
      "     | > loss_dur: 0.22436417639255524  (0.20709113776683807)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.6486, device='cuda:0')  (tensor(6.6274, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.2592  (0.2551764514711168)\n",
      "     | > loader_time: 0.002  (0.014012588395012756)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:40:59 -- STEP: 43/406 -- GLOBAL_STEP: 19125\u001b[0m\n",
      "     | > loss: 0.012840136885643005  (0.008118000834487204)\n",
      "     | > log_mle: -0.2012852430343628  (-0.20866951277089674)\n",
      "     | > loss_dur: 0.2141253799200058  (0.21678751360538395)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.7105, device='cuda:0')  (tensor(7.9324, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.2983  (0.26412374474281486)\n",
      "     | > loader_time: 0.002  (0.007076119267663293)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:41:07 -- STEP: 68/406 -- GLOBAL_STEP: 19150\u001b[0m\n",
      "     | > loss: 0.014366194605827332  (0.01046464351170203)\n",
      "     | > log_mle: -0.22071993350982666  (-0.21116663077298337)\n",
      "     | > loss_dur: 0.235086128115654  (0.22163127428468535)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(3.6883, device='cuda:0')  (tensor(8.8647, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.2893  (0.2771341274766361)\n",
      "     | > loader_time: 0.002  (0.005431354045867922)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:41:15 -- STEP: 93/406 -- GLOBAL_STEP: 19175\u001b[0m\n",
      "     | > loss: 0.005832776427268982  (0.011061749631358728)\n",
      "     | > log_mle: -0.24277126789093018  (-0.21457337307673632)\n",
      "     | > loss_dur: 0.24860404431819916  (0.22563512270809502)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.2661, device='cuda:0')  (tensor(8.8356, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.3123  (0.2907479680994505)\n",
      "     | > loader_time: 0.003  (0.004713899345808134)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:41:24 -- STEP: 118/406 -- GLOBAL_STEP: 19200\u001b[0m\n",
      "     | > loss: 0.013108015060424805  (0.011217686963283407)\n",
      "     | > log_mle: -0.2276839017868042  (-0.2171989598516691)\n",
      "     | > loss_dur: 0.240791916847229  (0.22841664681495247)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.1627, device='cuda:0')  (tensor(9.4227, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.3223  (0.3027286731590659)\n",
      "     | > loader_time: 0.004  (0.004376821598764194)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:41:33 -- STEP: 143/406 -- GLOBAL_STEP: 19225\u001b[0m\n",
      "     | > loss: 0.009199738502502441  (0.011550104597231721)\n",
      "     | > log_mle: -0.23939204216003418  (-0.21977567339276932)\n",
      "     | > loss_dur: 0.24859178066253662  (0.23132577799000106)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.5559, device='cuda:0')  (tensor(9.5537, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.4224  (0.31467415402819227)\n",
      "     | > loader_time: 0.003  (0.004185611551458186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:41:43 -- STEP: 168/406 -- GLOBAL_STEP: 19250\u001b[0m\n",
      "     | > loss: 0.01091812551021576  (0.012103367508167312)\n",
      "     | > log_mle: -0.22278881072998047  (-0.22135876332010543)\n",
      "     | > loss_dur: 0.23370693624019623  (0.23346213082827272)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.9132, device='cuda:0')  (tensor(9.7713, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.3733  (0.32545351840200865)\n",
      "     | > loader_time: 0.003  (0.0040870096002306264)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:41:54 -- STEP: 193/406 -- GLOBAL_STEP: 19275\u001b[0m\n",
      "     | > loss: 0.01387566328048706  (0.012006780258114474)\n",
      "     | > log_mle: -0.24040722846984863  (-0.22315592036963744)\n",
      "     | > loss_dur: 0.2542828917503357  (0.2351627006277519)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.2176, device='cuda:0')  (tensor(10.1031, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.4694  (0.33796253352585226)\n",
      "     | > loader_time: 0.004  (0.00404509608609689)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:42:05 -- STEP: 218/406 -- GLOBAL_STEP: 19300\u001b[0m\n",
      "     | > loss: 0.011251524090766907  (0.012107690539928752)\n",
      "     | > log_mle: -0.23531365394592285  (-0.2245163299621792)\n",
      "     | > loss_dur: 0.24656517803668976  (0.23662402050210796)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.4428, device='cuda:0')  (tensor(10.3721, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.4094  (0.3488008549454015)\n",
      "     | > loader_time: 0.004  (0.004021978159563259)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:42:17 -- STEP: 243/406 -- GLOBAL_STEP: 19325\u001b[0m\n",
      "     | > loss: 0.012902677059173584  (0.012098922283070569)\n",
      "     | > log_mle: -0.2517486810684204  (-0.22607750755278663)\n",
      "     | > loss_dur: 0.264651358127594  (0.23817642983585718)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.6577, device='cuda:0')  (tensor(10.5508, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.5365  (0.3601427029189749)\n",
      "     | > loader_time: 0.004  (0.004036565866980533)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:42:29 -- STEP: 268/406 -- GLOBAL_STEP: 19350\u001b[0m\n",
      "     | > loss: 0.0045893192291259766  (0.011917684894444338)\n",
      "     | > log_mle: -0.24361884593963623  (-0.2271348607184282)\n",
      "     | > loss_dur: 0.2482081651687622  (0.23905254561287254)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.3156, device='cuda:0')  (tensor(10.6342, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.5445  (0.37246958622291904)\n",
      "     | > loader_time: 0.005  (0.0040633544993044736)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:42:42 -- STEP: 293/406 -- GLOBAL_STEP: 19375\u001b[0m\n",
      "     | > loss: 0.0005079060792922974  (0.011821446972088602)\n",
      "     | > log_mle: -0.2423309087753296  (-0.2281269010016536)\n",
      "     | > loss_dur: 0.2428388148546219  (0.23994834797374218)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(37.5021, device='cuda:0')  (tensor(11.0021, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.4754  (0.3830857504756784)\n",
      "     | > loader_time: 0.005  (0.0040958277601430846)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:42:55 -- STEP: 318/406 -- GLOBAL_STEP: 19400\u001b[0m\n",
      "     | > loss: 0.02354457974433899  (0.011843250185813546)\n",
      "     | > log_mle: -0.23688697814941406  (-0.22906692222979083)\n",
      "     | > loss_dur: 0.26043155789375305  (0.2409101724156044)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.3027, device='cuda:0')  (tensor(11.2981, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.4844  (0.3951602814332493)\n",
      "     | > loader_time: 0.005  (0.004145269124013074)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:43:09 -- STEP: 343/406 -- GLOBAL_STEP: 19425\u001b[0m\n",
      "     | > loss: 0.014138907194137573  (0.012165648640070992)\n",
      "     | > log_mle: -0.25094354152679443  (-0.22990470585948178)\n",
      "     | > loss_dur: 0.265082448720932  (0.24207035449955275)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.9277, device='cuda:0')  (tensor(11.3826, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.5065  (0.4066863358889654)\n",
      "     | > loader_time: 0.005  (0.0041933024937487896)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:43:24 -- STEP: 368/406 -- GLOBAL_STEP: 19450\u001b[0m\n",
      "     | > loss: -0.005500778555870056  (0.012012432896248674)\n",
      "     | > log_mle: -0.2503321170806885  (-0.23080681458763455)\n",
      "     | > loss_dur: 0.24483133852481842  (0.24281924748388323)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.6454, device='cuda:0')  (tensor(11.3239, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.5455  (0.41796284395715455)\n",
      "     | > loader_time: 0.005  (0.0042457049307615844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:43:40 -- STEP: 393/406 -- GLOBAL_STEP: 19475\u001b[0m\n",
      "     | > loss: 0.009963899850845337  (0.011966370406344953)\n",
      "     | > log_mle: -0.24180686473846436  (-0.23158576864625965)\n",
      "     | > loss_dur: 0.2517707645893097  (0.2435521390526046)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.6282, device='cuda:0')  (tensor(11.5454, device='cuda:0'))\n",
      "     | > current_lr: 1.1750000000000001e-05 \n",
      "     | > step_time: 0.6986  (0.4312864199242822)\n",
      "     | > loader_time: 0.005  (0.004293989589196123)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09496140480041504 \u001b[0m(-0.0008760690689086914)\n",
      "     | > avg_loss:\u001b[92m -0.024866580963134766 \u001b[0m(-0.019077124074101448)\n",
      "     | > avg_log_mle:\u001b[92m -0.2506111413240433 \u001b[0m(-0.015979334712028503)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2257445603609085 \u001b[0m(-0.0030977893620729446)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_19488.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 48/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:44:19) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:44:38 -- STEP: 12/406 -- GLOBAL_STEP: 19500\u001b[0m\n",
      "     | > loss: 0.0006428062915802002  (-0.017041256030400593)\n",
      "     | > log_mle: -0.2213956117630005  (-0.2136275370915731)\n",
      "     | > loss_dur: 0.2220384180545807  (0.19658628106117249)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.3407, device='cuda:0')  (tensor(4.4099, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.2512  (0.2563161651293437)\n",
      "     | > loader_time: 0.002  (0.019100606441497803)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:44:44 -- STEP: 37/406 -- GLOBAL_STEP: 19525\u001b[0m\n",
      "     | > loss: 0.012650102376937866  (-0.004535250164367057)\n",
      "     | > log_mle: -0.20766830444335938  (-0.21287650997574264)\n",
      "     | > loss_dur: 0.22031840682029724  (0.20834125981137558)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.2510, device='cuda:0')  (tensor(5.7923, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.2863  (0.26223817387142695)\n",
      "     | > loader_time: 0.002  (0.0076554788125527875)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:44:52 -- STEP: 62/406 -- GLOBAL_STEP: 19550\u001b[0m\n",
      "     | > loss: -0.008051946759223938  (0.0018086719416802934)\n",
      "     | > log_mle: -0.20593535900115967  (-0.2144859048628038)\n",
      "     | > loss_dur: 0.19788341224193573  (0.21629457680448408)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.1106, device='cuda:0')  (tensor(7.3077, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.3223  (0.27910830128577446)\n",
      "     | > loader_time: 0.002  (0.005521066727176789)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:45:00 -- STEP: 87/406 -- GLOBAL_STEP: 19575\u001b[0m\n",
      "     | > loss: -0.012735947966575623  (0.0033122813222052037)\n",
      "     | > log_mle: -0.24429059028625488  (-0.21790367844461025)\n",
      "     | > loss_dur: 0.23155464231967926  (0.22121595976681546)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.3843, device='cuda:0')  (tensor(7.5060, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.3053  (0.29052814944037086)\n",
      "     | > loader_time: 0.003  (0.004751408237150346)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:45:09 -- STEP: 112/406 -- GLOBAL_STEP: 19600\u001b[0m\n",
      "     | > loss: -0.010439485311508179  (0.0034457811021379064)\n",
      "     | > log_mle: -0.2409764528274536  (-0.22090356051921844)\n",
      "     | > loss_dur: 0.23053696751594543  (0.22434934162135636)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.4473, device='cuda:0')  (tensor(8.2711, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.3833  (0.3030161495719638)\n",
      "     | > loader_time: 0.003  (0.004370055028370448)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:45:18 -- STEP: 137/406 -- GLOBAL_STEP: 19625\u001b[0m\n",
      "     | > loss: 0.028898239135742188  (0.004442627521326942)\n",
      "     | > log_mle: -0.23198509216308594  (-0.22320597798284825)\n",
      "     | > loss_dur: 0.2608833312988281  (0.22764860550417518)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.4056, device='cuda:0')  (tensor(8.9970, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.3423  (0.3134962224612272)\n",
      "     | > loader_time: 0.004  (0.00419364358386854)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:45:28 -- STEP: 162/406 -- GLOBAL_STEP: 19650\u001b[0m\n",
      "     | > loss: 0.009714990854263306  (0.005097776191470066)\n",
      "     | > log_mle: -0.2521880865097046  (-0.22494837089821143)\n",
      "     | > loss_dur: 0.2619030773639679  (0.23004614708968152)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.0365, device='cuda:0')  (tensor(9.3271, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.4434  (0.3253446964570035)\n",
      "     | > loader_time: 0.004  (0.004114880973910105)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:45:38 -- STEP: 187/406 -- GLOBAL_STEP: 19675\u001b[0m\n",
      "     | > loss: -0.0003618299961090088  (0.005090657800914132)\n",
      "     | > log_mle: -0.23838603496551514  (-0.22668786609874053)\n",
      "     | > loss_dur: 0.23802420496940613  (0.23177852389965464)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.7228, device='cuda:0')  (tensor(9.7541, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.3743  (0.33689938254534885)\n",
      "     | > loader_time: 0.004  (0.004051830679337603)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:45:49 -- STEP: 212/406 -- GLOBAL_STEP: 19700\u001b[0m\n",
      "     | > loss: 0.013463109731674194  (0.005278075500479284)\n",
      "     | > log_mle: -0.2426912784576416  (-0.2281343475827631)\n",
      "     | > loss_dur: 0.2561543881893158  (0.2334124230832424)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.8816, device='cuda:0')  (tensor(10.0809, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.4004  (0.3477091474353142)\n",
      "     | > loader_time: 0.004  (0.004031958445063174)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:46:01 -- STEP: 237/406 -- GLOBAL_STEP: 19725\u001b[0m\n",
      "     | > loss: 0.007452636957168579  (0.005466056712569064)\n",
      "     | > log_mle: -0.24818086624145508  (-0.22957554949989803)\n",
      "     | > loss_dur: 0.25563350319862366  (0.23504160621246709)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.4652, device='cuda:0')  (tensor(10.5164, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.5377  (0.3578043315984026)\n",
      "     | > loader_time: 0.005  (0.004037380218505856)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:46:13 -- STEP: 262/406 -- GLOBAL_STEP: 19750\u001b[0m\n",
      "     | > loss: 0.009100571274757385  (0.005321771020197687)\n",
      "     | > log_mle: -0.23029029369354248  (-0.23085411268336173)\n",
      "     | > loss_dur: 0.23939086496829987  (0.2361758837035594)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.5231, device='cuda:0')  (tensor(10.7059, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.5425  (0.37025465947071107)\n",
      "     | > loader_time: 0.004  (0.004091462106195111)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:46:25 -- STEP: 287/406 -- GLOBAL_STEP: 19775\u001b[0m\n",
      "     | > loss: 0.05192303657531738  (0.005213336817894248)\n",
      "     | > log_mle: -0.2341291904449463  (-0.23195585099662222)\n",
      "     | > loss_dur: 0.28605222702026367  (0.23716918781451649)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.9331, device='cuda:0')  (tensor(11.0543, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.5655  (0.38076956014599966)\n",
      "     | > loader_time: 0.005  (0.004129139803843212)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:46:39 -- STEP: 312/406 -- GLOBAL_STEP: 19800\u001b[0m\n",
      "     | > loss: 0.01739749312400818  (0.005233857207573378)\n",
      "     | > log_mle: -0.2360771894454956  (-0.2328925526294953)\n",
      "     | > loss_dur: 0.2534746825695038  (0.23812640983706865)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.3807, device='cuda:0')  (tensor(11.1802, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.4934  (0.3926566533553297)\n",
      "     | > loader_time: 0.005  (0.004189635698611916)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:46:53 -- STEP: 337/406 -- GLOBAL_STEP: 19825\u001b[0m\n",
      "     | > loss: -0.009877979755401611  (0.005506056219958413)\n",
      "     | > log_mle: -0.25053703784942627  (-0.23369364604044385)\n",
      "     | > loss_dur: 0.24065905809402466  (0.23919970226040227)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.8178, device='cuda:0')  (tensor(11.3091, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.6376  (0.40407502403598883)\n",
      "     | > loader_time: 0.005  (0.004238191627253407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:47:07 -- STEP: 362/406 -- GLOBAL_STEP: 19850\u001b[0m\n",
      "     | > loss: 0.0018487274646759033  (0.005461508644878539)\n",
      "     | > log_mle: -0.25116586685180664  (-0.23457762319080078)\n",
      "     | > loss_dur: 0.25301459431648254  (0.24003913183567932)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.3651, device='cuda:0')  (tensor(11.4594, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.5485  (0.415210275360234)\n",
      "     | > loader_time: 0.005  (0.00429109907940606)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:47:22 -- STEP: 387/406 -- GLOBAL_STEP: 19875\u001b[0m\n",
      "     | > loss: 0.00868263840675354  (0.005301596312867889)\n",
      "     | > log_mle: -0.24626481533050537  (-0.2353873573224366)\n",
      "     | > loss_dur: 0.2549474537372589  (0.2406889536353045)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.8711, device='cuda:0')  (tensor(11.6505, device='cuda:0'))\n",
      "     | > current_lr: 1.2e-05 \n",
      "     | > step_time: 0.5475  (0.4278930644348304)\n",
      "     | > loader_time: 0.005  (0.004352694025951452)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09054157137870789 \u001b[0m(-0.004419833421707153)\n",
      "     | > avg_loss:\u001b[92m -0.0320171844214201 \u001b[0m(-0.007150603458285332)\n",
      "     | > avg_log_mle:\u001b[92m -0.25298216938972473 \u001b[0m(-0.0023710280656814575)\n",
      "     | > avg_loss_dur:\u001b[92m 0.22096498496830463 \u001b[0m(-0.004779575392603874)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_19894.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 49/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:48:05) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:48:23 -- STEP: 6/406 -- GLOBAL_STEP: 19900\u001b[0m\n",
      "     | > loss: -0.0245608389377594  (-0.02115056167046229)\n",
      "     | > log_mle: -0.21434974670410156  (-0.21551811695098877)\n",
      "     | > loss_dur: 0.18978890776634216  (0.1943675552805265)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(2.4508, device='cuda:0')  (tensor(5.9008, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.2502  (0.2609033187230428)\n",
      "     | > loader_time: 0.001  (0.030194322268168133)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:48:29 -- STEP: 31/406 -- GLOBAL_STEP: 19925\u001b[0m\n",
      "     | > loss: 0.001934349536895752  (-0.011898434931232084)\n",
      "     | > log_mle: -0.2124943733215332  (-0.21725441948060067)\n",
      "     | > loss_dur: 0.21442872285842896  (0.20535598454936857)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.6271, device='cuda:0')  (tensor(5.7091, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.2562  (0.26052670325002364)\n",
      "     | > loader_time: 0.003  (0.007393890811551002)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:48:37 -- STEP: 56/406 -- GLOBAL_STEP: 19950\u001b[0m\n",
      "     | > loss: 0.007567942142486572  (-0.004518061876296995)\n",
      "     | > log_mle: -0.2244093418121338  (-0.21810480739389146)\n",
      "     | > loss_dur: 0.23197728395462036  (0.21358674551759446)\n",
      "     | > amp_scaler: 16384.0  (8923.42857142857)\n",
      "     | > grad_norm: tensor(6.5938, device='cuda:0')  (tensor(6.3387, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.3193  (0.27260446548461903)\n",
      "     | > loader_time: 0.003  (0.005201326949255807)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:48:45 -- STEP: 81/406 -- GLOBAL_STEP: 19975\u001b[0m\n",
      "     | > loss: -0.0054739415645599365  (-0.0025178019279315134)\n",
      "     | > log_mle: -0.233817458152771  (-0.22044369320810578)\n",
      "     | > loss_dur: 0.22834351658821106  (0.21792589128017426)\n",
      "     | > amp_scaler: 16384.0  (11226.074074074073)\n",
      "     | > grad_norm: tensor(8.3056, device='cuda:0')  (tensor(6.8357, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.3553  (0.28592614480006834)\n",
      "     | > loader_time: 0.003  (0.00446099705166287)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:48:53 -- STEP: 106/406 -- GLOBAL_STEP: 20000\u001b[0m\n",
      "     | > loss: -0.010300353169441223  (-0.0019276724109109826)\n",
      "     | > log_mle: -0.22630822658538818  (-0.22338544197802274)\n",
      "     | > loss_dur: 0.21600787341594696  (0.22145776956711175)\n",
      "     | > amp_scaler: 16384.0  (12442.566037735849)\n",
      "     | > grad_norm: tensor(10.8938, device='cuda:0')  (tensor(8.0768, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.3803  (0.2991961218276113)\n",
      "     | > loader_time: 0.004  (0.004107583243891879)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_20000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:49:06 -- STEP: 131/406 -- GLOBAL_STEP: 20025\u001b[0m\n",
      "     | > loss: -0.018558889627456665  (-0.0017899460237444794)\n",
      "     | > log_mle: -0.23681247234344482  (-0.22602676253282386)\n",
      "     | > loss_dur: 0.21825358271598816  (0.2242368165090794)\n",
      "     | > amp_scaler: 16384.0  (13194.748091603053)\n",
      "     | > grad_norm: tensor(9.1829, device='cuda:0')  (tensor(8.6614, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.3563  (0.3119062412786119)\n",
      "     | > loader_time: 0.004  (0.00393492938908002)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:49:16 -- STEP: 156/406 -- GLOBAL_STEP: 20050\u001b[0m\n",
      "     | > loss: -0.006653845310211182  (-0.0010999529025493505)\n",
      "     | > log_mle: -0.2426680326461792  (-0.22795671148177904)\n",
      "     | > loss_dur: 0.23601418733596802  (0.22685675857922968)\n",
      "     | > amp_scaler: 16384.0  (13705.846153846154)\n",
      "     | > grad_norm: tensor(6.8684, device='cuda:0')  (tensor(9.1867, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.3453  (0.32379146569814415)\n",
      "     | > loader_time: 0.004  (0.0038690062669607325)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:49:26 -- STEP: 181/406 -- GLOBAL_STEP: 20075\u001b[0m\n",
      "     | > loss: 0.015620559453964233  (-0.0008109141943863068)\n",
      "     | > log_mle: -0.23789525032043457  (-0.22963508255573925)\n",
      "     | > loss_dur: 0.2535158097743988  (0.22882416836135294)\n",
      "     | > amp_scaler: 16384.0  (14075.756906077348)\n",
      "     | > grad_norm: tensor(18.0763, device='cuda:0')  (tensor(9.4438, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.4614  (0.33527462390246293)\n",
      "     | > loader_time: 0.004  (0.0038488741079088086)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:49:37 -- STEP: 206/406 -- GLOBAL_STEP: 20100\u001b[0m\n",
      "     | > loss: 0.012507379055023193  (-0.0003248422035893175)\n",
      "     | > log_mle: -0.24094176292419434  (-0.23116520539070795)\n",
      "     | > loss_dur: 0.25344914197921753  (0.23084036318711865)\n",
      "     | > amp_scaler: 16384.0  (14355.883495145632)\n",
      "     | > grad_norm: tensor(13.1387, device='cuda:0')  (tensor(10.0262, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.3833  (0.34552541867043196)\n",
      "     | > loader_time: 0.004  (0.003862787218927181)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:49:48 -- STEP: 231/406 -- GLOBAL_STEP: 20125\u001b[0m\n",
      "     | > loss: 0.011639565229415894  (-0.000390982924601731)\n",
      "     | > log_mle: -0.24966931343078613  (-0.2327179361731459)\n",
      "     | > loss_dur: 0.261308878660202  (0.23232695324854416)\n",
      "     | > amp_scaler: 16384.0  (14575.376623376624)\n",
      "     | > grad_norm: tensor(6.6765, device='cuda:0')  (tensor(10.4248, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.5225  (0.3553772529998382)\n",
      "     | > loader_time: 0.004  (0.003886679034212452)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:50:00 -- STEP: 256/406 -- GLOBAL_STEP: 20150\u001b[0m\n",
      "     | > loss: -0.02339845895767212  (-0.00048237072769552345)\n",
      "     | > log_mle: -0.24541795253753662  (-0.23406012170016766)\n",
      "     | > loss_dur: 0.2220194935798645  (0.23357775097247213)\n",
      "     | > amp_scaler: 16384.0  (14752.0)\n",
      "     | > grad_norm: tensor(11.9796, device='cuda:0')  (tensor(10.8141, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.5385  (0.3669410254806279)\n",
      "     | > loader_time: 0.005  (0.00391762424260378)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:50:12 -- STEP: 281/406 -- GLOBAL_STEP: 20175\u001b[0m\n",
      "     | > loss: -0.014583110809326172  (-0.0009082791219826683)\n",
      "     | > log_mle: -0.2602043151855469  (-0.2352357958559464)\n",
      "     | > loss_dur: 0.2456212043762207  (0.2343275167339637)\n",
      "     | > amp_scaler: 16384.0  (14897.195729537369)\n",
      "     | > grad_norm: tensor(5.4642, device='cuda:0')  (tensor(11.0151, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.5595  (0.3778399131476241)\n",
      "     | > loader_time: 0.004  (0.00396088179320203)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:50:25 -- STEP: 306/406 -- GLOBAL_STEP: 20200\u001b[0m\n",
      "     | > loss: 0.010567724704742432  (-0.0005833017670251175)\n",
      "     | > log_mle: -0.24524199962615967  (-0.23617573657066993)\n",
      "     | > loss_dur: 0.2558097243309021  (0.2355924348036448)\n",
      "     | > amp_scaler: 16384.0  (15018.666666666666)\n",
      "     | > grad_norm: tensor(19.2121, device='cuda:0')  (tensor(11.2424, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.4694  (0.3888746905171012)\n",
      "     | > loader_time: 0.005  (0.004016696238050274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:50:39 -- STEP: 331/406 -- GLOBAL_STEP: 20225\u001b[0m\n",
      "     | > loss: 0.0023361146450042725  (-0.0004510712947730204)\n",
      "     | > log_mle: -0.24580621719360352  (-0.23693533570384692)\n",
      "     | > loss_dur: 0.2481423318386078  (0.23648426440907389)\n",
      "     | > amp_scaler: 16384.0  (15121.788519637463)\n",
      "     | > grad_norm: tensor(11.8485, device='cuda:0')  (tensor(11.4514, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.6136  (0.3999692363681389)\n",
      "     | > loader_time: 0.004  (0.0040550159903811524)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:50:53 -- STEP: 356/406 -- GLOBAL_STEP: 20250\u001b[0m\n",
      "     | > loss: 0.007093995809555054  (-0.00027832506078012795)\n",
      "     | > log_mle: -0.25592875480651855  (-0.2378406159663468)\n",
      "     | > loss_dur: 0.2630227506160736  (0.2375622909055667)\n",
      "     | > amp_scaler: 16384.0  (15210.426966292134)\n",
      "     | > grad_norm: tensor(21.3848, device='cuda:0')  (tensor(11.6948, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.6386  (0.41128249717562376)\n",
      "     | > loader_time: 0.005  (0.004113238848996964)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:51:08 -- STEP: 381/406 -- GLOBAL_STEP: 20275\u001b[0m\n",
      "     | > loss: 0.013919949531555176  (-0.0004607135151314915)\n",
      "     | > log_mle: -0.2431124448776245  (-0.23871893144342218)\n",
      "     | > loss_dur: 0.2570323944091797  (0.2382582179282907)\n",
      "     | > amp_scaler: 16384.0  (15287.433070866142)\n",
      "     | > grad_norm: tensor(16.3919, device='cuda:0')  (tensor(11.8666, device='cuda:0'))\n",
      "     | > current_lr: 1.225e-05 \n",
      "     | > step_time: 0.5515  (0.4235594585498799)\n",
      "     | > loader_time: 0.005  (0.004190086379764584)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08295062184333801 \u001b[0m(-0.007590949535369873)\n",
      "     | > avg_loss:\u001b[92m -0.03716452792286873 \u001b[0m(-0.005147343501448631)\n",
      "     | > avg_log_mle:\u001b[92m -0.2559753507375717 \u001b[0m(-0.002993181347846985)\n",
      "     | > avg_loss_dur:\u001b[92m 0.218810822814703 \u001b[0m(-0.0021541621536016464)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_20300.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 50/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:51:55) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:52:11 -- STEP: 0/406 -- GLOBAL_STEP: 20300\u001b[0m\n",
      "     | > loss: -0.009804561734199524  (-0.009804561734199524)\n",
      "     | > log_mle: -0.2083035707473755  (-0.2083035707473755)\n",
      "     | > loss_dur: 0.19849900901317596  (0.19849900901317596)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(4.4433, device='cuda:0')  (tensor(4.4433, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.4434  (0.4434020519256592)\n",
      "     | > loader_time: 15.2457  (15.245690822601318)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:52:17 -- STEP: 25/406 -- GLOBAL_STEP: 20325\u001b[0m\n",
      "     | > loss: 0.01722787320613861  (-0.02022807776927948)\n",
      "     | > log_mle: -0.2162717580795288  (-0.22003558158874512)\n",
      "     | > loss_dur: 0.23349963128566742  (0.19980750381946563)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.6670, device='cuda:0')  (tensor(7.6039, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.2582  (0.25887505531311034)\n",
      "     | > loader_time: 0.002  (0.010329437255859372)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:52:24 -- STEP: 50/406 -- GLOBAL_STEP: 20350\u001b[0m\n",
      "     | > loss: -0.0004342198371887207  (-0.010925832092761994)\n",
      "     | > log_mle: -0.24187743663787842  (-0.2204565191268921)\n",
      "     | > loss_dur: 0.2414432168006897  (0.2095306870341301)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.4166, device='cuda:0')  (tensor(7.8383, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.3103  (0.2694246912002564)\n",
      "     | > loader_time: 0.003  (0.006245532035827634)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:52:32 -- STEP: 75/406 -- GLOBAL_STEP: 20375\u001b[0m\n",
      "     | > loss: -0.017039328813552856  (-0.00933516283830007)\n",
      "     | > log_mle: -0.23434972763061523  (-0.223504589398702)\n",
      "     | > loss_dur: 0.21731039881706238  (0.21416942656040192)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1872, device='cuda:0')  (tensor(8.1743, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.3453  (0.2820561663309733)\n",
      "     | > loader_time: 0.003  (0.005057849884033201)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:52:41 -- STEP: 100/406 -- GLOBAL_STEP: 20400\u001b[0m\n",
      "     | > loss: 0.019254878163337708  (-0.007233819067478181)\n",
      "     | > log_mle: -0.22726118564605713  (-0.22618761658668518)\n",
      "     | > loss_dur: 0.24651606380939484  (0.218953797519207)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(11.1357, device='cuda:0')  (tensor(8.7078, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.3773  (0.2953481578826903)\n",
      "     | > loader_time: 0.003  (0.004524092674255368)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:52:50 -- STEP: 125/406 -- GLOBAL_STEP: 20425\u001b[0m\n",
      "     | > loss: -0.026507630944252014  (-0.007287782311439515)\n",
      "     | > log_mle: -0.2548220157623291  (-0.22910359287261964)\n",
      "     | > loss_dur: 0.2283143848180771  (0.2218158105611801)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(13.2234, device='cuda:0')  (tensor(9.3141, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.3253  (0.30703080558776846)\n",
      "     | > loader_time: 0.003  (0.00425978851318359)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:52:59 -- STEP: 150/406 -- GLOBAL_STEP: 20450\u001b[0m\n",
      "     | > loss: -0.003215476870536804  (-0.006814389526844025)\n",
      "     | > log_mle: -0.23749184608459473  (-0.23112912813822428)\n",
      "     | > loss_dur: 0.23427636921405792  (0.22431473861138027)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.2890, device='cuda:0')  (tensor(9.5695, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.3563  (0.317788537343343)\n",
      "     | > loader_time: 0.004  (0.004137040774027503)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:53:09 -- STEP: 175/406 -- GLOBAL_STEP: 20475\u001b[0m\n",
      "     | > loss: -0.012693911790847778  (-0.0065553240265165055)\n",
      "     | > log_mle: -0.24191641807556152  (-0.23260473251342773)\n",
      "     | > loss_dur: 0.22922250628471375  (0.22604940848691124)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.4233, device='cuda:0')  (tensor(10.1230, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.4554  (0.3297108173370363)\n",
      "     | > loader_time: 0.004  (0.004066456386021202)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:53:20 -- STEP: 200/406 -- GLOBAL_STEP: 20500\u001b[0m\n",
      "     | > loss: -0.01013195514678955  (-0.006208160221576691)\n",
      "     | > log_mle: -0.24648046493530273  (-0.2341417020559311)\n",
      "     | > loss_dur: 0.23634850978851318  (0.2279335418343544)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(16.1447, device='cuda:0')  (tensor(10.8466, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.4764  (0.3423609375953675)\n",
      "     | > loader_time: 0.004  (0.00403357148170471)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:53:31 -- STEP: 225/406 -- GLOBAL_STEP: 20525\u001b[0m\n",
      "     | > loss: -0.0012685209512710571  (-0.005975519551171197)\n",
      "     | > log_mle: -0.24440991878509521  (-0.23561559518178304)\n",
      "     | > loss_dur: 0.24314139783382416  (0.22964007563061184)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(23.0611, device='cuda:0')  (tensor(11.3890, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.5025  (0.3525290648142497)\n",
      "     | > loader_time: 0.005  (0.004034653769599064)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:53:43 -- STEP: 250/406 -- GLOBAL_STEP: 20550\u001b[0m\n",
      "     | > loss: -0.021059364080429077  (-0.005818585455417633)\n",
      "     | > log_mle: -0.26773202419281006  (-0.23706565761566162)\n",
      "     | > loss_dur: 0.24667266011238098  (0.23124707216024398)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(16.7129, device='cuda:0')  (tensor(11.6015, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.5385  (0.3645430574417115)\n",
      "     | > loader_time: 0.004  (0.004051588058471676)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:53:56 -- STEP: 275/406 -- GLOBAL_STEP: 20575\u001b[0m\n",
      "     | > loss: 0.0025865137577056885  (-0.006184884255582636)\n",
      "     | > log_mle: -0.24024510383605957  (-0.23827773961153897)\n",
      "     | > loss_dur: 0.24283161759376526  (0.23209285535595633)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(26.9643, device='cuda:0')  (tensor(11.6929, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.5575  (0.37609793402931907)\n",
      "     | > loader_time: 0.005  (0.00408358660611239)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:54:08 -- STEP: 300/406 -- GLOBAL_STEP: 20600\u001b[0m\n",
      "     | > loss: 0.0020871758460998535  (-0.006085966378450396)\n",
      "     | > log_mle: -0.23712515830993652  (-0.23919899543126424)\n",
      "     | > loss_dur: 0.23921233415603638  (0.23311302905281384)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3980, device='cuda:0')  (tensor(12.3706, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.4644  (0.38720166126887)\n",
      "     | > loader_time: 0.005  (0.004116944471995029)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:54:22 -- STEP: 325/406 -- GLOBAL_STEP: 20625\u001b[0m\n",
      "     | > loss: 0.01204991340637207  (-0.0058315240878325245)\n",
      "     | > log_mle: -0.241021990776062  (-0.2399917169717642)\n",
      "     | > loss_dur: 0.2530719041824341  (0.23416019288393167)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(16.5708, device='cuda:0')  (tensor(13.0042, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.6206  (0.39921795258155235)\n",
      "     | > loader_time: 0.005  (0.004154405593872065)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:54:36 -- STEP: 350/406 -- GLOBAL_STEP: 20650\u001b[0m\n",
      "     | > loss: -0.0183325856924057  (-0.005503883702414377)\n",
      "     | > log_mle: -0.2566009759902954  (-0.24080501658575876)\n",
      "     | > loss_dur: 0.2382683902978897  (0.23530113288334437)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(24.5961, device='cuda:0')  (tensor(13.2285, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.5195  (0.41073017052241734)\n",
      "     | > loader_time: 0.005  (0.004232264246259413)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:54:51 -- STEP: 375/406 -- GLOBAL_STEP: 20675\u001b[0m\n",
      "     | > loss: -0.012779995799064636  (-0.0056425379117329925)\n",
      "     | > log_mle: -0.2598453760147095  (-0.24162765820821128)\n",
      "     | > loss_dur: 0.24706538021564484  (0.23598512029647828)\n",
      "     | > amp_scaler: 8192.0  (16209.237333333333)\n",
      "     | > grad_norm: tensor(38.2652, device='cuda:0')  (tensor(13.6905, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.6576  (0.4225490792592366)\n",
      "     | > loader_time: 0.005  (0.004286421457926427)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:55:08 -- STEP: 400/406 -- GLOBAL_STEP: 20700\u001b[0m\n",
      "     | > loss: -0.0010869204998016357  (-0.005677076689898969)\n",
      "     | > log_mle: -0.2570904493331909  (-0.2423943853378296)\n",
      "     | > loss_dur: 0.2560035288333893  (0.2367173086479306)\n",
      "     | > amp_scaler: 8192.0  (15708.16)\n",
      "     | > grad_norm: tensor(25.8206, device='cuda:0')  (tensor(13.5541, device='cuda:0'))\n",
      "     | > current_lr: 1.2499999999999999e-05 \n",
      "     | > step_time: 0.7409  (0.43626182556152343)\n",
      "     | > loader_time: 0.004  (0.004341296553611748)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10101068019866943 \u001b[0m(+0.01806005835533142)\n",
      "     | > avg_loss:\u001b[92m -0.044219812378287315 \u001b[0m(-0.007055284455418587)\n",
      "     | > avg_log_mle:\u001b[92m -0.26106616854667664 \u001b[0m(-0.005090817809104919)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21684635616838932 \u001b[0m(-0.0019644666463136673)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_20706.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 51/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:55:42) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:56:03 -- STEP: 19/406 -- GLOBAL_STEP: 20725\u001b[0m\n",
      "     | > loss: -0.02429184317588806  (-0.030405820984589427)\n",
      "     | > log_mle: -0.2121349573135376  (-0.2245965505901136)\n",
      "     | > loss_dur: 0.18784311413764954  (0.19419072960552416)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.1447, device='cuda:0')  (tensor(6.9712, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.2612  (0.25797088522660105)\n",
      "     | > loader_time: 0.002  (0.014592459327296206)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:56:10 -- STEP: 44/406 -- GLOBAL_STEP: 20750\u001b[0m\n",
      "     | > loss: 0.01042291522026062  (-0.018433050337162884)\n",
      "     | > log_mle: -0.23044610023498535  (-0.22366646203127774)\n",
      "     | > loss_dur: 0.24086901545524597  (0.20523341169411485)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.1558, device='cuda:0')  (tensor(7.4606, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.2642  (0.2658093680034984)\n",
      "     | > loader_time: 0.002  (0.007666251876137473)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:56:18 -- STEP: 69/406 -- GLOBAL_STEP: 20775\u001b[0m\n",
      "     | > loss: -0.00050315260887146  (-0.015148422424344046)\n",
      "     | > log_mle: -0.23504769802093506  (-0.22622328737507696)\n",
      "     | > loss_dur: 0.2345445454120636  (0.2110748649507329)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.8040, device='cuda:0')  (tensor(7.9540, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.3443  (0.2793402913687885)\n",
      "     | > loader_time: 0.003  (0.005802686663641446)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:56:26 -- STEP: 94/406 -- GLOBAL_STEP: 20800\u001b[0m\n",
      "     | > loss: -0.02280355989933014  (-0.014493075774071062)\n",
      "     | > log_mle: -0.24264705181121826  (-0.22960761379688344)\n",
      "     | > loss_dur: 0.21984349191188812  (0.21511453802281238)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.0920, device='cuda:0')  (tensor(8.4596, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.3713  (0.2931490147367436)\n",
      "     | > loader_time: 0.003  (0.005015340257198252)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:56:35 -- STEP: 119/406 -- GLOBAL_STEP: 20825\u001b[0m\n",
      "     | > loss: -0.012789934873580933  (-0.013681250209567926)\n",
      "     | > log_mle: -0.25475013256073  (-0.2322176995397616)\n",
      "     | > loss_dur: 0.24196019768714905  (0.21853644933019364)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.8702, device='cuda:0')  (tensor(9.3425, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.4004  (0.30506681193824586)\n",
      "     | > loader_time: 0.003  (0.004634590709910673)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:56:44 -- STEP: 144/406 -- GLOBAL_STEP: 20850\u001b[0m\n",
      "     | > loss: -5.093216896057129e-05  (-0.013032123446464535)\n",
      "     | > log_mle: -0.23689353466033936  (-0.23450608634286457)\n",
      "     | > loss_dur: 0.23684260249137878  (0.22147396289640003)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.9611, device='cuda:0')  (tensor(9.1218, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.3463  (0.3162523441844517)\n",
      "     | > loader_time: 0.003  (0.004413861367437575)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:56:54 -- STEP: 169/406 -- GLOBAL_STEP: 20875\u001b[0m\n",
      "     | > loss: -0.008040085434913635  (-0.012475373653265147)\n",
      "     | > log_mle: -0.24515056610107422  (-0.2360022815726918)\n",
      "     | > loss_dur: 0.23711048066616058  (0.22352690791942664)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.9239, device='cuda:0')  (tensor(9.9978, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.4364  (0.3273208211864946)\n",
      "     | > loader_time: 0.004  (0.0042820555218578095)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:57:05 -- STEP: 194/406 -- GLOBAL_STEP: 20900\u001b[0m\n",
      "     | > loss: -0.007829785346984863  (-0.01225315940748785)\n",
      "     | > log_mle: -0.2470865249633789  (-0.23770472315168872)\n",
      "     | > loss_dur: 0.23925673961639404  (0.22545156374420086)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.2829, device='cuda:0')  (tensor(10.5767, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.4664  (0.33972082433012357)\n",
      "     | > loader_time: 0.004  (0.004215190091083962)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:57:16 -- STEP: 219/406 -- GLOBAL_STEP: 20925\u001b[0m\n",
      "     | > loss: -0.018933817744255066  (-0.012020049438084641)\n",
      "     | > log_mle: -0.25375330448150635  (-0.23900645399746828)\n",
      "     | > loss_dur: 0.23481948673725128  (0.22698640455938365)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.2283, device='cuda:0')  (tensor(11.0015, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.5055  (0.3507705322683675)\n",
      "     | > loader_time: 0.005  (0.004250451310040202)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:57:28 -- STEP: 244/406 -- GLOBAL_STEP: 20950\u001b[0m\n",
      "     | > loss: -0.023512080311775208  (-0.011840206311374415)\n",
      "     | > log_mle: -0.25067138671875  (-0.2404846710259797)\n",
      "     | > loss_dur: 0.2271593064069748  (0.2286444647146053)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.9943, device='cuda:0')  (tensor(11.3245, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.4154  (0.36156194229595007)\n",
      "     | > loader_time: 0.005  (0.004245659366982886)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:57:40 -- STEP: 269/406 -- GLOBAL_STEP: 20975\u001b[0m\n",
      "     | > loss: -0.02415265142917633  (-0.011835451462898113)\n",
      "     | > log_mle: -0.2578248977661133  (-0.24153423796799103)\n",
      "     | > loss_dur: 0.23367224633693695  (0.2296987865050929)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.1593, device='cuda:0')  (tensor(11.3047, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.5415  (0.3740698972156058)\n",
      "     | > loader_time: 0.004  (0.004249191638705459)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:57:53 -- STEP: 294/406 -- GLOBAL_STEP: 21000\u001b[0m\n",
      "     | > loss: -0.006090104579925537  (-0.011796148303820166)\n",
      "     | > log_mle: -0.260351300239563  (-0.24245898577631736)\n",
      "     | > loss_dur: 0.25426119565963745  (0.2306628374724972)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.1355, device='cuda:0')  (tensor(11.6975, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.4654  (0.3842244886216664)\n",
      "     | > loader_time: 0.005  (0.00426918227656358)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_21000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:58:12 -- STEP: 319/406 -- GLOBAL_STEP: 21025\u001b[0m\n",
      "     | > loss: 0.009373098611831665  (-0.01154992259968785)\n",
      "     | > log_mle: -0.25779473781585693  (-0.24339465997809526)\n",
      "     | > loss_dur: 0.2671678364276886  (0.2318447373784074)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.4664, device='cuda:0')  (tensor(11.9795, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.6216  (0.39821313092701116)\n",
      "     | > loader_time: 0.005  (0.004314246969910624)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:58:25 -- STEP: 344/406 -- GLOBAL_STEP: 21050\u001b[0m\n",
      "     | > loss: 0.00038151443004608154  (-0.01124795340001584)\n",
      "     | > log_mle: -0.2480539083480835  (-0.2441892173401145)\n",
      "     | > loss_dur: 0.24843542277812958  (0.23294126394009868)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.8238, device='cuda:0')  (tensor(12.2126, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.5375  (0.4093218147754669)\n",
      "     | > loader_time: 0.004  (0.004338241593782293)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:58:40 -- STEP: 369/406 -- GLOBAL_STEP: 21075\u001b[0m\n",
      "     | > loss: 0.0021563172340393066  (-0.01137985341594149)\n",
      "     | > log_mle: -0.2493809461593628  (-0.24511190352401113)\n",
      "     | > loss_dur: 0.2515372633934021  (0.23373205010806966)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.1383, device='cuda:0')  (tensor(12.4682, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.6946  (0.42082346099502027)\n",
      "     | > loader_time: 0.005  (0.004380672604734014)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:58:56 -- STEP: 394/406 -- GLOBAL_STEP: 21100\u001b[0m\n",
      "     | > loss: -0.013282671570777893  (-0.011522779647771486)\n",
      "     | > log_mle: -0.25505518913269043  (-0.2459239330388568)\n",
      "     | > loss_dur: 0.24177251756191254  (0.2344011533910853)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.1736, device='cuda:0')  (tensor(12.6702, device='cuda:0'))\n",
      "     | > current_lr: 1.275e-05 \n",
      "     | > step_time: 0.5885  (0.4336827472986909)\n",
      "     | > loader_time: 0.005  (0.004425362281992957)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09083247184753418 \u001b[0m(-0.010178208351135254)\n",
      "     | > avg_loss:\u001b[92m -0.05015822313725948 \u001b[0m(-0.005938410758972168)\n",
      "     | > avg_log_mle:\u001b[92m -0.2640853822231293 \u001b[0m(-0.0030192136764526367)\n",
      "     | > avg_loss_dur:\u001b[92m 0.2139271590858698 \u001b[0m(-0.0029191970825195312)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_21112.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 52/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 04:59:34) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 04:59:54 -- STEP: 13/406 -- GLOBAL_STEP: 21125\u001b[0m\n",
      "     | > loss: -0.03126184642314911  (-0.038003077873816855)\n",
      "     | > log_mle: -0.23541545867919922  (-0.22879815101623535)\n",
      "     | > loss_dur: 0.2041536122560501  (0.1907950731424185)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.5706, device='cuda:0')  (tensor(7.0183, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.2582  (0.2556166648864746)\n",
      "     | > loader_time: 0.002  (0.017092521374042217)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:00:01 -- STEP: 38/406 -- GLOBAL_STEP: 21150\u001b[0m\n",
      "     | > loss: -0.0042908042669296265  (-0.025402023996177473)\n",
      "     | > log_mle: -0.23445940017700195  (-0.22747160259046054)\n",
      "     | > loss_dur: 0.23016859591007233  (0.20206957859428307)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.8512, device='cuda:0')  (tensor(6.7795, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.2903  (0.26531986813796193)\n",
      "     | > loader_time: 0.002  (0.0073223302238865935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:00:08 -- STEP: 63/406 -- GLOBAL_STEP: 21175\u001b[0m\n",
      "     | > loss: -0.009653300046920776  (-0.02045889080516876)\n",
      "     | > log_mle: -0.23905479907989502  (-0.22882290870424302)\n",
      "     | > loss_dur: 0.22940149903297424  (0.20836401789907424)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.8415, device='cuda:0')  (tensor(7.9939, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.2782  (0.2770452158791678)\n",
      "     | > loader_time: 0.002  (0.005497001466296969)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:00:16 -- STEP: 88/406 -- GLOBAL_STEP: 21200\u001b[0m\n",
      "     | > loss: -0.013921856880187988  (-0.01885802010920914)\n",
      "     | > log_mle: -0.22932231426239014  (-0.23173095285892487)\n",
      "     | > loss_dur: 0.21540045738220215  (0.21287293274971572)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.9501, device='cuda:0')  (tensor(8.1673, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.3653  (0.290343230420893)\n",
      "     | > loader_time: 0.002  (0.0046745999292893865)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:00:25 -- STEP: 113/406 -- GLOBAL_STEP: 21225\u001b[0m\n",
      "     | > loss: -0.00923234224319458  (-0.018741339313245446)\n",
      "     | > log_mle: -0.2472996711730957  (-0.23462910673259635)\n",
      "     | > loss_dur: 0.23806732892990112  (0.2158877674193509)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.4753, device='cuda:0')  (tensor(9.4032, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.3213  (0.30401950177893167)\n",
      "     | > loader_time: 0.004  (0.004313572318153046)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:00:34 -- STEP: 138/406 -- GLOBAL_STEP: 21250\u001b[0m\n",
      "     | > loss: 0.01538434624671936  (-0.017155711525592244)\n",
      "     | > log_mle: -0.24891114234924316  (-0.23683732661648074)\n",
      "     | > loss_dur: 0.2642954885959625  (0.2196816150908885)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.9398, device='cuda:0')  (tensor(10.4097, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.4054  (0.3145682759906934)\n",
      "     | > loader_time: 0.003  (0.004119644994321078)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:00:44 -- STEP: 163/406 -- GLOBAL_STEP: 21275\u001b[0m\n",
      "     | > loss: -0.008338496088981628  (-0.016410256273176046)\n",
      "     | > log_mle: -0.25429344177246094  (-0.23835936280115982)\n",
      "     | > loss_dur: 0.2459549456834793  (0.22194910652798383)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.4105, device='cuda:0')  (tensor(12.1445, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.4334  (0.3257743507806509)\n",
      "     | > loader_time: 0.004  (0.004015881591047979)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:00:55 -- STEP: 188/406 -- GLOBAL_STEP: 21300\u001b[0m\n",
      "     | > loss: -0.013485193252563477  (-0.016248899967746526)\n",
      "     | > log_mle: -0.26793062686920166  (-0.23998913359134755)\n",
      "     | > loss_dur: 0.2544454336166382  (0.22374023362360107)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.5517, device='cuda:0')  (tensor(12.9191, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.3833  (0.3368537197721767)\n",
      "     | > loader_time: 0.004  (0.00399298870817144)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:01:06 -- STEP: 213/406 -- GLOBAL_STEP: 21325\u001b[0m\n",
      "     | > loss: -0.022647589445114136  (-0.01585280951199956)\n",
      "     | > log_mle: -0.25679969787597656  (-0.24129661483943743)\n",
      "     | > loss_dur: 0.23415210843086243  (0.22544380532743788)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.6661, device='cuda:0')  (tensor(13.3445, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.4014  (0.34799208775372586)\n",
      "     | > loader_time: 0.004  (0.003984810600818046)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:01:17 -- STEP: 238/406 -- GLOBAL_STEP: 21350\u001b[0m\n",
      "     | > loss: -0.015338972210884094  (-0.015455151743748596)\n",
      "     | > log_mle: -0.2591015100479126  (-0.24266718215301258)\n",
      "     | > loss_dur: 0.2437625378370285  (0.227212030409264)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.1483, device='cuda:0')  (tensor(14.0901, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.4044  (0.3579931719964293)\n",
      "     | > loader_time: 0.005  (0.004007806297109912)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:01:29 -- STEP: 263/406 -- GLOBAL_STEP: 21375\u001b[0m\n",
      "     | > loss: -0.029288649559020996  (-0.015657541473102193)\n",
      "     | > log_mle: -0.25884008407592773  (-0.24381625833620138)\n",
      "     | > loss_dur: 0.22955143451690674  (0.2281587168630992)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.3081, device='cuda:0')  (tensor(14.6438, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.5355  (0.3711316902827855)\n",
      "     | > loader_time: 0.005  (0.004053072331069543)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:01:42 -- STEP: 288/406 -- GLOBAL_STEP: 21400\u001b[0m\n",
      "     | > loss: -0.017498984932899475  (-0.01559327128860684)\n",
      "     | > log_mle: -0.24828755855560303  (-0.24479658239417607)\n",
      "     | > loss_dur: 0.23078857362270355  (0.2292033111055692)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(35.6199, device='cuda:0')  (tensor(15.2648, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.4884  (0.38146795001294886)\n",
      "     | > loader_time: 0.005  (0.004093924330340493)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:01:55 -- STEP: 313/406 -- GLOBAL_STEP: 21425\u001b[0m\n",
      "     | > loss: -0.007109850645065308  (-0.015380807482777297)\n",
      "     | > log_mle: -0.25344061851501465  (-0.24566904995768976)\n",
      "     | > loss_dur: 0.24633076786994934  (0.23028824247491245)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.6206, device='cuda:0')  (tensor(15.3812, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.5925  (0.3936162124426602)\n",
      "     | > loader_time: 0.004  (0.004157067106935546)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:02:09 -- STEP: 338/406 -- GLOBAL_STEP: 21450\u001b[0m\n",
      "     | > loss: -0.01843509078025818  (-0.014969310728755915)\n",
      "     | > log_mle: -0.25624024868011475  (-0.24635147872055776)\n",
      "     | > loss_dur: 0.23780515789985657  (0.23138216799180183)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.9133, device='cuda:0')  (tensor(15.3804, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.5105  (0.40532331777042196)\n",
      "     | > loader_time: 0.004  (0.004219764788475263)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:02:23 -- STEP: 363/406 -- GLOBAL_STEP: 21475\u001b[0m\n",
      "     | > loss: -0.019024118781089783  (-0.01493197039139171)\n",
      "     | > log_mle: -0.2679719924926758  (-0.24722858401369457)\n",
      "     | > loss_dur: 0.248947873711586  (0.23229661362230286)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.3623, device='cuda:0')  (tensor(15.4111, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.5215  (0.4162233394696365)\n",
      "     | > loader_time: 0.006  (0.004284848851605881)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:02:39 -- STEP: 388/406 -- GLOBAL_STEP: 21500\u001b[0m\n",
      "     | > loss: -0.014494866132736206  (-0.014964807240926102)\n",
      "     | > log_mle: -0.2559783458709717  (-0.24795678380838374)\n",
      "     | > loss_dur: 0.24148347973823547  (0.23299197656745763)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.0176, device='cuda:0')  (tensor(15.4930, device='cuda:0'))\n",
      "     | > current_lr: 1.3e-05 \n",
      "     | > step_time: 0.6966  (0.42921181499343564)\n",
      "     | > loader_time: 0.005  (0.004341547022160797)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08908101916313171 \u001b[0m(-0.0017514526844024658)\n",
      "     | > avg_loss:\u001b[92m -0.05157738924026489 \u001b[0m(-0.0014191661030054092)\n",
      "     | > avg_log_mle:\u001b[92m -0.26569177210330963 \u001b[0m(-0.0016063898801803589)\n",
      "     | > avg_loss_dur:\u001b[91m 0.21411438286304474 \u001b[0m(+0.00018722377717494965)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_21518.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 53/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:03:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:03:39 -- STEP: 7/406 -- GLOBAL_STEP: 21525\u001b[0m\n",
      "     | > loss: -0.03270217776298523  (-0.04817928373813629)\n",
      "     | > log_mle: -0.22206342220306396  (-0.22838245119367326)\n",
      "     | > loss_dur: 0.18936124444007874  (0.18020316745553697)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.5746, device='cuda:0')  (tensor(7.2669, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.2532  (0.2573759896414621)\n",
      "     | > loader_time: 0.001  (0.03817776271275112)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:03:46 -- STEP: 32/406 -- GLOBAL_STEP: 21550\u001b[0m\n",
      "     | > loss: -0.046573296189308167  (-0.03434006636962294)\n",
      "     | > log_mle: -0.23265957832336426  (-0.2295183502137661)\n",
      "     | > loss_dur: 0.1860862821340561  (0.19517828384414315)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.0617, device='cuda:0')  (tensor(11.2498, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.2572  (0.2599857598543167)\n",
      "     | > loader_time: 0.003  (0.009946733713150024)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:03:53 -- STEP: 57/406 -- GLOBAL_STEP: 21575\u001b[0m\n",
      "     | > loss: -0.02097707986831665  (-0.026474683169733015)\n",
      "     | > log_mle: -0.2294609546661377  (-0.23038717320090846)\n",
      "     | > loss_dur: 0.20848387479782104  (0.20391249003117545)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.5251, device='cuda:0')  (tensor(11.9705, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.3183  (0.27335312910247267)\n",
      "     | > loader_time: 0.003  (0.006637878585280035)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:04:01 -- STEP: 82/406 -- GLOBAL_STEP: 21600\u001b[0m\n",
      "     | > loss: -0.02731435000896454  (-0.024947659634962316)\n",
      "     | > log_mle: -0.24691081047058105  (-0.23297550329347935)\n",
      "     | > loss_dur: 0.21959646046161652  (0.20802784365851704)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.7296, device='cuda:0')  (tensor(12.4221, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.3603  (0.286637940057894)\n",
      "     | > loader_time: 0.003  (0.005432111460988115)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:04:10 -- STEP: 107/406 -- GLOBAL_STEP: 21625\u001b[0m\n",
      "     | > loss: -0.019810795783996582  (-0.02344811965371961)\n",
      "     | > log_mle: -0.2446962594985962  (-0.23584433916573214)\n",
      "     | > loss_dur: 0.2248854637145996  (0.2123962195120125)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.3955, device='cuda:0')  (tensor(12.8560, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.3854  (0.29952411116840677)\n",
      "     | > loader_time: 0.003  (0.004845708330100942)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:04:19 -- STEP: 132/406 -- GLOBAL_STEP: 21650\u001b[0m\n",
      "     | > loss: -0.03148101270198822  (-0.022743320374777824)\n",
      "     | > log_mle: -0.2625793218612671  (-0.23851016795996463)\n",
      "     | > loss_dur: 0.23109830915927887  (0.21576684758518683)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.7423, device='cuda:0')  (tensor(13.7446, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.3313  (0.3103724898714007)\n",
      "     | > loader_time: 0.004  (0.00455736391472094)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:04:29 -- STEP: 157/406 -- GLOBAL_STEP: 21675\u001b[0m\n",
      "     | > loss: -0.014063403010368347  (-0.02174590452081838)\n",
      "     | > log_mle: -0.2473282814025879  (-0.24020856125339582)\n",
      "     | > loss_dur: 0.23326487839221954  (0.21846265673257742)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.7035, device='cuda:0')  (tensor(13.8992, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.4254  (0.32203737489736745)\n",
      "     | > loader_time: 0.003  (0.004367243712115439)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:04:39 -- STEP: 182/406 -- GLOBAL_STEP: 21700\u001b[0m\n",
      "     | > loss: -0.017725378274917603  (-0.021263689293966187)\n",
      "     | > log_mle: -0.2516220808029175  (-0.24169743388563722)\n",
      "     | > loss_dur: 0.23389670252799988  (0.22043374459167103)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.3595, device='cuda:0')  (tensor(13.9551, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.3703  (0.33390189658154484)\n",
      "     | > loader_time: 0.004  (0.004278768549908647)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:04:50 -- STEP: 207/406 -- GLOBAL_STEP: 21725\u001b[0m\n",
      "     | > loss: -0.012241154909133911  (-0.020700723220760695)\n",
      "     | > log_mle: -0.24294006824493408  (-0.24312842065009518)\n",
      "     | > loss_dur: 0.23069891333580017  (0.2224276974293345)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.8105, device='cuda:0')  (tensor(14.0884, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.4804  (0.34521188597748237)\n",
      "     | > loader_time: 0.004  (0.004240661427594613)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:05:01 -- STEP: 232/406 -- GLOBAL_STEP: 21750\u001b[0m\n",
      "     | > loss: -0.014277428388595581  (-0.020723612015617305)\n",
      "     | > log_mle: -0.261289119720459  (-0.244727977390947)\n",
      "     | > loss_dur: 0.2470116913318634  (0.2240043653753297)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.8032, device='cuda:0')  (tensor(14.0995, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.4094  (0.35533546476528555)\n",
      "     | > loader_time: 0.004  (0.0042237526383893265)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:05:13 -- STEP: 257/406 -- GLOBAL_STEP: 21775\u001b[0m\n",
      "     | > loss: -0.00021079182624816895  (-0.02052799493422304)\n",
      "     | > log_mle: -0.2590322494506836  (-0.24594719910899954)\n",
      "     | > loss_dur: 0.2588214576244354  (0.22541920417477648)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.3038, device='cuda:0')  (tensor(14.3863, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.5465  (0.3681785893347476)\n",
      "     | > loader_time: 0.004  (0.004217881636860772)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:05:26 -- STEP: 282/406 -- GLOBAL_STEP: 21800\u001b[0m\n",
      "     | > loss: -0.028232619166374207  (-0.02071475290448953)\n",
      "     | > log_mle: -0.2641024589538574  (-0.2470497062020268)\n",
      "     | > loss_dur: 0.23586983978748322  (0.22633495329753725)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.2869, device='cuda:0')  (tensor(14.4132, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.4544  (0.379390517025129)\n",
      "     | > loader_time: 0.005  (0.004234371455848642)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:05:39 -- STEP: 307/406 -- GLOBAL_STEP: 21825\u001b[0m\n",
      "     | > loss: -0.013951361179351807  (-0.020234983062511154)\n",
      "     | > log_mle: -0.2551100254058838  (-0.24793630042371223)\n",
      "     | > loss_dur: 0.24115866422653198  (0.22770131736120106)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.8218, device='cuda:0')  (tensor(14.4673, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.6066  (0.391280272884555)\n",
      "     | > loader_time: 0.006  (0.004271024989771145)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:05:53 -- STEP: 332/406 -- GLOBAL_STEP: 21850\u001b[0m\n",
      "     | > loss: -0.014899134635925293  (-0.020123138171003526)\n",
      "     | > log_mle: -0.25211167335510254  (-0.24874517106148133)\n",
      "     | > loss_dur: 0.23721253871917725  (0.2286220328904778)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.5919, device='cuda:0')  (tensor(14.2614, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.5185  (0.4026486536106428)\n",
      "     | > loader_time: 0.004  (0.004302141178085143)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:06:07 -- STEP: 357/406 -- GLOBAL_STEP: 21875\u001b[0m\n",
      "     | > loss: -0.006585448980331421  (-0.019994286762900052)\n",
      "     | > log_mle: -0.25058889389038086  (-0.24969123391544118)\n",
      "     | > loss_dur: 0.24400344491004944  (0.22969694715254113)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.2003, device='cuda:0')  (tensor(14.1234, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.5375  (0.4144911124926652)\n",
      "     | > loader_time: 0.005  (0.004345740256857138)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:06:23 -- STEP: 382/406 -- GLOBAL_STEP: 21900\u001b[0m\n",
      "     | > loss: -0.003761589527130127  (-0.0202346141425727)\n",
      "     | > log_mle: -0.2570312023162842  (-0.25056693535200597)\n",
      "     | > loss_dur: 0.25326961278915405  (0.2303323212094332)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.6775, device='cuda:0')  (tensor(14.1319, device='cuda:0'))\n",
      "     | > current_lr: 1.325e-05 \n",
      "     | > step_time: 0.5555  (0.42664908738660534)\n",
      "     | > loader_time: 0.005  (0.004394097477977814)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09550678730010986 \u001b[0m(+0.006425768136978149)\n",
      "     | > avg_loss:\u001b[92m -0.056372273713350296 \u001b[0m(-0.0047948844730854034)\n",
      "     | > avg_log_mle:\u001b[92m -0.27037326991558075 \u001b[0m(-0.004681497812271118)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21400099620223045 \u001b[0m(-0.00011338666081428528)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_21924.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 54/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:07:09) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:07:25 -- STEP: 1/406 -- GLOBAL_STEP: 21925\u001b[0m\n",
      "     | > loss: -0.06563951075077057  (-0.06563951075077057)\n",
      "     | > log_mle: -0.23548591136932373  (-0.23548591136932373)\n",
      "     | > loss_dur: 0.16984640061855316  (0.16984640061855316)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.7855, device='cuda:0')  (tensor(4.7855, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.2652  (0.2652413845062256)\n",
      "     | > loader_time: 0.001  (0.0010004043579101562)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:07:32 -- STEP: 26/406 -- GLOBAL_STEP: 21950\u001b[0m\n",
      "     | > loss: -0.017964288592338562  (-0.0406349404500081)\n",
      "     | > log_mle: -0.23740410804748535  (-0.2335268625846276)\n",
      "     | > loss_dur: 0.2194398194551468  (0.1928919221346195)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.6403, device='cuda:0')  (tensor(7.4101, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.2562  (0.2574646197832547)\n",
      "     | > loader_time: 0.002  (0.010355527584369369)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:07:39 -- STEP: 51/406 -- GLOBAL_STEP: 21975\u001b[0m\n",
      "     | > loss: -0.045448318123817444  (-0.03141596124452703)\n",
      "     | > log_mle: -0.26151418685913086  (-0.23417741177128812)\n",
      "     | > loss_dur: 0.21606586873531342  (0.20276145052676106)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.5996, device='cuda:0')  (tensor(8.2644, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.3103  (0.269381841023763)\n",
      "     | > loader_time: 0.003  (0.006437212813134288)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:07:47 -- STEP: 76/406 -- GLOBAL_STEP: 22000\u001b[0m\n",
      "     | > loss: -0.03677539527416229  (-0.03002974626265074)\n",
      "     | > log_mle: -0.23631882667541504  (-0.23659947514533997)\n",
      "     | > loss_dur: 0.19954343140125275  (0.20656972888268924)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.9369, device='cuda:0')  (tensor(9.2230, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.2843  (0.2810183669391431)\n",
      "     | > loader_time: 0.003  (0.005228356311195776)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_22000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:07:58 -- STEP: 101/406 -- GLOBAL_STEP: 22025\u001b[0m\n",
      "     | > loss: -0.0348474383354187  (-0.028345922137250994)\n",
      "     | > log_mle: -0.2526814937591553  (-0.239530610566092)\n",
      "     | > loss_dur: 0.21783405542373657  (0.21118468842884103)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.0308, device='cuda:0')  (tensor(9.7367, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.3143  (0.29667422559001666)\n",
      "     | > loader_time: 0.003  (0.004687361197896525)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:08:08 -- STEP: 126/406 -- GLOBAL_STEP: 22050\u001b[0m\n",
      "     | > loss: -0.0164291113615036  (-0.028211753638017745)\n",
      "     | > log_mle: -0.2433086633682251  (-0.24242902180505177)\n",
      "     | > loss_dur: 0.2268795520067215  (0.21421726816703404)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.8968, device='cuda:0')  (tensor(10.5103, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.4014  (0.30880333506871793)\n",
      "     | > loader_time: 0.004  (0.004400720672001916)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:08:17 -- STEP: 151/406 -- GLOBAL_STEP: 22075\u001b[0m\n",
      "     | > loss: -0.017632365226745605  (-0.027874335646629333)\n",
      "     | > log_mle: -0.25075459480285645  (-0.2445624095714645)\n",
      "     | > loss_dur: 0.23312222957611084  (0.2166880739248352)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.5630, device='cuda:0')  (tensor(10.6347, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.4364  (0.31952118399916907)\n",
      "     | > loader_time: 0.004  (0.004248784867343526)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:08:27 -- STEP: 176/406 -- GLOBAL_STEP: 22100\u001b[0m\n",
      "     | > loss: -0.024756819009780884  (-0.02736082359809767)\n",
      "     | > log_mle: -0.24923741817474365  (-0.24599977379495447)\n",
      "     | > loss_dur: 0.22448059916496277  (0.21863895019685683)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.8204, device='cuda:0')  (tensor(11.0011, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.3723  (0.33073150027881976)\n",
      "     | > loader_time: 0.003  (0.0041741322387348545)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:08:38 -- STEP: 201/406 -- GLOBAL_STEP: 22125\u001b[0m\n",
      "     | > loss: -0.023250654339790344  (-0.02704732179345183)\n",
      "     | > log_mle: -0.25230371952056885  (-0.24757965109241542)\n",
      "     | > loss_dur: 0.2290530651807785  (0.22053232929896363)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.7696, device='cuda:0')  (tensor(11.2836, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.3924  (0.34302235835820294)\n",
      "     | > loader_time: 0.004  (0.004132990813373928)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:08:49 -- STEP: 226/406 -- GLOBAL_STEP: 22150\u001b[0m\n",
      "     | > loss: -0.026711881160736084  (-0.026830343348262585)\n",
      "     | > log_mle: -0.2675442695617676  (-0.2490563292418961)\n",
      "     | > loss_dur: 0.2408323884010315  (0.22222598589363354)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.4905, device='cuda:0')  (tensor(11.5381, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.4094  (0.35308565080693344)\n",
      "     | > loader_time: 0.004  (0.004127534089890201)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:09:01 -- STEP: 251/406 -- GLOBAL_STEP: 22175\u001b[0m\n",
      "     | > loss: -0.029743298888206482  (-0.026696280951044)\n",
      "     | > log_mle: -0.2555166482925415  (-0.25037483865046406)\n",
      "     | > loss_dur: 0.22577334940433502  (0.22367855769942008)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.3202, device='cuda:0')  (tensor(12.1587, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.5265  (0.3653153708256574)\n",
      "     | > loader_time: 0.005  (0.004159054433207113)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:09:13 -- STEP: 276/406 -- GLOBAL_STEP: 22200\u001b[0m\n",
      "     | > loss: -0.019522085785865784  (-0.026995552136846207)\n",
      "     | > log_mle: -0.2642267942428589  (-0.25153603933859564)\n",
      "     | > loss_dur: 0.2447047084569931  (0.2245404872017494)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(30.0640, device='cuda:0')  (tensor(12.5994, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.4564  (0.3764306695564934)\n",
      "     | > loader_time: 0.004  (0.004166717978491299)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:09:26 -- STEP: 301/406 -- GLOBAL_STEP: 22225\u001b[0m\n",
      "     | > loss: -0.01946958899497986  (-0.026798168389108083)\n",
      "     | > log_mle: -0.27787482738494873  (-0.25244167991650845)\n",
      "     | > loss_dur: 0.25840523838996887  (0.22564351152740048)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.4450, device='cuda:0')  (tensor(13.0595, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.6196  (0.3879786543671871)\n",
      "     | > loader_time: 0.004  (0.004183093574752047)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:09:40 -- STEP: 326/406 -- GLOBAL_STEP: 22250\u001b[0m\n",
      "     | > loss: -0.029862195253372192  (-0.026612269640700206)\n",
      "     | > log_mle: -0.2559621334075928  (-0.2532220095213204)\n",
      "     | > loss_dur: 0.22609993815422058  (0.22660973988062033)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.6600, device='cuda:0')  (tensor(13.1753, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.5235  (0.399594528543437)\n",
      "     | > loader_time: 0.004  (0.004239957025446042)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:09:54 -- STEP: 351/406 -- GLOBAL_STEP: 22275\u001b[0m\n",
      "     | > loss: -0.010954663157463074  (-0.02625042943023887)\n",
      "     | > log_mle: -0.25859534740448  (-0.2540704287015475)\n",
      "     | > loss_dur: 0.2476406842470169  (0.22781999927130858)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.6377, device='cuda:0')  (tensor(13.3188, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.6466  (0.41133046150207503)\n",
      "     | > loader_time: 0.005  (0.004283007733162991)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:10:09 -- STEP: 376/406 -- GLOBAL_STEP: 22300\u001b[0m\n",
      "     | > loss: -0.007748246192932129  (-0.026456720334418267)\n",
      "     | > log_mle: -0.262357234954834  (-0.2549915782948758)\n",
      "     | > loss_dur: 0.25460898876190186  (0.2285348579604575)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.0919, device='cuda:0')  (tensor(13.5187, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.5635  (0.42286774769742425)\n",
      "     | > loader_time: 0.005  (0.004330994600945331)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:10:26 -- STEP: 401/406 -- GLOBAL_STEP: 22325\u001b[0m\n",
      "     | > loss: -0.03574107587337494  (-0.02651673358426129)\n",
      "     | > log_mle: -0.26666247844696045  (-0.25580092826091744)\n",
      "     | > loss_dur: 0.2309214025735855  (0.2292841946766561)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.9613, device='cuda:0')  (tensor(13.7344, device='cuda:0'))\n",
      "     | > current_lr: 1.35e-05 \n",
      "     | > step_time: 0.7121  (0.4370130160800238)\n",
      "     | > loader_time: 0.004  (0.004380468715753343)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09771385788917542 \u001b[0m(+0.0022070705890655518)\n",
      "     | > avg_loss:\u001b[92m -0.06093394011259079 \u001b[0m(-0.004561666399240494)\n",
      "     | > avg_log_mle:\u001b[92m -0.27320970594882965 \u001b[0m(-0.0028364360332489014)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21227576583623886 \u001b[0m(-0.0017252303659915924)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_22330.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 55/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:10:59) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:11:21 -- STEP: 20/406 -- GLOBAL_STEP: 22350\u001b[0m\n",
      "     | > loss: -0.024574697017669678  (-0.05162223353981972)\n",
      "     | > log_mle: -0.21993589401245117  (-0.2375223457813263)\n",
      "     | > loss_dur: 0.1953611969947815  (0.1859001122415066)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.9339, device='cuda:0')  (tensor(7.2492, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.2622  (0.25488039255142214)\n",
      "     | > loader_time: 0.002  (0.013613402843475342)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:11:28 -- STEP: 45/406 -- GLOBAL_STEP: 22375\u001b[0m\n",
      "     | > loss: -0.02852773666381836  (-0.040101157956653165)\n",
      "     | > log_mle: -0.2285526990890503  (-0.23648333814409045)\n",
      "     | > loss_dur: 0.20002496242523193  (0.19638218018743728)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.8259, device='cuda:0')  (tensor(8.1268, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.3053  (0.26492878595987956)\n",
      "     | > loader_time: 0.003  (0.007362863752577039)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:11:35 -- STEP: 70/406 -- GLOBAL_STEP: 22400\u001b[0m\n",
      "     | > loss: -0.0541406124830246  (-0.03652413359710149)\n",
      "     | > log_mle: -0.2526019811630249  (-0.23928961413247243)\n",
      "     | > loss_dur: 0.1984613686800003  (0.20276548053537097)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.3240, device='cuda:0')  (tensor(9.0218, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.2813  (0.27800900254930766)\n",
      "     | > loader_time: 0.002  (0.005620012964521135)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:11:44 -- STEP: 95/406 -- GLOBAL_STEP: 22425\u001b[0m\n",
      "     | > loss: -0.015987485647201538  (-0.034840320285997886)\n",
      "     | > log_mle: -0.24781250953674316  (-0.24242640921944067)\n",
      "     | > loss_dur: 0.23182502388954163  (0.20758608893344277)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.3998, device='cuda:0')  (tensor(10.1437, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.3033  (0.2916854080400969)\n",
      "     | > loader_time: 0.003  (0.004920746150769685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:11:52 -- STEP: 120/406 -- GLOBAL_STEP: 22450\u001b[0m\n",
      "     | > loss: -0.03667627274990082  (-0.033932424957553546)\n",
      "     | > log_mle: -0.2612713575363159  (-0.24495726625124614)\n",
      "     | > loss_dur: 0.2245950847864151  (0.2110248412936926)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.3337, device='cuda:0')  (tensor(10.8960, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.3253  (0.3038171112537384)\n",
      "     | > loader_time: 0.003  (0.004546167453130087)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:12:02 -- STEP: 145/406 -- GLOBAL_STEP: 22475\u001b[0m\n",
      "     | > loss: -0.04577335715293884  (-0.03311286332278416)\n",
      "     | > log_mle: -0.2478111982345581  (-0.24706324791086132)\n",
      "     | > loss_dur: 0.20203784108161926  (0.21395038458807714)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.7067, device='cuda:0')  (tensor(11.6791, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.3573  (0.31531351516986705)\n",
      "     | > loader_time: 0.004  (0.0043628758397595635)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:12:12 -- STEP: 170/406 -- GLOBAL_STEP: 22500\u001b[0m\n",
      "     | > loss: -0.03388117253780365  (-0.032031008601188654)\n",
      "     | > log_mle: -0.25768840312957764  (-0.24837462060591753)\n",
      "     | > loss_dur: 0.223807230591774  (0.21634361200472887)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.1621, device='cuda:0')  (tensor(13.1447, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.3603  (0.32621351971345774)\n",
      "     | > loader_time: 0.004  (0.004257043670205508)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:12:22 -- STEP: 195/406 -- GLOBAL_STEP: 22525\u001b[0m\n",
      "     | > loss: -0.030123502016067505  (-0.0318098566471002)\n",
      "     | > log_mle: -0.2442312240600586  (-0.24998887991293883)\n",
      "     | > loss_dur: 0.2141077220439911  (0.21817902326583863)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.7236, device='cuda:0')  (tensor(13.2268, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.3954  (0.33892285029093394)\n",
      "     | > loader_time: 0.003  (0.004178367516933339)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:12:33 -- STEP: 220/406 -- GLOBAL_STEP: 22550\u001b[0m\n",
      "     | > loss: -0.049765363335609436  (-0.03149267746643587)\n",
      "     | > log_mle: -0.2852667570114136  (-0.25153714851899567)\n",
      "     | > loss_dur: 0.23550139367580414  (0.22004447105255995)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.1122, device='cuda:0')  (tensor(13.5364, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.4034  (0.3497991962866347)\n",
      "     | > loader_time: 0.004  (0.004167606613852756)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:12:45 -- STEP: 245/406 -- GLOBAL_STEP: 22575\u001b[0m\n",
      "     | > loss: -0.027317360043525696  (-0.031262734471535186)\n",
      "     | > log_mle: -0.260931134223938  (-0.2529341629573275)\n",
      "     | > loss_dur: 0.2336137741804123  (0.22167142848579252)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.3659, device='cuda:0')  (tensor(13.7302, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.5375  (0.3611767039007068)\n",
      "     | > loader_time: 0.004  (0.004163124123398134)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:12:58 -- STEP: 270/406 -- GLOBAL_STEP: 22600\u001b[0m\n",
      "     | > loss: -0.03464466333389282  (-0.03149006361210786)\n",
      "     | > log_mle: -0.26719093322753906  (-0.2540416841153743)\n",
      "     | > loss_dur: 0.23254626989364624  (0.22255162050326666)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.2572, device='cuda:0')  (tensor(13.8128, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.4424  (0.3733202501579565)\n",
      "     | > loader_time: 0.004  (0.0041743048915156575)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:13:10 -- STEP: 295/406 -- GLOBAL_STEP: 22625\u001b[0m\n",
      "     | > loss: -0.029402002692222595  (-0.031497757010540715)\n",
      "     | > log_mle: -0.26803863048553467  (-0.2550637859409135)\n",
      "     | > loss_dur: 0.23863662779331207  (0.2235660289303731)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.8527, device='cuda:0')  (tensor(13.7323, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.5885  (0.38408414307287164)\n",
      "     | > loader_time: 0.005  (0.004200545812057234)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:13:24 -- STEP: 320/406 -- GLOBAL_STEP: 22650\u001b[0m\n",
      "     | > loss: -0.022892162203788757  (-0.031240672711282957)\n",
      "     | > log_mle: -0.25584495067596436  (-0.25593377538025347)\n",
      "     | > loss_dur: 0.2329527884721756  (0.22469310266897083)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.6738, device='cuda:0')  (tensor(13.6208, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.5065  (0.39626586735248537)\n",
      "     | > loader_time: 0.005  (0.004238331317901609)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:13:38 -- STEP: 345/406 -- GLOBAL_STEP: 22675\u001b[0m\n",
      "     | > loss: -0.03661221265792847  (-0.030871397818344217)\n",
      "     | > log_mle: -0.2738933563232422  (-0.25673296589782235)\n",
      "     | > loss_dur: 0.23728114366531372  (0.2258615680794785)\n",
      "     | > amp_scaler: 16384.0  (8381.959420289852)\n",
      "     | > grad_norm: tensor(24.4227, device='cuda:0')  (tensor(13.8957, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.6426  (0.4079781677411948)\n",
      "     | > loader_time: 0.005  (0.0042880493661631705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:13:53 -- STEP: 370/406 -- GLOBAL_STEP: 22700\u001b[0m\n",
      "     | > loss: -0.049388304352760315  (-0.03093196508046742)\n",
      "     | > log_mle: -0.2841930389404297  (-0.25766321066263514)\n",
      "     | > loss_dur: 0.23480473458766937  (0.22673124558216817)\n",
      "     | > amp_scaler: 16384.0  (8922.637837837834)\n",
      "     | > grad_norm: tensor(24.1556, device='cuda:0')  (tensor(14.1027, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.5285  (0.4193447261243251)\n",
      "     | > loader_time: 0.005  (0.004341863941501926)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:14:09 -- STEP: 395/406 -- GLOBAL_STEP: 22725\u001b[0m\n",
      "     | > loss: -0.03264985978603363  (-0.030993992656092092)\n",
      "     | > log_mle: -0.27874815464019775  (-0.25842330757575666)\n",
      "     | > loss_dur: 0.24609829485416412  (0.2274293149196649)\n",
      "     | > amp_scaler: 16384.0  (9394.875949367088)\n",
      "     | > grad_norm: tensor(17.5047, device='cuda:0')  (tensor(14.2697, device='cuda:0'))\n",
      "     | > current_lr: 1.375e-05 \n",
      "     | > step_time: 0.7207  (0.43266034126281716)\n",
      "     | > loader_time: 0.006  (0.004386351983758468)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10059171915054321 \u001b[0m(+0.002877861261367798)\n",
      "     | > avg_loss:\u001b[92m -0.06573522090911865 \u001b[0m(-0.0048012807965278625)\n",
      "     | > avg_log_mle:\u001b[92m -0.2767373025417328 \u001b[0m(-0.003527596592903137)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21100208163261414 \u001b[0m(-0.0012736842036247253)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_22736.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 56/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:14:47) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:15:06 -- STEP: 14/406 -- GLOBAL_STEP: 22750\u001b[0m\n",
      "     | > loss: -0.053732484579086304  (-0.05964286944695881)\n",
      "     | > log_mle: -0.2524470090866089  (-0.24247564588274276)\n",
      "     | > loss_dur: 0.19871452450752258  (0.18283277643578394)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(26.7627, device='cuda:0')  (tensor(8.8374, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.2592  (0.2570904663630894)\n",
      "     | > loader_time: 0.002  (0.018231102398463657)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:15:13 -- STEP: 39/406 -- GLOBAL_STEP: 22775\u001b[0m\n",
      "     | > loss: -0.03152664005756378  (-0.045524961673296414)\n",
      "     | > log_mle: -0.23391211032867432  (-0.23943366148532966)\n",
      "     | > loss_dur: 0.20238547027111053  (0.19390869981203324)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(5.4817, device='cuda:0')  (tensor(7.6786, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.2632  (0.262699903585972)\n",
      "     | > loader_time: 0.002  (0.00798185666402181)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:15:21 -- STEP: 64/406 -- GLOBAL_STEP: 22800\u001b[0m\n",
      "     | > loss: -0.056823283433914185  (-0.0400590100325644)\n",
      "     | > log_mle: -0.24124515056610107  (-0.24096877314150333)\n",
      "     | > loss_dur: 0.1844218671321869  (0.20090976310893893)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.2549, device='cuda:0')  (tensor(8.6510, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.2883  (0.2765634432435037)\n",
      "     | > loader_time: 0.003  (0.00578673928976059)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:15:29 -- STEP: 89/406 -- GLOBAL_STEP: 22825\u001b[0m\n",
      "     | > loss: -0.03170450031757355  (-0.03810310631655575)\n",
      "     | > log_mle: -0.2432868480682373  (-0.24406354480914855)\n",
      "     | > loss_dur: 0.21158234775066376  (0.2059604384925928)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.3245, device='cuda:0')  (tensor(9.6104, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.3023  (0.2920178911659155)\n",
      "     | > loader_time: 0.003  (0.004948441901903477)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:15:38 -- STEP: 114/406 -- GLOBAL_STEP: 22850\u001b[0m\n",
      "     | > loss: -0.04815813899040222  (-0.037945184529873346)\n",
      "     | > log_mle: -0.27453529834747314  (-0.24742950263776278)\n",
      "     | > loss_dur: 0.22637715935707092  (0.20948431810788942)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(17.3277, device='cuda:0')  (tensor(10.0835, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.3874  (0.3042849971537004)\n",
      "     | > loader_time: 0.003  (0.0045129353539985545)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:15:47 -- STEP: 139/406 -- GLOBAL_STEP: 22875\u001b[0m\n",
      "     | > loss: -0.040189072489738464  (-0.03655433365338139)\n",
      "     | > log_mle: -0.2599310874938965  (-0.2494893828741938)\n",
      "     | > loss_dur: 0.21974201500415802  (0.2129350492208124)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(14.8238, device='cuda:0')  (tensor(10.6215, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.4134  (0.31527898637510887)\n",
      "     | > loader_time: 0.004  (0.0043205391588828565)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:15:57 -- STEP: 164/406 -- GLOBAL_STEP: 22900\u001b[0m\n",
      "     | > loss: -0.036272838711738586  (-0.035779239473546415)\n",
      "     | > log_mle: -0.25151216983795166  (-0.25103721749491803)\n",
      "     | > loss_dur: 0.21523933112621307  (0.21525797802137164)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(17.2159, device='cuda:0')  (tensor(11.6638, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.3573  (0.3260154491517602)\n",
      "     | > loader_time: 0.004  (0.004192909089530388)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:16:08 -- STEP: 189/406 -- GLOBAL_STEP: 22925\u001b[0m\n",
      "     | > loss: -0.04308193922042847  (-0.035649201463139234)\n",
      "     | > log_mle: -0.261940598487854  (-0.25276590276647487)\n",
      "     | > loss_dur: 0.21885865926742554  (0.2171167013033357)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.5361, device='cuda:0')  (tensor(12.5962, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.4574  (0.33775637767933026)\n",
      "     | > loader_time: 0.003  (0.0041572442130437)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:16:18 -- STEP: 214/406 -- GLOBAL_STEP: 22950\u001b[0m\n",
      "     | > loss: -0.044174209237098694  (-0.03524899120642757)\n",
      "     | > log_mle: -0.26590263843536377  (-0.2540977808916678)\n",
      "     | > loss_dur: 0.22172842919826508  (0.2188487896852404)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(21.1356, device='cuda:0')  (tensor(13.3894, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.4954  (0.3489242446756808)\n",
      "     | > loader_time: 0.004  (0.004139295248227702)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:16:30 -- STEP: 239/406 -- GLOBAL_STEP: 22975\u001b[0m\n",
      "     | > loss: -0.03332127630710602  (-0.0349801644745232)\n",
      "     | > log_mle: -0.2714073657989502  (-0.255569074941978)\n",
      "     | > loss_dur: 0.23808608949184418  (0.22058891046745507)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(10.0833, device='cuda:0')  (tensor(13.9801, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.5295  (0.3591712658375376)\n",
      "     | > loader_time: 0.004  (0.0041376496957435775)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:16:42 -- STEP: 264/406 -- GLOBAL_STEP: 23000\u001b[0m\n",
      "     | > loss: -0.0328730046749115  (-0.03530331813927851)\n",
      "     | > log_mle: -0.26049208641052246  (-0.256742760990605)\n",
      "     | > loss_dur: 0.22761908173561096  (0.2214394428513267)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(20.3284, device='cuda:0')  (tensor(14.4090, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.4354  (0.3717920906615979)\n",
      "     | > loader_time: 0.004  (0.004147694869474931)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_23000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:16:59 -- STEP: 289/406 -- GLOBAL_STEP: 23025\u001b[0m\n",
      "     | > loss: -0.03720846772193909  (-0.03528128007497753)\n",
      "     | > log_mle: -0.25977957248687744  (-0.2577777040870955)\n",
      "     | > loss_dur: 0.22257110476493835  (0.22249642401211805)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(24.7621, device='cuda:0')  (tensor(14.7560, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.4524  (0.3826588016892799)\n",
      "     | > loader_time: 0.004  (0.004173346456771905)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:17:13 -- STEP: 314/406 -- GLOBAL_STEP: 23050\u001b[0m\n",
      "     | > loss: -0.03132206201553345  (-0.03507935991332786)\n",
      "     | > log_mle: -0.27310502529144287  (-0.25867035700257407)\n",
      "     | > loss_dur: 0.24178296327590942  (0.22359099708924618)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(16.9806, device='cuda:0')  (tensor(14.7944, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.4884  (0.3949955139949824)\n",
      "     | > loader_time: 0.005  (0.004210839605635139)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:17:27 -- STEP: 339/406 -- GLOBAL_STEP: 23075\u001b[0m\n",
      "     | > loss: -0.027228444814682007  (-0.034705981304511885)\n",
      "     | > log_mle: -0.26954972743988037  (-0.2593425793633698)\n",
      "     | > loss_dur: 0.24232128262519836  (0.22463659805885802)\n",
      "     | > amp_scaler: 8192.0  (16214.84365781711)\n",
      "     | > grad_norm: tensor(18.0488, device='cuda:0')  (tensor(15.1751, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.6496  (0.4063729037225774)\n",
      "     | > loader_time: 0.005  (0.004260501327064537)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:17:41 -- STEP: 364/406 -- GLOBAL_STEP: 23100\u001b[0m\n",
      "     | > loss: -0.03598269820213318  (-0.03469385546478593)\n",
      "     | > log_mle: -0.27435827255249023  (-0.260216238406988)\n",
      "     | > loss_dur: 0.23837557435035706  (0.22552238294220225)\n",
      "     | > amp_scaler: 8192.0  (15663.824175824177)\n",
      "     | > grad_norm: tensor(21.4987, device='cuda:0')  (tensor(15.4042, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.6586  (0.4176136124265063)\n",
      "     | > loader_time: 0.005  (0.004303342038458519)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:17:57 -- STEP: 389/406 -- GLOBAL_STEP: 23125\u001b[0m\n",
      "     | > loss: -0.03735579550266266  (-0.03476555898287605)\n",
      "     | > log_mle: -0.2828911542892456  (-0.26099569877193013)\n",
      "     | > loss_dur: 0.24553535878658295  (0.22623013978905412)\n",
      "     | > amp_scaler: 8192.0  (15183.629820051414)\n",
      "     | > grad_norm: tensor(24.7236, device='cuda:0')  (tensor(15.4485, device='cuda:0'))\n",
      "     | > current_lr: 1.4e-05 \n",
      "     | > step_time: 0.5625  (0.4304456735331479)\n",
      "     | > loader_time: 0.005  (0.004363841446628908)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09008482098579407 \u001b[0m(-0.010506898164749146)\n",
      "     | > avg_loss:\u001b[92m -0.06758786924183369 \u001b[0m(-0.0018526483327150345)\n",
      "     | > avg_log_mle:\u001b[92m -0.28011226654052734 \u001b[0m(-0.0033749639987945557)\n",
      "     | > avg_loss_dur:\u001b[91m 0.21252439729869366 \u001b[0m(+0.0015223156660795212)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_23142.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 57/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:18:39) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:18:57 -- STEP: 8/406 -- GLOBAL_STEP: 23150\u001b[0m\n",
      "     | > loss: -0.06868353486061096  (-0.06924027018249035)\n",
      "     | > log_mle: -0.26092052459716797  (-0.24475808441638947)\n",
      "     | > loss_dur: 0.192236989736557  (0.17551781423389912)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.4294, device='cuda:0')  (tensor(6.1843, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.2532  (0.25548192858695984)\n",
      "     | > loader_time: 0.001  (0.001751720905303955)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:19:03 -- STEP: 33/406 -- GLOBAL_STEP: 23175\u001b[0m\n",
      "     | > loss: -0.03739708662033081  (-0.054100309357498634)\n",
      "     | > log_mle: -0.23629212379455566  (-0.2427116957577792)\n",
      "     | > loss_dur: 0.19889503717422485  (0.18861138640028058)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.7443, device='cuda:0')  (tensor(8.2065, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.2863  (0.25920508124611596)\n",
      "     | > loader_time: 0.002  (0.0018501426234389796)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:19:11 -- STEP: 58/406 -- GLOBAL_STEP: 23200\u001b[0m\n",
      "     | > loss: -0.03366221487522125  (-0.04457979520847057)\n",
      "     | > log_mle: -0.24285626411437988  (-0.2429211817938706)\n",
      "     | > loss_dur: 0.20919404923915863  (0.19834138658540001)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.8938, device='cuda:0')  (tensor(10.5906, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.3163  (0.2722299304501764)\n",
      "     | > loader_time: 0.003  (0.0020708174541078754)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:19:19 -- STEP: 83/406 -- GLOBAL_STEP: 23225\u001b[0m\n",
      "     | > loss: -0.028256520628929138  (-0.042176931916949274)\n",
      "     | > log_mle: -0.25389957427978516  (-0.24545604636870236)\n",
      "     | > loss_dur: 0.22564305365085602  (0.2032791144517531)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.7034, device='cuda:0')  (tensor(11.2217, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.3523  (0.28582580118294215)\n",
      "     | > loader_time: 0.004  (0.002242909856589443)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:19:27 -- STEP: 108/406 -- GLOBAL_STEP: 23250\u001b[0m\n",
      "     | > loss: -0.03492787480354309  (-0.041538228453309456)\n",
      "     | > log_mle: -0.2577331066131592  (-0.24852432145012748)\n",
      "     | > loss_dur: 0.2228052318096161  (0.20698609299681806)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.0382, device='cuda:0')  (tensor(11.9495, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.3173  (0.29747383903574065)\n",
      "     | > loader_time: 0.003  (0.002381655904981825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:19:36 -- STEP: 133/406 -- GLOBAL_STEP: 23275\u001b[0m\n",
      "     | > loss: -0.04312409460544586  (-0.04130737886841136)\n",
      "     | > log_mle: -0.26434314250946045  (-0.25136707689529075)\n",
      "     | > loss_dur: 0.2212190479040146  (0.21005969802687938)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.0729, device='cuda:0')  (tensor(12.3719, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.3343  (0.30814444929137264)\n",
      "     | > loader_time: 0.002  (0.00250591550554548)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:19:46 -- STEP: 158/406 -- GLOBAL_STEP: 23300\u001b[0m\n",
      "     | > loss: -0.04337210953235626  (-0.04047539320927632)\n",
      "     | > log_mle: -0.27069878578186035  (-0.25315862894058233)\n",
      "     | > loss_dur: 0.2273266762495041  (0.21268323573130596)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.4152, device='cuda:0')  (tensor(12.5679, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.3563  (0.3197206394581855)\n",
      "     | > loader_time: 0.003  (0.002635233009917827)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:19:56 -- STEP: 183/406 -- GLOBAL_STEP: 23325\u001b[0m\n",
      "     | > loss: -0.043186649680137634  (-0.04001351604696179)\n",
      "     | > log_mle: -0.26851701736450195  (-0.2546979560226689)\n",
      "     | > loss_dur: 0.22533036768436432  (0.21468443997570727)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.5300, device='cuda:0')  (tensor(13.0974, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.4604  (0.3319953947119373)\n",
      "     | > loader_time: 0.005  (0.0027784076544756435)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:20:07 -- STEP: 208/406 -- GLOBAL_STEP: 23350\u001b[0m\n",
      "     | > loss: -0.041339412331581116  (-0.03950766681765134)\n",
      "     | > log_mle: -0.2735499143600464  (-0.2561116849000635)\n",
      "     | > loss_dur: 0.23221050202846527  (0.2166040180824124)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(31.2850, device='cuda:0')  (tensor(13.6088, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.4864  (0.3435715402548129)\n",
      "     | > loader_time: 0.003  (0.0029016022498791023)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:20:18 -- STEP: 233/406 -- GLOBAL_STEP: 23375\u001b[0m\n",
      "     | > loss: -0.03987990319728851  (-0.03949772915103404)\n",
      "     | > log_mle: -0.2741192579269409  (-0.2576880188970604)\n",
      "     | > loss_dur: 0.2342393547296524  (0.2181902897460266)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.1867, device='cuda:0')  (tensor(14.0705, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.4324  (0.3535012390480532)\n",
      "     | > loader_time: 0.004  (0.003032742651747019)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:20:31 -- STEP: 258/406 -- GLOBAL_STEP: 23400\u001b[0m\n",
      "     | > loss: -0.0324002206325531  (-0.039624369017375524)\n",
      "     | > log_mle: -0.26699376106262207  (-0.2589789947798083)\n",
      "     | > loss_dur: 0.23459354043006897  (0.21935462576243303)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.6712, device='cuda:0')  (tensor(14.3229, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.4404  (0.3667904147806093)\n",
      "     | > loader_time: 0.004  (0.0031849885171698037)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:20:43 -- STEP: 283/406 -- GLOBAL_STEP: 23425\u001b[0m\n",
      "     | > loss: -0.030912041664123535  (-0.03969275961916355)\n",
      "     | > log_mle: -0.2711174488067627  (-0.260201555680049)\n",
      "     | > loss_dur: 0.24020540714263916  (0.22050879606088566)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.4569, device='cuda:0')  (tensor(14.4710, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.4584  (0.377922646148466)\n",
      "     | > loader_time: 0.006  (0.003303285201109761)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:20:56 -- STEP: 308/406 -- GLOBAL_STEP: 23450\u001b[0m\n",
      "     | > loss: -0.04670761525630951  (-0.039465988708006876)\n",
      "     | > log_mle: -0.2766913175582886  (-0.2611616339002338)\n",
      "     | > loss_dur: 0.22998370230197906  (0.22169564519222681)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.9415, device='cuda:0')  (tensor(14.4481, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.4834  (0.3897889960895886)\n",
      "     | > loader_time: 0.004  (0.0033958639417375836)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:21:10 -- STEP: 333/406 -- GLOBAL_STEP: 23475\u001b[0m\n",
      "     | > loss: -0.0467604398727417  (-0.03927516373428139)\n",
      "     | > log_mle: -0.2788732051849365  (-0.26185089689833274)\n",
      "     | > loss_dur: 0.23211276531219482  (0.22257573316405127)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.1306, device='cuda:0')  (tensor(14.6281, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.4844  (0.4011660545795888)\n",
      "     | > loader_time: 0.004  (0.0034805582808302687)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:21:25 -- STEP: 358/406 -- GLOBAL_STEP: 23500\u001b[0m\n",
      "     | > loss: -0.059388667345047  (-0.038929665638081846)\n",
      "     | > log_mle: -0.2894552946090698  (-0.2626599979134246)\n",
      "     | > loss_dur: 0.23006662726402283  (0.22373033227534267)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.4453, device='cuda:0')  (tensor(15.1335, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.5285  (0.413187996635224)\n",
      "     | > loader_time: 0.005  (0.0035813986922109595)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:21:40 -- STEP: 383/406 -- GLOBAL_STEP: 23525\u001b[0m\n",
      "     | > loss: -0.02605774998664856  (-0.03902840945023468)\n",
      "     | > log_mle: -0.27341198921203613  (-0.2634374438626959)\n",
      "     | > loss_dur: 0.24735423922538757  (0.2244090344124612)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.3212, device='cuda:0')  (tensor(15.3099, device='cuda:0'))\n",
      "     | > current_lr: 1.425e-05 \n",
      "     | > step_time: 0.6766  (0.425579606397345)\n",
      "     | > loader_time: 0.006  (0.0036716834683331125)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09307271242141724 \u001b[0m(+0.002987891435623169)\n",
      "     | > avg_loss:\u001b[92m -0.07104804366827011 \u001b[0m(-0.0034601744264364243)\n",
      "     | > avg_log_mle:\u001b[92m -0.28206096589565277 \u001b[0m(-0.0019486993551254272)\n",
      "     | > avg_loss_dur:\u001b[92m 0.21101292222738266 \u001b[0m(-0.001511475071310997)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_23548.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 58/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:22:26) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:22:42 -- STEP: 2/406 -- GLOBAL_STEP: 23550\u001b[0m\n",
      "     | > loss: -0.11558881402015686  (-0.0948062390089035)\n",
      "     | > log_mle: -0.2647874355316162  (-0.25701797008514404)\n",
      "     | > loss_dur: 0.14919862151145935  (0.16221173107624054)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.9205, device='cuda:0')  (tensor(4.4649, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.2552  (0.2617378234863281)\n",
      "     | > loader_time: 0.001  (0.001501321792602539)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:22:49 -- STEP: 27/406 -- GLOBAL_STEP: 23575\u001b[0m\n",
      "     | > loss: -0.05804945528507233  (-0.059479599749600445)\n",
      "     | > log_mle: -0.2461637258529663  (-0.24598499139149985)\n",
      "     | > loss_dur: 0.18811427056789398  (0.1865053916418994)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.7265, device='cuda:0')  (tensor(9.0454, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.2602  (0.25819726343508126)\n",
      "     | > loader_time: 0.002  (0.008489211400349935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:22:56 -- STEP: 52/406 -- GLOBAL_STEP: 23600\u001b[0m\n",
      "     | > loss: -0.014909490942955017  (-0.04901275411248207)\n",
      "     | > log_mle: -0.2418975830078125  (-0.24630191234441903)\n",
      "     | > loss_dur: 0.22698809206485748  (0.19728915823193696)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.9680, device='cuda:0')  (tensor(9.2629, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.2742  (0.2698987859946031)\n",
      "     | > loader_time: 0.002  (0.00550501163189228)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:23:04 -- STEP: 77/406 -- GLOBAL_STEP: 23625\u001b[0m\n",
      "     | > loss: -0.02541176974773407  (-0.04683388905091719)\n",
      "     | > log_mle: -0.24665653705596924  (-0.2486603848345868)\n",
      "     | > loss_dur: 0.22124476730823517  (0.20182649578366962)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.0807, device='cuda:0')  (tensor(11.0601, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.3513  (0.28257866339250043)\n",
      "     | > loader_time: 0.003  (0.004549571446010046)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:23:12 -- STEP: 102/406 -- GLOBAL_STEP: 23650\u001b[0m\n",
      "     | > loss: -0.05372069776058197  (-0.04545086096314823)\n",
      "     | > log_mle: -0.2698383331298828  (-0.25139134537939944)\n",
      "     | > loss_dur: 0.21611763536930084  (0.2059404844162511)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.1865, device='cuda:0')  (tensor(12.8743, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.3763  (0.29563902639875234)\n",
      "     | > loader_time: 0.003  (0.00412139238095751)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:23:21 -- STEP: 127/406 -- GLOBAL_STEP: 23675\u001b[0m\n",
      "     | > loss: -0.0448727160692215  (-0.044965759271711814)\n",
      "     | > log_mle: -0.26290035247802734  (-0.25392860502708614)\n",
      "     | > loss_dur: 0.21802763640880585  (0.20896284575537433)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.4931, device='cuda:0')  (tensor(13.6085, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.3233  (0.3072301459124709)\n",
      "     | > loader_time: 0.004  (0.003964247666006013)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:23:31 -- STEP: 152/406 -- GLOBAL_STEP: 23700\u001b[0m\n",
      "     | > loss: -0.013845369219779968  (-0.044461395199361604)\n",
      "     | > log_mle: -0.25866127014160156  (-0.25588279021413707)\n",
      "     | > loss_dur: 0.2448159009218216  (0.21142139501477542)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.5669, device='cuda:0')  (tensor(14.0965, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.4364  (0.3187156429416256)\n",
      "     | > loader_time: 0.004  (0.0038851609355524965)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:23:41 -- STEP: 177/406 -- GLOBAL_STEP: 23725\u001b[0m\n",
      "     | > loss: -0.07061122357845306  (-0.044145598081545646)\n",
      "     | > log_mle: -0.2796463966369629  (-0.25727150669205673)\n",
      "     | > loss_dur: 0.20903517305850983  (0.21312590861051095)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.5293, device='cuda:0')  (tensor(14.7425, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.4684  (0.33007250936691374)\n",
      "     | > loader_time: 0.004  (0.0038736135946155267)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:23:52 -- STEP: 202/406 -- GLOBAL_STEP: 23750\u001b[0m\n",
      "     | > loss: -0.02300034463405609  (-0.043708794114023154)\n",
      "     | > log_mle: -0.26064276695251465  (-0.258733060100291)\n",
      "     | > loss_dur: 0.23764242231845856  (0.2150242659862679)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.4716, device='cuda:0')  (tensor(14.9748, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.3974  (0.34215610570246635)\n",
      "     | > loader_time: 0.004  (0.003855047839702946)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:24:03 -- STEP: 227/406 -- GLOBAL_STEP: 23775\u001b[0m\n",
      "     | > loss: -0.021009042859077454  (-0.043464355859987536)\n",
      "     | > log_mle: -0.25943517684936523  (-0.2602380839738552)\n",
      "     | > loss_dur: 0.23842613399028778  (0.21677372811386764)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.5120, device='cuda:0')  (tensor(15.3404, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.4034  (0.35221749360340815)\n",
      "     | > loader_time: 0.004  (0.003884641084376936)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:24:15 -- STEP: 252/406 -- GLOBAL_STEP: 23800\u001b[0m\n",
      "     | > loss: -0.04949820041656494  (-0.0435122556629635)\n",
      "     | > log_mle: -0.273248553276062  (-0.261632075385442)\n",
      "     | > loss_dur: 0.22375035285949707  (0.21811981972247835)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.5904, device='cuda:0')  (tensor(15.6035, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.4314  (0.3644425263480535)\n",
      "     | > loader_time: 0.004  (0.003904394687168182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:24:27 -- STEP: 277/406 -- GLOBAL_STEP: 23825\u001b[0m\n",
      "     | > loss: -0.057294368743896484  (-0.04374977946281433)\n",
      "     | > log_mle: -0.26952338218688965  (-0.2628037606766079)\n",
      "     | > loss_dur: 0.21222901344299316  (0.21905398121379344)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.4069, device='cuda:0')  (tensor(15.5630, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.5445  (0.3759663853834683)\n",
      "     | > loader_time: 0.004  (0.003949446798661986)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:24:40 -- STEP: 302/406 -- GLOBAL_STEP: 23850\u001b[0m\n",
      "     | > loss: -0.0465303510427475  (-0.04352192472148417)\n",
      "     | > log_mle: -0.27928900718688965  (-0.26375052707874236)\n",
      "     | > loss_dur: 0.23275865614414215  (0.22022860235725808)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(33.4611, device='cuda:0')  (tensor(15.6175, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.5835  (0.3876802542351731)\n",
      "     | > loader_time: 0.004  (0.004003611621477745)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:24:54 -- STEP: 327/406 -- GLOBAL_STEP: 23875\u001b[0m\n",
      "     | > loss: -0.04694673418998718  (-0.04334777274627571)\n",
      "     | > log_mle: -0.2740823030471802  (-0.2644595782691186)\n",
      "     | > loss_dur: 0.227135568857193  (0.22111180552284287)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.9533, device='cuda:0')  (tensor(16.0727, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.5175  (0.3991426524765997)\n",
      "     | > loader_time: 0.004  (0.004070932347475572)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:25:08 -- STEP: 352/406 -- GLOBAL_STEP: 23900\u001b[0m\n",
      "     | > loss: -0.04322946071624756  (-0.04303537503900854)\n",
      "     | > log_mle: -0.2684231996536255  (-0.26524230363694107)\n",
      "     | > loss_dur: 0.22519373893737793  (0.2222069285979325)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.1874, device='cuda:0')  (tensor(16.2042, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.5245  (0.41090510717847156)\n",
      "     | > loader_time: 0.005  (0.0041258660229769656)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:25:23 -- STEP: 377/406 -- GLOBAL_STEP: 23925\u001b[0m\n",
      "     | > loss: -0.037587255239486694  (-0.0431246445254875)\n",
      "     | > log_mle: -0.27312278747558594  (-0.26605334617098714)\n",
      "     | > loss_dur: 0.23553553223609924  (0.22292870164549952)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(35.7069, device='cuda:0')  (tensor(17.5536, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.6856  (0.4230559175779714)\n",
      "     | > loader_time: 0.006  (0.004181474210096607)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:25:39 -- STEP: 402/406 -- GLOBAL_STEP: 23950\u001b[0m\n",
      "     | > loss: -0.05523449182510376  (-0.04317055968799403)\n",
      "     | > log_mle: -0.28411543369293213  (-0.26682897675689793)\n",
      "     | > loss_dur: 0.22888094186782837  (0.22365841706890371)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.7871, device='cuda:0')  (tensor(17.5870, device='cuda:0'))\n",
      "     | > current_lr: 1.45e-05 \n",
      "     | > step_time: 0.548  (0.4366348305744913)\n",
      "     | > loader_time: 0.004  (0.004232666978788614)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09759023785591125 \u001b[0m(+0.0045175254344940186)\n",
      "     | > avg_loss:\u001b[91m -0.06838623434305191 \u001b[0m(+0.0026618093252182007)\n",
      "     | > avg_log_mle:\u001b[91m -0.28035545349121094 \u001b[0m(+0.0017055124044418335)\n",
      "     | > avg_loss_dur:\u001b[91m 0.21196921914815903 \u001b[0m(+0.0009562969207763672)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 59/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:26:12) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:26:34 -- STEP: 21/406 -- GLOBAL_STEP: 23975\u001b[0m\n",
      "     | > loss: -0.06565973162651062  (-0.06628571095920745)\n",
      "     | > log_mle: -0.2532268762588501  (-0.24719009512946719)\n",
      "     | > loss_dur: 0.18756714463233948  (0.18090438417025975)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.6712, device='cuda:0')  (tensor(16.1325, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.2592  (0.2566136632646833)\n",
      "     | > loader_time: 0.002  (0.013631639026460193)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:26:40 -- STEP: 46/406 -- GLOBAL_STEP: 24000\u001b[0m\n",
      "     | > loss: -0.04555627703666687  (-0.05542832839748134)\n",
      "     | > log_mle: -0.25093233585357666  (-0.24635202729183694)\n",
      "     | > loss_dur: 0.2053760588169098  (0.19092369889435562)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.5050, device='cuda:0')  (tensor(13.5986, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.2993  (0.2665244911027991)\n",
      "     | > loader_time: 0.002  (0.007485042447629182)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_24000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:26:51 -- STEP: 71/406 -- GLOBAL_STEP: 24025\u001b[0m\n",
      "     | > loss: -0.03661143779754639  (-0.050837164613562566)\n",
      "     | > log_mle: -0.2558107376098633  (-0.24919713215089181)\n",
      "     | > loss_dur: 0.2191992998123169  (0.19835996753732923)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(33.9928, device='cuda:0')  (tensor(14.9907, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.3483  (0.2822438831060704)\n",
      "     | > loader_time: 0.002  (0.005723449545846858)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:26:59 -- STEP: 96/406 -- GLOBAL_STEP: 24050\u001b[0m\n",
      "     | > loss: -0.05068430304527283  (-0.04970385010043779)\n",
      "     | > log_mle: -0.26566314697265625  (-0.2526654141644637)\n",
      "     | > loss_dur: 0.21497884392738342  (0.20296156406402588)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.3269, device='cuda:0')  (tensor(14.7300, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.3713  (0.2951756591598191)\n",
      "     | > loader_time: 0.003  (0.004962697625160216)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:27:08 -- STEP: 121/406 -- GLOBAL_STEP: 24075\u001b[0m\n",
      "     | > loss: -0.043860241770744324  (-0.04909828810159824)\n",
      "     | > log_mle: -0.26157617568969727  (-0.25541189288304866)\n",
      "     | > loss_dur: 0.21771593391895294  (0.20631360478145033)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.9850, device='cuda:0')  (tensor(14.5107, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.3944  (0.30687475204467757)\n",
      "     | > loader_time: 0.003  (0.004566007409213989)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:27:17 -- STEP: 146/406 -- GLOBAL_STEP: 24100\u001b[0m\n",
      "     | > loss: -0.04114529490470886  (-0.0488068864566006)\n",
      "     | > log_mle: -0.2586669921875  (-0.25765308533629344)\n",
      "     | > loss_dur: 0.21752169728279114  (0.20884619887969266)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.5347, device='cuda:0')  (tensor(14.6793, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.4134  (0.3178922542153972)\n",
      "     | > loader_time: 0.004  (0.004366889391859917)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:27:27 -- STEP: 171/406 -- GLOBAL_STEP: 24125\u001b[0m\n",
      "     | > loss: -0.057157471776008606  (-0.048160136965980295)\n",
      "     | > log_mle: -0.2729753255844116  (-0.25932111865595786)\n",
      "     | > loss_dur: 0.21581785380840302  (0.21116098168997738)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.5143, device='cuda:0')  (tensor(15.5388, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.4414  (0.3286090705826966)\n",
      "     | > loader_time: 0.003  (0.004266948030706035)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:27:38 -- STEP: 196/406 -- GLOBAL_STEP: 24150\u001b[0m\n",
      "     | > loss: -0.051881954073905945  (-0.04799142814412408)\n",
      "     | > log_mle: -0.27251136302948  (-0.26088934832689736)\n",
      "     | > loss_dur: 0.22062940895557404  (0.21289792018277304)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.1241, device='cuda:0')  (tensor(15.8752, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.4694  (0.3409975779299835)\n",
      "     | > loader_time: 0.003  (0.004212928061582604)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:27:49 -- STEP: 221/406 -- GLOBAL_STEP: 24175\u001b[0m\n",
      "     | > loss: -0.02363954484462738  (-0.04780058036832248)\n",
      "     | > log_mle: -0.2644357681274414  (-0.2623168025081514)\n",
      "     | > loss_dur: 0.24079622328281403  (0.21451622213982888)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.0649, device='cuda:0')  (tensor(16.1876, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.4084  (0.351358994099889)\n",
      "     | > loader_time: 0.004  (0.004189277666186855)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:28:01 -- STEP: 246/406 -- GLOBAL_STEP: 24200\u001b[0m\n",
      "     | > loss: -0.052813366055488586  (-0.0475846643491489)\n",
      "     | > log_mle: -0.2699153423309326  (-0.2636713550342777)\n",
      "     | > loss_dur: 0.21710197627544403  (0.21608669068512878)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.4276, device='cuda:0')  (tensor(16.9723, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.4274  (0.3626213248183089)\n",
      "     | > loader_time: 0.004  (0.004194804323397999)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:28:13 -- STEP: 271/406 -- GLOBAL_STEP: 24225\u001b[0m\n",
      "     | > loss: -0.05883242189884186  (-0.04775768628419545)\n",
      "     | > log_mle: -0.2863500118255615  (-0.26476272269808493)\n",
      "     | > loss_dur: 0.22751758992671967  (0.21700503641388952)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.9154, device='cuda:0')  (tensor(17.2538, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.4484  (0.37483794574807944)\n",
      "     | > loader_time: 0.005  (0.004221480710919931)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:28:26 -- STEP: 296/406 -- GLOBAL_STEP: 24250\u001b[0m\n",
      "     | > loss: -0.03918918967247009  (-0.047571115044725915)\n",
      "     | > log_mle: -0.27763283252716064  (-0.26569469555004216)\n",
      "     | > loss_dur: 0.23844364285469055  (0.21812358050531633)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.5328, device='cuda:0')  (tensor(17.4719, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.4954  (0.3857012737441708)\n",
      "     | > loader_time: 0.005  (0.004250387887696962)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:28:40 -- STEP: 321/406 -- GLOBAL_STEP: 24275\u001b[0m\n",
      "     | > loss: -0.045093804597854614  (-0.04735289718317468)\n",
      "     | > log_mle: -0.26981043815612793  (-0.2665527609649849)\n",
      "     | > loss_dur: 0.22471663355827332  (0.21919986378181017)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.3502, device='cuda:0')  (tensor(17.6144, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.5025  (0.3977503137796468)\n",
      "     | > loader_time: 0.004  (0.004287255515933408)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:28:54 -- STEP: 346/406 -- GLOBAL_STEP: 24300\u001b[0m\n",
      "     | > loss: -0.051634907722473145  (-0.04708478410292224)\n",
      "     | > log_mle: -0.273237943649292  (-0.2672978401873153)\n",
      "     | > loss_dur: 0.22160303592681885  (0.22021305608439307)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.4804, device='cuda:0')  (tensor(17.9414, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.5285  (0.4093570371583708)\n",
      "     | > loader_time: 0.005  (0.00431016897190513)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:29:08 -- STEP: 371/406 -- GLOBAL_STEP: 24325\u001b[0m\n",
      "     | > loss: -0.03992143273353577  (-0.04704661671363441)\n",
      "     | > log_mle: -0.27991628646850586  (-0.26811564643428015)\n",
      "     | > loss_dur: 0.2399948537349701  (0.2210690297206457)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.4632, device='cuda:0')  (tensor(18.2054, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.5495  (0.4206512938291237)\n",
      "     | > loader_time: 0.005  (0.004359651447306426)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:29:24 -- STEP: 396/406 -- GLOBAL_STEP: 24350\u001b[0m\n",
      "     | > loss: -0.06280285120010376  (-0.0469564132091373)\n",
      "     | > log_mle: -0.29334473609924316  (-0.26871723629007443)\n",
      "     | > loss_dur: 0.2305418848991394  (0.22176082308093706)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.1016, device='cuda:0')  (tensor(18.3246, device='cuda:0'))\n",
      "     | > current_lr: 1.475e-05 \n",
      "     | > step_time: 0.5725  (0.4341937532328597)\n",
      "     | > loader_time: 0.004  (0.004392787061556421)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0973365306854248 \u001b[0m(-0.0002537071704864502)\n",
      "     | > avg_loss:\u001b[92m -0.07967368699610233 \u001b[0m(-0.011287452653050423)\n",
      "     | > avg_log_mle:\u001b[92m -0.28895431756973267 \u001b[0m(-0.008598864078521729)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20928063057363033 \u001b[0m(-0.002688588574528694)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_24360.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 60/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:30:02) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:30:22 -- STEP: 15/406 -- GLOBAL_STEP: 24375\u001b[0m\n",
      "     | > loss: -0.06814561784267426  (-0.07659498651822408)\n",
      "     | > log_mle: -0.2514742612838745  (-0.2538691441218058)\n",
      "     | > loss_dur: 0.18332864344120026  (0.17727415760358176)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.7667, device='cuda:0')  (tensor(9.7073, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.2582  (0.2554987589518229)\n",
      "     | > loader_time: 0.002  (0.015413840611775717)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:30:29 -- STEP: 40/406 -- GLOBAL_STEP: 24400\u001b[0m\n",
      "     | > loss: -0.03618575632572174  (-0.061796223372220974)\n",
      "     | > log_mle: -0.24042391777038574  (-0.2505117326974869)\n",
      "     | > loss_dur: 0.204238161444664  (0.18871550932526587)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.8230, device='cuda:0')  (tensor(10.8114, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.2963  (0.27360749244689947)\n",
      "     | > loader_time: 0.002  (0.007206356525421143)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:30:36 -- STEP: 65/406 -- GLOBAL_STEP: 24425\u001b[0m\n",
      "     | > loss: -0.050628453493118286  (-0.05649828383555778)\n",
      "     | > log_mle: -0.2612816095352173  (-0.25215306648841257)\n",
      "     | > loss_dur: 0.210653156042099  (0.1956547826528549)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.6676, device='cuda:0')  (tensor(11.5698, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3303  (0.2830010450803317)\n",
      "     | > loader_time: 0.002  (0.005312310732327975)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:30:45 -- STEP: 90/406 -- GLOBAL_STEP: 24450\u001b[0m\n",
      "     | > loss: -0.061586931347846985  (-0.05417284402582379)\n",
      "     | > log_mle: -0.2672818899154663  (-0.25503903097576547)\n",
      "     | > loss_dur: 0.20569495856761932  (0.20086618694994185)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.0451, device='cuda:0')  (tensor(12.9264, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3623  (0.2947383191850451)\n",
      "     | > loader_time: 0.003  (0.004615105523003473)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:30:54 -- STEP: 115/406 -- GLOBAL_STEP: 24475\u001b[0m\n",
      "     | > loss: -0.028150290250778198  (-0.05375815280105756)\n",
      "     | > log_mle: -0.25479912757873535  (-0.25809569877126926)\n",
      "     | > loss_dur: 0.22664883732795715  (0.20433754597021186)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.2765, device='cuda:0')  (tensor(14.2198, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3183  (0.30794365302376125)\n",
      "     | > loader_time: 0.003  (0.004264566172724186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:31:03 -- STEP: 140/406 -- GLOBAL_STEP: 24500\u001b[0m\n",
      "     | > loss: -0.06259196996688843  (-0.05263955092855862)\n",
      "     | > log_mle: -0.27305829524993896  (-0.2602699586323328)\n",
      "     | > loss_dur: 0.21046632528305054  (0.20763040770377436)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.7611, device='cuda:0')  (tensor(14.2879, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3423  (0.318077164036887)\n",
      "     | > loader_time: 0.003  (0.0041392905371529735)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:31:13 -- STEP: 165/406 -- GLOBAL_STEP: 24525\u001b[0m\n",
      "     | > loss: -0.05754305422306061  (-0.05192901708863001)\n",
      "     | > log_mle: -0.28139567375183105  (-0.2617613337256691)\n",
      "     | > loss_dur: 0.22385261952877045  (0.20983231663703922)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.8731, device='cuda:0')  (tensor(14.9422, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3643  (0.32819721337520724)\n",
      "     | > loader_time: 0.004  (0.00405196710066362)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:31:23 -- STEP: 190/406 -- GLOBAL_STEP: 24550\u001b[0m\n",
      "     | > loss: -0.03851594030857086  (-0.05189161779064883)\n",
      "     | > log_mle: -0.27862679958343506  (-0.2634196193594681)\n",
      "     | > loss_dur: 0.2401108592748642  (0.21152800156881937)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.4696, device='cuda:0')  (tensor(15.2154, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3816  (0.33969622787676357)\n",
      "     | > loader_time: 0.004  (0.004019172568070264)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:31:34 -- STEP: 215/406 -- GLOBAL_STEP: 24575\u001b[0m\n",
      "     | > loss: -0.05818115174770355  (-0.05147329589655235)\n",
      "     | > log_mle: -0.27902770042419434  (-0.26466996337092197)\n",
      "     | > loss_dur: 0.22084654867649078  (0.21319666747436972)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.2050, device='cuda:0')  (tensor(15.7706, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.3904  (0.3503119257993476)\n",
      "     | > loader_time: 0.005  (0.004012725519579512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:31:45 -- STEP: 240/406 -- GLOBAL_STEP: 24600\u001b[0m\n",
      "     | > loss: -0.0658617615699768  (-0.05104935591419539)\n",
      "     | > log_mle: -0.28715670108795166  (-0.26607895096143086)\n",
      "     | > loss_dur: 0.22129493951797485  (0.2150295950472355)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.6941, device='cuda:0')  (tensor(16.0659, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.5195  (0.36068030297756193)\n",
      "     | > loader_time: 0.004  (0.004024284084637961)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:31:58 -- STEP: 265/406 -- GLOBAL_STEP: 24625\u001b[0m\n",
      "     | > loss: -0.04743863642215729  (-0.051194560190416745)\n",
      "     | > log_mle: -0.28137123584747314  (-0.2672454946445969)\n",
      "     | > loss_dur: 0.23393259942531586  (0.2160509344541802)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.4327, device='cuda:0')  (tensor(16.3592, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.4334  (0.3727372538368657)\n",
      "     | > loader_time: 0.005  (0.0040449997164168465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:32:10 -- STEP: 290/406 -- GLOBAL_STEP: 24650\u001b[0m\n",
      "     | > loss: -0.06989602744579315  (-0.05132234271230372)\n",
      "     | > log_mle: -0.2891108989715576  (-0.26829928858526814)\n",
      "     | > loss_dur: 0.21921487152576447  (0.2169769458729645)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.8959, device='cuda:0')  (tensor(16.8719, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.5775  (0.38332366450079547)\n",
      "     | > loader_time: 0.005  (0.004089745981939909)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:32:24 -- STEP: 315/406 -- GLOBAL_STEP: 24675\u001b[0m\n",
      "     | > loss: -0.07074344158172607  (-0.051204930316834256)\n",
      "     | > log_mle: -0.2896599769592285  (-0.26923315146612736)\n",
      "     | > loss_dur: 0.21891653537750244  (0.2180282211492932)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(28.2455, device='cuda:0')  (tensor(16.9458, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.5125  (0.39500921870034833)\n",
      "     | > loader_time: 0.006  (0.004130561768062534)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:32:38 -- STEP: 340/406 -- GLOBAL_STEP: 24700\u001b[0m\n",
      "     | > loss: -0.025815561413764954  (-0.05075213142177641)\n",
      "     | > log_mle: -0.26157498359680176  (-0.2698860245592453)\n",
      "     | > loss_dur: 0.2357594221830368  (0.219133893137469)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.0083, device='cuda:0')  (tensor(17.0504, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.5105  (0.4062863749616286)\n",
      "     | > loader_time: 0.005  (0.004185983713935405)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:32:52 -- STEP: 365/406 -- GLOBAL_STEP: 24725\u001b[0m\n",
      "     | > loss: -0.050966933369636536  (-0.05080443322658542)\n",
      "     | > log_mle: -0.2816275358200073  (-0.27077777712312445)\n",
      "     | > loss_dur: 0.2306606024503708  (0.21997334389653925)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.5101, device='cuda:0')  (tensor(17.3224, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.5595  (0.41738978412053357)\n",
      "     | > loader_time: 0.005  (0.004233818184839536)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:33:08 -- STEP: 390/406 -- GLOBAL_STEP: 24750\u001b[0m\n",
      "     | > loss: -0.071070596575737  (-0.05083563583783617)\n",
      "     | > log_mle: -0.2913569211959839  (-0.27145652862695535)\n",
      "     | > loss_dur: 0.2202863246202469  (0.22062089278911934)\n",
      "     | > amp_scaler: 4096.0  (7939.9384615384615)\n",
      "     | > grad_norm: tensor(19.3606, device='cuda:0')  (tensor(17.8055, device='cuda:0'))\n",
      "     | > current_lr: 1.4999999999999999e-05 \n",
      "     | > step_time: 0.6966  (0.4301802323414729)\n",
      "     | > loader_time: 0.005  (0.004293491290165829)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09845322370529175 \u001b[0m(+0.0011166930198669434)\n",
      "     | > avg_loss:\u001b[92m -0.08564320579171181 \u001b[0m(-0.005969518795609474)\n",
      "     | > avg_log_mle:\u001b[92m -0.29193392395973206 \u001b[0m(-0.0029796063899993896)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20629071816802025 \u001b[0m(-0.0029899124056100845)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_24766.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 61/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:33:49) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:34:07 -- STEP: 9/406 -- GLOBAL_STEP: 24775\u001b[0m\n",
      "     | > loss: -0.0470077246427536  (-0.08188201818201277)\n",
      "     | > log_mle: -0.25200188159942627  (-0.2553256087832981)\n",
      "     | > loss_dur: 0.20499415695667267  (0.1734435906012853)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.0893, device='cuda:0')  (tensor(11.6859, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.2502  (0.2616819540659587)\n",
      "     | > loader_time: 0.002  (0.021463791529337566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:34:14 -- STEP: 34/406 -- GLOBAL_STEP: 24800\u001b[0m\n",
      "     | > loss: -0.04137864708900452  (-0.06819002067341524)\n",
      "     | > log_mle: -0.24054396152496338  (-0.25378536476808444)\n",
      "     | > loss_dur: 0.19916531443595886  (0.18559534409466913)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.0496, device='cuda:0')  (tensor(11.1188, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.2602  (0.2613844310536104)\n",
      "     | > loader_time: 0.002  (0.007153314702651078)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:34:21 -- STEP: 59/406 -- GLOBAL_STEP: 24825\u001b[0m\n",
      "     | > loss: -0.05209167301654816  (-0.06002556519993281)\n",
      "     | > log_mle: -0.2671186923980713  (-0.2551238961138968)\n",
      "     | > loss_dur: 0.21502701938152313  (0.19509833091396397)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.3660, device='cuda:0')  (tensor(11.9131, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.3243  (0.2758607015771381)\n",
      "     | > loader_time: 0.002  (0.005123138427734373)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:34:29 -- STEP: 84/406 -- GLOBAL_STEP: 24850\u001b[0m\n",
      "     | > loss: -0.04513618350028992  (-0.05803961572902543)\n",
      "     | > log_mle: -0.2685896158218384  (-0.2572768742129917)\n",
      "     | > loss_dur: 0.22345343232154846  (0.19923725848396615)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.6803, device='cuda:0')  (tensor(13.7669, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.3013  (0.28777326856340696)\n",
      "     | > loader_time: 0.003  (0.0044086263293311705)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:34:38 -- STEP: 109/406 -- GLOBAL_STEP: 24875\u001b[0m\n",
      "     | > loss: -0.06076420843601227  (-0.05745021547746221)\n",
      "     | > log_mle: -0.2761634588241577  (-0.2598165383032704)\n",
      "     | > loss_dur: 0.21539925038814545  (0.20236632282580802)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.9725, device='cuda:0')  (tensor(14.7305, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.3793  (0.30034613609313976)\n",
      "     | > loader_time: 0.004  (0.004095372803714297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:34:47 -- STEP: 134/406 -- GLOBAL_STEP: 24900\u001b[0m\n",
      "     | > loss: -0.04572683572769165  (-0.05648809893807368)\n",
      "     | > log_mle: -0.26939964294433594  (-0.2620790485125871)\n",
      "     | > loss_dur: 0.2236728072166443  (0.20559094957451318)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.4329, device='cuda:0')  (tensor(15.4396, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.4094  (0.31098394251581457)\n",
      "     | > loader_time: 0.003  (0.0039363458975037536)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:34:57 -- STEP: 159/406 -- GLOBAL_STEP: 24925\u001b[0m\n",
      "     | > loss: -0.05229784548282623  (-0.05565945672913917)\n",
      "     | > log_mle: -0.2700948715209961  (-0.2636580617172915)\n",
      "     | > loss_dur: 0.21779702603816986  (0.20799860498815212)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.8224, device='cuda:0')  (tensor(15.6050, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.3613  (0.32211013560025203)\n",
      "     | > loader_time: 0.005  (0.0038714048997411194)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:35:07 -- STEP: 184/406 -- GLOBAL_STEP: 24950\u001b[0m\n",
      "     | > loss: -0.040925249457359314  (-0.05534561180874058)\n",
      "     | > log_mle: -0.28905534744262695  (-0.2652452328930732)\n",
      "     | > loss_dur: 0.24813009798526764  (0.20989962108433247)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.6400, device='cuda:0')  (tensor(15.7764, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.3733  (0.334385157927223)\n",
      "     | > loader_time: 0.003  (0.003856735384982566)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:35:18 -- STEP: 209/406 -- GLOBAL_STEP: 24975\u001b[0m\n",
      "     | > loss: -0.05633017420768738  (-0.054774607767899074)\n",
      "     | > log_mle: -0.28443408012390137  (-0.2664992113432817)\n",
      "     | > loss_dur: 0.228103905916214  (0.2117246035753825)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.8084, device='cuda:0')  (tensor(16.0758, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.3894  (0.34579243728418685)\n",
      "     | > loader_time: 0.004  (0.0038791159123324898)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:35:29 -- STEP: 234/406 -- GLOBAL_STEP: 25000\u001b[0m\n",
      "     | > loss: -0.04967285692691803  (-0.05456448734825493)\n",
      "     | > log_mle: -0.28741157054901123  (-0.2679552038510641)\n",
      "     | > loss_dur: 0.2377387136220932  (0.2133907165028091)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.9308, device='cuda:0')  (tensor(16.0168, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.5145  (0.3565631524110453)\n",
      "     | > loader_time: 0.005  (0.003935154686626205)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_25000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:35:46 -- STEP: 259/406 -- GLOBAL_STEP: 25025\u001b[0m\n",
      "     | > loss: -0.05858582258224487  (-0.05473606898287549)\n",
      "     | > log_mle: -0.2950040102005005  (-0.2692440191291014)\n",
      "     | > loss_dur: 0.23641818761825562  (0.2145079501462259)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.5966, device='cuda:0')  (tensor(15.8048, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.5295  (0.3693818852708147)\n",
      "     | > loader_time: 0.005  (0.0039726583193628005)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:35:59 -- STEP: 284/406 -- GLOBAL_STEP: 25050\u001b[0m\n",
      "     | > loss: -0.04627344012260437  (-0.054988970481593846)\n",
      "     | > log_mle: -0.28794264793395996  (-0.2704030615343175)\n",
      "     | > loss_dur: 0.2416692078113556  (0.2154140910527236)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.5811, device='cuda:0')  (tensor(16.4010, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.5505  (0.3825654832410142)\n",
      "     | > loader_time: 0.005  (0.004007060762862082)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:36:13 -- STEP: 309/406 -- GLOBAL_STEP: 25075\u001b[0m\n",
      "     | > loss: -0.0635157972574234  (-0.05481343506609352)\n",
      "     | > log_mle: -0.2856590747833252  (-0.2713200748931245)\n",
      "     | > loss_dur: 0.2221432775259018  (0.21650663982703075)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.5752, device='cuda:0')  (tensor(16.6283, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.6246  (0.3942186207447237)\n",
      "     | > loader_time: 0.005  (0.0040715327154857)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:36:26 -- STEP: 334/406 -- GLOBAL_STEP: 25100\u001b[0m\n",
      "     | > loss: -0.05056464672088623  (-0.05470586630577099)\n",
      "     | > log_mle: -0.2936060428619385  (-0.2721008058793532)\n",
      "     | > loss_dur: 0.24304139614105225  (0.21739493957358205)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.5567, device='cuda:0')  (tensor(16.5861, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.6326  (0.4052210724996236)\n",
      "     | > loader_time: 0.005  (0.004129380523087733)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:36:41 -- STEP: 359/406 -- GLOBAL_STEP: 25125\u001b[0m\n",
      "     | > loss: -0.0544363409280777  (-0.054655264596089013)\n",
      "     | > log_mle: -0.28182804584503174  (-0.272969366116112)\n",
      "     | > loss_dur: 0.22739170491695404  (0.21831410152002298)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.6935, device='cuda:0')  (tensor(16.7541, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.5525  (0.41677384788279415)\n",
      "     | > loader_time: 0.005  (0.00419030216078904)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:36:56 -- STEP: 384/406 -- GLOBAL_STEP: 25150\u001b[0m\n",
      "     | > loss: -0.06078137457370758  (-0.054894876666367054)\n",
      "     | > log_mle: -0.2815791368484497  (-0.27382374585916586)\n",
      "     | > loss_dur: 0.22079776227474213  (0.21892886919279894)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.7742, device='cuda:0')  (tensor(16.8864, device='cuda:0'))\n",
      "     | > current_lr: 1.525e-05 \n",
      "     | > step_time: 0.5625  (0.42900399553279084)\n",
      "     | > loader_time: 0.005  (0.004248513529698051)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09558790922164917 \u001b[0m(-0.002865314483642578)\n",
      "     | > avg_loss:\u001b[92m -0.08623764663934708 \u001b[0m(-0.0005944408476352692)\n",
      "     | > avg_log_mle:\u001b[92m -0.2930828928947449 \u001b[0m(-0.0011489689350128174)\n",
      "     | > avg_loss_dur:\u001b[91m 0.2068452462553978 \u001b[0m(+0.0005545280873775482)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_25172.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 62/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:37:41) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:37:58 -- STEP: 3/406 -- GLOBAL_STEP: 25175\u001b[0m\n",
      "     | > loss: -0.09190820157527924  (-0.10213583211104076)\n",
      "     | > log_mle: -0.2624732255935669  (-0.2652939160664876)\n",
      "     | > loss_dur: 0.17056502401828766  (0.16315808395544687)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.5642, device='cuda:0')  (tensor(18.5609, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.2492  (0.26390520731608075)\n",
      "     | > loader_time: 0.2222  (0.07540249824523926)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:38:05 -- STEP: 28/406 -- GLOBAL_STEP: 25200\u001b[0m\n",
      "     | > loss: -0.03391258418560028  (-0.07192728562014443)\n",
      "     | > log_mle: -0.25505685806274414  (-0.2551560997962952)\n",
      "     | > loss_dur: 0.22114427387714386  (0.18322881417615072)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.0723, device='cuda:0')  (tensor(11.6111, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.2863  (0.2653475659234183)\n",
      "     | > loader_time: 0.002  (0.00975935799734933)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:38:12 -- STEP: 53/406 -- GLOBAL_STEP: 25225\u001b[0m\n",
      "     | > loss: -0.05762098729610443  (-0.06336823949274029)\n",
      "     | > log_mle: -0.251567006111145  (-0.2553699196509595)\n",
      "     | > loss_dur: 0.1939460188150406  (0.19200168015821925)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.4947, device='cuda:0')  (tensor(12.4484, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.3103  (0.27619399214690593)\n",
      "     | > loader_time: 0.003  (0.006307804359579986)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:38:20 -- STEP: 78/406 -- GLOBAL_STEP: 25250\u001b[0m\n",
      "     | > loss: -0.05878625810146332  (-0.06174511118577079)\n",
      "     | > log_mle: -0.26147639751434326  (-0.2580950611676925)\n",
      "     | > loss_dur: 0.20269013941287994  (0.19634994998192176)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.1362, device='cuda:0')  (tensor(12.2619, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.3003  (0.28763289023668337)\n",
      "     | > loader_time: 0.003  (0.00513296860914964)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:38:29 -- STEP: 103/406 -- GLOBAL_STEP: 25275\u001b[0m\n",
      "     | > loss: -0.07712890207767487  (-0.06089926619552873)\n",
      "     | > log_mle: -0.29213547706604004  (-0.2614865164154941)\n",
      "     | > loss_dur: 0.21500657498836517  (0.20058725021996546)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.5731, device='cuda:0')  (tensor(13.0441, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.3093  (0.2999325354122421)\n",
      "     | > loader_time: 0.003  (0.00461589248435011)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:38:38 -- STEP: 128/406 -- GLOBAL_STEP: 25300\u001b[0m\n",
      "     | > loss: -0.0636141300201416  (-0.06060170195996763)\n",
      "     | > log_mle: -0.27935826778411865  (-0.26397182699292887)\n",
      "     | > loss_dur: 0.21574413776397705  (0.20337012503296137)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.7938, device='cuda:0')  (tensor(13.1733, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.4004  (0.31147033534944046)\n",
      "     | > loader_time: 0.004  (0.004347715526819229)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:38:47 -- STEP: 153/406 -- GLOBAL_STEP: 25325\u001b[0m\n",
      "     | > loss: -0.05622263252735138  (-0.05996379908782985)\n",
      "     | > log_mle: -0.2712048292160034  (-0.26598483207179036)\n",
      "     | > loss_dur: 0.21498219668865204  (0.20602103298396066)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.0765, device='cuda:0')  (tensor(13.3242, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.3643  (0.32221412502862257)\n",
      "     | > loader_time: 0.004  (0.0042260783949708645)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:38:58 -- STEP: 178/406 -- GLOBAL_STEP: 25350\u001b[0m\n",
      "     | > loss: -0.054824113845825195  (-0.0599659187405297)\n",
      "     | > log_mle: -0.264276385307312  (-0.26758272728223453)\n",
      "     | > loss_dur: 0.20945227146148682  (0.2076168085417051)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.9896, device='cuda:0')  (tensor(13.7357, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.4584  (0.33372440230980355)\n",
      "     | > loader_time: 0.003  (0.004132919097214603)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:39:08 -- STEP: 203/406 -- GLOBAL_STEP: 25375\u001b[0m\n",
      "     | > loss: -0.03253866732120514  (-0.05960610795197229)\n",
      "     | > log_mle: -0.27037715911865234  (-0.26919258462971635)\n",
      "     | > loss_dur: 0.2378384917974472  (0.20958647667774427)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.2584, device='cuda:0')  (tensor(14.1931, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.3914  (0.3451212955813104)\n",
      "     | > loader_time: 0.004  (0.0041071064953733544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:39:19 -- STEP: 228/406 -- GLOBAL_STEP: 25400\u001b[0m\n",
      "     | > loss: -0.0708388090133667  (-0.05958515974251848)\n",
      "     | > log_mle: -0.29234302043914795  (-0.2708501648484613)\n",
      "     | > loss_dur: 0.22150421142578125  (0.211265005105943)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.5187, device='cuda:0')  (tensor(14.3366, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.5075  (0.35536675913292076)\n",
      "     | > loader_time: 0.005  (0.004113279936606424)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:39:32 -- STEP: 253/406 -- GLOBAL_STEP: 25425\u001b[0m\n",
      "     | > loss: -0.07016624510288239  (-0.059599404278480025)\n",
      "     | > log_mle: -0.2987021207809448  (-0.2722811571694172)\n",
      "     | > loss_dur: 0.22853587567806244  (0.2126817528909374)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.2362, device='cuda:0')  (tensor(14.7770, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.4214  (0.3679350449633694)\n",
      "     | > loader_time: 0.004  (0.004126199149331556)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:39:44 -- STEP: 278/406 -- GLOBAL_STEP: 25450\u001b[0m\n",
      "     | > loss: -0.053891152143478394  (-0.06010239549892412)\n",
      "     | > log_mle: -0.2683429718017578  (-0.2733854767229915)\n",
      "     | > loss_dur: 0.21445181965827942  (0.21328308122406764)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.3563, device='cuda:0')  (tensor(15.1562, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.5575  (0.37925101269920963)\n",
      "     | > loader_time: 0.004  (0.004151137612706465)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:39:57 -- STEP: 303/406 -- GLOBAL_STEP: 25475\u001b[0m\n",
      "     | > loss: -0.04070959985256195  (-0.05997419278613805)\n",
      "     | > log_mle: -0.28520190715789795  (-0.27443851142039766)\n",
      "     | > loss_dur: 0.244492307305336  (0.21446431863425983)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.0414, device='cuda:0')  (tensor(15.3041, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.4554  (0.3898128636992807)\n",
      "     | > loader_time: 0.004  (0.004162076282815962)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:40:11 -- STEP: 328/406 -- GLOBAL_STEP: 25500\u001b[0m\n",
      "     | > loss: -0.03591948747634888  (-0.0597449435239158)\n",
      "     | > log_mle: -0.288763165473938  (-0.2752074900923703)\n",
      "     | > loss_dur: 0.2528436779975891  (0.21546254656845476)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.0033, device='cuda:0')  (tensor(15.4282, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.6076  (0.4009923062673433)\n",
      "     | > loader_time: 0.005  (0.004195759936076838)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:40:25 -- STEP: 353/406 -- GLOBAL_STEP: 25525\u001b[0m\n",
      "     | > loss: -0.06775940954685211  (-0.05951889969471832)\n",
      "     | > log_mle: -0.2989102602005005  (-0.2760630356353671)\n",
      "     | > loss_dur: 0.23115085065364838  (0.21654413594064903)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.9025, device='cuda:0')  (tensor(15.6349, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.6816  (0.4124965323267175)\n",
      "     | > loader_time: 0.006  (0.004247320947836207)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:40:40 -- STEP: 378/406 -- GLOBAL_STEP: 25550\u001b[0m\n",
      "     | > loss: -0.052628323435783386  (-0.05971267437020307)\n",
      "     | > log_mle: -0.28239357471466064  (-0.2769468978599262)\n",
      "     | > loss_dur: 0.22976525127887726  (0.21723422348972352)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.5362, device='cuda:0')  (tensor(16.2684, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.6766  (0.4241366014278758)\n",
      "     | > loader_time: 0.005  (0.0042947410906433395)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:40:56 -- STEP: 403/406 -- GLOBAL_STEP: 25575\u001b[0m\n",
      "     | > loss: -0.07815839350223541  (-0.05990519598311289)\n",
      "     | > log_mle: -0.28276169300079346  (-0.27777960253116757)\n",
      "     | > loss_dur: 0.20460329949855804  (0.21787440654805518)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.1378, device='cuda:0')  (tensor(16.4309, device='cuda:0'))\n",
      "     | > current_lr: 1.55e-05 \n",
      "     | > step_time: 0.7144  (0.43739813610578615)\n",
      "     | > loader_time: 0.004  (0.00433379663131373)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09014031291007996 \u001b[0m(-0.005447596311569214)\n",
      "     | > avg_loss:\u001b[92m -0.09205621667206287 \u001b[0m(-0.005818570032715797)\n",
      "     | > avg_log_mle:\u001b[92m -0.2970474660396576 \u001b[0m(-0.00396457314491272)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20499124936759472 \u001b[0m(-0.0018539968878030777)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_25578.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 63/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:41:28) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:41:50 -- STEP: 22/406 -- GLOBAL_STEP: 25600\u001b[0m\n",
      "     | > loss: -0.06494121253490448  (-0.08231533860618417)\n",
      "     | > log_mle: -0.25301194190979004  (-0.2604770714586431)\n",
      "     | > loss_dur: 0.18807072937488556  (0.17816173285245895)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(5.5094, device='cuda:0')  (tensor(8.5000, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.2582  (0.256551211530512)\n",
      "     | > loader_time: 0.002  (0.012875296852805397)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:41:57 -- STEP: 47/406 -- GLOBAL_STEP: 25625\u001b[0m\n",
      "     | > loss: -0.04193376004695892  (-0.07085654773610704)\n",
      "     | > log_mle: -0.26677048206329346  (-0.25864935682174994)\n",
      "     | > loss_dur: 0.22483672201633453  (0.18779280908564303)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.8739, device='cuda:0')  (tensor(10.4110, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.3003  (0.26677415726032666)\n",
      "     | > loader_time: 0.002  (0.007240609919771235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:42:05 -- STEP: 72/406 -- GLOBAL_STEP: 25650\u001b[0m\n",
      "     | > loss: -0.06867803633213043  (-0.06715445924136376)\n",
      "     | > log_mle: -0.2591332197189331  (-0.2611979378594291)\n",
      "     | > loss_dur: 0.19045518338680267  (0.1940434786180655)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(7.8578, device='cuda:0')  (tensor(10.9090, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.2913  (0.27897558278507656)\n",
      "     | > loader_time: 0.003  (0.00563004281785753)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:42:13 -- STEP: 97/406 -- GLOBAL_STEP: 25675\u001b[0m\n",
      "     | > loss: -0.05251483619213104  (-0.06601949543068092)\n",
      "     | > log_mle: -0.26497459411621094  (-0.2645062798077297)\n",
      "     | > loss_dur: 0.2124597579240799  (0.19848678437704892)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.4137, device='cuda:0')  (tensor(12.2749, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.3123  (0.2924098796451214)\n",
      "     | > loader_time: 0.003  (0.004911634110912834)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:42:22 -- STEP: 122/406 -- GLOBAL_STEP: 25700\u001b[0m\n",
      "     | > loss: -0.059609293937683105  (-0.06565403999363793)\n",
      "     | > log_mle: -0.26378655433654785  (-0.26701998026644586)\n",
      "     | > loss_dur: 0.20417726039886475  (0.20136594027280807)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.0074, device='cuda:0')  (tensor(13.2590, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.3974  (0.3049654491612168)\n",
      "     | > loader_time: 0.003  (0.004545053497689669)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:42:31 -- STEP: 147/406 -- GLOBAL_STEP: 25725\u001b[0m\n",
      "     | > loss: -0.06160271167755127  (-0.06538203419471277)\n",
      "     | > log_mle: -0.2777066230773926  (-0.26925328069803656)\n",
      "     | > loss_dur: 0.2161039113998413  (0.2038712465033239)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.7204, device='cuda:0')  (tensor(13.5773, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.3403  (0.31585140779715815)\n",
      "     | > loader_time: 0.004  (0.004350864968332304)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:42:41 -- STEP: 172/406 -- GLOBAL_STEP: 25750\u001b[0m\n",
      "     | > loss: -0.06457872688770294  (-0.06480223529560625)\n",
      "     | > log_mle: -0.2841193675994873  (-0.2708879140920415)\n",
      "     | > loss_dur: 0.21954064071178436  (0.20608567879643544)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.6701, device='cuda:0')  (tensor(14.2126, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.4464  (0.32746591124423713)\n",
      "     | > loader_time: 0.004  (0.004248020260833031)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:42:52 -- STEP: 197/406 -- GLOBAL_STEP: 25775\u001b[0m\n",
      "     | > loss: -0.05947530269622803  (-0.06463539343194911)\n",
      "     | > log_mle: -0.2828322649002075  (-0.2725017718252188)\n",
      "     | > loss_dur: 0.2233569622039795  (0.20786637839326996)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.9844, device='cuda:0')  (tensor(14.7640, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.4694  (0.34012419439209296)\n",
      "     | > loader_time: 0.004  (0.004166168609851508)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:43:03 -- STEP: 222/406 -- GLOBAL_STEP: 25800\u001b[0m\n",
      "     | > loss: -0.06178855895996094  (-0.0643719087044398)\n",
      "     | > log_mle: -0.28481781482696533  (-0.27392881518011675)\n",
      "     | > loss_dur: 0.2230292558670044  (0.2095569064756771)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(56.9173, device='cuda:0')  (tensor(15.4312, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.5035  (0.35153192442816655)\n",
      "     | > loader_time: 0.004  (0.004138825175998447)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:43:15 -- STEP: 247/406 -- GLOBAL_STEP: 25825\u001b[0m\n",
      "     | > loss: -0.052141785621643066  (-0.06421238358928126)\n",
      "     | > log_mle: -0.2745382785797119  (-0.2751350996465333)\n",
      "     | > loss_dur: 0.22239649295806885  (0.21092271605725224)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.7161, device='cuda:0')  (tensor(16.0339, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.5635  (0.36239075274602606)\n",
      "     | > loader_time: 0.005  (0.004133233174621332)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:43:27 -- STEP: 272/406 -- GLOBAL_STEP: 25850\u001b[0m\n",
      "     | > loss: -0.08116352558135986  (-0.06459773205878104)\n",
      "     | > log_mle: -0.2932701110839844  (-0.27632328166681164)\n",
      "     | > loss_dur: 0.2121065855026245  (0.2117255496080307)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.2215, device='cuda:0')  (tensor(16.4041, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.5345  (0.3738807869308135)\n",
      "     | > loader_time: 0.004  (0.004139729282435247)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:43:40 -- STEP: 297/406 -- GLOBAL_STEP: 25875\u001b[0m\n",
      "     | > loss: -0.06553006172180176  (-0.06424847992783041)\n",
      "     | > log_mle: -0.28656673431396484  (-0.2772670161443125)\n",
      "     | > loss_dur: 0.22103667259216309  (0.2130185362164821)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.9514, device='cuda:0')  (tensor(16.5937, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.4674  (0.38399929149383644)\n",
      "     | > loader_time: 0.005  (0.004155225625343192)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:43:53 -- STEP: 322/406 -- GLOBAL_STEP: 25900\u001b[0m\n",
      "     | > loss: -0.06137751042842865  (-0.06400498410004263)\n",
      "     | > log_mle: -0.2931809425354004  (-0.2781327140997654)\n",
      "     | > loss_dur: 0.23180343210697174  (0.21412772999972282)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.1054, device='cuda:0')  (tensor(16.7264, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.5945  (0.39593165409490927)\n",
      "     | > loader_time: 0.005  (0.004199413779359423)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:44:07 -- STEP: 347/406 -- GLOBAL_STEP: 25925\u001b[0m\n",
      "     | > loss: -0.07158444821834564  (-0.06381180938279589)\n",
      "     | > log_mle: -0.2987879514694214  (-0.27891307914634944)\n",
      "     | > loss_dur: 0.22720350325107574  (0.21510126976355343)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.6462, device='cuda:0')  (tensor(16.9493, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.5295  (0.4069379337926419)\n",
      "     | > loader_time: 0.004  (0.0042314495064683134)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:44:22 -- STEP: 372/406 -- GLOBAL_STEP: 25950\u001b[0m\n",
      "     | > loss: -0.05492779612541199  (-0.06391356344665243)\n",
      "     | > log_mle: -0.2805171012878418  (-0.2797684733585643)\n",
      "     | > loss_dur: 0.2255893051624298  (0.2158549099119119)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.2981, device='cuda:0')  (tensor(17.1509, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.6556  (0.4184316941486892)\n",
      "     | > loader_time: 0.005  (0.004286073228364344)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:44:38 -- STEP: 397/406 -- GLOBAL_STEP: 25975\u001b[0m\n",
      "     | > loss: -0.07377989590167999  (-0.06407685161237447)\n",
      "     | > log_mle: -0.29383933544158936  (-0.28049870402146315)\n",
      "     | > loss_dur: 0.22005943953990936  (0.21642185240908887)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.4534, device='cuda:0')  (tensor(17.5882, device='cuda:0'))\n",
      "     | > current_lr: 1.575e-05 \n",
      "     | > step_time: 0.7354  (0.4318555770653021)\n",
      "     | > loader_time: 0.006  (0.004356532012785708)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09183374047279358 \u001b[0m(+0.001693427562713623)\n",
      "     | > avg_loss:\u001b[92m -0.09646567516028881 \u001b[0m(-0.004409458488225937)\n",
      "     | > avg_log_mle:\u001b[92m -0.29903413355350494 \u001b[0m(-0.001986667513847351)\n",
      "     | > avg_loss_dur:\u001b[92m 0.20256845839321613 \u001b[0m(-0.002422790974378586)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_25984.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 64/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:45:15) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:45:35 -- STEP: 16/406 -- GLOBAL_STEP: 26000\u001b[0m\n",
      "     | > loss: -0.07062852382659912  (-0.09369707200676203)\n",
      "     | > log_mle: -0.26351964473724365  (-0.26535895466804504)\n",
      "     | > loss_dur: 0.19289112091064453  (0.17166188266128302)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.5926, device='cuda:0')  (tensor(10.4584, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.2572  (0.2567332237958908)\n",
      "     | > loader_time: 0.001  (0.017891153693199158)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_26000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:45:44 -- STEP: 41/406 -- GLOBAL_STEP: 26025\u001b[0m\n",
      "     | > loss: -0.0606691837310791  (-0.07689773091455786)\n",
      "     | > log_mle: -0.25156402587890625  (-0.26124093299958767)\n",
      "     | > loss_dur: 0.19089484214782715  (0.1843432020850298)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.9821, device='cuda:0')  (tensor(12.3696, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.2642  (0.26477693348396125)\n",
      "     | > loader_time: 0.003  (0.008349104625422783)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:45:51 -- STEP: 66/406 -- GLOBAL_STEP: 26050\u001b[0m\n",
      "     | > loss: -0.059070512652397156  (-0.07126614451408386)\n",
      "     | > log_mle: -0.26618099212646484  (-0.26274682897509943)\n",
      "     | > loss_dur: 0.2071104794740677  (0.19148068446101568)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.1103, device='cuda:0')  (tensor(11.8119, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.2923  (0.27746385516542377)\n",
      "     | > loader_time: 0.003  (0.006142139434814455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:45:59 -- STEP: 91/406 -- GLOBAL_STEP: 26075\u001b[0m\n",
      "     | > loss: -0.07765507698059082  (-0.0699052109823122)\n",
      "     | > log_mle: -0.29087066650390625  (-0.2657431521258511)\n",
      "     | > loss_dur: 0.21321558952331543  (0.19583794114353892)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.8926, device='cuda:0')  (tensor(12.1257, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.3023  (0.29085726528377326)\n",
      "     | > loader_time: 0.003  (0.0052577453655201015)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:46:09 -- STEP: 116/406 -- GLOBAL_STEP: 26100\u001b[0m\n",
      "     | > loss: -0.04741792380809784  (-0.06976300285294137)\n",
      "     | > log_mle: -0.2667299509048462  (-0.26870639468061486)\n",
      "     | > loss_dur: 0.21931202709674835  (0.19894339182767376)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.1152, device='cuda:0')  (tensor(12.3585, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.3253  (0.3050353033789274)\n",
      "     | > loader_time: 0.003  (0.004780450771594872)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:46:18 -- STEP: 141/406 -- GLOBAL_STEP: 26125\u001b[0m\n",
      "     | > loss: -0.06664927303791046  (-0.0687588188031041)\n",
      "     | > log_mle: -0.2875000238418579  (-0.27110249522729946)\n",
      "     | > loss_dur: 0.22085075080394745  (0.20234367642419557)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.4136, device='cuda:0')  (tensor(13.4454, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.4254  (0.31607390126438023)\n",
      "     | > loader_time: 0.004  (0.004515005341658359)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:46:28 -- STEP: 166/406 -- GLOBAL_STEP: 26150\u001b[0m\n",
      "     | > loss: -0.0896441787481308  (-0.06799163076891952)\n",
      "     | > log_mle: -0.2954075336456299  (-0.27261348876608416)\n",
      "     | > loss_dur: 0.20576335489749908  (0.20462185799716467)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.0739, device='cuda:0')  (tensor(15.3628, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.4384  (0.32669991901121953)\n",
      "     | > loader_time: 0.003  (0.004377742847764351)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:46:38 -- STEP: 191/406 -- GLOBAL_STEP: 26175\u001b[0m\n",
      "     | > loss: -0.073507159948349  (-0.06796973655049085)\n",
      "     | > log_mle: -0.2877460718154907  (-0.27428499940802303)\n",
      "     | > loss_dur: 0.21423891186714172  (0.206315262857532)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.0374, device='cuda:0')  (tensor(15.8027, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.4654  (0.3381150405444401)\n",
      "     | > loader_time: 0.004  (0.004302586560474016)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:46:49 -- STEP: 216/406 -- GLOBAL_STEP: 26200\u001b[0m\n",
      "     | > loss: -0.06199197471141815  (-0.06766595636252999)\n",
      "     | > log_mle: -0.29338109493255615  (-0.27546661761071956)\n",
      "     | > loss_dur: 0.231389120221138  (0.20780066124818944)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.1163, device='cuda:0')  (tensor(16.6290, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.4834  (0.3489850825733609)\n",
      "     | > loader_time: 0.004  (0.004244822042959707)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:47:00 -- STEP: 241/406 -- GLOBAL_STEP: 26225\u001b[0m\n",
      "     | > loss: -0.052786022424697876  (-0.06730228909813016)\n",
      "     | > log_mle: -0.2789393663406372  (-0.2768790355856488)\n",
      "     | > loss_dur: 0.22615334391593933  (0.20957674648751856)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.9953, device='cuda:0')  (tensor(16.7310, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.4144  (0.3589207126886519)\n",
      "     | > loader_time: 0.005  (0.004244694571277412)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:47:13 -- STEP: 266/406 -- GLOBAL_STEP: 26250\u001b[0m\n",
      "     | > loss: -0.06292690336704254  (-0.06738770036096854)\n",
      "     | > log_mle: -0.2865173816680908  (-0.2780307280389886)\n",
      "     | > loss_dur: 0.22359047830104828  (0.21064302767802)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.8760, device='cuda:0')  (tensor(16.9004, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.5455  (0.3713001514735975)\n",
      "     | > loader_time: 0.005  (0.00424840486139283)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:47:25 -- STEP: 291/406 -- GLOBAL_STEP: 26275\u001b[0m\n",
      "     | > loss: -0.06344425678253174  (-0.0675462556049176)\n",
      "     | > log_mle: -0.2776299715042114  (-0.2790935604842667)\n",
      "     | > loss_dur: 0.2141857147216797  (0.21154730487934914)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.4196, device='cuda:0')  (tensor(17.1366, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.4734  (0.38140183379969644)\n",
      "     | > loader_time: 0.005  (0.00427209798413044)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:47:39 -- STEP: 316/406 -- GLOBAL_STEP: 26300\u001b[0m\n",
      "     | > loss: -0.05859266221523285  (-0.06743860617280004)\n",
      "     | > log_mle: -0.29089105129241943  (-0.2801422073116785)\n",
      "     | > loss_dur: 0.23229838907718658  (0.2127036011388785)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.5975, device='cuda:0')  (tensor(17.4293, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.6146  (0.393535026266605)\n",
      "     | > loader_time: 0.005  (0.004298370850237112)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:47:52 -- STEP: 341/406 -- GLOBAL_STEP: 26325\u001b[0m\n",
      "     | > loss: -0.07851672172546387  (-0.06718793878457407)\n",
      "     | > log_mle: -0.3119382858276367  (-0.2809120070549749)\n",
      "     | > loss_dur: 0.23342156410217285  (0.21372406827040086)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.3687, device='cuda:0')  (tensor(17.6244, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.5275  (0.40456723327860455)\n",
      "     | > loader_time: 0.005  (0.004326674945193653)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:48:07 -- STEP: 366/406 -- GLOBAL_STEP: 26350\u001b[0m\n",
      "     | > loss: -0.07979889214038849  (-0.06736725768267776)\n",
      "     | > log_mle: -0.3035775423049927  (-0.28189775298853376)\n",
      "     | > loss_dur: 0.2237786501646042  (0.2145304953058561)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.1920, device='cuda:0')  (tensor(17.7314, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.5435  (0.4155186779512082)\n",
      "     | > loader_time: 0.005  (0.004364760195622681)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:48:22 -- STEP: 391/406 -- GLOBAL_STEP: 26375\u001b[0m\n",
      "     | > loss: -0.08706788718700409  (-0.06752422783533316)\n",
      "     | > log_mle: -0.30415213108062744  (-0.2827124894427519)\n",
      "     | > loss_dur: 0.21708424389362335  (0.2151882616074189)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.0053, device='cuda:0')  (tensor(17.7643, device='cuda:0'))\n",
      "     | > current_lr: 1.6e-05 \n",
      "     | > step_time: 0.6766  (0.42862896602172074)\n",
      "     | > loader_time: 0.005  (0.004410771152857321)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09683993458747864 \u001b[0m(+0.005006194114685059)\n",
      "     | > avg_loss:\u001b[92m -0.1029170323163271 \u001b[0m(-0.006451357156038284)\n",
      "     | > avg_log_mle:\u001b[92m -0.30274727940559387 \u001b[0m(-0.0037131458520889282)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19983024708926678 \u001b[0m(-0.002738211303949356)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_26390.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 65/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:49:03) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:49:21 -- STEP: 10/406 -- GLOBAL_STEP: 26400\u001b[0m\n",
      "     | > loss: -0.12245641648769379  (-0.10107501447200776)\n",
      "     | > log_mle: -0.26643896102905273  (-0.2671735525131226)\n",
      "     | > loss_dur: 0.14398254454135895  (0.1660985380411148)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(4.0214, device='cuda:0')  (tensor(7.8384, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.2512  (0.25543196201324464)\n",
      "     | > loader_time: 0.001  (0.023421168327331543)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:49:28 -- STEP: 35/406 -- GLOBAL_STEP: 26425\u001b[0m\n",
      "     | > loss: -0.08012507855892181  (-0.0842138579913548)\n",
      "     | > log_mle: -0.28370440006256104  (-0.26450766495295935)\n",
      "     | > loss_dur: 0.20357932150363922  (0.1802938069616045)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(9.9320, device='cuda:0')  (tensor(14.9705, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.2632  (0.26063670430864605)\n",
      "     | > loader_time: 0.002  (0.00815004621233259)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:49:36 -- STEP: 60/406 -- GLOBAL_STEP: 26450\u001b[0m\n",
      "     | > loss: -0.07897980511188507  (-0.07633915667732556)\n",
      "     | > log_mle: -0.265552282333374  (-0.2653093417485554)\n",
      "     | > loss_dur: 0.18657247722148895  (0.18897018507122992)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.7391, device='cuda:0')  (tensor(14.9590, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.2803  (0.274849538008372)\n",
      "     | > loader_time: 0.002  (0.005805102984110514)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:49:44 -- STEP: 85/406 -- GLOBAL_STEP: 26475\u001b[0m\n",
      "     | > loss: -0.07701702415943146  (-0.07405528952093685)\n",
      "     | > log_mle: -0.28779590129852295  (-0.2678005456924437)\n",
      "     | > loss_dur: 0.2107788771390915  (0.193745256171507)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.1394, device='cuda:0')  (tensor(16.5553, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.2983  (0.28751990374396835)\n",
      "     | > loader_time: 0.003  (0.004980853024651023)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:49:52 -- STEP: 110/406 -- GLOBAL_STEP: 26500\u001b[0m\n",
      "     | > loss: -0.07501424849033356  (-0.07347484678030017)\n",
      "     | > log_mle: -0.29504144191741943  (-0.2705268914049321)\n",
      "     | > loss_dur: 0.22002719342708588  (0.19705204462463205)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.3521, device='cuda:0')  (tensor(17.0215, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.3233  (0.3002635739066384)\n",
      "     | > loader_time: 0.003  (0.00454036539251154)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:50:01 -- STEP: 135/406 -- GLOBAL_STEP: 26525\u001b[0m\n",
      "     | > loss: -0.06414523720741272  (-0.07220937532407269)\n",
      "     | > log_mle: -0.2889821529388428  (-0.2727691985942699)\n",
      "     | > loss_dur: 0.22483691573143005  (0.20055982327019728)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.5821, device='cuda:0')  (tensor(17.2452, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.3323  (0.3109763392695674)\n",
      "     | > loader_time: 0.003  (0.00428526136610243)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:50:11 -- STEP: 160/406 -- GLOBAL_STEP: 26550\u001b[0m\n",
      "     | > loss: -0.059914082288742065  (-0.07131590871140361)\n",
      "     | > log_mle: -0.2879638671875  (-0.2743214718997477)\n",
      "     | > loss_dur: 0.22804978489875793  (0.2030055631883442)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.3763, device='cuda:0')  (tensor(17.9203, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.4254  (0.32266602814197554)\n",
      "     | > loader_time: 0.003  (0.004191200435161588)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:50:22 -- STEP: 185/406 -- GLOBAL_STEP: 26575\u001b[0m\n",
      "     | > loss: -0.06349657475948334  (-0.07069123967273813)\n",
      "     | > log_mle: -0.2881234884262085  (-0.275808893667685)\n",
      "     | > loss_dur: 0.22462691366672516  (0.20511765399494683)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.4038, device='cuda:0')  (tensor(19.0129, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.3914  (0.33461024310137805)\n",
      "     | > loader_time: 0.004  (0.00415500176919473)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:50:33 -- STEP: 210/406 -- GLOBAL_STEP: 26600\u001b[0m\n",
      "     | > loss: -0.07393406331539154  (-0.07030521070673347)\n",
      "     | > log_mle: -0.285434365272522  (-0.27715480327606207)\n",
      "     | > loss_dur: 0.21150030195713043  (0.20684959256932844)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.0445, device='cuda:0')  (tensor(19.1133, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.3914  (0.346441679909116)\n",
      "     | > loader_time: 0.003  (0.004127461569649831)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:50:44 -- STEP: 235/406 -- GLOBAL_STEP: 26625\u001b[0m\n",
      "     | > loss: -0.073907271027565  (-0.0703176350669657)\n",
      "     | > log_mle: -0.2897059917449951  (-0.27871834470870654)\n",
      "     | > loss_dur: 0.21579872071743011  (0.20840070964174065)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.8225, device='cuda:0')  (tensor(19.2591, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.4054  (0.3565437053112276)\n",
      "     | > loader_time: 0.004  (0.0041313201823133085)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:50:56 -- STEP: 260/406 -- GLOBAL_STEP: 26650\u001b[0m\n",
      "     | > loss: -0.08363001048564911  (-0.07051739377471108)\n",
      "     | > log_mle: -0.29505813121795654  (-0.28000116073168246)\n",
      "     | > loss_dur: 0.21142812073230743  (0.20948376695697124)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.9712, device='cuda:0')  (tensor(18.9216, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.5325  (0.3695612788200381)\n",
      "     | > loader_time: 0.005  (0.0041613936424255375)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:51:09 -- STEP: 285/406 -- GLOBAL_STEP: 26675\u001b[0m\n",
      "     | > loss: -0.07121461629867554  (-0.07050732311449545)\n",
      "     | > log_mle: -0.28585946559906006  (-0.28100092745663835)\n",
      "     | > loss_dur: 0.21464484930038452  (0.2104936043421427)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.4695, device='cuda:0')  (tensor(19.3218, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.4558  (0.38060206195764396)\n",
      "     | > loader_time: 0.004  (0.004193188851339776)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:51:22 -- STEP: 310/406 -- GLOBAL_STEP: 26700\u001b[0m\n",
      "     | > loss: -0.07092876732349396  (-0.07037103277060291)\n",
      "     | > log_mle: -0.28526031970977783  (-0.2819432070178371)\n",
      "     | > loss_dur: 0.21433155238628387  (0.21157217424723404)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.8315, device='cuda:0')  (tensor(19.5183, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.6166  (0.3928408799632904)\n",
      "     | > loader_time: 0.005  (0.004223092140689975)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:51:36 -- STEP: 335/406 -- GLOBAL_STEP: 26725\u001b[0m\n",
      "     | > loss: -0.04626783728599548  (-0.07018479166635821)\n",
      "     | > log_mle: -0.29195189476013184  (-0.2827591899615616)\n",
      "     | > loss_dur: 0.24568405747413635  (0.21257439829520322)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.5247, device='cuda:0')  (tensor(19.6015, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.4774  (0.4033008077251378)\n",
      "     | > loader_time: 0.005  (0.004272444568463228)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:51:50 -- STEP: 360/406 -- GLOBAL_STEP: 26750\u001b[0m\n",
      "     | > loss: -0.08382722735404968  (-0.07024372460113626)\n",
      "     | > log_mle: -0.29739952087402344  (-0.2836756050586703)\n",
      "     | > loss_dur: 0.21357229351997375  (0.2134318804575337)\n",
      "     | > amp_scaler: 8192.0  (4369.0666666666675)\n",
      "     | > grad_norm: tensor(21.8552, device='cuda:0')  (tensor(19.6422, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.5205  (0.4148380253050063)\n",
      "     | > loader_time: 0.005  (0.004328866137398613)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:52:06 -- STEP: 385/406 -- GLOBAL_STEP: 26775\u001b[0m\n",
      "     | > loss: -0.053643450140953064  (-0.07032938371231022)\n",
      "     | > log_mle: -0.29050683975219727  (-0.2844979307868266)\n",
      "     | > loss_dur: 0.2368633896112442  (0.21416854707451607)\n",
      "     | > amp_scaler: 8192.0  (4617.309090909094)\n",
      "     | > grad_norm: tensor(28.1467, device='cuda:0')  (tensor(19.8591, device='cuda:0'))\n",
      "     | > current_lr: 1.625e-05 \n",
      "     | > step_time: 0.7036  (0.4275598470266764)\n",
      "     | > loader_time: 0.005  (0.004383149704375824)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08647152781486511 \u001b[0m(-0.010368406772613525)\n",
      "     | > avg_loss:\u001b[92m -0.1047423966228962 \u001b[0m(-0.0018253643065690994)\n",
      "     | > avg_log_mle:\u001b[92m -0.304917573928833 \u001b[0m(-0.0021702945232391357)\n",
      "     | > avg_loss_dur:\u001b[91m 0.2001751773059368 \u001b[0m(+0.0003449302166700363)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_26796.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 66/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:52:50) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:53:07 -- STEP: 4/406 -- GLOBAL_STEP: 26800\u001b[0m\n",
      "     | > loss: -0.0983140766620636  (-0.11055977642536163)\n",
      "     | > log_mle: -0.2511293888092041  (-0.27104172110557556)\n",
      "     | > loss_dur: 0.1528153121471405  (0.16048194468021393)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(4.9874, device='cuda:0')  (tensor(9.5499, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.2562  (0.25973623991012573)\n",
      "     | > loader_time: 0.002  (0.06130564212799072)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:53:14 -- STEP: 29/406 -- GLOBAL_STEP: 26825\u001b[0m\n",
      "     | > loss: -0.09079687297344208  (-0.08906410274834468)\n",
      "     | > log_mle: -0.26980674266815186  (-0.2665041890637627)\n",
      "     | > loss_dur: 0.17900986969470978  (0.1774400863154181)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(5.0060, device='cuda:0')  (tensor(12.3882, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.2773  (0.2598222699658624)\n",
      "     | > loader_time: 0.002  (0.00993996653063544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:53:21 -- STEP: 54/406 -- GLOBAL_STEP: 26850\u001b[0m\n",
      "     | > loss: -0.0638541430234909  (-0.07999320135072426)\n",
      "     | > log_mle: -0.2700554132461548  (-0.266965678444615)\n",
      "     | > loss_dur: 0.20620127022266388  (0.18697247709389092)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.7863, device='cuda:0')  (tensor(11.6737, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.2763  (0.27109800886224816)\n",
      "     | > loader_time: 0.003  (0.006487351876718028)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:53:29 -- STEP: 79/406 -- GLOBAL_STEP: 26875\u001b[0m\n",
      "     | > loss: -0.06115688383579254  (-0.0777011600476277)\n",
      "     | > log_mle: -0.2793177366256714  (-0.269581658930718)\n",
      "     | > loss_dur: 0.21816085278987885  (0.1918804988830905)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.3203, device='cuda:0')  (tensor(12.6327, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.3583  (0.2844100964220265)\n",
      "     | > loader_time: 0.004  (0.005321324626101722)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:53:38 -- STEP: 104/406 -- GLOBAL_STEP: 26900\u001b[0m\n",
      "     | > loss: -0.06985072791576385  (-0.07621408755389542)\n",
      "     | > log_mle: -0.2757326364517212  (-0.2724645699446018)\n",
      "     | > loss_dur: 0.20588190853595734  (0.1962504823907064)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.1526, device='cuda:0')  (tensor(14.3359, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.3864  (0.2972025023056911)\n",
      "     | > loader_time: 0.004  (0.004763937913454498)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:53:47 -- STEP: 129/406 -- GLOBAL_STEP: 26925\u001b[0m\n",
      "     | > loss: -0.06542576849460602  (-0.07576991363551264)\n",
      "     | > log_mle: -0.2761138677597046  (-0.27506629995597426)\n",
      "     | > loss_dur: 0.21068809926509857  (0.19929638632046162)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.1242, device='cuda:0')  (tensor(15.0931, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.4034  (0.309350610703461)\n",
      "     | > loader_time: 0.003  (0.004438137823297074)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:53:56 -- STEP: 154/406 -- GLOBAL_STEP: 26950\u001b[0m\n",
      "     | > loss: -0.0813952386379242  (-0.07565003972161899)\n",
      "     | > log_mle: -0.2791334390640259  (-0.27710786500534457)\n",
      "     | > loss_dur: 0.19773820042610168  (0.20145782528372555)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.7621, device='cuda:0')  (tensor(15.5540, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.4314  (0.32039476215065316)\n",
      "     | > loader_time: 0.004  (0.004289636364230864)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:54:06 -- STEP: 179/406 -- GLOBAL_STEP: 26975\u001b[0m\n",
      "     | > loss: -0.07107186317443848  (-0.07528588159124276)\n",
      "     | > log_mle: -0.29534459114074707  (-0.27866989407459464)\n",
      "     | > loss_dur: 0.2242727279663086  (0.20338401248335172)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.6019, device='cuda:0')  (tensor(16.0607, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.3763  (0.33170896402284433)\n",
      "     | > loader_time: 0.004  (0.004182581129020819)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:54:17 -- STEP: 204/406 -- GLOBAL_STEP: 27000\u001b[0m\n",
      "     | > loss: -0.07873305678367615  (-0.07494816030649577)\n",
      "     | > log_mle: -0.28942596912384033  (-0.28017246430995424)\n",
      "     | > loss_dur: 0.21069291234016418  (0.2052243040034584)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.5276, device='cuda:0')  (tensor(16.5701, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.3954  (0.34326258009555305)\n",
      "     | > loader_time: 0.004  (0.004136136933869006)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_27000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:54:33 -- STEP: 229/406 -- GLOBAL_STEP: 27025\u001b[0m\n",
      "     | > loss: -0.07532528042793274  (-0.07500980722852149)\n",
      "     | > log_mle: -0.28457188606262207  (-0.2817674698267442)\n",
      "     | > loss_dur: 0.20924660563468933  (0.20675766259822262)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.7443, device='cuda:0')  (tensor(16.9363, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.4124  (0.35434370790506564)\n",
      "     | > loader_time: 0.004  (0.004134823661704252)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:54:45 -- STEP: 254/406 -- GLOBAL_STEP: 27050\u001b[0m\n",
      "     | > loss: -0.08141745626926422  (-0.07505004653545815)\n",
      "     | > log_mle: -0.28301548957824707  (-0.28309740231731756)\n",
      "     | > loss_dur: 0.20159803330898285  (0.2080473557818593)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.3109, device='cuda:0')  (tensor(17.2810, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.5325  (0.366659775493652)\n",
      "     | > loader_time: 0.004  (0.0041258823214553484)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:54:57 -- STEP: 279/406 -- GLOBAL_STEP: 27075\u001b[0m\n",
      "     | > loss: -0.05533964931964874  (-0.07513266363878834)\n",
      "     | > log_mle: -0.2852746248245239  (-0.2840862624534143)\n",
      "     | > loss_dur: 0.22993497550487518  (0.20895359881462586)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.8556, device='cuda:0')  (tensor(17.1722, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.4434  (0.3780314845423546)\n",
      "     | > loader_time: 0.004  (0.004161568952717661)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:55:10 -- STEP: 304/406 -- GLOBAL_STEP: 27100\u001b[0m\n",
      "     | > loss: -0.08043362200260162  (-0.07502613902876255)\n",
      "     | > log_mle: -0.3005220890045166  (-0.28510117099473364)\n",
      "     | > loss_dur: 0.22008846700191498  (0.210075031965971)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.1703, device='cuda:0')  (tensor(17.6447, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.6056  (0.3895512552637803)\n",
      "     | > loader_time: 0.004  (0.00419796375851882)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:55:24 -- STEP: 329/406 -- GLOBAL_STEP: 27125\u001b[0m\n",
      "     | > loss: -0.07907354831695557  (-0.07474089674311934)\n",
      "     | > log_mle: -0.28683388233184814  (-0.2858009457950535)\n",
      "     | > loss_dur: 0.20776033401489258  (0.2110600490519341)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(35.5693, device='cuda:0')  (tensor(17.9522, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.4874  (0.400710508816148)\n",
      "     | > loader_time: 0.004  (0.00422884265702546)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:55:38 -- STEP: 354/406 -- GLOBAL_STEP: 27150\u001b[0m\n",
      "     | > loss: -0.0680859386920929  (-0.07453081382196504)\n",
      "     | > log_mle: -0.29469001293182373  (-0.28666194010589086)\n",
      "     | > loss_dur: 0.22660407423973083  (0.2121311262839258)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.9856, device='cuda:0')  (tensor(18.1738, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.5185  (0.4127167395952731)\n",
      "     | > loader_time: 0.005  (0.004272294583293676)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:55:53 -- STEP: 379/406 -- GLOBAL_STEP: 27175\u001b[0m\n",
      "     | > loss: -0.09385184943675995  (-0.0747871436276977)\n",
      "     | > log_mle: -0.3042241334915161  (-0.2875650784585596)\n",
      "     | > loss_dur: 0.21037228405475616  (0.21277793483086185)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.0744, device='cuda:0')  (tensor(18.5106, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.5655  (0.424834472837423)\n",
      "     | > loader_time: 0.005  (0.00433378672536885)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:56:10 -- STEP: 404/406 -- GLOBAL_STEP: 27200\u001b[0m\n",
      "     | > loss: -0.06593573093414307  (-0.07474456336533673)\n",
      "     | > log_mle: -0.2986123561859131  (-0.28826656081888946)\n",
      "     | > loss_dur: 0.23267662525177002  (0.21352199745355266)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(30.6072, device='cuda:0')  (tensor(19.3621, device='cuda:0'))\n",
      "     | > current_lr: 1.65e-05 \n",
      "     | > step_time: 0.5679  (0.43838141165157357)\n",
      "     | > loader_time: 0.004  (0.004365370415224888)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09254974126815796 \u001b[0m(+0.006078213453292847)\n",
      "     | > avg_loss:\u001b[92m -0.10795710422098637 \u001b[0m(-0.003214707598090172)\n",
      "     | > avg_log_mle:\u001b[92m -0.3087184429168701 \u001b[0m(-0.0038008689880371094)\n",
      "     | > avg_loss_dur:\u001b[91m 0.20076133869588375 \u001b[0m(+0.0005861613899469376)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_27202.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 67/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 05:56:42) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:57:04 -- STEP: 23/406 -- GLOBAL_STEP: 27225\u001b[0m\n",
      "     | > loss: -0.07650558650493622  (-0.0980327686537867)\n",
      "     | > log_mle: -0.26641368865966797  (-0.2703567950621895)\n",
      "     | > loss_dur: 0.18990810215473175  (0.1723240264084028)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.1492, device='cuda:0')  (tensor(13.3882, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.2682  (0.25823409661002783)\n",
      "     | > loader_time: 0.002  (0.00896496358125106)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:57:11 -- STEP: 48/406 -- GLOBAL_STEP: 27250\u001b[0m\n",
      "     | > loss: -0.07224488258361816  (-0.08662447240203619)\n",
      "     | > log_mle: -0.27251148223876953  (-0.2691785568992297)\n",
      "     | > loss_dur: 0.20026659965515137  (0.1825540844971935)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.0557, device='cuda:0')  (tensor(13.0897, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.3043  (0.2685976674159369)\n",
      "     | > loader_time: 0.003  (0.005505318442980447)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:57:19 -- STEP: 73/406 -- GLOBAL_STEP: 27275\u001b[0m\n",
      "     | > loss: -0.09099924564361572  (-0.08283946754997723)\n",
      "     | > log_mle: -0.29393506050109863  (-0.271809025986554)\n",
      "     | > loss_dur: 0.2029358148574829  (0.18896955843657665)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.6430, device='cuda:0')  (tensor(13.4234, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.3433  (0.2808436726870603)\n",
      "     | > loader_time: 0.003  (0.004497488884076679)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:57:27 -- STEP: 98/406 -- GLOBAL_STEP: 27300\u001b[0m\n",
      "     | > loss: -0.07103295624256134  (-0.08091503001597465)\n",
      "     | > log_mle: -0.2740422487258911  (-0.27467645309409333)\n",
      "     | > loss_dur: 0.20300929248332977  (0.1937614230781186)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.1290, device='cuda:0')  (tensor(14.6577, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.3793  (0.2946141277040756)\n",
      "     | > loader_time: 0.003  (0.0040447225376051285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:57:36 -- STEP: 123/406 -- GLOBAL_STEP: 27325\u001b[0m\n",
      "     | > loss: -0.06722515821456909  (-0.08016188479051359)\n",
      "     | > log_mle: -0.2925471067428589  (-0.27733712370802727)\n",
      "     | > loss_dur: 0.2253219485282898  (0.19717523891751365)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.5039, device='cuda:0')  (tensor(15.3214, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.3203  (0.30610692404150003)\n",
      "     | > loader_time: 0.003  (0.0038655017449603824)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:57:45 -- STEP: 148/406 -- GLOBAL_STEP: 27350\u001b[0m\n",
      "     | > loss: -0.06823621690273285  (-0.07934799035255975)\n",
      "     | > log_mle: -0.298423171043396  (-0.27940099062146384)\n",
      "     | > loss_dur: 0.23018695414066315  (0.200053000268904)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.9011, device='cuda:0')  (tensor(15.9853, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.3473  (0.316821159543218)\n",
      "     | > loader_time: 0.004  (0.003787433778917467)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:57:56 -- STEP: 173/406 -- GLOBAL_STEP: 27375\u001b[0m\n",
      "     | > loss: -0.06788389384746552  (-0.0789570512971437)\n",
      "     | > log_mle: -0.2866095304489136  (-0.28094847216082464)\n",
      "     | > loss_dur: 0.21872563660144806  (0.2019914208636808)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.4361, device='cuda:0')  (tensor(16.5778, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.3743  (0.32834985766107644)\n",
      "     | > loader_time: 0.004  (0.0037666442077283913)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:58:06 -- STEP: 198/406 -- GLOBAL_STEP: 27400\u001b[0m\n",
      "     | > loss: -0.0822114646434784  (-0.07885556675568976)\n",
      "     | > log_mle: -0.29475343227386475  (-0.2825675371921425)\n",
      "     | > loss_dur: 0.21254196763038635  (0.20371197043645264)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.6585, device='cuda:0')  (tensor(16.7914, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.3944  (0.3409029979898472)\n",
      "     | > loader_time: 0.004  (0.00379151286500873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:58:17 -- STEP: 223/406 -- GLOBAL_STEP: 27425\u001b[0m\n",
      "     | > loss: -0.08985923230648041  (-0.07842120461399779)\n",
      "     | > log_mle: -0.2896684408187866  (-0.2839527183584036)\n",
      "     | > loss_dur: 0.1998092085123062  (0.2055315137444056)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.0036, device='cuda:0')  (tensor(17.3804, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.3974  (0.35170390253109785)\n",
      "     | > loader_time: 0.004  (0.003817534767458792)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:58:29 -- STEP: 248/406 -- GLOBAL_STEP: 27450\u001b[0m\n",
      "     | > loss: -0.09044836461544037  (-0.07838177008013572)\n",
      "     | > log_mle: -0.29070544242858887  (-0.28524915104912196)\n",
      "     | > loss_dur: 0.2002570778131485  (0.20686738096898605)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(41.9753, device='cuda:0')  (tensor(17.6540, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.5295  (0.36373656122915204)\n",
      "     | > loader_time: 0.004  (0.003860500551039173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:58:42 -- STEP: 273/406 -- GLOBAL_STEP: 27475\u001b[0m\n",
      "     | > loss: -0.0875912606716156  (-0.0785982615890957)\n",
      "     | > log_mle: -0.3055412769317627  (-0.28638018312908375)\n",
      "     | > loss_dur: 0.2179500162601471  (0.20778192153998784)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.9830, device='cuda:0')  (tensor(18.0521, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.4434  (0.37531406713492715)\n",
      "     | > loader_time: 0.005  (0.0039102454761882404)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:58:55 -- STEP: 298/406 -- GLOBAL_STEP: 27500\u001b[0m\n",
      "     | > loss: -0.07944568991661072  (-0.07824640961101388)\n",
      "     | > log_mle: -0.28277480602264404  (-0.28720635255711213)\n",
      "     | > loss_dur: 0.20332911610603333  (0.20895994294609804)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.4113, device='cuda:0')  (tensor(17.9538, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.6025  (0.38619783020659587)\n",
      "     | > loader_time: 0.004  (0.003965110586793631)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:59:08 -- STEP: 323/406 -- GLOBAL_STEP: 27525\u001b[0m\n",
      "     | > loss: -0.08756561577320099  (-0.078059496571405)\n",
      "     | > log_mle: -0.30328094959259033  (-0.2880966238931239)\n",
      "     | > loss_dur: 0.21571533381938934  (0.21003712732171864)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.5861, device='cuda:0')  (tensor(18.5253, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.4874  (0.39805942718458626)\n",
      "     | > loader_time: 0.005  (0.004011476741117588)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:59:22 -- STEP: 348/406 -- GLOBAL_STEP: 27550\u001b[0m\n",
      "     | > loss: -0.07504145801067352  (-0.07780850991264154)\n",
      "     | > log_mle: -0.2927439212799072  (-0.2888961071255567)\n",
      "     | > loss_dur: 0.2177024632692337  (0.21108759721291476)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.5715, device='cuda:0')  (tensor(18.7081, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.6736  (0.40968937709413733)\n",
      "     | > loader_time: 0.005  (0.004079947526427522)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:59:37 -- STEP: 373/406 -- GLOBAL_STEP: 27575\u001b[0m\n",
      "     | > loss: -0.08600389957427979  (-0.07793593638384302)\n",
      "     | > log_mle: -0.3012228012084961  (-0.2897492206128612)\n",
      "     | > loss_dur: 0.2152189016342163  (0.21181328422901777)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.5236, device='cuda:0')  (tensor(19.0564, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.5635  (0.42093835823018183)\n",
      "     | > loader_time: 0.005  (0.0041499745110723995)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 05:59:53 -- STEP: 398/406 -- GLOBAL_STEP: 27600\u001b[0m\n",
      "     | > loss: -0.08549235761165619  (-0.07801272645218284)\n",
      "     | > log_mle: -0.30672574043273926  (-0.290459379179394)\n",
      "     | > loss_dur: 0.22123338282108307  (0.21244665272721094)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(33.7674, device='cuda:0')  (tensor(20.1694, device='cuda:0'))\n",
      "     | > current_lr: 1.675e-05 \n",
      "     | > step_time: 0.7347  (0.4347128089348875)\n",
      "     | > loader_time: 0.004  (0.004216241477122857)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08905038237571716 \u001b[0m(-0.003499358892440796)\n",
      "     | > avg_loss:\u001b[92m -0.10980363376438618 \u001b[0m(-0.0018465295433998108)\n",
      "     | > avg_log_mle:\u001b[92m -0.30926844477653503 \u001b[0m(-0.000550001859664917)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19946481101214886 \u001b[0m(-0.0012965276837348938)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_27608.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 68/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:00:30) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:00:50 -- STEP: 17/406 -- GLOBAL_STEP: 27625\u001b[0m\n",
      "     | > loss: -0.09356583654880524  (-0.1031824166283888)\n",
      "     | > log_mle: -0.2686340808868408  (-0.27387457735398235)\n",
      "     | > loss_dur: 0.17506824433803558  (0.17069216072559357)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.4560, device='cuda:0')  (tensor(16.7495, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.2582  (0.25676250457763683)\n",
      "     | > loader_time: 0.002  (0.019076277227962717)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:00:57 -- STEP: 42/406 -- GLOBAL_STEP: 27650\u001b[0m\n",
      "     | > loss: -0.08413746953010559  (-0.08945889522631963)\n",
      "     | > log_mle: -0.2779136896133423  (-0.2704670060248602)\n",
      "     | > loss_dur: 0.1937762200832367  (0.18100811079854054)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.8663, device='cuda:0')  (tensor(13.8686, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.2963  (0.2637156304858981)\n",
      "     | > loader_time: 0.002  (0.009103479839506606)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:01:04 -- STEP: 67/406 -- GLOBAL_STEP: 27675\u001b[0m\n",
      "     | > loss: -0.08494807779788971  (-0.08544994312435833)\n",
      "     | > log_mle: -0.2868591547012329  (-0.2726904064861696)\n",
      "     | > loss_dur: 0.2019110769033432  (0.18724046336181127)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.8365, device='cuda:0')  (tensor(13.7066, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.3353  (0.27693808612538806)\n",
      "     | > loader_time: 0.002  (0.006677613329531543)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:01:13 -- STEP: 92/406 -- GLOBAL_STEP: 27700\u001b[0m\n",
      "     | > loss: -0.07015927135944366  (-0.08358724577271419)\n",
      "     | > log_mle: -0.2979010343551636  (-0.27605173510053893)\n",
      "     | > loss_dur: 0.2277417629957199  (0.19246448932782464)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.5429, device='cuda:0')  (tensor(14.3177, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.3613  (0.2903506393017976)\n",
      "     | > loader_time: 0.003  (0.0056028702984685505)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:01:21 -- STEP: 117/406 -- GLOBAL_STEP: 27725\u001b[0m\n",
      "     | > loss: -0.06263087689876556  (-0.08301585390527025)\n",
      "     | > log_mle: -0.2888045310974121  (-0.27879404002784663)\n",
      "     | > loss_dur: 0.22617365419864655  (0.1957781861225764)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.4678, device='cuda:0')  (tensor(15.4700, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.3843  (0.3024114278646616)\n",
      "     | > loader_time: 0.003  (0.005081470196063704)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:01:31 -- STEP: 142/406 -- GLOBAL_STEP: 27750\u001b[0m\n",
      "     | > loss: -0.10113094747066498  (-0.08244613411141113)\n",
      "     | > log_mle: -0.30004584789276123  (-0.2812853212087927)\n",
      "     | > loss_dur: 0.19891490042209625  (0.19883918709738155)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.0832, device='cuda:0')  (tensor(15.9312, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.3323  (0.3139893723205781)\n",
      "     | > loader_time: 0.003  (0.004807136428188272)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:01:41 -- STEP: 167/406 -- GLOBAL_STEP: 27775\u001b[0m\n",
      "     | > loss: -0.08104565739631653  (-0.08184963259511364)\n",
      "     | > log_mle: -0.2951202392578125  (-0.2828537604052149)\n",
      "     | > loss_dur: 0.21407458186149597  (0.2010041278101013)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.8520, device='cuda:0')  (tensor(16.6088, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.3573  (0.3251455329849336)\n",
      "     | > loader_time: 0.004  (0.00463294126316459)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:01:51 -- STEP: 192/406 -- GLOBAL_STEP: 27800\u001b[0m\n",
      "     | > loss: -0.07684898376464844  (-0.08170262118801472)\n",
      "     | > log_mle: -0.2956598997116089  (-0.2844687358786663)\n",
      "     | > loss_dur: 0.21881091594696045  (0.2027661146906515)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.9475, device='cuda:0')  (tensor(16.8098, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.3853  (0.33726976811885834)\n",
      "     | > loader_time: 0.003  (0.004514525334040324)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:02:02 -- STEP: 217/406 -- GLOBAL_STEP: 27825\u001b[0m\n",
      "     | > loss: -0.06418691575527191  (-0.08150981977787983)\n",
      "     | > log_mle: -0.2974379062652588  (-0.28578460820808915)\n",
      "     | > loss_dur: 0.23325099050998688  (0.20427478843020952)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.2083, device='cuda:0')  (tensor(17.4773, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.4064  (0.34858836007008354)\n",
      "     | > loader_time: 0.005  (0.0044695254295103)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:02:14 -- STEP: 242/406 -- GLOBAL_STEP: 27850\u001b[0m\n",
      "     | > loss: -0.0939239114522934  (-0.08147680537759763)\n",
      "     | > log_mle: -0.31588196754455566  (-0.2872529886970834)\n",
      "     | > loss_dur: 0.22195805609226227  (0.20577618331948588)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.9447, device='cuda:0')  (tensor(17.9014, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.5395  (0.35952474854209204)\n",
      "     | > loader_time: 0.004  (0.004437944120612026)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:02:26 -- STEP: 267/406 -- GLOBAL_STEP: 27875\u001b[0m\n",
      "     | > loss: -0.08076250553131104  (-0.08149889775653009)\n",
      "     | > log_mle: -0.29986584186553955  (-0.28825755735461617)\n",
      "     | > loss_dur: 0.21910333633422852  (0.2067586595980862)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.2552, device='cuda:0')  (tensor(18.6186, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.4274  (0.37172696385044285)\n",
      "     | > loader_time: 0.004  (0.004408540797144285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:02:39 -- STEP: 292/406 -- GLOBAL_STEP: 27900\u001b[0m\n",
      "     | > loss: -0.06866934895515442  (-0.08150863968958591)\n",
      "     | > log_mle: -0.2964961528778076  (-0.28920638806199356)\n",
      "     | > loss_dur: 0.2278268039226532  (0.2076977483724078)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.4201, device='cuda:0')  (tensor(18.9935, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.5685  (0.38259389384152137)\n",
      "     | > loader_time: 0.005  (0.004401299234938948)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:02:52 -- STEP: 317/406 -- GLOBAL_STEP: 27925\u001b[0m\n",
      "     | > loss: -0.07743902504444122  (-0.08133716072757913)\n",
      "     | > log_mle: -0.2937765121459961  (-0.29017581849444163)\n",
      "     | > loss_dur: 0.21633748710155487  (0.20883865776686258)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.2850, device='cuda:0')  (tensor(19.4168, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.5045  (0.39465478090833783)\n",
      "     | > loader_time: 0.005  (0.004417308873558644)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:03:06 -- STEP: 342/406 -- GLOBAL_STEP: 27950\u001b[0m\n",
      "     | > loss: -0.0832357406616211  (-0.08100481357490806)\n",
      "     | > log_mle: -0.3023681640625  (-0.290879105963902)\n",
      "     | > loss_dur: 0.2191324234008789  (0.20987429238899405)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(38.3576, device='cuda:0')  (tensor(19.5392, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.6436  (0.4061171924858762)\n",
      "     | > loader_time: 0.005  (0.004433902383547778)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:03:21 -- STEP: 367/406 -- GLOBAL_STEP: 27975\u001b[0m\n",
      "     | > loss: -0.08950532972812653  (-0.08091131441437252)\n",
      "     | > log_mle: -0.29905104637145996  (-0.29164896544058894)\n",
      "     | > loss_dur: 0.20954571664333344  (0.21073765102621642)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.8503, device='cuda:0')  (tensor(20.0453, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.6566  (0.41747705683071534)\n",
      "     | > loader_time: 0.006  (0.004524593457214191)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:03:36 -- STEP: 392/406 -- GLOBAL_STEP: 28000\u001b[0m\n",
      "     | > loss: -0.08419430255889893  (-0.08094758779874864)\n",
      "     | > log_mle: -0.3035249710083008  (-0.2923770732417398)\n",
      "     | > loss_dur: 0.21933066844940186  (0.21142948544299112)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.0849, device='cuda:0')  (tensor(20.2456, device='cuda:0'))\n",
      "     | > current_lr: 1.7e-05 \n",
      "     | > step_time: 0.5645  (0.43058218578903035)\n",
      "     | > loader_time: 0.005  (0.0045603124462828375)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_28000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10211792588233948 \u001b[0m(+0.013067543506622314)\n",
      "     | > avg_loss:\u001b[92m -0.1138121522963047 \u001b[0m(-0.004008518531918526)\n",
      "     | > avg_log_mle:\u001b[92m -0.3131414204835892 \u001b[0m(-0.003872975707054138)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19932926818728447 \u001b[0m(-0.0001355428248643875)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_28014.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 69/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:04:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:04:41 -- STEP: 11/406 -- GLOBAL_STEP: 28025\u001b[0m\n",
      "     | > loss: -0.13072310388088226  (-0.11739634248343381)\n",
      "     | > log_mle: -0.2783355712890625  (-0.27713871002197266)\n",
      "     | > loss_dur: 0.14761246740818024  (0.15974236753853885)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(7.4887, device='cuda:0')  (tensor(13.9400, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.2522  (0.25404882431030273)\n",
      "     | > loader_time: 0.002  (0.024932926351373844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:04:47 -- STEP: 36/406 -- GLOBAL_STEP: 28050\u001b[0m\n",
      "     | > loss: -0.08115638792514801  (-0.09665930395325024)\n",
      "     | > log_mle: -0.26805591583251953  (-0.2744495537545947)\n",
      "     | > loss_dur: 0.18689952790737152  (0.17779024980134434)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.9953, device='cuda:0')  (tensor(16.3742, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.2823  (0.260180718368954)\n",
      "     | > loader_time: 0.003  (0.009147504965464274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:04:55 -- STEP: 61/406 -- GLOBAL_STEP: 28075\u001b[0m\n",
      "     | > loss: -0.051072657108306885  (-0.089852936932298)\n",
      "     | > log_mle: -0.27454936504364014  (-0.27539465271058633)\n",
      "     | > loss_dur: 0.22347670793533325  (0.1855417157782883)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.3363, device='cuda:0')  (tensor(14.4389, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.2813  (0.2739699629486585)\n",
      "     | > loader_time: 0.003  (0.006415945584656763)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:05:03 -- STEP: 86/406 -- GLOBAL_STEP: 28100\u001b[0m\n",
      "     | > loss: -0.08095754683017731  (-0.08795018944629403)\n",
      "     | > log_mle: -0.2791184186935425  (-0.2778771006783774)\n",
      "     | > loss_dur: 0.19816087186336517  (0.18992691123208336)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.7971, device='cuda:0')  (tensor(15.4917, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.3583  (0.2872258230697277)\n",
      "     | > loader_time: 0.003  (0.005318946616594184)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:05:12 -- STEP: 111/406 -- GLOBAL_STEP: 28125\u001b[0m\n",
      "     | > loss: -0.09314794838428497  (-0.08683572521617822)\n",
      "     | > log_mle: -0.3046426773071289  (-0.2808655446714108)\n",
      "     | > loss_dur: 0.21149472892284393  (0.1940298194552327)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.0705, device='cuda:0')  (tensor(17.0157, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.3213  (0.29922658043938694)\n",
      "     | > loader_time: 0.004  (0.004806262952787385)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:05:21 -- STEP: 136/406 -- GLOBAL_STEP: 28150\u001b[0m\n",
      "     | > loss: -0.06822890043258667  (-0.08568369147970398)\n",
      "     | > log_mle: -0.29878509044647217  (-0.28311868274913105)\n",
      "     | > loss_dur: 0.2305561900138855  (0.19743499126942718)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.3690, device='cuda:0')  (tensor(17.3559, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.4204  (0.3108041742268729)\n",
      "     | > loader_time: 0.003  (0.004511550945394182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:05:31 -- STEP: 161/406 -- GLOBAL_STEP: 28175\u001b[0m\n",
      "     | > loss: -0.05553153157234192  (-0.08459401260251584)\n",
      "     | > log_mle: -0.28052759170532227  (-0.28454290043493224)\n",
      "     | > loss_dur: 0.22499606013298035  (0.19994888783241646)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.4555, device='cuda:0')  (tensor(17.2013, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.3493  (0.323094492373259)\n",
      "     | > loader_time: 0.004  (0.004395388668368323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:05:41 -- STEP: 186/406 -- GLOBAL_STEP: 28200\u001b[0m\n",
      "     | > loss: -0.09201590716838837  (-0.08444180035142484)\n",
      "     | > log_mle: -0.3041684627532959  (-0.28615469445464414)\n",
      "     | > loss_dur: 0.21215255558490753  (0.20171289410321938)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.8974, device='cuda:0')  (tensor(18.5091, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.4714  (0.3355357223941433)\n",
      "     | > loader_time: 0.003  (0.004310456655358756)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:05:52 -- STEP: 211/406 -- GLOBAL_STEP: 28225\u001b[0m\n",
      "     | > loss: -0.0996054857969284  (-0.08428851370280384)\n",
      "     | > log_mle: -0.3125185966491699  (-0.28755088666039025)\n",
      "     | > loss_dur: 0.21291311085224152  (0.20326237295758665)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.0084, device='cuda:0')  (tensor(18.2337, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.4804  (0.3466511168186132)\n",
      "     | > loader_time: 0.004  (0.004264625892819954)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:06:03 -- STEP: 236/406 -- GLOBAL_STEP: 28250\u001b[0m\n",
      "     | > loss: -0.07845534384250641  (-0.0838333605078317)\n",
      "     | > log_mle: -0.2878986597061157  (-0.28888397853253217)\n",
      "     | > loss_dur: 0.20944331586360931  (0.20505061802470076)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.8018, device='cuda:0')  (tensor(18.7334, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.4194  (0.3565057940402272)\n",
      "     | > loader_time: 0.004  (0.004249703075926184)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:06:16 -- STEP: 261/406 -- GLOBAL_STEP: 28275\u001b[0m\n",
      "     | > loss: -0.10512396693229675  (-0.08416996119807961)\n",
      "     | > log_mle: -0.3026888370513916  (-0.29024688357137596)\n",
      "     | > loss_dur: 0.19756487011909485  (0.20607692237329664)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.6313, device='cuda:0')  (tensor(19.3098, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.4344  (0.36950397126062606)\n",
      "     | > loader_time: 0.004  (0.004260642318433274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:06:28 -- STEP: 286/406 -- GLOBAL_STEP: 28300\u001b[0m\n",
      "     | > loss: -0.09356269240379333  (-0.08437015084953571)\n",
      "     | > log_mle: -0.3056982755661011  (-0.2913974756961099)\n",
      "     | > loss_dur: 0.21213558316230774  (0.20702732484657443)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.4957, device='cuda:0')  (tensor(19.6611, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.4584  (0.38013874484108867)\n",
      "     | > loader_time: 0.005  (0.004287187036100804)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:06:42 -- STEP: 311/406 -- GLOBAL_STEP: 28325\u001b[0m\n",
      "     | > loss: -0.09201103448867798  (-0.08426587091956488)\n",
      "     | > log_mle: -0.3104877471923828  (-0.29237246360042835)\n",
      "     | > loss_dur: 0.21847671270370483  (0.20810659268086354)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.0464, device='cuda:0')  (tensor(20.0682, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.4704  (0.3924462480943685)\n",
      "     | > loader_time: 0.004  (0.004315886083523181)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:06:55 -- STEP: 336/406 -- GLOBAL_STEP: 28350\u001b[0m\n",
      "     | > loss: -0.06948716938495636  (-0.08393991232982698)\n",
      "     | > log_mle: -0.29122161865234375  (-0.29308776912235046)\n",
      "     | > loss_dur: 0.2217344492673874  (0.20914785679252365)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.7866, device='cuda:0')  (tensor(20.1427, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.6526  (0.40362530308110367)\n",
      "     | > loader_time: 0.006  (0.004352238206636343)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:07:10 -- STEP: 361/406 -- GLOBAL_STEP: 28375\u001b[0m\n",
      "     | > loss: -0.08284254372119904  (-0.08391489266028358)\n",
      "     | > log_mle: -0.3005192279815674  (-0.29392631265265096)\n",
      "     | > loss_dur: 0.21767668426036835  (0.21001141999236758)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.4496, device='cuda:0')  (tensor(20.5502, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.6746  (0.41516909242666983)\n",
      "     | > loader_time: 0.005  (0.004411283292268455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:07:25 -- STEP: 386/406 -- GLOBAL_STEP: 28400\u001b[0m\n",
      "     | > loss: -0.08562253415584564  (-0.0841312562091362)\n",
      "     | > log_mle: -0.30641090869903564  (-0.29475448724519365)\n",
      "     | > loss_dur: 0.22078837454319  (0.21062323103605768)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.2026, device='cuda:0')  (tensor(20.9257, device='cuda:0'))\n",
      "     | > current_lr: 1.725e-05 \n",
      "     | > step_time: 0.7096  (0.42798697577856976)\n",
      "     | > loader_time: 0.005  (0.004454889445724888)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0875813364982605 \u001b[0m(-0.01453658938407898)\n",
      "     | > avg_loss:\u001b[92m -0.11712119728326797 \u001b[0m(-0.003309044986963272)\n",
      "     | > avg_log_mle:\u001b[92m -0.3162446767091751 \u001b[0m(-0.0031032562255859375)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19912347942590714 \u001b[0m(-0.0002057887613773346)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_28420.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 70/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:08:09) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:08:27 -- STEP: 5/406 -- GLOBAL_STEP: 28425\u001b[0m\n",
      "     | > loss: -0.10830222070217133  (-0.12912817001342775)\n",
      "     | > log_mle: -0.27108490467071533  (-0.2797404289245605)\n",
      "     | > loss_dur: 0.162782683968544  (0.1506122589111328)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.5768, device='cuda:0')  (tensor(15.0031, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.2492  (0.25523128509521487)\n",
      "     | > loader_time: 0.001  (0.054649734497070314)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:08:33 -- STEP: 30/406 -- GLOBAL_STEP: 28450\u001b[0m\n",
      "     | > loss: -0.09064015746116638  (-0.10243405898412068)\n",
      "     | > log_mle: -0.27318620681762695  (-0.2768113891283671)\n",
      "     | > loss_dur: 0.18254604935646057  (0.17437733014424642)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.6408, device='cuda:0')  (tensor(14.1855, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.2542  (0.2590682506561279)\n",
      "     | > loader_time: 0.003  (0.010643283526102701)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:08:40 -- STEP: 55/406 -- GLOBAL_STEP: 28475\u001b[0m\n",
      "     | > loss: -0.08998116850852966  (-0.09333703761751001)\n",
      "     | > log_mle: -0.289931058883667  (-0.2767137072303078)\n",
      "     | > loss_dur: 0.19994989037513733  (0.18337666961279786)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.3820, device='cuda:0')  (tensor(13.7744, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.2793  (0.27057258866050027)\n",
      "     | > loader_time: 0.003  (0.006897592544555662)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:08:48 -- STEP: 80/406 -- GLOBAL_STEP: 28500\u001b[0m\n",
      "     | > loss: -0.0779120922088623  (-0.09061737079173328)\n",
      "     | > log_mle: -0.2717454433441162  (-0.2788036137819291)\n",
      "     | > loss_dur: 0.1938333511352539  (0.18818624299019585)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.1066, device='cuda:0')  (tensor(15.5619, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.2953  (0.2838198095560074)\n",
      "     | > loader_time: 0.003  (0.005605462193489074)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:08:57 -- STEP: 105/406 -- GLOBAL_STEP: 28525\u001b[0m\n",
      "     | > loss: -0.09431497752666473  (-0.08997060841038115)\n",
      "     | > log_mle: -0.28314733505249023  (-0.282174673534575)\n",
      "     | > loss_dur: 0.1888323575258255  (0.19220406512419388)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.4151, device='cuda:0')  (tensor(15.9613, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.3113  (0.29703120958237417)\n",
      "     | > loader_time: 0.003  (0.004957262674967446)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:09:06 -- STEP: 130/406 -- GLOBAL_STEP: 28550\u001b[0m\n",
      "     | > loss: -0.09178869426250458  (-0.08933448699804454)\n",
      "     | > log_mle: -0.29730796813964844  (-0.2847046980491052)\n",
      "     | > loss_dur: 0.20551927387714386  (0.19537021105106067)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.5260, device='cuda:0')  (tensor(16.9005, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.3293  (0.3090340394240159)\n",
      "     | > loader_time: 0.003  (0.0046199633524968056)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:09:16 -- STEP: 155/406 -- GLOBAL_STEP: 28575\u001b[0m\n",
      "     | > loss: -0.07087750732898712  (-0.08873044665782685)\n",
      "     | > log_mle: -0.2848447561264038  (-0.2865101506633142)\n",
      "     | > loss_dur: 0.2139672487974167  (0.19777970400548756)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.8448, device='cuda:0')  (tensor(17.1673, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.3593  (0.3199675467706497)\n",
      "     | > loader_time: 0.005  (0.0044366621202038175)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:09:26 -- STEP: 180/406 -- GLOBAL_STEP: 28600\u001b[0m\n",
      "     | > loss: -0.08255098760128021  (-0.08831814684801634)\n",
      "     | > log_mle: -0.30131328105926514  (-0.2880003730456032)\n",
      "     | > loss_dur: 0.21876229345798492  (0.19968222619758716)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.5887, device='cuda:0')  (tensor(17.2387, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.4664  (0.3318448543548586)\n",
      "     | > loader_time: 0.004  (0.004348766803741456)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:09:37 -- STEP: 205/406 -- GLOBAL_STEP: 28625\u001b[0m\n",
      "     | > loss: -0.08732117712497711  (-0.08774138107532409)\n",
      "     | > log_mle: -0.3126969337463379  (-0.28948438981684227)\n",
      "     | > loss_dur: 0.22537575662136078  (0.20174300874151838)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.0487, device='cuda:0')  (tensor(17.5326, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.4824  (0.34336462718684513)\n",
      "     | > loader_time: 0.004  (0.004296893608279346)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:09:48 -- STEP: 230/406 -- GLOBAL_STEP: 28650\u001b[0m\n",
      "     | > loss: -0.08141303062438965  (-0.08757858658614366)\n",
      "     | > log_mle: -0.3043637275695801  (-0.29083233294279653)\n",
      "     | > loss_dur: 0.22295069694519043  (0.20325374635665316)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(51.7063, device='cuda:0')  (tensor(19.5378, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.4064  (0.3533461923184603)\n",
      "     | > loader_time: 0.004  (0.004278074140134068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:10:00 -- STEP: 255/406 -- GLOBAL_STEP: 28675\u001b[0m\n",
      "     | > loss: -0.09405016899108887  (-0.087608963952345)\n",
      "     | > log_mle: -0.30081677436828613  (-0.2921943907644232)\n",
      "     | > loss_dur: 0.20676660537719727  (0.20458542681207847)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.0718, device='cuda:0')  (tensor(19.7813, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.4264  (0.36557441786223777)\n",
      "     | > loader_time: 0.004  (0.004278642991009883)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:10:12 -- STEP: 280/406 -- GLOBAL_STEP: 28700\u001b[0m\n",
      "     | > loss: -0.09412629902362823  (-0.08782549239695071)\n",
      "     | > log_mle: -0.31195151805877686  (-0.29330598797116936)\n",
      "     | > loss_dur: 0.21782521903514862  (0.2054804955742189)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(37.3847, device='cuda:0')  (tensor(20.5680, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.4474  (0.37703459347997403)\n",
      "     | > loader_time: 0.004  (0.0042898501668657595)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:10:25 -- STEP: 305/406 -- GLOBAL_STEP: 28725\u001b[0m\n",
      "     | > loss: -0.06944477558135986  (-0.08764785870176844)\n",
      "     | > log_mle: -0.30053281784057617  (-0.2943302588384657)\n",
      "     | > loss_dur: 0.2310880422592163  (0.20668240013669753)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(40.3442, device='cuda:0')  (tensor(20.8825, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.4934  (0.3886605270573353)\n",
      "     | > loader_time: 0.005  (0.004312326869026562)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:10:39 -- STEP: 330/406 -- GLOBAL_STEP: 28750\u001b[0m\n",
      "     | > loss: -0.08332021534442902  (-0.08748256803461996)\n",
      "     | > log_mle: -0.31424379348754883  (-0.295081581130172)\n",
      "     | > loss_dur: 0.2309235781431198  (0.20759901309555231)\n",
      "     | > amp_scaler: 16384.0  (8787.781818181815)\n",
      "     | > grad_norm: tensor(23.0817, device='cuda:0')  (tensor(20.9375, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.4904  (0.4002508228475398)\n",
      "     | > loader_time: 0.005  (0.0043526324358853456)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:10:53 -- STEP: 355/406 -- GLOBAL_STEP: 28775\u001b[0m\n",
      "     | > loss: -0.09043560922145844  (-0.0872221897605439)\n",
      "     | > log_mle: -0.3130500316619873  (-0.29587366580963115)\n",
      "     | > loss_dur: 0.22261442244052887  (0.20865147604908746)\n",
      "     | > amp_scaler: 8192.0  (9022.738028169011)\n",
      "     | > grad_norm: tensor(21.6333, device='cuda:0')  (tensor(20.9670, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.5255  (0.4119144110612467)\n",
      "     | > loader_time: 0.005  (0.004404169405010385)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:11:09 -- STEP: 380/406 -- GLOBAL_STEP: 28800\u001b[0m\n",
      "     | > loss: -0.08576694130897522  (-0.08730006719890392)\n",
      "     | > log_mle: -0.3057835102081299  (-0.29660495645121504)\n",
      "     | > loss_dur: 0.22001656889915466  (0.20930488925231133)\n",
      "     | > amp_scaler: 8192.0  (8968.084210526315)\n",
      "     | > grad_norm: tensor(26.3196, device='cuda:0')  (tensor(21.3683, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.6686  (0.42435055782920444)\n",
      "     | > loader_time: 0.005  (0.004438412816900956)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:11:24 -- STEP: 405/406 -- GLOBAL_STEP: 28825\u001b[0m\n",
      "     | > loss: -0.0973891168832779  (-0.08741852567519669)\n",
      "     | > log_mle: -0.30677783489227295  (-0.2973557036599992)\n",
      "     | > loss_dur: 0.20938871800899506  (0.20993717798480285)\n",
      "     | > amp_scaler: 8192.0  (8920.177777777775)\n",
      "     | > grad_norm: tensor(13.9918, device='cuda:0')  (tensor(21.8380, device='cuda:0'))\n",
      "     | > current_lr: 1.7500000000000002e-05 \n",
      "     | > step_time: 0.3053  (0.4369098916465854)\n",
      "     | > loader_time: 0.002  (0.004451124167736666)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09621265530586243 \u001b[0m(+0.008631318807601929)\n",
      "     | > avg_loss:\u001b[92m -0.12214788421988487 \u001b[0m(-0.005026686936616898)\n",
      "     | > avg_log_mle:\u001b[92m -0.318375363945961 \u001b[0m(-0.0021306872367858887)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19622747972607613 \u001b[0m(-0.002895999699831009)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_28826.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 71/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:11:56) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:12:19 -- STEP: 24/406 -- GLOBAL_STEP: 28850\u001b[0m\n",
      "     | > loss: -0.09980595111846924  (-0.10982854415973027)\n",
      "     | > log_mle: -0.27188408374786377  (-0.27764535943667096)\n",
      "     | > loss_dur: 0.17207813262939453  (0.16781681527694067)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.7275, device='cuda:0')  (tensor(20.3090, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.2592  (0.2579009731610616)\n",
      "     | > loader_time: 0.002  (0.011385271946589151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:12:26 -- STEP: 49/406 -- GLOBAL_STEP: 28875\u001b[0m\n",
      "     | > loss: -0.07941007614135742  (-0.0967017910918411)\n",
      "     | > log_mle: -0.27861058712005615  (-0.275853266521376)\n",
      "     | > loss_dur: 0.19920051097869873  (0.1791514754295349)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(6.8801, device='cuda:0')  (tensor(15.3052, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.2722  (0.2682640649834458)\n",
      "     | > loader_time: 0.003  (0.006781587795335419)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:12:33 -- STEP: 74/406 -- GLOBAL_STEP: 28900\u001b[0m\n",
      "     | > loss: -0.07713189721107483  (-0.09294052663687113)\n",
      "     | > log_mle: -0.307675838470459  (-0.2790449438868343)\n",
      "     | > loss_dur: 0.23054394125938416  (0.1861044172499631)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.6061, device='cuda:0')  (tensor(15.9871, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.2933  (0.28109320434364116)\n",
      "     | > loader_time: 0.002  (0.0053966754191630585)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:12:42 -- STEP: 99/406 -- GLOBAL_STEP: 28925\u001b[0m\n",
      "     | > loss: -0.08881542086601257  (-0.0917239597048422)\n",
      "     | > log_mle: -0.28953373432159424  (-0.2823571087134005)\n",
      "     | > loss_dur: 0.20071831345558167  (0.19063314900855827)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(30.7325, device='cuda:0')  (tensor(16.7381, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.3083  (0.2941358980506359)\n",
      "     | > loader_time: 0.003  (0.00477188042920045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:12:51 -- STEP: 124/406 -- GLOBAL_STEP: 28950\u001b[0m\n",
      "     | > loss: -0.08350761234760284  (-0.09151236676881389)\n",
      "     | > log_mle: -0.2996635437011719  (-0.2854801416397096)\n",
      "     | > loss_dur: 0.21615593135356903  (0.19396777487089556)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.8163, device='cuda:0')  (tensor(17.5350, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.3924  (0.30632659696763576)\n",
      "     | > loader_time: 0.003  (0.004447539006510088)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:13:00 -- STEP: 149/406 -- GLOBAL_STEP: 28975\u001b[0m\n",
      "     | > loss: -0.08168129622936249  (-0.0914697049048123)\n",
      "     | > log_mle: -0.30521726608276367  (-0.28789815566683785)\n",
      "     | > loss_dur: 0.22353596985340118  (0.19642845076202547)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.6748, device='cuda:0')  (tensor(17.7706, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.4154  (0.31724109905678166)\n",
      "     | > loader_time: 0.004  (0.004299171818982833)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:13:10 -- STEP: 174/406 -- GLOBAL_STEP: 29000\u001b[0m\n",
      "     | > loss: -0.08535979688167572  (-0.09095234860633984)\n",
      "     | > log_mle: -0.29230356216430664  (-0.2893357167298766)\n",
      "     | > loss_dur: 0.20694376528263092  (0.19838336812353682)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.7432, device='cuda:0')  (tensor(18.3855, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.4404  (0.32862598594577846)\n",
      "     | > loader_time: 0.004  (0.004204948743184407)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_29000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:13:25 -- STEP: 199/406 -- GLOBAL_STEP: 29025\u001b[0m\n",
      "     | > loss: -0.07659298181533813  (-0.09097712820199269)\n",
      "     | > log_mle: -0.2937883138656616  (-0.29105134405682437)\n",
      "     | > loss_dur: 0.2171953320503235  (0.20007421585483168)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.8028, device='cuda:0')  (tensor(18.8893, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.4824  (0.3423039002634174)\n",
      "     | > loader_time: 0.004  (0.004174569144320848)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:13:36 -- STEP: 224/406 -- GLOBAL_STEP: 29050\u001b[0m\n",
      "     | > loss: -0.10215924680233002  (-0.09092913840764337)\n",
      "     | > log_mle: -0.30069899559020996  (-0.2926311657897065)\n",
      "     | > loss_dur: 0.19853974878787994  (0.20170202738206303)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.1190, device='cuda:0')  (tensor(18.9932, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.4064  (0.3522467698369708)\n",
      "     | > loader_time: 0.004  (0.004146558897835868)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:13:48 -- STEP: 249/406 -- GLOBAL_STEP: 29075\u001b[0m\n",
      "     | > loss: -0.08808471262454987  (-0.09067993985122468)\n",
      "     | > log_mle: -0.2946763038635254  (-0.2938567457428899)\n",
      "     | > loss_dur: 0.20659159123897552  (0.20317680589166512)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.1385, device='cuda:0')  (tensor(19.6170, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.4204  (0.3642609799243361)\n",
      "     | > loader_time: 0.004  (0.004160374522687921)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:14:01 -- STEP: 274/406 -- GLOBAL_STEP: 29100\u001b[0m\n",
      "     | > loss: -0.09041658043861389  (-0.09095701580717618)\n",
      "     | > log_mle: -0.3058433532714844  (-0.2950388915347358)\n",
      "     | > loss_dur: 0.21542677283287048  (0.20408187572755956)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.8574, device='cuda:0')  (tensor(19.9123, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.4484  (0.37577417384098916)\n",
      "     | > loader_time: 0.004  (0.004182594535994706)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:14:14 -- STEP: 299/406 -- GLOBAL_STEP: 29125\u001b[0m\n",
      "     | > loss: -0.11444486677646637  (-0.09089686943336475)\n",
      "     | > log_mle: -0.32997429370880127  (-0.2959767408594241)\n",
      "     | > loss_dur: 0.2155294269323349  (0.20507987142605927)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.7801, device='cuda:0')  (tensor(19.7513, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.6045  (0.3870927139269468)\n",
      "     | > loader_time: 0.005  (0.004214494124702787)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:14:27 -- STEP: 324/406 -- GLOBAL_STEP: 29150\u001b[0m\n",
      "     | > loss: -0.0984124094247818  (-0.0906987179208685)\n",
      "     | > log_mle: -0.30583417415618896  (-0.2967964432857657)\n",
      "     | > loss_dur: 0.20742176473140717  (0.20609772536489698)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(33.7092, device='cuda:0')  (tensor(20.1304, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.5075  (0.3986818370995699)\n",
      "     | > loader_time: 0.005  (0.004244563020305871)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:14:41 -- STEP: 349/406 -- GLOBAL_STEP: 29175\u001b[0m\n",
      "     | > loss: -0.06001506745815277  (-0.09033404576744254)\n",
      "     | > log_mle: -0.30398428440093994  (-0.2975900986133129)\n",
      "     | > loss_dur: 0.24396921694278717  (0.20725605284587018)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.3663, device='cuda:0')  (tensor(20.4075, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.5115  (0.41055511061988115)\n",
      "     | > loader_time: 0.005  (0.004287510683338418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:14:56 -- STEP: 374/406 -- GLOBAL_STEP: 29200\u001b[0m\n",
      "     | > loss: -0.09871287643909454  (-0.09057010387513727)\n",
      "     | > log_mle: -0.3076813220977783  (-0.2984820792381778)\n",
      "     | > loss_dur: 0.20896844565868378  (0.20791197536304035)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.3496, device='cuda:0')  (tensor(20.6566, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.6996  (0.42222195321863354)\n",
      "     | > loader_time: 0.005  (0.004335445516249714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:15:12 -- STEP: 399/406 -- GLOBAL_STEP: 29225\u001b[0m\n",
      "     | > loss: -0.07444685697555542  (-0.0905587494298629)\n",
      "     | > log_mle: -0.3079032897949219  (-0.2992686263301918)\n",
      "     | > loss_dur: 0.23345643281936646  (0.20870987690032872)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(39.8329, device='cuda:0')  (tensor(20.8063, device='cuda:0'))\n",
      "     | > current_lr: 1.775e-05 \n",
      "     | > step_time: 0.5634  (0.43577556861074357)\n",
      "     | > loader_time: 0.005  (0.004377351966418121)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09608674049377441 \u001b[0m(-0.0001259148120880127)\n",
      "     | > avg_loss:\u001b[91m -0.11642088741064072 \u001b[0m(+0.005726996809244156)\n",
      "     | > avg_log_mle:\u001b[91m -0.31556436419487 \u001b[0m(+0.0028109997510910034)\n",
      "     | > avg_loss_dur:\u001b[91m 0.19914347678422928 \u001b[0m(+0.0029159970581531525)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 72/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:15:47) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:16:08 -- STEP: 18/406 -- GLOBAL_STEP: 29250\u001b[0m\n",
      "     | > loss: -0.09983356297016144  (-0.11654330955611335)\n",
      "     | > log_mle: -0.2719303369522095  (-0.28359230359395343)\n",
      "     | > loss_dur: 0.17209677398204803  (0.1670489940378401)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.2237, device='cuda:0')  (tensor(15.0242, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.2552  (0.2553987503051758)\n",
      "     | > loader_time: 0.002  (0.01251135932074653)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:16:15 -- STEP: 43/406 -- GLOBAL_STEP: 29275\u001b[0m\n",
      "     | > loss: -0.10233348608016968  (-0.10340433203896811)\n",
      "     | > log_mle: -0.2712862491607666  (-0.27978907075039167)\n",
      "     | > loss_dur: 0.16895276308059692  (0.1763847387114236)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.5135, device='cuda:0')  (tensor(13.4609, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.2983  (0.26396070524703624)\n",
      "     | > loader_time: 0.003  (0.006540864012962166)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:16:22 -- STEP: 68/406 -- GLOBAL_STEP: 29300\u001b[0m\n",
      "     | > loss: -0.08186802268028259  (-0.09809257353053373)\n",
      "     | > log_mle: -0.28886115550994873  (-0.281604908845004)\n",
      "     | > loss_dur: 0.20699313282966614  (0.18351233531447012)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.5995, device='cuda:0')  (tensor(15.5132, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.2923  (0.27682501428267536)\n",
      "     | > loader_time: 0.003  (0.005033931311439066)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:16:31 -- STEP: 93/406 -- GLOBAL_STEP: 29325\u001b[0m\n",
      "     | > loss: -0.1061471551656723  (-0.09682454841752205)\n",
      "     | > log_mle: -0.31603097915649414  (-0.28530841617174063)\n",
      "     | > loss_dur: 0.20988382399082184  (0.18848386775421835)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.5258, device='cuda:0')  (tensor(16.5931, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.3113  (0.29054351006784745)\n",
      "     | > loader_time: 0.003  (0.0044125305709018505)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:16:39 -- STEP: 118/406 -- GLOBAL_STEP: 29350\u001b[0m\n",
      "     | > loss: -0.09307710826396942  (-0.09589750180810185)\n",
      "     | > log_mle: -0.2969326972961426  (-0.2879939503588922)\n",
      "     | > loss_dur: 0.20385558903217316  (0.19209644855079)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.5886, device='cuda:0')  (tensor(17.2573, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.3203  (0.302647758338411)\n",
      "     | > loader_time: 0.003  (0.0041393001200789115)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:16:49 -- STEP: 143/406 -- GLOBAL_STEP: 29375\u001b[0m\n",
      "     | > loss: -0.09641757607460022  (-0.09520520592902924)\n",
      "     | > log_mle: -0.3088395595550537  (-0.2905009801571188)\n",
      "     | > loss_dur: 0.2124219834804535  (0.1952957742280893)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(40.8958, device='cuda:0')  (tensor(18.2836, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.4154  (0.31566426470563136)\n",
      "     | > loader_time: 0.003  (0.003982622306663673)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:16:59 -- STEP: 168/406 -- GLOBAL_STEP: 29400\u001b[0m\n",
      "     | > loss: -0.08946011960506439  (-0.09452547443409759)\n",
      "     | > log_mle: -0.29283177852630615  (-0.2919496993223828)\n",
      "     | > loss_dur: 0.20337165892124176  (0.19742422488828495)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.1479, device='cuda:0')  (tensor(18.6653, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.3633  (0.32565287890888395)\n",
      "     | > loader_time: 0.004  (0.003932136864889235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:17:09 -- STEP: 193/406 -- GLOBAL_STEP: 29425\u001b[0m\n",
      "     | > loss: -0.09543144702911377  (-0.09425198143936805)\n",
      "     | > log_mle: -0.31259918212890625  (-0.2934783623008534)\n",
      "     | > loss_dur: 0.21716773509979248  (0.19922638086148492)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.4595, device='cuda:0')  (tensor(19.2658, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.4614  (0.3375552268843575)\n",
      "     | > loader_time: 0.004  (0.003920681118347483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:17:20 -- STEP: 218/406 -- GLOBAL_STEP: 29450\u001b[0m\n",
      "     | > loss: -0.086400106549263  (-0.09400478490722286)\n",
      "     | > log_mle: -0.3065357208251953  (-0.2948021172383514)\n",
      "     | > loss_dur: 0.2201356142759323  (0.20079733233112804)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(30.7086, device='cuda:0')  (tensor(19.5470, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.4034  (0.3479453937723001)\n",
      "     | > loader_time: 0.004  (0.003911838618987196)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:17:32 -- STEP: 243/406 -- GLOBAL_STEP: 29475\u001b[0m\n",
      "     | > loss: -0.0888623595237732  (-0.09387039598614097)\n",
      "     | > log_mle: -0.32166802883148193  (-0.29627468507476346)\n",
      "     | > loss_dur: 0.23280566930770874  (0.202404289088622)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(33.2094, device='cuda:0')  (tensor(20.5174, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.5285  (0.3589688308935596)\n",
      "     | > loader_time: 0.005  (0.003929510038085434)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:17:44 -- STEP: 268/406 -- GLOBAL_STEP: 29500\u001b[0m\n",
      "     | > loss: -0.10312999784946442  (-0.09393347660774613)\n",
      "     | > log_mle: -0.31232142448425293  (-0.2972843811583167)\n",
      "     | > loss_dur: 0.2091914266347885  (0.20335090455057014)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.9615, device='cuda:0')  (tensor(20.5445, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.5385  (0.37091223873309226)\n",
      "     | > loader_time: 0.005  (0.003962560376124593)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:17:56 -- STEP: 293/406 -- GLOBAL_STEP: 29525\u001b[0m\n",
      "     | > loss: -0.09752082824707031  (-0.09388070708655655)\n",
      "     | > log_mle: -0.31153202056884766  (-0.29824460529223273)\n",
      "     | > loss_dur: 0.21401119232177734  (0.20436389820567574)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(59.0260, device='cuda:0')  (tensor(20.8908, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.4714  (0.38127871747716685)\n",
      "     | > loader_time: 0.004  (0.00400360289694099)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:18:10 -- STEP: 318/406 -- GLOBAL_STEP: 29550\u001b[0m\n",
      "     | > loss: -0.08295279741287231  (-0.09366412310855189)\n",
      "     | > log_mle: -0.3063305616378784  (-0.29915652110141816)\n",
      "     | > loss_dur: 0.2233777642250061  (0.2054923979928658)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.0827, device='cuda:0')  (tensor(21.4800, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.4884  (0.3930903725654073)\n",
      "     | > loader_time: 0.005  (0.004063391835434631)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:18:24 -- STEP: 343/406 -- GLOBAL_STEP: 29575\u001b[0m\n",
      "     | > loss: -0.0814385712146759  (-0.09346904803295521)\n",
      "     | > log_mle: -0.32034194469451904  (-0.29992090091760953)\n",
      "     | > loss_dur: 0.23890337347984314  (0.206451852884654)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.7068, device='cuda:0')  (tensor(22.1264, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.5005  (0.4043241304836883)\n",
      "     | > loader_time: 0.004  (0.004120296361495039)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:18:38 -- STEP: 368/406 -- GLOBAL_STEP: 29600\u001b[0m\n",
      "     | > loss: -0.10605432093143463  (-0.09357939879207504)\n",
      "     | > log_mle: -0.32059764862060547  (-0.3007801673982457)\n",
      "     | > loss_dur: 0.21454332768917084  (0.20720076860617032)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.0549, device='cuda:0')  (tensor(22.3392, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.5405  (0.41539692230846553)\n",
      "     | > loader_time: 0.005  (0.004174923767214235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:18:54 -- STEP: 393/406 -- GLOBAL_STEP: 29625\u001b[0m\n",
      "     | > loss: -0.0898996889591217  (-0.09368236673848923)\n",
      "     | > log_mle: -0.31065213680267334  (-0.3015416769580989)\n",
      "     | > loss_dur: 0.22075244784355164  (0.20785931021960938)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.7197, device='cuda:0')  (tensor(22.5883, device='cuda:0'))\n",
      "     | > current_lr: 1.8e-05 \n",
      "     | > step_time: 0.6856  (0.42848488453386985)\n",
      "     | > loader_time: 0.005  (0.004232783353965701)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08997640013694763 \u001b[0m(-0.006110340356826782)\n",
      "     | > avg_loss:\u001b[92m -0.1270944233983755 \u001b[0m(-0.010673535987734795)\n",
      "     | > avg_log_mle:\u001b[92m -0.3224352151155472 \u001b[0m(-0.006870850920677185)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19534079171717167 \u001b[0m(-0.0038026850670576096)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_29638.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 73/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:19:33) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:19:52 -- STEP: 12/406 -- GLOBAL_STEP: 29650\u001b[0m\n",
      "     | > loss: -0.12281337380409241  (-0.13191289082169533)\n",
      "     | > log_mle: -0.29293394088745117  (-0.28768829504648846)\n",
      "     | > loss_dur: 0.17012056708335876  (0.1557754042247931)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.5404, device='cuda:0')  (tensor(17.8069, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.2522  (0.2525627414385478)\n",
      "     | > loader_time: 0.002  (0.021602710088094074)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:19:59 -- STEP: 37/406 -- GLOBAL_STEP: 29675\u001b[0m\n",
      "     | > loss: -0.08564285933971405  (-0.11145148083970353)\n",
      "     | > log_mle: -0.2750324010848999  (-0.28432126947351405)\n",
      "     | > loss_dur: 0.18938954174518585  (0.1728697886338105)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.7369, device='cuda:0')  (tensor(16.0140, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.2873  (0.2608855866097115)\n",
      "     | > loader_time: 0.002  (0.008412863757159258)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:20:06 -- STEP: 62/406 -- GLOBAL_STEP: 29700\u001b[0m\n",
      "     | > loss: -0.09326760470867157  (-0.10362821865466333)\n",
      "     | > log_mle: -0.27470409870147705  (-0.2850348680250107)\n",
      "     | > loss_dur: 0.18143649399280548  (0.1814066493703473)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.2674, device='cuda:0')  (tensor(16.1688, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.3263  (0.274959441154234)\n",
      "     | > loader_time: 0.003  (0.006053647687358241)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:20:15 -- STEP: 87/406 -- GLOBAL_STEP: 29725\u001b[0m\n",
      "     | > loss: -0.10951387882232666  (-0.10181096624368909)\n",
      "     | > log_mle: -0.3153434991836548  (-0.2880854168157469)\n",
      "     | > loss_dur: 0.20582962036132812  (0.18627445057205771)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.9929, device='cuda:0')  (tensor(17.1159, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.3073  (0.2880432633147843)\n",
      "     | > loader_time: 0.003  (0.005130937729758777)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:20:23 -- STEP: 112/406 -- GLOBAL_STEP: 29750\u001b[0m\n",
      "     | > loss: -0.11618447303771973  (-0.10136606650693077)\n",
      "     | > log_mle: -0.31074631214141846  (-0.2908150330185893)\n",
      "     | > loss_dur: 0.19456183910369873  (0.18944896651165827)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.9753, device='cuda:0')  (tensor(17.7439, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.3843  (0.30094300636223376)\n",
      "     | > loader_time: 0.003  (0.004646937761987958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:20:33 -- STEP: 137/406 -- GLOBAL_STEP: 29775\u001b[0m\n",
      "     | > loss: -0.08304892480373383  (-0.0998135482090233)\n",
      "     | > log_mle: -0.30206775665283203  (-0.29287732778674513)\n",
      "     | > loss_dur: 0.2190188318490982  (0.19306377957772164)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.4450, device='cuda:0')  (tensor(18.5738, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.3413  (0.3129119176934235)\n",
      "     | > loader_time: 0.003  (0.0043980640216465415)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:20:42 -- STEP: 162/406 -- GLOBAL_STEP: 29800\u001b[0m\n",
      "     | > loss: -0.08785873651504517  (-0.0986615581276976)\n",
      "     | > log_mle: -0.3203214406967163  (-0.2943708123984163)\n",
      "     | > loss_dur: 0.23246270418167114  (0.19570925427071842)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(31.1829, device='cuda:0')  (tensor(19.2339, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.4424  (0.32436864022855416)\n",
      "     | > loader_time: 0.004  (0.00425687101152208)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:20:53 -- STEP: 187/406 -- GLOBAL_STEP: 29825\u001b[0m\n",
      "     | > loss: -0.1004277765750885  (-0.09870449250394647)\n",
      "     | > log_mle: -0.30665719509124756  (-0.2959963714375217)\n",
      "     | > loss_dur: 0.20622941851615906  (0.19729187893357505)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.0844, device='cuda:0')  (tensor(19.6924, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.3763  (0.3363267878160121)\n",
      "     | > loader_time: 0.004  (0.004206965951358569)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:21:04 -- STEP: 212/406 -- GLOBAL_STEP: 29850\u001b[0m\n",
      "     | > loss: -0.09214821457862854  (-0.09830954720108014)\n",
      "     | > log_mle: -0.3099997043609619  (-0.2973593181034306)\n",
      "     | > loss_dur: 0.21785148978233337  (0.19904977090235026)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(34.7236, device='cuda:0')  (tensor(20.1270, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.4024  (0.3476080849485579)\n",
      "     | > loader_time: 0.004  (0.004173550965651027)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:21:15 -- STEP: 237/406 -- GLOBAL_STEP: 29875\u001b[0m\n",
      "     | > loss: -0.08678993582725525  (-0.09808549354096505)\n",
      "     | > log_mle: -0.3169804811477661  (-0.2987857448400829)\n",
      "     | > loss_dur: 0.23019054532051086  (0.2007002512991177)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(33.9511, device='cuda:0')  (tensor(20.6360, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.5285  (0.3585238788701312)\n",
      "     | > loader_time: 0.004  (0.004176735374997942)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:21:28 -- STEP: 262/406 -- GLOBAL_STEP: 29900\u001b[0m\n",
      "     | > loss: -0.08403412997722626  (-0.0981900447993788)\n",
      "     | > log_mle: -0.2987809181213379  (-0.29991458709003377)\n",
      "     | > loss_dur: 0.21474678814411163  (0.2017245422906548)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.3876, device='cuda:0')  (tensor(21.1916, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.5415  (0.37082911811712144)\n",
      "     | > loader_time: 0.005  (0.004171660838236338)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:21:40 -- STEP: 287/406 -- GLOBAL_STEP: 29925\u001b[0m\n",
      "     | > loss: -0.06388996541500092  (-0.09817916466383983)\n",
      "     | > log_mle: -0.30115222930908203  (-0.30097252691249005)\n",
      "     | > loss_dur: 0.23726226389408112  (0.20279336224864994)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.0885, device='cuda:0')  (tensor(21.1572, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.5605  (0.38100803023016006)\n",
      "     | > loader_time: 0.004  (0.004195366171594282)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:21:53 -- STEP: 312/406 -- GLOBAL_STEP: 29950\u001b[0m\n",
      "     | > loss: -0.09403157234191895  (-0.09790770131617019)\n",
      "     | > log_mle: -0.30250704288482666  (-0.3018288092735488)\n",
      "     | > loss_dur: 0.20847547054290771  (0.20392110795737828)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.0429, device='cuda:0')  (tensor(21.5551, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.4824  (0.39251351203673923)\n",
      "     | > loader_time: 0.005  (0.004228139534974711)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:22:07 -- STEP: 337/406 -- GLOBAL_STEP: 29975\u001b[0m\n",
      "     | > loss: -0.11260372400283813  (-0.09771804816645045)\n",
      "     | > log_mle: -0.32030367851257324  (-0.3025788535703894)\n",
      "     | > loss_dur: 0.2076999545097351  (0.2048608054039385)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.6179, device='cuda:0')  (tensor(21.5774, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.6336  (0.4036544041393065)\n",
      "     | > loader_time: 0.004  (0.004276806239911995)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:22:21 -- STEP: 362/406 -- GLOBAL_STEP: 30000\u001b[0m\n",
      "     | > loss: -0.09897647798061371  (-0.09753322000332298)\n",
      "     | > log_mle: -0.3150538206100464  (-0.30337707245547474)\n",
      "     | > loss_dur: 0.21607734262943268  (0.20584385245215156)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.2539, device='cuda:0')  (tensor(21.6276, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.5425  (0.4146030285081811)\n",
      "     | > loader_time: 0.004  (0.004313232490370946)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_30000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:22:42 -- STEP: 387/406 -- GLOBAL_STEP: 30025\u001b[0m\n",
      "     | > loss: -0.09578590095043182  (-0.09747479012770244)\n",
      "     | > log_mle: -0.31179213523864746  (-0.304051753470448)\n",
      "     | > loss_dur: 0.21600623428821564  (0.20657696334274536)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.1745, device='cuda:0')  (tensor(21.6193, device='cuda:0'))\n",
      "     | > current_lr: 1.825e-05 \n",
      "     | > step_time: 0.5535  (0.4281278827085668)\n",
      "     | > loader_time: 0.005  (0.004363055685077834)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08870702981948853 \u001b[0m(-0.0012693703174591064)\n",
      "     | > avg_loss:\u001b[92m -0.12989270873367786 \u001b[0m(-0.002798285335302353)\n",
      "     | > avg_log_mle:\u001b[92m -0.324373796582222 \u001b[0m(-0.0019385814666748047)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19448108784854412 \u001b[0m(-0.0008597038686275482)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_30044.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 74/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:23:25) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:23:43 -- STEP: 6/406 -- GLOBAL_STEP: 30050\u001b[0m\n",
      "     | > loss: -0.13047674298286438  (-0.1345806991060575)\n",
      "     | > log_mle: -0.2825723886489868  (-0.28843263785044354)\n",
      "     | > loss_dur: 0.15209564566612244  (0.15385193874438605)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.7122, device='cuda:0')  (tensor(16.2275, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.2572  (0.2560658852259318)\n",
      "     | > loader_time: 0.002  (0.03853503863016764)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:23:50 -- STEP: 31/406 -- GLOBAL_STEP: 30075\u001b[0m\n",
      "     | > loss: -0.10340040922164917  (-0.11579987454798914)\n",
      "     | > log_mle: -0.27986347675323486  (-0.28738317566533245)\n",
      "     | > loss_dur: 0.1764630675315857  (0.1715833011173433)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.2479, device='cuda:0')  (tensor(16.4340, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.2582  (0.2584928543336931)\n",
      "     | > loader_time: 0.003  (0.009137276680238785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:23:57 -- STEP: 56/406 -- GLOBAL_STEP: 30100\u001b[0m\n",
      "     | > loss: -0.09819462895393372  (-0.10771238058805466)\n",
      "     | > log_mle: -0.29368066787719727  (-0.2873743602207729)\n",
      "     | > loss_dur: 0.19548603892326355  (0.1796619796327182)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.0646, device='cuda:0')  (tensor(17.3442, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.3203  (0.27205064041273935)\n",
      "     | > loader_time: 0.003  (0.006130482469286237)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:24:05 -- STEP: 81/406 -- GLOBAL_STEP: 30125\u001b[0m\n",
      "     | > loss: -0.10134151577949524  (-0.10440278034887196)\n",
      "     | > log_mle: -0.30123817920684814  (-0.2891616939026632)\n",
      "     | > loss_dur: 0.1998966634273529  (0.1847589135537913)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.5949, device='cuda:0')  (tensor(17.0145, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.3603  (0.285259046672303)\n",
      "     | > loader_time: 0.003  (0.005066285898656021)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:24:13 -- STEP: 106/406 -- GLOBAL_STEP: 30150\u001b[0m\n",
      "     | > loss: -0.09597355127334595  (-0.10300354518980351)\n",
      "     | > log_mle: -0.2923671007156372  (-0.29170645970218584)\n",
      "     | > loss_dur: 0.19639354944229126  (0.18870291451238236)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.8141, device='cuda:0')  (tensor(17.6042, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.3783  (0.29826140403747553)\n",
      "     | > loader_time: 0.003  (0.004598473602870726)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:24:23 -- STEP: 131/406 -- GLOBAL_STEP: 30175\u001b[0m\n",
      "     | > loss: -0.1225644052028656  (-0.10238920004313229)\n",
      "     | > log_mle: -0.30321013927459717  (-0.29406430521084154)\n",
      "     | > loss_dur: 0.18064573407173157  (0.19167510516770925)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.6841, device='cuda:0')  (tensor(18.3538, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.3323  (0.3114736698965989)\n",
      "     | > loader_time: 0.004  (0.0043550757051424235)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:24:32 -- STEP: 156/406 -- GLOBAL_STEP: 30200\u001b[0m\n",
      "     | > loss: -0.10336491465568542  (-0.10131109945285015)\n",
      "     | > log_mle: -0.3097207546234131  (-0.29582097744330393)\n",
      "     | > loss_dur: 0.20635583996772766  (0.1945098779904537)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.8445, device='cuda:0')  (tensor(19.2466, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.3563  (0.32216433378366327)\n",
      "     | > loader_time: 0.005  (0.004189673142555435)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:24:43 -- STEP: 181/406 -- GLOBAL_STEP: 30225\u001b[0m\n",
      "     | > loss: -0.08286567032337189  (-0.1009980839425029)\n",
      "     | > log_mle: -0.30666565895080566  (-0.29735930716793846)\n",
      "     | > loss_dur: 0.22379998862743378  (0.1963612232254355)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.2908, device='cuda:0')  (tensor(20.2853, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.4634  (0.3343090708084529)\n",
      "     | > loader_time: 0.004  (0.004141869465949129)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:24:53 -- STEP: 206/406 -- GLOBAL_STEP: 30250\u001b[0m\n",
      "     | > loss: -0.08501644432544708  (-0.1005852375794383)\n",
      "     | > log_mle: -0.30862295627593994  (-0.29881418735078247)\n",
      "     | > loss_dur: 0.22360651195049286  (0.1982289497713441)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(44.6832, device='cuda:0')  (tensor(20.1562, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.3863  (0.3450462922309209)\n",
      "     | > loader_time: 0.004  (0.004100792616316419)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:25:05 -- STEP: 231/406 -- GLOBAL_STEP: 30275\u001b[0m\n",
      "     | > loss: -0.09374287724494934  (-0.10051278002334363)\n",
      "     | > log_mle: -0.31684744358062744  (-0.30029955416014714)\n",
      "     | > loss_dur: 0.2231045663356781  (0.19978677413680337)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.0518, device='cuda:0')  (tensor(20.7296, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.5265  (0.3553225921862054)\n",
      "     | > loader_time: 0.004  (0.00409463473728725)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:25:17 -- STEP: 256/406 -- GLOBAL_STEP: 30300\u001b[0m\n",
      "     | > loss: -0.10671202838420868  (-0.10051895410288125)\n",
      "     | > log_mle: -0.31170225143432617  (-0.3015652461908759)\n",
      "     | > loss_dur: 0.2049902230501175  (0.20104629208799452)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.2290, device='cuda:0')  (tensor(21.2320, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.5415  (0.36741948593407875)\n",
      "     | > loader_time: 0.005  (0.004124874249100687)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:25:29 -- STEP: 281/406 -- GLOBAL_STEP: 30325\u001b[0m\n",
      "     | > loss: -0.12180222570896149  (-0.10069208234230392)\n",
      "     | > log_mle: -0.3294483423233032  (-0.3027251691580668)\n",
      "     | > loss_dur: 0.20764611661434174  (0.20203308681576276)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.9646, device='cuda:0')  (tensor(21.4535, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.5865  (0.37880656303460064)\n",
      "     | > loader_time: 0.005  (0.004160380448310828)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:25:42 -- STEP: 306/406 -- GLOBAL_STEP: 30350\u001b[0m\n",
      "     | > loss: -0.07829971611499786  (-0.10037123353457915)\n",
      "     | > log_mle: -0.31136655807495117  (-0.3036200602849326)\n",
      "     | > loss_dur: 0.2330668419599533  (0.20324882675035325)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(34.4602, device='cuda:0')  (tensor(21.9231, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.4754  (0.3901875844967909)\n",
      "     | > loader_time: 0.005  (0.004209731139388741)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:25:56 -- STEP: 331/406 -- GLOBAL_STEP: 30375\u001b[0m\n",
      "     | > loss: -0.09648258984088898  (-0.1001660330418013)\n",
      "     | > log_mle: -0.31270265579223633  (-0.3043714415991057)\n",
      "     | > loss_dur: 0.21622006595134735  (0.20420540855730407)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.9778, device='cuda:0')  (tensor(22.1606, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.6156  (0.40183013227410896)\n",
      "     | > loader_time: 0.005  (0.00423648206128815)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:26:11 -- STEP: 356/406 -- GLOBAL_STEP: 30400\u001b[0m\n",
      "     | > loss: -0.09660826623439789  (-0.09998106667667289)\n",
      "     | > log_mle: -0.3242523670196533  (-0.3052313538749571)\n",
      "     | > loss_dur: 0.22764410078525543  (0.2052502871982837)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.3898, device='cuda:0')  (tensor(22.3353, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.6446  (0.41359745451573565)\n",
      "     | > loader_time: 0.006  (0.004293243536788428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:26:26 -- STEP: 381/406 -- GLOBAL_STEP: 30425\u001b[0m\n",
      "     | > loss: -0.0974164605140686  (-0.10013005649793176)\n",
      "     | > log_mle: -0.30968356132507324  (-0.3060104117931662)\n",
      "     | > loss_dur: 0.21226710081100464  (0.20588035529523385)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.2016, device='cuda:0')  (tensor(22.8071, device='cuda:0'))\n",
      "     | > current_lr: 1.8500000000000002e-05 \n",
      "     | > step_time: 0.5455  (0.4255780203761703)\n",
      "     | > loader_time: 0.005  (0.004334658149659169)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09290283918380737 \u001b[0m(+0.004195809364318848)\n",
      "     | > avg_loss:\u001b[92m -0.13128108903765678 \u001b[0m(-0.00138838030397892)\n",
      "     | > avg_log_mle:\u001b[92m -0.3268716335296631 \u001b[0m(-0.002497836947441101)\n",
      "     | > avg_loss_dur:\u001b[91m 0.1955905444920063 \u001b[0m(+0.001109456643462181)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_30450.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 75/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:27:13) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:27:28 -- STEP: 0/406 -- GLOBAL_STEP: 30450\u001b[0m\n",
      "     | > loss: -0.11919006705284119  (-0.11919006705284119)\n",
      "     | > log_mle: -0.2842499017715454  (-0.2842499017715454)\n",
      "     | > loss_dur: 0.16505983471870422  (0.16505983471870422)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.1998, device='cuda:0')  (tensor(14.1998, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.4484  (0.4484069347381592)\n",
      "     | > loader_time: 15.2188  (15.218751430511475)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:27:35 -- STEP: 25/406 -- GLOBAL_STEP: 30475\u001b[0m\n",
      "     | > loss: -0.09837564826011658  (-0.12499453961849209)\n",
      "     | > log_mle: -0.2843000888824463  (-0.2898857021331787)\n",
      "     | > loss_dur: 0.1859244406223297  (0.16489116251468658)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.3676, device='cuda:0')  (tensor(16.3000, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.2582  (0.2605167579650879)\n",
      "     | > loader_time: 0.002  (0.010849752426147462)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:27:42 -- STEP: 50/406 -- GLOBAL_STEP: 30500\u001b[0m\n",
      "     | > loss: -0.10522881150245667  (-0.11349049538373945)\n",
      "     | > log_mle: -0.3091549873352051  (-0.2891062378883362)\n",
      "     | > loss_dur: 0.2039261758327484  (0.17561574250459672)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.5514, device='cuda:0')  (tensor(16.2198, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.3103  (0.2715865182876588)\n",
      "     | > loader_time: 0.002  (0.006566033363342285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:27:50 -- STEP: 75/406 -- GLOBAL_STEP: 30525\u001b[0m\n",
      "     | > loss: -0.10567741096019745  (-0.10947978516419729)\n",
      "     | > log_mle: -0.30030953884124756  (-0.2914777088165283)\n",
      "     | > loss_dur: 0.1946321278810501  (0.181997923652331)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.5598, device='cuda:0')  (tensor(16.5416, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.3443  (0.2832571188608807)\n",
      "     | > loader_time: 0.003  (0.0052715078989664715)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:27:59 -- STEP: 100/406 -- GLOBAL_STEP: 30550\u001b[0m\n",
      "     | > loss: -0.08039963245391846  (-0.10683925330638885)\n",
      "     | > log_mle: -0.29468560218811035  (-0.293671234846115)\n",
      "     | > loss_dur: 0.2142859697341919  (0.1868319815397262)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.1741, device='cuda:0')  (tensor(17.3205, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.3763  (0.29626896142959613)\n",
      "     | > loader_time: 0.003  (0.004724285602569579)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:28:08 -- STEP: 125/406 -- GLOBAL_STEP: 30575\u001b[0m\n",
      "     | > loss: -0.12553457915782928  (-0.10666678714752197)\n",
      "     | > log_mle: -0.3206617832183838  (-0.29645585155487053)\n",
      "     | > loss_dur: 0.1951272040605545  (0.18978906440734858)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(35.6923, device='cuda:0')  (tensor(17.8583, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.3243  (0.3077978038787843)\n",
      "     | > loader_time: 0.003  (0.004395965576171873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:28:17 -- STEP: 150/406 -- GLOBAL_STEP: 30600\u001b[0m\n",
      "     | > loss: -0.10665908455848694  (-0.10556924432516097)\n",
      "     | > log_mle: -0.3046656847000122  (-0.2982964428265889)\n",
      "     | > loss_dur: 0.19800660014152527  (0.1927271985014279)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.9659, device='cuda:0')  (tensor(19.0623, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.3553  (0.31862791856129974)\n",
      "     | > loader_time: 0.003  (0.004230470657348631)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:28:27 -- STEP: 175/406 -- GLOBAL_STEP: 30625\u001b[0m\n",
      "     | > loss: -0.11150182783603668  (-0.10505826021943773)\n",
      "     | > log_mle: -0.3103846311569214  (-0.29969129289899543)\n",
      "     | > loss_dur: 0.1988828033208847  (0.19463303267955775)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.6139, device='cuda:0')  (tensor(19.5556, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.4574  (0.33043598038809646)\n",
      "     | > loader_time: 0.004  (0.004152311597551619)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:28:38 -- STEP: 200/406 -- GLOBAL_STEP: 30650\u001b[0m\n",
      "     | > loss: -0.10767294466495514  (-0.10452372074127197)\n",
      "     | > log_mle: -0.3131822347640991  (-0.30112115740776046)\n",
      "     | > loss_dur: 0.20550929009914398  (0.1965974366664886)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.5681, device='cuda:0')  (tensor(20.0408, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.4764  (0.3430004036426545)\n",
      "     | > loader_time: 0.004  (0.004133695363998414)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:28:49 -- STEP: 225/406 -- GLOBAL_STEP: 30675\u001b[0m\n",
      "     | > loss: -0.09031419456005096  (-0.10437948637538486)\n",
      "     | > log_mle: -0.30983757972717285  (-0.3024584955639308)\n",
      "     | > loss_dur: 0.2195233851671219  (0.19807900918854604)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.8948, device='cuda:0')  (tensor(20.5487, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.5025  (0.3538715267181397)\n",
      "     | > loader_time: 0.003  (0.00412365277608236)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:29:01 -- STEP: 250/406 -- GLOBAL_STEP: 30700\u001b[0m\n",
      "     | > loss: -0.12164206802845001  (-0.10412729746103287)\n",
      "     | > log_mle: -0.3345407247543335  (-0.30373256731033316)\n",
      "     | > loss_dur: 0.21289865672588348  (0.19960526984930035)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.9919, device='cuda:0')  (tensor(20.9978, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.5335  (0.3655791215896607)\n",
      "     | > loader_time: 0.005  (0.004139693260192873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:29:14 -- STEP: 275/406 -- GLOBAL_STEP: 30725\u001b[0m\n",
      "     | > loss: -0.08665016293525696  (-0.10417611181735992)\n",
      "     | > log_mle: -0.3059800863265991  (-0.3047564783963289)\n",
      "     | > loss_dur: 0.21932992339134216  (0.20058036657896908)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.5372, device='cuda:0')  (tensor(22.1842, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.5495  (0.3768905726346103)\n",
      "     | > loader_time: 0.004  (0.004170980453491213)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:29:27 -- STEP: 300/406 -- GLOBAL_STEP: 30750\u001b[0m\n",
      "     | > loss: -0.09601697325706482  (-0.10399158820509909)\n",
      "     | > log_mle: -0.3031054735183716  (-0.3056567704677581)\n",
      "     | > loss_dur: 0.20708850026130676  (0.20166518226265914)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.4966, device='cuda:0')  (tensor(22.2042, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.4674  (0.38780812342961624)\n",
      "     | > loader_time: 0.006  (0.004207071463267009)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:29:40 -- STEP: 325/406 -- GLOBAL_STEP: 30775\u001b[0m\n",
      "     | > loss: -0.08625282347202301  (-0.10372859812699826)\n",
      "     | > log_mle: -0.3060046434402466  (-0.30650151032667894)\n",
      "     | > loss_dur: 0.21975181996822357  (0.20277291219968072)\n",
      "     | > amp_scaler: 8192.0  (8217.206153846155)\n",
      "     | > grad_norm: tensor(42.2533, device='cuda:0')  (tensor(22.2979, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.6266  (0.3995190723125752)\n",
      "     | > loader_time: 0.005  (0.004253016985379732)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:29:54 -- STEP: 350/406 -- GLOBAL_STEP: 30800\u001b[0m\n",
      "     | > loss: -0.11779290437698364  (-0.10353273349148882)\n",
      "     | > log_mle: -0.3232896327972412  (-0.30729535886219583)\n",
      "     | > loss_dur: 0.20549672842025757  (0.2037626253707069)\n",
      "     | > amp_scaler: 8192.0  (8215.405714285713)\n",
      "     | > grad_norm: tensor(19.6015, device='cuda:0')  (tensor(22.7426, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.5165  (0.41109572069985534)\n",
      "     | > loader_time: 0.004  (0.004295256478445873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:30:09 -- STEP: 375/406 -- GLOBAL_STEP: 30825\u001b[0m\n",
      "     | > loss: -0.11117619276046753  (-0.1036971304416656)\n",
      "     | > log_mle: -0.3295173645019531  (-0.3082426490783694)\n",
      "     | > loss_dur: 0.2183411717414856  (0.20454551863670356)\n",
      "     | > amp_scaler: 8192.0  (8213.845333333333)\n",
      "     | > grad_norm: tensor(25.8321, device='cuda:0')  (tensor(23.0348, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.6626  (0.4230130341847738)\n",
      "     | > loader_time: 0.004  (0.004337207794189455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:30:26 -- STEP: 400/406 -- GLOBAL_STEP: 30850\u001b[0m\n",
      "     | > loss: -0.0982290655374527  (-0.10376850105822083)\n",
      "     | > log_mle: -0.32270073890686035  (-0.30903839379549053)\n",
      "     | > loss_dur: 0.22447167336940765  (0.20526989273726948)\n",
      "     | > amp_scaler: 8192.0  (8212.479999999996)\n",
      "     | > grad_norm: tensor(29.4944, device='cuda:0')  (tensor(23.0082, device='cuda:0'))\n",
      "     | > current_lr: 1.875e-05 \n",
      "     | > step_time: 0.7357  (0.4365640330314637)\n",
      "     | > loader_time: 0.005  (0.004391417503356935)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10259336233139038 \u001b[0m(+0.009690523147583008)\n",
      "     | > avg_loss:\u001b[92m -0.13353783264756203 \u001b[0m(-0.002256743609905243)\n",
      "     | > avg_log_mle:\u001b[92m -0.3271429240703583 \u001b[0m(-0.00027129054069519043)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19360509142279625 \u001b[0m(-0.0019854530692100525)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_30856.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 76/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:31:01) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:31:21 -- STEP: 19/406 -- GLOBAL_STEP: 30875\u001b[0m\n",
      "     | > loss: -0.1206267923116684  (-0.1283435798005054)\n",
      "     | > log_mle: -0.27800416946411133  (-0.29223536190233734)\n",
      "     | > loss_dur: 0.15737737715244293  (0.16389178210183195)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.6870, device='cuda:0')  (tensor(22.7344, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.2592  (0.25523186984815094)\n",
      "     | > loader_time: 0.002  (0.014065265655517578)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:31:28 -- STEP: 44/406 -- GLOBAL_STEP: 30900\u001b[0m\n",
      "     | > loss: -0.09934030473232269  (-0.11646604605696419)\n",
      "     | > log_mle: -0.29329705238342285  (-0.28930550000884314)\n",
      "     | > loss_dur: 0.19395674765110016  (0.172839453951879)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.6790, device='cuda:0')  (tensor(22.2455, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.2632  (0.26401253721930756)\n",
      "     | > loader_time: 0.002  (0.007324728098782626)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:31:36 -- STEP: 69/406 -- GLOBAL_STEP: 30925\u001b[0m\n",
      "     | > loss: -0.09045268595218658  (-0.1099134471969328)\n",
      "     | > log_mle: -0.2977275848388672  (-0.2906538334445677)\n",
      "     | > loss_dur: 0.2072748988866806  (0.1807403862476349)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.7947, device='cuda:0')  (tensor(21.1790, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.3463  (0.2781656375829723)\n",
      "     | > loader_time: 0.003  (0.005599201589390851)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:31:44 -- STEP: 94/406 -- GLOBAL_STEP: 30950\u001b[0m\n",
      "     | > loss: -0.10050299763679504  (-0.10878232184876786)\n",
      "     | > log_mle: -0.30729174613952637  (-0.2938516583848506)\n",
      "     | > loss_dur: 0.20678874850273132  (0.18506933653608282)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.1497, device='cuda:0')  (tensor(20.3374, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.3703  (0.29224414267438525)\n",
      "     | > loader_time: 0.003  (0.0048766922443471035)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:31:53 -- STEP: 119/406 -- GLOBAL_STEP: 30975\u001b[0m\n",
      "     | > loss: -0.11473985016345978  (-0.10783530709122409)\n",
      "     | > log_mle: -0.3199232816696167  (-0.2965956054815724)\n",
      "     | > loss_dur: 0.20518343150615692  (0.1887602983903484)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.8239, device='cuda:0')  (tensor(19.7176, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.3954  (0.30402399111194783)\n",
      "     | > loader_time: 0.003  (0.00451663361877954)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:32:03 -- STEP: 144/406 -- GLOBAL_STEP: 31000\u001b[0m\n",
      "     | > loss: -0.09757885336875916  (-0.10722560301009156)\n",
      "     | > log_mle: -0.29977357387542725  (-0.2988111906581454)\n",
      "     | > loss_dur: 0.2021947205066681  (0.19158558764805397)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.8412, device='cuda:0')  (tensor(20.1373, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.3473  (0.3155295534266367)\n",
      "     | > loader_time: 0.004  (0.004323320256339175)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_31000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:32:16 -- STEP: 169/406 -- GLOBAL_STEP: 31025\u001b[0m\n",
      "     | > loss: -0.10767722129821777  (-0.10677543176701793)\n",
      "     | > log_mle: -0.31081581115722656  (-0.3004462211089726)\n",
      "     | > loss_dur: 0.2031385898590088  (0.19367078934195478)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.3139, device='cuda:0')  (tensor(20.3878, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.4364  (0.3273031048520783)\n",
      "     | > loader_time: 0.003  (0.004234565080270256)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:32:27 -- STEP: 194/406 -- GLOBAL_STEP: 31050\u001b[0m\n",
      "     | > loss: -0.10710670053958893  (-0.10678868525728741)\n",
      "     | > log_mle: -0.30914807319641113  (-0.30214496433120414)\n",
      "     | > loss_dur: 0.2020413726568222  (0.19535627907391676)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.9649, device='cuda:0')  (tensor(21.6700, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.4674  (0.33986012468632953)\n",
      "     | > loader_time: 0.003  (0.00417384044411256)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:32:38 -- STEP: 219/406 -- GLOBAL_STEP: 31075\u001b[0m\n",
      "     | > loss: -0.11746515333652496  (-0.10642645246089869)\n",
      "     | > log_mle: -0.31830263137817383  (-0.3033710152046867)\n",
      "     | > loss_dur: 0.20083747804164886  (0.1969445627437879)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.4733, device='cuda:0')  (tensor(22.0049, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.4924  (0.3513353513256055)\n",
      "     | > loader_time: 0.004  (0.004140673162730315)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:32:50 -- STEP: 244/406 -- GLOBAL_STEP: 31100\u001b[0m\n",
      "     | > loss: -0.11452995240688324  (-0.10622714453789057)\n",
      "     | > log_mle: -0.31556785106658936  (-0.3048415149821611)\n",
      "     | > loss_dur: 0.20103789865970612  (0.19861437044427044)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.3485, device='cuda:0')  (tensor(22.7470, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.4224  (0.36157666562033475)\n",
      "     | > loader_time: 0.004  (0.004134795704825978)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:33:02 -- STEP: 269/406 -- GLOBAL_STEP: 31125\u001b[0m\n",
      "     | > loss: -0.1119428277015686  (-0.1061740982931343)\n",
      "     | > log_mle: -0.32334935665130615  (-0.30583712912846683)\n",
      "     | > loss_dur: 0.21140652894973755  (0.1996630308353325)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.3222, device='cuda:0')  (tensor(22.8208, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.5355  (0.37365439833318426)\n",
      "     | > loader_time: 0.004  (0.004141208407604117)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:33:15 -- STEP: 294/406 -- GLOBAL_STEP: 31150\u001b[0m\n",
      "     | > loss: -0.0991927981376648  (-0.10608076456249979)\n",
      "     | > log_mle: -0.32283079624176025  (-0.3067153821997093)\n",
      "     | > loss_dur: 0.22363799810409546  (0.20063461763720936)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(41.4721, device='cuda:0')  (tensor(22.9651, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.4604  (0.3834664213414093)\n",
      "     | > loader_time: 0.004  (0.004149952713324099)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:33:28 -- STEP: 319/406 -- GLOBAL_STEP: 31175\u001b[0m\n",
      "     | > loss: -0.09812016785144806  (-0.10584276396092207)\n",
      "     | > log_mle: -0.31995344161987305  (-0.30755371733519005)\n",
      "     | > loss_dur: 0.221833273768425  (0.20171095337426775)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.1513, device='cuda:0')  (tensor(23.1267, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.6116  (0.39550882297623474)\n",
      "     | > loader_time: 0.005  (0.004179287106265841)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:33:42 -- STEP: 344/406 -- GLOBAL_STEP: 31200\u001b[0m\n",
      "     | > loss: -0.09782934188842773  (-0.10563759146214922)\n",
      "     | > log_mle: -0.3117939233779907  (-0.30824947357177757)\n",
      "     | > loss_dur: 0.213964581489563  (0.20261188210962816)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.7089, device='cuda:0')  (tensor(23.0930, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.5345  (0.40631884267163815)\n",
      "     | > loader_time: 0.005  (0.004242176926413247)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:33:56 -- STEP: 369/406 -- GLOBAL_STEP: 31225\u001b[0m\n",
      "     | > loss: -0.10021792352199554  (-0.10546255123809105)\n",
      "     | > log_mle: -0.31185388565063477  (-0.3088708954451852)\n",
      "     | > loss_dur: 0.21163596212863922  (0.20340834420709428)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.9438, device='cuda:0')  (tensor(23.3490, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.6926  (0.4175872208303228)\n",
      "     | > loader_time: 0.005  (0.004299236183890157)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:34:12 -- STEP: 394/406 -- GLOBAL_STEP: 31250\u001b[0m\n",
      "     | > loss: -0.10925029218196869  (-0.1054501102736154)\n",
      "     | > log_mle: -0.31731438636779785  (-0.3095973376090151)\n",
      "     | > loss_dur: 0.20806409418582916  (0.20414722733539978)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(39.4969, device='cuda:0')  (tensor(23.2252, device='cuda:0'))\n",
      "     | > current_lr: 1.8999999999999998e-05 \n",
      "     | > step_time: 0.5695  (0.4303724209064153)\n",
      "     | > loader_time: 0.006  (0.004341448018998663)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09296855330467224 \u001b[0m(-0.00962480902671814)\n",
      "     | > avg_loss:\u001b[91m -0.13348940759897232 \u001b[0m(+4.842504858970642e-05)\n",
      "     | > avg_log_mle:\u001b[91m -0.3248170465230942 \u001b[0m(+0.002325877547264099)\n",
      "     | > avg_loss_dur:\u001b[92m 0.19132763892412186 \u001b[0m(-0.0022774524986743927)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 77/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:34:50) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:35:09 -- STEP: 13/406 -- GLOBAL_STEP: 31275\u001b[0m\n",
      "     | > loss: -0.12252989411354065  (-0.13557056509531462)\n",
      "     | > log_mle: -0.298648476600647  (-0.2938029857782217)\n",
      "     | > loss_dur: 0.17611858248710632  (0.1582324206829071)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.4334, device='cuda:0')  (tensor(18.7351, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.2542  (0.2541538201845609)\n",
      "     | > loader_time: 0.002  (0.015398759108323317)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:35:16 -- STEP: 38/406 -- GLOBAL_STEP: 31300\u001b[0m\n",
      "     | > loss: -0.09723798930644989  (-0.11560698441768945)\n",
      "     | > log_mle: -0.2932649850845337  (-0.2891732266074733)\n",
      "     | > loss_dur: 0.1960269957780838  (0.1735662421897838)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.1124, device='cuda:0')  (tensor(15.7151, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.2863  (0.26155327495775726)\n",
      "     | > loader_time: 0.002  (0.0066903578607659595)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:35:24 -- STEP: 63/406 -- GLOBAL_STEP: 31325\u001b[0m\n",
      "     | > loss: -0.09872095286846161  (-0.10873589345387048)\n",
      "     | > log_mle: -0.3006248474121094  (-0.28913735775720506)\n",
      "     | > loss_dur: 0.20190389454364777  (0.18040146430333456)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.9572, device='cuda:0')  (tensor(15.3896, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.2823  (0.275011660560729)\n",
      "     | > loader_time: 0.003  (0.005052161595178029)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:35:32 -- STEP: 88/406 -- GLOBAL_STEP: 31350\u001b[0m\n",
      "     | > loss: -0.09628407657146454  (-0.10822364298457447)\n",
      "     | > log_mle: -0.2950286865234375  (-0.2931321723894639)\n",
      "     | > loss_dur: 0.19874460995197296  (0.18490852940488944)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.9721, device='cuda:0')  (tensor(17.0855, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.3653  (0.2895015207203952)\n",
      "     | > loader_time: 0.003  (0.004413057457317004)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:35:41 -- STEP: 113/406 -- GLOBAL_STEP: 31375\u001b[0m\n",
      "     | > loss: -0.10944327712059021  (-0.10922250481305923)\n",
      "     | > log_mle: -0.31339025497436523  (-0.2969609256339282)\n",
      "     | > loss_dur: 0.20394697785377502  (0.18773842082086917)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.1790, device='cuda:0')  (tensor(17.1750, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.3233  (0.30151269499179534)\n",
      "     | > loader_time: 0.003  (0.004065631765179927)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:35:50 -- STEP: 138/406 -- GLOBAL_STEP: 31400\u001b[0m\n",
      "     | > loss: -0.08589008450508118  (-0.10823090558034784)\n",
      "     | > log_mle: -0.3147914409637451  (-0.2995164904041564)\n",
      "     | > loss_dur: 0.22890135645866394  (0.1912855848238088)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.8791, device='cuda:0')  (tensor(18.1581, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.4104  (0.312566384025242)\n",
      "     | > loader_time: 0.003  (0.003909356352211769)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:36:00 -- STEP: 163/406 -- GLOBAL_STEP: 31425\u001b[0m\n",
      "     | > loss: -0.0974988043308258  (-0.10786453437951445)\n",
      "     | > log_mle: -0.3195227384567261  (-0.3013903268275814)\n",
      "     | > loss_dur: 0.22202393412590027  (0.19352579244806725)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(36.1787, device='cuda:0')  (tensor(19.2486, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.4384  (0.32423301269671667)\n",
      "     | > loader_time: 0.003  (0.0038869790504315114)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:36:10 -- STEP: 188/406 -- GLOBAL_STEP: 31450\u001b[0m\n",
      "     | > loss: -0.11094488203525543  (-0.10820913473342328)\n",
      "     | > log_mle: -0.3317760229110718  (-0.3032938470231724)\n",
      "     | > loss_dur: 0.22083114087581635  (0.1950847122897493)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(38.1107, device='cuda:0')  (tensor(20.3113, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.3733  (0.33577822624368864)\n",
      "     | > loader_time: 0.004  (0.003865192545221204)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:36:21 -- STEP: 213/406 -- GLOBAL_STEP: 31475\u001b[0m\n",
      "     | > loss: -0.11494050920009613  (-0.10813231353468739)\n",
      "     | > log_mle: -0.3227357864379883  (-0.30479093336723206)\n",
      "     | > loss_dur: 0.20779527723789215  (0.19665861983254482)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.3186, device='cuda:0')  (tensor(20.4667, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.4054  (0.3472307075357212)\n",
      "     | > loader_time: 0.004  (0.003862651860769923)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:36:32 -- STEP: 238/406 -- GLOBAL_STEP: 31500\u001b[0m\n",
      "     | > loss: -0.10944411158561707  (-0.10802914997359284)\n",
      "     | > log_mle: -0.32353389263153076  (-0.3062841797075351)\n",
      "     | > loss_dur: 0.2140897810459137  (0.19825502973394232)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.5661, device='cuda:0')  (tensor(20.9042, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.4104  (0.35753044360825986)\n",
      "     | > loader_time: 0.006  (0.003890096640386499)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:36:45 -- STEP: 263/406 -- GLOBAL_STEP: 31525\u001b[0m\n",
      "     | > loss: -0.12482282519340515  (-0.10815087300742987)\n",
      "     | > log_mle: -0.32064712047576904  (-0.3073885943953074)\n",
      "     | > loss_dur: 0.1958242952823639  (0.19923772138787765)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.6521, device='cuda:0')  (tensor(21.4523, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.5325  (0.37073799956434117)\n",
      "     | > loader_time: 0.005  (0.0039313220252555564)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:36:57 -- STEP: 288/406 -- GLOBAL_STEP: 31550\u001b[0m\n",
      "     | > loss: -0.11348827183246613  (-0.1081297654244635)\n",
      "     | > log_mle: -0.3130849599838257  (-0.3084267071551745)\n",
      "     | > loss_dur: 0.19959668815135956  (0.2002969417307111)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.7689, device='cuda:0')  (tensor(21.5212, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.4874  (0.3809971784551938)\n",
      "     | > loader_time: 0.004  (0.0039793054262797015)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:37:11 -- STEP: 313/406 -- GLOBAL_STEP: 31575\u001b[0m\n",
      "     | > loss: -0.1035766750574112  (-0.10786852978479367)\n",
      "     | > log_mle: -0.31501901149749756  (-0.30927769254190834)\n",
      "     | > loss_dur: 0.21144233644008636  (0.20140916275711473)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(33.6717, device='cuda:0')  (tensor(21.8882, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.5995  (0.3932757994618279)\n",
      "     | > loader_time: 0.005  (0.004026026771472284)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:37:25 -- STEP: 338/406 -- GLOBAL_STEP: 31600\u001b[0m\n",
      "     | > loss: -0.11410553753376007  (-0.1076942052714218)\n",
      "     | > log_mle: -0.32135140895843506  (-0.30998455173165135)\n",
      "     | > loss_dur: 0.207245871424675  (0.20229034646022948)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.2812, device='cuda:0')  (tensor(22.0741, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.5295  (0.4047094139121694)\n",
      "     | > loader_time: 0.005  (0.004095426677952152)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:37:39 -- STEP: 363/406 -- GLOBAL_STEP: 31625\u001b[0m\n",
      "     | > loss: -0.12774470448493958  (-0.10760485830385823)\n",
      "     | > log_mle: -0.33183562755584717  (-0.31078865475562656)\n",
      "     | > loss_dur: 0.2040909230709076  (0.2031837964517682)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.5706, device='cuda:0')  (tensor(22.2632, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.5195  (0.4165092618012232)\n",
      "     | > loader_time: 0.005  (0.0041497528717209155)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:37:55 -- STEP: 388/406 -- GLOBAL_STEP: 31650\u001b[0m\n",
      "     | > loss: -0.10142524540424347  (-0.10771623637872874)\n",
      "     | > log_mle: -0.3186025619506836  (-0.3115338323657047)\n",
      "     | > loss_dur: 0.21717731654644012  (0.20381759598697577)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.0261, device='cuda:0')  (tensor(22.2126, device='cuda:0'))\n",
      "     | > current_lr: 1.925e-05 \n",
      "     | > step_time: 0.6936  (0.4291076365205431)\n",
      "     | > loader_time: 0.005  (0.004209972533983055)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09723135828971863 \u001b[0m(+0.004262804985046387)\n",
      "     | > avg_loss:\u001b[92m -0.13900511898100376 \u001b[0m(-0.005515711382031441)\n",
      "     | > avg_log_mle:\u001b[92m -0.33157995343208313 \u001b[0m(-0.006762906908988953)\n",
      "     | > avg_loss_dur:\u001b[91m 0.19257483445107937 \u001b[0m(+0.001247195526957512)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_31668.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 78/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:38:37) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:38:55 -- STEP: 7/406 -- GLOBAL_STEP: 31675\u001b[0m\n",
      "     | > loss: -0.14677737653255463  (-0.14345255068370275)\n",
      "     | > log_mle: -0.2878795862197876  (-0.2952418157032558)\n",
      "     | > loss_dur: 0.14110220968723297  (0.15178926501955306)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.4730, device='cuda:0')  (tensor(15.6904, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.2492  (0.2565177508762905)\n",
      "     | > loader_time: 0.002  (0.04446976525442941)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:39:02 -- STEP: 32/406 -- GLOBAL_STEP: 31700\u001b[0m\n",
      "     | > loss: -0.12135986983776093  (-0.12778009800240395)\n",
      "     | > log_mle: -0.29582011699676514  (-0.2956148833036423)\n",
      "     | > loss_dur: 0.1744602471590042  (0.1678347853012383)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.8534, device='cuda:0')  (tensor(16.6509, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.2582  (0.2590469792485237)\n",
      "     | > loader_time: 0.002  (0.011292189359664917)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:39:09 -- STEP: 57/406 -- GLOBAL_STEP: 31725\u001b[0m\n",
      "     | > loss: -0.1057596206665039  (-0.1183311758857024)\n",
      "     | > log_mle: -0.29178690910339355  (-0.29528679136644337)\n",
      "     | > loss_dur: 0.18602728843688965  (0.17695561548074085)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.4926, device='cuda:0')  (tensor(16.8921, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.3193  (0.27233439997622844)\n",
      "     | > loader_time: 0.002  (0.007375742259778476)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:39:17 -- STEP: 82/406 -- GLOBAL_STEP: 31750\u001b[0m\n",
      "     | > loss: -0.12155158817768097  (-0.11524095895086844)\n",
      "     | > log_mle: -0.3119269609451294  (-0.29726926291861183)\n",
      "     | > loss_dur: 0.19037537276744843  (0.18202830396774336)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.3686, device='cuda:0')  (tensor(17.9598, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.3573  (0.28550268964069647)\n",
      "     | > loader_time: 0.003  (0.005969315040402297)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:39:26 -- STEP: 107/406 -- GLOBAL_STEP: 31775\u001b[0m\n",
      "     | > loss: -0.11789606511592865  (-0.11458561270036428)\n",
      "     | > log_mle: -0.30993330478668213  (-0.30004424469493274)\n",
      "     | > loss_dur: 0.19203723967075348  (0.18545863199456827)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.2606, device='cuda:0')  (tensor(18.3820, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.3833  (0.2984762503722003)\n",
      "     | > loader_time: 0.003  (0.005257466129053421)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:39:35 -- STEP: 132/406 -- GLOBAL_STEP: 31800\u001b[0m\n",
      "     | > loss: -0.10751304030418396  (-0.1139324830111229)\n",
      "     | > log_mle: -0.3251912593841553  (-0.302592739914403)\n",
      "     | > loss_dur: 0.2176782190799713  (0.1886602569032799)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.7301, device='cuda:0')  (tensor(18.6784, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.3293  (0.30935631195704144)\n",
      "     | > loader_time: 0.004  (0.0048986872037251805)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:39:44 -- STEP: 157/406 -- GLOBAL_STEP: 31825\u001b[0m\n",
      "     | > loss: -0.10473406314849854  (-0.11271330533893242)\n",
      "     | > log_mle: -0.30978167057037354  (-0.30408021902582455)\n",
      "     | > loss_dur: 0.205047607421875  (0.19136691368689204)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.2934, device='cuda:0')  (tensor(19.1911, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.4224  (0.3213360385530314)\n",
      "     | > loader_time: 0.004  (0.004692428430933863)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:39:55 -- STEP: 182/406 -- GLOBAL_STEP: 31850\u001b[0m\n",
      "     | > loss: -0.10518768429756165  (-0.11243573911897427)\n",
      "     | > log_mle: -0.31465184688568115  (-0.305567897283114)\n",
      "     | > loss_dur: 0.2094641625881195  (0.19313215816413967)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.7152, device='cuda:0')  (tensor(19.4309, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.3733  (0.3333408452652311)\n",
      "     | > loader_time: 0.005  (0.004548334813379981)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:40:06 -- STEP: 207/406 -- GLOBAL_STEP: 31875\u001b[0m\n",
      "     | > loss: -0.1094527542591095  (-0.11192252418557225)\n",
      "     | > log_mle: -0.3057790994644165  (-0.306961999423262)\n",
      "     | > loss_dur: 0.196326345205307  (0.19503947523768977)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.7815, device='cuda:0')  (tensor(20.0682, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.4804  (0.34484919372964)\n",
      "     | > loader_time: 0.004  (0.004453542727779074)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:40:17 -- STEP: 232/406 -- GLOBAL_STEP: 31900\u001b[0m\n",
      "     | > loss: -0.11230848729610443  (-0.11193056372476033)\n",
      "     | > log_mle: -0.3244614601135254  (-0.3085189877912916)\n",
      "     | > loss_dur: 0.21215297281742096  (0.19658842406653126)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.3179, device='cuda:0')  (tensor(20.3390, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.4094  (0.35493425048630795)\n",
      "     | > loader_time: 0.004  (0.004409310118905428)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:40:29 -- STEP: 257/406 -- GLOBAL_STEP: 31925\u001b[0m\n",
      "     | > loss: -0.1035337895154953  (-0.11205724177425472)\n",
      "     | > log_mle: -0.32269608974456787  (-0.30975375054875237)\n",
      "     | > loss_dur: 0.21916230022907257  (0.19769650877449765)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.7881, device='cuda:0')  (tensor(20.7353, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.5515  (0.36765281606740974)\n",
      "     | > loader_time: 0.004  (0.004389304595234791)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:40:42 -- STEP: 282/406 -- GLOBAL_STEP: 31950\u001b[0m\n",
      "     | > loss: -0.12158949673175812  (-0.1123275059863185)\n",
      "     | > log_mle: -0.3305455446243286  (-0.31084904476260455)\n",
      "     | > loss_dur: 0.2089560478925705  (0.19852153877628614)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(28.2463, device='cuda:0')  (tensor(21.3598, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.4534  (0.3789397757104101)\n",
      "     | > loader_time: 0.005  (0.004390581279781692)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:40:55 -- STEP: 307/406 -- GLOBAL_STEP: 31975\u001b[0m\n",
      "     | > loss: -0.10142093896865845  (-0.11197387924605934)\n",
      "     | > log_mle: -0.3169025182723999  (-0.31170915470061156)\n",
      "     | > loss_dur: 0.21548157930374146  (0.1997352754545523)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.5990, device='cuda:0')  (tensor(21.4485, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.6086  (0.39061524580666596)\n",
      "     | > loader_time: 0.004  (0.004404690832579173)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:41:08 -- STEP: 332/406 -- GLOBAL_STEP: 32000\u001b[0m\n",
      "     | > loss: -0.10285690426826477  (-0.11187531399619144)\n",
      "     | > log_mle: -0.3133125305175781  (-0.3124494958354765)\n",
      "     | > loss_dur: 0.21045562624931335  (0.20057418183928521)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.4924, device='cuda:0')  (tensor(21.6524, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.5295  (0.40202769888452705)\n",
      "     | > loader_time: 0.005  (0.0044407679373959464)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_32000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:41:28 -- STEP: 357/406 -- GLOBAL_STEP: 32025\u001b[0m\n",
      "     | > loss: -0.09271444380283356  (-0.11176731226657949)\n",
      "     | > log_mle: -0.31288468837738037  (-0.3133762263450302)\n",
      "     | > loss_dur: 0.22017024457454681  (0.20160891407845075)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.7429, device='cuda:0')  (tensor(21.5445, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.5335  (0.4145246139761443)\n",
      "     | > loader_time: 0.005  (0.004480274451546977)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:41:43 -- STEP: 382/406 -- GLOBAL_STEP: 32050\u001b[0m\n",
      "     | > loss: -0.09753353893756866  (-0.11200941424251223)\n",
      "     | > log_mle: -0.3191181421279907  (-0.3142756111334756)\n",
      "     | > loss_dur: 0.22158460319042206  (0.2022661968909634)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.3501, device='cuda:0')  (tensor(21.6789, device='cuda:0'))\n",
      "     | > current_lr: 1.95e-05 \n",
      "     | > step_time: 0.5565  (0.4265310314937409)\n",
      "     | > loader_time: 0.004  (0.004509352888736426)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09201657772064209 \u001b[0m(-0.005214780569076538)\n",
      "     | > avg_loss:\u001b[92m -0.14729381166398525 \u001b[0m(-0.008288692682981491)\n",
      "     | > avg_log_mle:\u001b[92m -0.33694106340408325 \u001b[0m(-0.005361109972000122)\n",
      "     | > avg_loss_dur:\u001b[92m 0.189647251740098 \u001b[0m(-0.002927582710981369)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_32074.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 79/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:42:30) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:42:46 -- STEP: 1/406 -- GLOBAL_STEP: 32075\u001b[0m\n",
      "     | > loss: -0.168802872300148  (-0.168802872300148)\n",
      "     | > log_mle: -0.3007087707519531  (-0.3007087707519531)\n",
      "     | > loss_dur: 0.13190589845180511  (0.13190589845180511)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.8123, device='cuda:0')  (tensor(21.8123, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.2632  (0.26323962211608887)\n",
      "     | > loader_time: 0.001  (0.001001119613647461)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:42:53 -- STEP: 26/406 -- GLOBAL_STEP: 32100\u001b[0m\n",
      "     | > loss: -0.12018309533596039  (-0.13541135650414687)\n",
      "     | > log_mle: -0.30214130878448486  (-0.29907622245641863)\n",
      "     | > loss_dur: 0.18195821344852448  (0.16366486595227167)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.2298, device='cuda:0')  (tensor(16.8053, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.2652  (0.259966437633221)\n",
      "     | > loader_time: 0.002  (0.009432517565213717)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:43:00 -- STEP: 51/406 -- GLOBAL_STEP: 32125\u001b[0m\n",
      "     | > loss: -0.11570270359516144  (-0.12416289103966135)\n",
      "     | > log_mle: -0.3237488269805908  (-0.29870719535678053)\n",
      "     | > loss_dur: 0.20804612338542938  (0.17454430431711906)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.3103, device='cuda:0')  (tensor(16.8357, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.3093  (0.2705591379427442)\n",
      "     | > loader_time: 0.003  (0.005986288482067632)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:43:08 -- STEP: 76/406 -- GLOBAL_STEP: 32150\u001b[0m\n",
      "     | > loss: -0.11555436253547668  (-0.12049825783622892)\n",
      "     | > log_mle: -0.29835665225982666  (-0.30048446749386043)\n",
      "     | > loss_dur: 0.18280228972434998  (0.17998620965763137)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.9917, device='cuda:0')  (tensor(16.3981, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.2873  (0.2825722161092256)\n",
      "     | > loader_time: 0.003  (0.00489947984093114)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:43:16 -- STEP: 101/406 -- GLOBAL_STEP: 32175\u001b[0m\n",
      "     | > loss: -0.10796922445297241  (-0.11805535203749591)\n",
      "     | > log_mle: -0.3145148754119873  (-0.30294968350098883)\n",
      "     | > loss_dur: 0.2065456509590149  (0.1848943314634927)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.5910, device='cuda:0')  (tensor(17.7873, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.3123  (0.29584282459598943)\n",
      "     | > loader_time: 0.002  (0.004380433866293123)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:43:25 -- STEP: 126/406 -- GLOBAL_STEP: 32200\u001b[0m\n",
      "     | > loss: -0.09673905372619629  (-0.11784756467455909)\n",
      "     | > log_mle: -0.30558550357818604  (-0.305750572492206)\n",
      "     | > loss_dur: 0.20884644985198975  (0.1879030078176468)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(9.6681, device='cuda:0')  (tensor(17.8885, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.3994  (0.30793824082329146)\n",
      "     | > loader_time: 0.004  (0.004170625928848507)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:43:35 -- STEP: 151/406 -- GLOBAL_STEP: 32225\u001b[0m\n",
      "     | > loss: -0.10551190376281738  (-0.11699519893586241)\n",
      "     | > log_mle: -0.3133084774017334  (-0.3076111417732493)\n",
      "     | > loss_dur: 0.20779657363891602  (0.1906159428373867)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.1887, device='cuda:0')  (tensor(18.6520, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.4404  (0.31886564658967065)\n",
      "     | > loader_time: 0.003  (0.004083276584448404)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:43:45 -- STEP: 176/406 -- GLOBAL_STEP: 32250\u001b[0m\n",
      "     | > loss: -0.1129782646894455  (-0.11648339710452339)\n",
      "     | > log_mle: -0.3108489513397217  (-0.308920720084147)\n",
      "     | > loss_dur: 0.19787068665027618  (0.19243732297962363)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.0041, device='cuda:0')  (tensor(19.5713, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.3763  (0.33029995587739075)\n",
      "     | > loader_time: 0.003  (0.004020644859834151)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:43:56 -- STEP: 201/406 -- GLOBAL_STEP: 32275\u001b[0m\n",
      "     | > loss: -0.12393103539943695  (-0.11659099984524855)\n",
      "     | > log_mle: -0.31559956073760986  (-0.3105019010714631)\n",
      "     | > loss_dur: 0.1916685253381729  (0.19391090122621452)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(28.9706, device='cuda:0')  (tensor(20.4712, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.3944  (0.34266645279689795)\n",
      "     | > loader_time: 0.004  (0.004008588506214653)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:44:07 -- STEP: 226/406 -- GLOBAL_STEP: 32300\u001b[0m\n",
      "     | > loss: -0.12057164311408997  (-0.11655192420018458)\n",
      "     | > log_mle: -0.3288857936859131  (-0.3119955701110637)\n",
      "     | > loss_dur: 0.20831415057182312  (0.19544364591087915)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(55.3896, device='cuda:0')  (tensor(21.0261, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.4104  (0.3524546106304741)\n",
      "     | > loader_time: 0.004  (0.004021320722799383)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:44:19 -- STEP: 251/406 -- GLOBAL_STEP: 32325\u001b[0m\n",
      "     | > loss: -0.10840821266174316  (-0.11638697299111887)\n",
      "     | > log_mle: -0.3146136999130249  (-0.31312163370064056)\n",
      "     | > loss_dur: 0.20620548725128174  (0.1967346607095217)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(54.9042, device='cuda:0')  (tensor(21.3295, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.5265  (0.3645917105959705)\n",
      "     | > loader_time: 0.005  (0.004035514664364999)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:44:31 -- STEP: 276/406 -- GLOBAL_STEP: 32350\u001b[0m\n",
      "     | > loss: -0.10849656164646149  (-0.11651532017234442)\n",
      "     | > log_mle: -0.325484037399292  (-0.31418359279632574)\n",
      "     | > loss_dur: 0.2169874757528305  (0.19766827262398126)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.4949, device='cuda:0')  (tensor(21.5093, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.4574  (0.37568324458771846)\n",
      "     | > loader_time: 0.004  (0.004047117371490034)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:44:44 -- STEP: 301/406 -- GLOBAL_STEP: 32375\u001b[0m\n",
      "     | > loss: -0.11523789167404175  (-0.11614875376620562)\n",
      "     | > log_mle: -0.3410545587539673  (-0.3149213426532937)\n",
      "     | > loss_dur: 0.22581666707992554  (0.198772588887088)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(48.9916, device='cuda:0')  (tensor(22.2472, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.6216  (0.38733320933243753)\n",
      "     | > loader_time: 0.004  (0.0040700831682579045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:44:58 -- STEP: 326/406 -- GLOBAL_STEP: 32400\u001b[0m\n",
      "     | > loss: -0.10998408496379852  (-0.11591306913849767)\n",
      "     | > log_mle: -0.3171638250350952  (-0.3156427781274716)\n",
      "     | > loss_dur: 0.2071797400712967  (0.19972970898897383)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.0107, device='cuda:0')  (tensor(22.3781, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.5175  (0.39912905137231736)\n",
      "     | > loader_time: 0.004  (0.004124173357442842)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:45:12 -- STEP: 351/406 -- GLOBAL_STEP: 32425\u001b[0m\n",
      "     | > loss: -0.099972665309906  (-0.11560422721241953)\n",
      "     | > log_mle: -0.32022106647491455  (-0.3163902368980259)\n",
      "     | > loss_dur: 0.22024840116500854  (0.20078600968560614)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.6578, device='cuda:0')  (tensor(22.9078, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.6526  (0.4108742682682482)\n",
      "     | > loader_time: 0.005  (0.0041783345051300816)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:45:27 -- STEP: 376/406 -- GLOBAL_STEP: 32450\u001b[0m\n",
      "     | > loss: -0.11156028509140015  (-0.11581885489694616)\n",
      "     | > log_mle: -0.32583165168762207  (-0.31729113643473805)\n",
      "     | > loss_dur: 0.21427136659622192  (0.20147228153779162)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.7364, device='cuda:0')  (tensor(23.3884, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.5545  (0.42252149163408476)\n",
      "     | > loader_time: 0.005  (0.004238597256072021)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:45:43 -- STEP: 401/406 -- GLOBAL_STEP: 32475\u001b[0m\n",
      "     | > loss: -0.11909323930740356  (-0.11598472992083675)\n",
      "     | > log_mle: -0.3278712034225464  (-0.31810263951223117)\n",
      "     | > loss_dur: 0.20877796411514282  (0.20211790959139428)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.3792, device='cuda:0')  (tensor(23.5061, device='cuda:0'))\n",
      "     | > current_lr: 1.975e-05 \n",
      "     | > step_time: 0.7155  (0.43637390564801976)\n",
      "     | > loader_time: 0.004  (0.00429633668533287)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09504500031471252 \u001b[0m(+0.0030284225940704346)\n",
      "     | > avg_loss:\u001b[92m -0.15260369330644608 \u001b[0m(-0.005309881642460823)\n",
      "     | > avg_log_mle:\u001b[92m -0.3411962538957596 \u001b[0m(-0.004255190491676331)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1885925605893135 \u001b[0m(-0.0010546911507844925)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_32480.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 80/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:46:17) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:46:39 -- STEP: 20/406 -- GLOBAL_STEP: 32500\u001b[0m\n",
      "     | > loss: -0.1133289635181427  (-0.14299412965774536)\n",
      "     | > log_mle: -0.28418028354644775  (-0.30180261135101316)\n",
      "     | > loss_dur: 0.17085132002830505  (0.15880848206579684)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.4729, device='cuda:0')  (tensor(16.8198, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.2662  (0.2572335958480835)\n",
      "     | > loader_time: 0.002  (0.011760675907135011)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:46:46 -- STEP: 45/406 -- GLOBAL_STEP: 32525\u001b[0m\n",
      "     | > loss: -0.10599479079246521  (-0.1307208286391364)\n",
      "     | > log_mle: -0.2895362377166748  (-0.2999135812123615)\n",
      "     | > loss_dur: 0.1835414469242096  (0.16919275273879367)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(10.1129, device='cuda:0')  (tensor(15.8009, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.3033  (0.2666686058044433)\n",
      "     | > loader_time: 0.002  (0.006405862172444664)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:46:53 -- STEP: 70/406 -- GLOBAL_STEP: 32550\u001b[0m\n",
      "     | > loss: -0.13314755260944366  (-0.12462688769612991)\n",
      "     | > log_mle: -0.313806414604187  (-0.30184368916920246)\n",
      "     | > loss_dur: 0.18065886199474335  (0.17721680157950948)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(15.3820, device='cuda:0')  (tensor(17.1968, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.2833  (0.27894166878291526)\n",
      "     | > loader_time: 0.003  (0.005047512054443361)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:47:02 -- STEP: 95/406 -- GLOBAL_STEP: 32575\u001b[0m\n",
      "     | > loss: -0.10407790541648865  (-0.12232259433520466)\n",
      "     | > log_mle: -0.30938589572906494  (-0.3041871271635357)\n",
      "     | > loss_dur: 0.2053079903125763  (0.1818645329067581)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.7454, device='cuda:0')  (tensor(18.5570, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.3253  (0.2924570008328084)\n",
      "     | > loader_time: 0.003  (0.004488315080341538)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:47:10 -- STEP: 120/406 -- GLOBAL_STEP: 32600\u001b[0m\n",
      "     | > loss: -0.12649661302566528  (-0.12148998553554216)\n",
      "     | > log_mle: -0.322162389755249  (-0.30678625504175816)\n",
      "     | > loss_dur: 0.19566577672958374  (0.1852962695683042)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(12.3215, device='cuda:0')  (tensor(18.5529, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.3223  (0.3042694886525471)\n",
      "     | > loader_time: 0.003  (0.004220489660898844)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:47:20 -- STEP: 145/406 -- GLOBAL_STEP: 32625\u001b[0m\n",
      "     | > loss: -0.1393016278743744  (-0.12015300423934541)\n",
      "     | > log_mle: -0.3078572750091553  (-0.3083372247630151)\n",
      "     | > loss_dur: 0.16855564713478088  (0.18818422057505313)\n",
      "     | > amp_scaler: 4096.0  (7824.772413793104)\n",
      "     | > grad_norm: tensor(14.1866, device='cuda:0')  (tensor(20.7582, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.3543  (0.3151287802334489)\n",
      "     | > loader_time: 0.004  (0.004072685899405642)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:47:30 -- STEP: 170/406 -- GLOBAL_STEP: 32650\u001b[0m\n",
      "     | > loss: -0.10967178642749786  (-0.11921737711219227)\n",
      "     | > log_mle: -0.3192325830459595  (-0.3099091424661523)\n",
      "     | > loss_dur: 0.2095607966184616  (0.19069176539778718)\n",
      "     | > amp_scaler: 4096.0  (7276.423529411764)\n",
      "     | > grad_norm: tensor(15.4225, device='cuda:0')  (tensor(20.9956, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.3583  (0.3259970412534825)\n",
      "     | > loader_time: 0.004  (0.004003655209260827)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:47:40 -- STEP: 195/406 -- GLOBAL_STEP: 32675\u001b[0m\n",
      "     | > loss: -0.1100877970457077  (-0.11887223391960829)\n",
      "     | > log_mle: -0.30576181411743164  (-0.31156848699618606)\n",
      "     | > loss_dur: 0.19567401707172394  (0.19269625311478597)\n",
      "     | > amp_scaler: 4096.0  (6868.676923076923)\n",
      "     | > grad_norm: tensor(22.0156, device='cuda:0')  (tensor(22.0119, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.3924  (0.33853903428102144)\n",
      "     | > loader_time: 0.003  (0.003977993207100108)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:47:51 -- STEP: 220/406 -- GLOBAL_STEP: 32700\u001b[0m\n",
      "     | > loss: -0.1313866525888443  (-0.11888374252752824)\n",
      "     | > log_mle: -0.3489178419113159  (-0.313165015524084)\n",
      "     | > loss_dur: 0.21753118932247162  (0.194281273030422)\n",
      "     | > amp_scaler: 4096.0  (6553.6)\n",
      "     | > grad_norm: tensor(16.7898, device='cuda:0')  (tensor(22.3993, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.4064  (0.3496819095178083)\n",
      "     | > loader_time: 0.004  (0.003999106450514358)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:48:03 -- STEP: 245/406 -- GLOBAL_STEP: 32725\u001b[0m\n",
      "     | > loss: -0.11628790199756622  (-0.11866761032415896)\n",
      "     | > log_mle: -0.3233358860015869  (-0.3145170095015546)\n",
      "     | > loss_dur: 0.2070479840040207  (0.19584939920780617)\n",
      "     | > amp_scaler: 4096.0  (6302.824489795918)\n",
      "     | > grad_norm: tensor(13.7521, device='cuda:0')  (tensor(22.9627, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.5405  (0.36094882342280166)\n",
      "     | > loader_time: 0.005  (0.004003644476131516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:48:16 -- STEP: 270/406 -- GLOBAL_STEP: 32750\u001b[0m\n",
      "     | > loss: -0.12791647017002106  (-0.11880970619342945)\n",
      "     | > log_mle: -0.3291478157043457  (-0.3155089131108037)\n",
      "     | > loss_dur: 0.20123134553432465  (0.196699206944969)\n",
      "     | > amp_scaler: 4096.0  (6098.488888888888)\n",
      "     | > grad_norm: tensor(21.9355, device='cuda:0')  (tensor(23.3279, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.4424  (0.37300596590395324)\n",
      "     | > loader_time: 0.004  (0.004040716312549732)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:48:28 -- STEP: 295/406 -- GLOBAL_STEP: 32775\u001b[0m\n",
      "     | > loss: -0.11229722201824188  (-0.11881314440298889)\n",
      "     | > log_mle: -0.32801127433776855  (-0.31650962829589846)\n",
      "     | > loss_dur: 0.21571405231952667  (0.19769648391816574)\n",
      "     | > amp_scaler: 4096.0  (5928.786440677967)\n",
      "     | > grad_norm: tensor(22.9448, device='cuda:0')  (tensor(23.3557, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.5835  (0.38364380981962554)\n",
      "     | > loader_time: 0.005  (0.004081688088885808)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:48:42 -- STEP: 320/406 -- GLOBAL_STEP: 32800\u001b[0m\n",
      "     | > loss: -0.11007405817508698  (-0.11842898991890252)\n",
      "     | > log_mle: -0.31496429443359375  (-0.31724609769880757)\n",
      "     | > loss_dur: 0.20489023625850677  (0.19881710780318823)\n",
      "     | > amp_scaler: 4096.0  (5785.600000000001)\n",
      "     | > grad_norm: tensor(24.6758, device='cuda:0')  (tensor(23.9705, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.4864  (0.3956128172576426)\n",
      "     | > loader_time: 0.004  (0.004125649482011796)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:48:56 -- STEP: 345/406 -- GLOBAL_STEP: 32825\u001b[0m\n",
      "     | > loss: -0.11877384781837463  (-0.11828655475291652)\n",
      "     | > log_mle: -0.3312896490097046  (-0.31796901329703936)\n",
      "     | > loss_dur: 0.21251580119132996  (0.19968245856571884)\n",
      "     | > amp_scaler: 4096.0  (5663.165217391308)\n",
      "     | > grad_norm: tensor(41.2284, device='cuda:0')  (tensor(24.3120, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.6276  (0.4072687764098677)\n",
      "     | > loader_time: 0.005  (0.0041893426922784355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:49:10 -- STEP: 370/406 -- GLOBAL_STEP: 32850\u001b[0m\n",
      "     | > loss: -0.1288946568965912  (-0.11824949174313931)\n",
      "     | > log_mle: -0.3421497344970703  (-0.31871478879773923)\n",
      "     | > loss_dur: 0.21325507760047913  (0.20046529707473673)\n",
      "     | > amp_scaler: 4096.0  (5557.2756756756835)\n",
      "     | > grad_norm: tensor(40.0631, device='cuda:0')  (tensor(25.1261, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.5285  (0.4184451953784838)\n",
      "     | > loader_time: 0.005  (0.004252548475523251)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:49:26 -- STEP: 395/406 -- GLOBAL_STEP: 32875\u001b[0m\n",
      "     | > loss: -0.12139266729354858  (-0.1181467493123646)\n",
      "     | > log_mle: -0.33820366859436035  (-0.31930192844777167)\n",
      "     | > loss_dur: 0.21681100130081177  (0.20115517915426925)\n",
      "     | > amp_scaler: 4096.0  (5464.789873417726)\n",
      "     | > grad_norm: tensor(24.7874, device='cuda:0')  (tensor(25.3861, device='cuda:0'))\n",
      "     | > current_lr: 1.9999999999999998e-05 \n",
      "     | > step_time: 0.7247  (0.43191403497623476)\n",
      "     | > loader_time: 0.005  (0.00430775895903382)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09320488572120667 \u001b[0m(-0.0018401145935058594)\n",
      "     | > avg_loss:\u001b[91m -0.15116055309772491 \u001b[0m(+0.0014431402087211609)\n",
      "     | > avg_log_mle:\u001b[91m -0.3396456241607666 \u001b[0m(+0.001550629734992981)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1884850710630417 \u001b[0m(-0.00010748952627182007)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 81/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:50:04) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:50:24 -- STEP: 14/406 -- GLOBAL_STEP: 32900\u001b[0m\n",
      "     | > loss: -0.13318046927452087  (-0.14987205288239888)\n",
      "     | > log_mle: -0.3119267225265503  (-0.3035287175859724)\n",
      "     | > loss_dur: 0.17874625325202942  (0.1536566647035735)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.7002, device='cuda:0')  (tensor(20.4342, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.2582  (0.25580321039472304)\n",
      "     | > loader_time: 0.002  (0.015371458871023995)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:50:30 -- STEP: 39/406 -- GLOBAL_STEP: 32925\u001b[0m\n",
      "     | > loss: -0.1298636496067047  (-0.13464355927247268)\n",
      "     | > log_mle: -0.29154276847839355  (-0.30054782904111416)\n",
      "     | > loss_dur: 0.16167911887168884  (0.16590426976864156)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.8527, device='cuda:0')  (tensor(16.7259, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.2913  (0.2642137943170009)\n",
      "     | > loader_time: 0.002  (0.006955525813958581)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:50:38 -- STEP: 64/406 -- GLOBAL_STEP: 32950\u001b[0m\n",
      "     | > loss: -0.13709433376789093  (-0.12756119854748255)\n",
      "     | > log_mle: -0.3008936643600464  (-0.30128926411271095)\n",
      "     | > loss_dur: 0.16379933059215546  (0.17372806556522846)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.2606, device='cuda:0')  (tensor(18.1571, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.2843  (0.2799256220459938)\n",
      "     | > loader_time: 0.003  (0.005255185067653654)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:50:46 -- STEP: 89/406 -- GLOBAL_STEP: 32975\u001b[0m\n",
      "     | > loss: -0.11145968735218048  (-0.12449706755997093)\n",
      "     | > log_mle: -0.3020092248916626  (-0.3041894931471749)\n",
      "     | > loss_dur: 0.19054953753948212  (0.179692425587204)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.4935, device='cuda:0')  (tensor(17.8523, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.3013  (0.29280479570453094)\n",
      "     | > loader_time: 0.002  (0.004588780778177667)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:50:55 -- STEP: 114/406 -- GLOBAL_STEP: 33000\u001b[0m\n",
      "     | > loss: -0.14046193659305573  (-0.12421892583370212)\n",
      "     | > log_mle: -0.33430564403533936  (-0.30775940627382514)\n",
      "     | > loss_dur: 0.19384370744228363  (0.18354048044012297)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.9499, device='cuda:0')  (tensor(18.1207, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.3874  (0.3048290390717357)\n",
      "     | > loader_time: 0.003  (0.00427614178573876)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_33000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:51:09 -- STEP: 139/406 -- GLOBAL_STEP: 33025\u001b[0m\n",
      "     | > loss: -0.12159882485866547  (-0.1225481356005017)\n",
      "     | > log_mle: -0.3210076093673706  (-0.3098323473827444)\n",
      "     | > loss_dur: 0.19940878450870514  (0.18728421178224267)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.8128, device='cuda:0')  (tensor(18.2085, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.4144  (0.3177413957582104)\n",
      "     | > loader_time: 0.004  (0.0041191234863061695)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:51:18 -- STEP: 164/406 -- GLOBAL_STEP: 33050\u001b[0m\n",
      "     | > loss: -0.12298941612243652  (-0.1218189200977)\n",
      "     | > log_mle: -0.3129781484603882  (-0.3114583143373813)\n",
      "     | > loss_dur: 0.18998873233795166  (0.1896393942396814)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.8376, device='cuda:0')  (tensor(19.2506, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.3593  (0.3281696162572722)\n",
      "     | > loader_time: 0.004  (0.004064903026673853)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:51:29 -- STEP: 189/406 -- GLOBAL_STEP: 33075\u001b[0m\n",
      "     | > loss: -0.12521594762802124  (-0.12202086429747326)\n",
      "     | > log_mle: -0.3208721876144409  (-0.31328273513329713)\n",
      "     | > loss_dur: 0.19565623998641968  (0.1912618708358239)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.5896, device='cuda:0')  (tensor(19.7058, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.4584  (0.3397526387815123)\n",
      "     | > loader_time: 0.004  (0.004019751119865944)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:51:40 -- STEP: 214/406 -- GLOBAL_STEP: 33100\u001b[0m\n",
      "     | > loss: -0.1312810182571411  (-0.12173646173187506)\n",
      "     | > log_mle: -0.32687926292419434  (-0.3146963314475299)\n",
      "     | > loss_dur: 0.19559824466705322  (0.1929598697156549)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.9549, device='cuda:0')  (tensor(20.2585, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.4904  (0.350808909006208)\n",
      "     | > loader_time: 0.004  (0.004003838958027207)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:51:51 -- STEP: 239/406 -- GLOBAL_STEP: 33125\u001b[0m\n",
      "     | > loss: -0.11581525206565857  (-0.12153073652768236)\n",
      "     | > log_mle: -0.33109521865844727  (-0.31622368471393014)\n",
      "     | > loss_dur: 0.2152799665927887  (0.19469294818624786)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.4466, device='cuda:0')  (tensor(21.1448, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.5325  (0.3609718518277093)\n",
      "     | > loader_time: 0.004  (0.004020586173404711)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:52:04 -- STEP: 264/406 -- GLOBAL_STEP: 33150\u001b[0m\n",
      "     | > loss: -0.10271470248699188  (-0.12188555272013853)\n",
      "     | > log_mle: -0.32252728939056396  (-0.31749326397072175)\n",
      "     | > loss_dur: 0.21981258690357208  (0.19560771125058327)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.6073, device='cuda:0')  (tensor(21.5309, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.4404  (0.37364204634319664)\n",
      "     | > loader_time: 0.004  (0.004030357707630506)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:52:16 -- STEP: 289/406 -- GLOBAL_STEP: 33175\u001b[0m\n",
      "     | > loss: -0.1203005462884903  (-0.1220841860482437)\n",
      "     | > log_mle: -0.3213001489639282  (-0.31861302885629716)\n",
      "     | > loss_dur: 0.20099960267543793  (0.19652884280805352)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.6720, device='cuda:0')  (tensor(21.7826, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.4524  (0.3837980745572946)\n",
      "     | > loader_time: 0.005  (0.004069599725795865)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:52:30 -- STEP: 314/406 -- GLOBAL_STEP: 33200\u001b[0m\n",
      "     | > loss: -0.13028886914253235  (-0.1219423842752815)\n",
      "     | > log_mle: -0.3351097106933594  (-0.31960533416954545)\n",
      "     | > loss_dur: 0.20482084155082703  (0.19766294989426422)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.1718, device='cuda:0')  (tensor(22.2742, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.4904  (0.3958687736729908)\n",
      "     | > loader_time: 0.005  (0.00413128676687836)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:52:44 -- STEP: 339/406 -- GLOBAL_STEP: 33225\u001b[0m\n",
      "     | > loss: -0.12271362543106079  (-0.12174769181065855)\n",
      "     | > log_mle: -0.3320115804672241  (-0.32033454949876866)\n",
      "     | > loss_dur: 0.20929795503616333  (0.1985868576881105)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.3294, device='cuda:0')  (tensor(22.7487, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.6526  (0.40740544746759016)\n",
      "     | > loader_time: 0.006  (0.004195679605534647)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:52:58 -- STEP: 364/406 -- GLOBAL_STEP: 33250\u001b[0m\n",
      "     | > loss: -0.12022027373313904  (-0.12154808059171006)\n",
      "     | > log_mle: -0.33113300800323486  (-0.321148621839481)\n",
      "     | > loss_dur: 0.21091273427009583  (0.19960054124777132)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.7840, device='cuda:0')  (tensor(23.3973, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.6526  (0.4184969912518512)\n",
      "     | > loader_time: 0.006  (0.004259477604876509)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:53:14 -- STEP: 389/406 -- GLOBAL_STEP: 33275\u001b[0m\n",
      "     | > loss: -0.1294597089290619  (-0.12155828301275297)\n",
      "     | > log_mle: -0.34321320056915283  (-0.3218159853339499)\n",
      "     | > loss_dur: 0.21375349164009094  (0.2002577023211972)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.1200, device='cuda:0')  (tensor(23.7297, device='cuda:0'))\n",
      "     | > current_lr: 2.025e-05 \n",
      "     | > step_time: 0.5585  (0.4312619807481153)\n",
      "     | > loader_time: 0.005  (0.004320221265974267)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.12008732557296753 \u001b[0m(+0.026882439851760864)\n",
      "     | > avg_loss:\u001b[91m -0.14962122030556202 \u001b[0m(+0.0015393327921628952)\n",
      "     | > avg_log_mle:\u001b[92m -0.3414893001317978 \u001b[0m(-0.001843675971031189)\n",
      "     | > avg_loss_dur:\u001b[91m 0.19186807982623577 \u001b[0m(+0.003383008763194084)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 82/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:53:56) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:54:14 -- STEP: 8/406 -- GLOBAL_STEP: 33300\u001b[0m\n",
      "     | > loss: -0.15073026716709137  (-0.15508312173187733)\n",
      "     | > log_mle: -0.3234586715698242  (-0.30673636496067047)\n",
      "     | > loss_dur: 0.17272840440273285  (0.15165324322879314)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.5013, device='cuda:0')  (tensor(25.8393, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.2522  (0.2578592896461487)\n",
      "     | > loader_time: 0.001  (0.025648176670074463)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:54:20 -- STEP: 33/406 -- GLOBAL_STEP: 33325\u001b[0m\n",
      "     | > loss: -0.11019577085971832  (-0.14024239101193173)\n",
      "     | > log_mle: -0.2963860034942627  (-0.3052407575376106)\n",
      "     | > loss_dur: 0.18619023263454437  (0.16499836652567892)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.6074, device='cuda:0')  (tensor(18.3690, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.2853  (0.25999372655695135)\n",
      "     | > loader_time: 0.002  (0.007734190333973278)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:54:27 -- STEP: 58/406 -- GLOBAL_STEP: 33350\u001b[0m\n",
      "     | > loss: -0.12246888875961304  (-0.1314936822344517)\n",
      "     | > log_mle: -0.3061612844467163  (-0.30550478039116696)\n",
      "     | > loss_dur: 0.18369239568710327  (0.17401109815671525)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.8821, device='cuda:0')  (tensor(17.2988, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.3223  (0.2731791693588783)\n",
      "     | > loader_time: 0.003  (0.005435840836886702)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:54:36 -- STEP: 83/406 -- GLOBAL_STEP: 33375\u001b[0m\n",
      "     | > loss: -0.11111468076705933  (-0.12867709527532736)\n",
      "     | > log_mle: -0.3136245012283325  (-0.307789680469467)\n",
      "     | > loss_dur: 0.2025098204612732  (0.17911258519413958)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.7758, device='cuda:0')  (tensor(17.5506, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.3533  (0.2864770688206317)\n",
      "     | > loader_time: 0.003  (0.004630568515823547)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:54:44 -- STEP: 108/406 -- GLOBAL_STEP: 33400\u001b[0m\n",
      "     | > loss: -0.12269553542137146  (-0.12743717652780037)\n",
      "     | > log_mle: -0.31665849685668945  (-0.31028832991917943)\n",
      "     | > loss_dur: 0.193962961435318  (0.18285115339137886)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.8355, device='cuda:0')  (tensor(18.3877, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.3213  (0.2987435084802133)\n",
      "     | > loader_time: 0.003  (0.004272306406939468)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:54:53 -- STEP: 133/406 -- GLOBAL_STEP: 33425\u001b[0m\n",
      "     | > loss: -0.12429478764533997  (-0.1264247906611378)\n",
      "     | > log_mle: -0.32398760318756104  (-0.3124709371337318)\n",
      "     | > loss_dur: 0.19969281554222107  (0.18604614647259388)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.4400, device='cuda:0')  (tensor(19.4382, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.3323  (0.30956678641469854)\n",
      "     | > loader_time: 0.003  (0.004078814857884454)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:55:03 -- STEP: 158/406 -- GLOBAL_STEP: 33450\u001b[0m\n",
      "     | > loss: -0.11966323852539062  (-0.12523541929601117)\n",
      "     | > log_mle: -0.33176958560943604  (-0.3140938764886011)\n",
      "     | > loss_dur: 0.2121063470840454  (0.18885845719258995)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.7871, device='cuda:0')  (tensor(20.6387, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.3603  (0.32128537455691564)\n",
      "     | > loader_time: 0.003  (0.003978234303148483)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:55:13 -- STEP: 183/406 -- GLOBAL_STEP: 33475\u001b[0m\n",
      "     | > loss: -0.127034530043602  (-0.12508549138170783)\n",
      "     | > log_mle: -0.3306986093521118  (-0.3157112168484047)\n",
      "     | > loss_dur: 0.20366407930850983  (0.19062572546669695)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.7791, device='cuda:0')  (tensor(21.3399, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.4634  (0.33375658754442566)\n",
      "     | > loader_time: 0.004  (0.003948877417976084)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:55:24 -- STEP: 208/406 -- GLOBAL_STEP: 33500\u001b[0m\n",
      "     | > loss: -0.12763400375843048  (-0.12481722486420321)\n",
      "     | > log_mle: -0.3349114656448364  (-0.3171723622542162)\n",
      "     | > loss_dur: 0.20727746188640594  (0.19235513739001292)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.8483, device='cuda:0')  (tensor(21.5784, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.4894  (0.3452221109316901)\n",
      "     | > loader_time: 0.004  (0.003960259831868683)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:55:36 -- STEP: 233/406 -- GLOBAL_STEP: 33525\u001b[0m\n",
      "     | > loss: -0.13200964033603668  (-0.12491160554435635)\n",
      "     | > log_mle: -0.33447158336639404  (-0.3187064515674575)\n",
      "     | > loss_dur: 0.20246194303035736  (0.19379484602310115)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.8652, device='cuda:0')  (tensor(22.1101, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.4434  (0.3570365946691948)\n",
      "     | > loader_time: 0.005  (0.0039907085025770945)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:55:49 -- STEP: 258/406 -- GLOBAL_STEP: 33550\u001b[0m\n",
      "     | > loss: -0.11871518194675446  (-0.12500792424115106)\n",
      "     | > log_mle: -0.3260006904602051  (-0.3198735381281654)\n",
      "     | > loss_dur: 0.20728550851345062  (0.19486561388701432)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.8805, device='cuda:0')  (tensor(22.9098, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.4564  (0.37156601746877044)\n",
      "     | > loader_time: 0.005  (0.004038518713426216)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:56:02 -- STEP: 283/406 -- GLOBAL_STEP: 33575\u001b[0m\n",
      "     | > loss: -0.1063188761472702  (-0.12508379481074672)\n",
      "     | > log_mle: -0.3228330612182617  (-0.3208751025553727)\n",
      "     | > loss_dur: 0.21651418507099152  (0.195791307744626)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(86.5728, device='cuda:0')  (tensor(24.0523, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.4714  (0.3843737010821017)\n",
      "     | > loader_time: 0.005  (0.004074336783203553)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:56:15 -- STEP: 308/406 -- GLOBAL_STEP: 33600\u001b[0m\n",
      "     | > loss: -0.13018858432769775  (-0.12469618786852085)\n",
      "     | > log_mle: -0.33728814125061035  (-0.32165578936601613)\n",
      "     | > loss_dur: 0.2070995569229126  (0.19695960149749536)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.3995, device='cuda:0')  (tensor(24.7311, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.4934  (0.3969480263722408)\n",
      "     | > loader_time: 0.005  (0.004123854946780512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:56:29 -- STEP: 333/406 -- GLOBAL_STEP: 33625\u001b[0m\n",
      "     | > loss: -0.13953359425067902  (-0.12451541911553339)\n",
      "     | > log_mle: -0.33983874320983887  (-0.3222881867004944)\n",
      "     | > loss_dur: 0.20030514895915985  (0.1977727675849611)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.9941, device='cuda:0')  (tensor(24.7955, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.4904  (0.4085901657024305)\n",
      "     | > loader_time: 0.005  (0.004177939784419427)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:56:44 -- STEP: 358/406 -- GLOBAL_STEP: 33650\u001b[0m\n",
      "     | > loss: -0.14531365036964417  (-0.1243081454125197)\n",
      "     | > log_mle: -0.350034236907959  (-0.3230623676124231)\n",
      "     | > loss_dur: 0.20472058653831482  (0.19875422219990352)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.1705, device='cuda:0')  (tensor(25.2058, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.5315  (0.4207031753476107)\n",
      "     | > loader_time: 0.005  (0.004224478865468967)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:57:00 -- STEP: 383/406 -- GLOBAL_STEP: 33675\u001b[0m\n",
      "     | > loss: -0.1141689270734787  (-0.12430523713326022)\n",
      "     | > log_mle: -0.33371424674987793  (-0.32375017532169353)\n",
      "     | > loss_dur: 0.21954531967639923  (0.19944493818843334)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.3427, device='cuda:0')  (tensor(25.2597, device='cuda:0'))\n",
      "     | > current_lr: 2.05e-05 \n",
      "     | > step_time: 0.6906  (0.4333699533895788)\n",
      "     | > loader_time: 0.005  (0.004285854085618459)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.10184261202812195 \u001b[0m(-0.01824471354484558)\n",
      "     | > avg_loss:\u001b[92m -0.1589755341410637 \u001b[0m(-0.00935431383550167)\n",
      "     | > avg_log_mle:\u001b[92m -0.3461206555366516 \u001b[0m(-0.004631355404853821)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18714512139558792 \u001b[0m(-0.00472295843064785)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_33698.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 83/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 06:57:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:58:03 -- STEP: 2/406 -- GLOBAL_STEP: 33700\u001b[0m\n",
      "     | > loss: -0.18658360838890076  (-0.17999736219644547)\n",
      "     | > log_mle: -0.3222256898880005  (-0.3152117133140564)\n",
      "     | > loss_dur: 0.13564208149909973  (0.13521435111761093)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.6950, device='cuda:0')  (tensor(34.6543, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.2682  (0.27324843406677246)\n",
      "     | > loader_time: 0.002  (0.0020020008087158203)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:58:10 -- STEP: 27/406 -- GLOBAL_STEP: 33725\u001b[0m\n",
      "     | > loss: -0.13664039969444275  (-0.14370272722509173)\n",
      "     | > log_mle: -0.3053020238876343  (-0.30494116853784636)\n",
      "     | > loss_dur: 0.16866162419319153  (0.16123844158870207)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.3437, device='cuda:0')  (tensor(21.6093, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.2612  (0.2709124883015951)\n",
      "     | > loader_time: 0.002  (0.009082546940556277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:58:17 -- STEP: 52/406 -- GLOBAL_STEP: 33750\u001b[0m\n",
      "     | > loss: -0.10048748552799225  (-0.13404028662122217)\n",
      "     | > log_mle: -0.2997584342956543  (-0.30550869840842027)\n",
      "     | > loss_dur: 0.19927094876766205  (0.1714684119304786)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.6020, device='cuda:0')  (tensor(20.7794, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.2763  (0.2783543650920576)\n",
      "     | > loader_time: 0.003  (0.0059095437710101765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:58:25 -- STEP: 77/406 -- GLOBAL_STEP: 33775\u001b[0m\n",
      "     | > loss: -0.10696820914745331  (-0.13064808640387152)\n",
      "     | > log_mle: -0.3053523302078247  (-0.3076859511338271)\n",
      "     | > loss_dur: 0.1983841210603714  (0.17703786482671643)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.9444, device='cuda:0')  (tensor(20.5110, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.3613  (0.28940927517878556)\n",
      "     | > loader_time: 0.003  (0.004874848700188969)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:58:34 -- STEP: 102/406 -- GLOBAL_STEP: 33800\u001b[0m\n",
      "     | > loss: -0.1359904557466507  (-0.12897002945343647)\n",
      "     | > log_mle: -0.3281850814819336  (-0.3103993242862177)\n",
      "     | > loss_dur: 0.1921946257352829  (0.18142929490582616)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.3442, device='cuda:0')  (tensor(20.9483, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.3884  (0.30173743238636097)\n",
      "     | > loader_time: 0.003  (0.0043768321766572815)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:58:43 -- STEP: 127/406 -- GLOBAL_STEP: 33825\u001b[0m\n",
      "     | > loss: -0.1274583339691162  (-0.12846187742676318)\n",
      "     | > log_mle: -0.3209517002105713  (-0.3129006239372913)\n",
      "     | > loss_dur: 0.19349336624145508  (0.1844387465691942)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.3082, device='cuda:0')  (tensor(22.8538, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.3293  (0.3129949363197868)\n",
      "     | > loader_time: 0.003  (0.004130014284389224)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:58:52 -- STEP: 152/406 -- GLOBAL_STEP: 33850\u001b[0m\n",
      "     | > loss: -0.09842568635940552  (-0.1274128663108537)\n",
      "     | > log_mle: -0.3122212886810303  (-0.3147821096997512)\n",
      "     | > loss_dur: 0.21379560232162476  (0.18736924343791447)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(48.2664, device='cuda:0')  (tensor(23.6070, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.4404  (0.3245266064217216)\n",
      "     | > loader_time: 0.003  (0.00404344263829683)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:59:03 -- STEP: 177/406 -- GLOBAL_STEP: 33875\u001b[0m\n",
      "     | > loss: -0.14602519571781158  (-0.12696005589207693)\n",
      "     | > log_mle: -0.3381214141845703  (-0.3161355243564325)\n",
      "     | > loss_dur: 0.19209621846675873  (0.18917546850644928)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.7037, device='cuda:0')  (tensor(23.5680, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.4714  (0.33584304179175417)\n",
      "     | > loader_time: 0.003  (0.003986951321531824)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:59:14 -- STEP: 202/406 -- GLOBAL_STEP: 33900\u001b[0m\n",
      "     | > loss: -0.09397044777870178  (-0.12636076607326474)\n",
      "     | > log_mle: -0.31487131118774414  (-0.3175009530369597)\n",
      "     | > loss_dur: 0.22090086340904236  (0.1911401870005791)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(47.3962, device='cuda:0')  (tensor(24.9547, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.3994  (0.3478070261454817)\n",
      "     | > loader_time: 0.003  (0.003939518834104633)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:59:25 -- STEP: 227/406 -- GLOBAL_STEP: 33925\u001b[0m\n",
      "     | > loss: -0.09107305109500885  (-0.12577350299789)\n",
      "     | > log_mle: -0.3124159574508667  (-0.31859494515977754)\n",
      "     | > loss_dur: 0.22134290635585785  (0.19282144219470962)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.8720, device='cuda:0')  (tensor(25.2109, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.4114  (0.35768255368203306)\n",
      "     | > loader_time: 0.004  (0.003959855319119761)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:59:37 -- STEP: 252/406 -- GLOBAL_STEP: 33950\u001b[0m\n",
      "     | > loss: -0.11540819704532623  (-0.12575223332359686)\n",
      "     | > log_mle: -0.32857799530029297  (-0.31988751604443494)\n",
      "     | > loss_dur: 0.21316979825496674  (0.194135282750404)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.0801, device='cuda:0')  (tensor(25.3759, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.4334  (0.37007891942584314)\n",
      "     | > loader_time: 0.005  (0.004015849696265325)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 06:59:49 -- STEP: 277/406 -- GLOBAL_STEP: 33975\u001b[0m\n",
      "     | > loss: -0.13731054961681366  (-0.12603517871901454)\n",
      "     | > log_mle: -0.32787859439849854  (-0.3210817803544687)\n",
      "     | > loss_dur: 0.19056804478168488  (0.19504660166235172)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.0080, device='cuda:0')  (tensor(25.4215, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.5485  (0.38146980919132156)\n",
      "     | > loader_time: 0.004  (0.004054531724014005)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:00:03 -- STEP: 302/406 -- GLOBAL_STEP: 34000\u001b[0m\n",
      "     | > loss: -0.13148781657218933  (-0.12597777329335946)\n",
      "     | > log_mle: -0.3396341800689697  (-0.32213883013125266)\n",
      "     | > loss_dur: 0.2081463634967804  (0.19616105686256421)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.2875, device='cuda:0')  (tensor(25.3485, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.5875  (0.39305616925094305)\n",
      "     | > loader_time: 0.004  (0.004103385060038785)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_34000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:00:22 -- STEP: 327/406 -- GLOBAL_STEP: 34025\u001b[0m\n",
      "     | > loss: -0.12623922526836395  (-0.12584270158674388)\n",
      "     | > log_mle: -0.33590948581695557  (-0.32296883731807025)\n",
      "     | > loss_dur: 0.2096702605485916  (0.1971261357541113)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.9298, device='cuda:0')  (tensor(25.1466, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.5185  (0.4063801247774643)\n",
      "     | > loader_time: 0.005  (0.004172248577852862)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:00:37 -- STEP: 352/406 -- GLOBAL_STEP: 34050\u001b[0m\n",
      "     | > loss: -0.12630383670330048  (-0.12570773827081394)\n",
      "     | > log_mle: -0.3283652067184448  (-0.3238114880567246)\n",
      "     | > loss_dur: 0.20206137001514435  (0.19810374980707735)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.8074, device='cuda:0')  (tensor(25.2341, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.5175  (0.4188309819860892)\n",
      "     | > loader_time: 0.005  (0.004239882257851689)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:00:52 -- STEP: 377/406 -- GLOBAL_STEP: 34075\u001b[0m\n",
      "     | > loss: -0.1292692869901657  (-0.1260849525979091)\n",
      "     | > log_mle: -0.3334696292877197  (-0.3248199496408355)\n",
      "     | > loss_dur: 0.20420034229755402  (0.19873499706268938)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.7376, device='cuda:0')  (tensor(25.6125, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.6726  (0.43085977443017126)\n",
      "     | > loader_time: 0.005  (0.004295884139974178)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:01:08 -- STEP: 402/406 -- GLOBAL_STEP: 34100\u001b[0m\n",
      "     | > loss: -0.13718372583389282  (-0.12627614508220816)\n",
      "     | > log_mle: -0.34638750553131104  (-0.3257139007843549)\n",
      "     | > loss_dur: 0.2092037796974182  (0.1994377557206806)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.5057, device='cuda:0')  (tensor(25.6022, device='cuda:0'))\n",
      "     | > current_lr: 2.075e-05 \n",
      "     | > step_time: 0.5502  (0.44447264386646784)\n",
      "     | > loader_time: 0.004  (0.004357365233388118)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09571188688278198 \u001b[0m(-0.006130725145339966)\n",
      "     | > avg_loss:\u001b[92m -0.16022740863263607 \u001b[0m(-0.00125187449157238)\n",
      "     | > avg_log_mle:\u001b[92m -0.34889501333236694 \u001b[0m(-0.002774357795715332)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18866760469973087 \u001b[0m(+0.001522483304142952)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_34104.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 84/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:01:42) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:02:04 -- STEP: 21/406 -- GLOBAL_STEP: 34125\u001b[0m\n",
      "     | > loss: -0.13366594910621643  (-0.15119375998065585)\n",
      "     | > log_mle: -0.3167203664779663  (-0.3106975555419922)\n",
      "     | > loss_dur: 0.18305441737174988  (0.15950379556133634)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.8562, device='cuda:0')  (tensor(20.0866, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.2602  (0.259426060177031)\n",
      "     | > loader_time: 0.002  (0.0165863831837972)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:02:11 -- STEP: 46/406 -- GLOBAL_STEP: 34150\u001b[0m\n",
      "     | > loss: -0.13169914484024048  (-0.13995125889778137)\n",
      "     | > log_mle: -0.3121849298477173  (-0.308180860851122)\n",
      "     | > loss_dur: 0.1804857850074768  (0.16822960195334064)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.8912, device='cuda:0')  (tensor(17.7889, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.3083  (0.26991891342660645)\n",
      "     | > loader_time: 0.002  (0.008942847666533096)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:02:19 -- STEP: 71/406 -- GLOBAL_STEP: 34175\u001b[0m\n",
      "     | > loss: -0.11874417960643768  (-0.1350668815659805)\n",
      "     | > log_mle: -0.3156242370605469  (-0.3102952258687624)\n",
      "     | > loss_dur: 0.1968800574541092  (0.17522834430278184)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.1897, device='cuda:0')  (tensor(17.6138, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.3603  (0.2836659256841094)\n",
      "     | > loader_time: 0.003  (0.006710304340846101)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:02:28 -- STEP: 96/406 -- GLOBAL_STEP: 34200\u001b[0m\n",
      "     | > loss: -0.13451334834098816  (-0.13324108766391868)\n",
      "     | > log_mle: -0.3260105848312378  (-0.31295649086435656)\n",
      "     | > loss_dur: 0.19149723649024963  (0.17971540320043763)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.8503, device='cuda:0')  (tensor(19.8133, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.3823  (0.2977806950608888)\n",
      "     | > loader_time: 0.004  (0.0057135249177614825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:02:37 -- STEP: 121/406 -- GLOBAL_STEP: 34225\u001b[0m\n",
      "     | > loss: -0.1366434395313263  (-0.13230716258533723)\n",
      "     | > log_mle: -0.3191561698913574  (-0.315298069607128)\n",
      "     | > loss_dur: 0.18251273036003113  (0.1829909070217905)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(6.2357, device='cuda:0')  (tensor(19.5587, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.3974  (0.30998385248105376)\n",
      "     | > loader_time: 0.003  (0.005169955166903407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:02:46 -- STEP: 146/406 -- GLOBAL_STEP: 34250\u001b[0m\n",
      "     | > loss: -0.11438143253326416  (-0.13076944067461846)\n",
      "     | > log_mle: -0.3137497901916504  (-0.3166340663008495)\n",
      "     | > loss_dur: 0.19936835765838623  (0.18586462562623088)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.8952, device='cuda:0')  (tensor(22.7611, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.4284  (0.321908660130958)\n",
      "     | > loader_time: 0.003  (0.004853692773270278)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:02:57 -- STEP: 171/406 -- GLOBAL_STEP: 34275\u001b[0m\n",
      "     | > loss: -0.14476698637008667  (-0.1298641062270828)\n",
      "     | > log_mle: -0.3298799991607666  (-0.31799395181979356)\n",
      "     | > loss_dur: 0.18511301279067993  (0.1881298455927108)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.0651, device='cuda:0')  (tensor(23.3990, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.4494  (0.3333142723953515)\n",
      "     | > loader_time: 0.004  (0.004694294511226182)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:03:08 -- STEP: 196/406 -- GLOBAL_STEP: 34300\u001b[0m\n",
      "     | > loss: -0.12278342247009277  (-0.1294739114082589)\n",
      "     | > log_mle: -0.3311265707015991  (-0.3195197454520634)\n",
      "     | > loss_dur: 0.20834314823150635  (0.19004583404380454)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.7537, device='cuda:0')  (tensor(23.7363, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.4774  (0.346120294259519)\n",
      "     | > loader_time: 0.004  (0.004580678988476186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:03:19 -- STEP: 221/406 -- GLOBAL_STEP: 34325\u001b[0m\n",
      "     | > loss: -0.11213597655296326  (-0.12923525408652034)\n",
      "     | > log_mle: -0.3234487771987915  (-0.32097914585700404)\n",
      "     | > loss_dur: 0.21131280064582825  (0.19174389177048373)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.1133, device='cuda:0')  (tensor(23.9634, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.4114  (0.35702090996962327)\n",
      "     | > loader_time: 0.004  (0.004524463981524852)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:03:31 -- STEP: 246/406 -- GLOBAL_STEP: 34350\u001b[0m\n",
      "     | > loss: -0.12870068848133087  (-0.12929337635272883)\n",
      "     | > log_mle: -0.32813215255737305  (-0.3224235598633929)\n",
      "     | > loss_dur: 0.19943146407604218  (0.19313018351066408)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.5088, device='cuda:0')  (tensor(24.6285, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.4344  (0.3687168010851232)\n",
      "     | > loader_time: 0.004  (0.004487813003664094)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:03:43 -- STEP: 271/406 -- GLOBAL_STEP: 34375\u001b[0m\n",
      "     | > loss: -0.14285549521446228  (-0.1293350745721057)\n",
      "     | > log_mle: -0.343090295791626  (-0.32337185993405726)\n",
      "     | > loss_dur: 0.2002348005771637  (0.19403678536195162)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.7986, device='cuda:0')  (tensor(25.2317, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.4564  (0.38130183413459806)\n",
      "     | > loader_time: 0.004  (0.004480091848056695)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:03:56 -- STEP: 296/406 -- GLOBAL_STEP: 34400\u001b[0m\n",
      "     | > loss: -0.10927635431289673  (-0.12897745872268804)\n",
      "     | > log_mle: -0.33306849002838135  (-0.3241487656896178)\n",
      "     | > loss_dur: 0.22379213571548462  (0.19517130696692989)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(42.2011, device='cuda:0')  (tensor(25.9619, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.5075  (0.39242041272086076)\n",
      "     | > loader_time: 0.004  (0.004487188281239691)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:04:10 -- STEP: 321/406 -- GLOBAL_STEP: 34425\u001b[0m\n",
      "     | > loss: -0.12207901477813721  (-0.12862945958461341)\n",
      "     | > log_mle: -0.323203444480896  (-0.3248335969782321)\n",
      "     | > loss_dur: 0.2011244297027588  (0.19620413739361875)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.1932, device='cuda:0')  (tensor(26.2514, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.5115  (0.4046695113553436)\n",
      "     | > loader_time: 0.005  (0.004505661789130573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:04:25 -- STEP: 346/406 -- GLOBAL_STEP: 34450\u001b[0m\n",
      "     | > loss: -0.13288402557373047  (-0.12837657685569256)\n",
      "     | > log_mle: -0.3290717601776123  (-0.32537742501738454)\n",
      "     | > loss_dur: 0.19618773460388184  (0.19700084816169194)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.7969, device='cuda:0')  (tensor(26.2171, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.5305  (0.4163779564675568)\n",
      "     | > loader_time: 0.005  (0.004527246331892951)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:04:40 -- STEP: 371/406 -- GLOBAL_STEP: 34475\u001b[0m\n",
      "     | > loss: -0.1229153573513031  (-0.12831778374483005)\n",
      "     | > log_mle: -0.3402531147003174  (-0.3261692086962677)\n",
      "     | > loss_dur: 0.21733775734901428  (0.19785142495143776)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(35.6940, device='cuda:0')  (tensor(26.1545, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.5605  (0.42793021176381896)\n",
      "     | > loader_time: 0.005  (0.004570208469812442)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:04:56 -- STEP: 396/406 -- GLOBAL_STEP: 34500\u001b[0m\n",
      "     | > loss: -0.1453353762626648  (-0.1282919419157988)\n",
      "     | > log_mle: -0.35450661182403564  (-0.3269117188574088)\n",
      "     | > loss_dur: 0.20917123556137085  (0.19861977694161018)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(41.8278, device='cuda:0')  (tensor(26.2613, device='cuda:0'))\n",
      "     | > current_lr: 2.1e-05 \n",
      "     | > step_time: 0.5745  (0.4416458179252316)\n",
      "     | > loader_time: 0.005  (0.00460523246514677)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08932459354400635 \u001b[0m(-0.006387293338775635)\n",
      "     | > avg_loss:\u001b[92m -0.16238882020115852 \u001b[0m(-0.0021614115685224533)\n",
      "     | > avg_log_mle:\u001b[92m -0.3497203439474106 \u001b[0m(-0.0008253306150436401)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18733152374625206 \u001b[0m(-0.0013360809534788132)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_34510.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 85/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:05:34) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:05:54 -- STEP: 15/406 -- GLOBAL_STEP: 34525\u001b[0m\n",
      "     | > loss: -0.14243462681770325  (-0.1570548713207245)\n",
      "     | > log_mle: -0.3069082498550415  (-0.31000333627065024)\n",
      "     | > loss_dur: 0.16447362303733826  (0.15294846494992573)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.3561, device='cuda:0')  (tensor(18.0712, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.2642  (0.258568255106608)\n",
      "     | > loader_time: 0.002  (0.012477842966715495)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:06:01 -- STEP: 40/406 -- GLOBAL_STEP: 34550\u001b[0m\n",
      "     | > loss: -0.11181339621543884  (-0.139646377414465)\n",
      "     | > log_mle: -0.29736149311065674  (-0.3051107853651046)\n",
      "     | > loss_dur: 0.1855480968952179  (0.1654644079506397)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.2158, device='cuda:0')  (tensor(17.8051, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.3023  (0.2673678874969482)\n",
      "     | > loader_time: 0.002  (0.006030356884002686)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:06:09 -- STEP: 65/406 -- GLOBAL_STEP: 34575\u001b[0m\n",
      "     | > loss: -0.13525080680847168  (-0.13520217469105353)\n",
      "     | > log_mle: -0.31675827503204346  (-0.3074296529476458)\n",
      "     | > loss_dur: 0.18150746822357178  (0.17222747825659238)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.6502, device='cuda:0')  (tensor(18.2837, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.3363  (0.2813016891479491)\n",
      "     | > loader_time: 0.003  (0.004681081038254958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:06:18 -- STEP: 90/406 -- GLOBAL_STEP: 34600\u001b[0m\n",
      "     | > loss: -0.14881351590156555  (-0.1331877100798819)\n",
      "     | > log_mle: -0.32615017890930176  (-0.31076853275299066)\n",
      "     | > loss_dur: 0.1773366630077362  (0.17758082267310887)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.9670, device='cuda:0')  (tensor(19.4138, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.3683  (0.2974368757671779)\n",
      "     | > loader_time: 0.004  (0.004181445969475639)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:06:26 -- STEP: 115/406 -- GLOBAL_STEP: 34625\u001b[0m\n",
      "     | > loss: -0.10017651319503784  (-0.13300300447837166)\n",
      "     | > log_mle: -0.31357455253601074  (-0.3145567261654398)\n",
      "     | > loss_dur: 0.2133980393409729  (0.18155372168706815)\n",
      "     | > amp_scaler: 8192.0  (4559.026086956521)\n",
      "     | > grad_norm: tensor(17.1379, device='cuda:0')  (tensor(20.1324, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.3263  (0.30846279600392207)\n",
      "     | > loader_time: 0.003  (0.003933925214021102)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:06:36 -- STEP: 140/406 -- GLOBAL_STEP: 34650\u001b[0m\n",
      "     | > loss: -0.13377301394939423  (-0.1314527198672295)\n",
      "     | > log_mle: -0.32954156398773193  (-0.3166037951196943)\n",
      "     | > loss_dur: 0.1957685500383377  (0.18515107525246485)\n",
      "     | > amp_scaler: 8192.0  (5207.771428571428)\n",
      "     | > grad_norm: tensor(19.5122, device='cuda:0')  (tensor(20.5254, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.3453  (0.3191255722727093)\n",
      "     | > loader_time: 0.003  (0.0038105300494602748)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:06:46 -- STEP: 165/406 -- GLOBAL_STEP: 34675\u001b[0m\n",
      "     | > loss: -0.1440529078245163  (-0.1306667895028086)\n",
      "     | > log_mle: -0.34235870838165283  (-0.31812926566962046)\n",
      "     | > loss_dur: 0.19830580055713654  (0.18746247616681183)\n",
      "     | > amp_scaler: 8192.0  (5659.927272727271)\n",
      "     | > grad_norm: tensor(25.9361, device='cuda:0')  (tensor(21.6653, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.3603  (0.3299056645595664)\n",
      "     | > loader_time: 0.004  (0.003754888881336559)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:06:56 -- STEP: 190/406 -- GLOBAL_STEP: 34700\u001b[0m\n",
      "     | > loss: -0.11768925189971924  (-0.13050317183921217)\n",
      "     | > log_mle: -0.33592796325683594  (-0.3197430460076585)\n",
      "     | > loss_dur: 0.2182387113571167  (0.18923987416844615)\n",
      "     | > amp_scaler: 8192.0  (5993.094736842103)\n",
      "     | > grad_norm: tensor(20.8544, device='cuda:0')  (tensor(22.5402, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.3904  (0.34195262758355377)\n",
      "     | > loader_time: 0.003  (0.0037665417319849917)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:07:08 -- STEP: 215/406 -- GLOBAL_STEP: 34725\u001b[0m\n",
      "     | > loss: -0.1387985348701477  (-0.1306200541729151)\n",
      "     | > log_mle: -0.3370281457901001  (-0.32120179630989276)\n",
      "     | > loss_dur: 0.1982296109199524  (0.1905817421369774)\n",
      "     | > amp_scaler: 8192.0  (6248.781395348835)\n",
      "     | > grad_norm: tensor(21.9029, device='cuda:0')  (tensor(22.4875, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.3984  (0.3538934607838474)\n",
      "     | > loader_time: 0.004  (0.003812726708345635)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:07:19 -- STEP: 240/406 -- GLOBAL_STEP: 34750\u001b[0m\n",
      "     | > loss: -0.15260392427444458  (-0.13063570732871702)\n",
      "     | > log_mle: -0.34593772888183594  (-0.3227700437108678)\n",
      "     | > loss_dur: 0.19333380460739136  (0.19213433638215063)\n",
      "     | > amp_scaler: 8192.0  (6451.199999999998)\n",
      "     | > grad_norm: tensor(29.9068, device='cuda:0')  (tensor(23.2034, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.5315  (0.3649522066116332)\n",
      "     | > loader_time: 0.004  (0.003853483994801839)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:07:32 -- STEP: 265/406 -- GLOBAL_STEP: 34775\u001b[0m\n",
      "     | > loss: -0.11978913843631744  (-0.13097936477301267)\n",
      "     | > log_mle: -0.3382519483566284  (-0.32403070251896715)\n",
      "     | > loss_dur: 0.21846280992031097  (0.19305133774595437)\n",
      "     | > amp_scaler: 8192.0  (6615.426415094338)\n",
      "     | > grad_norm: tensor(39.2399, device='cuda:0')  (tensor(23.3805, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.4384  (0.3776523464130904)\n",
      "     | > loader_time: 0.004  (0.003894085254309312)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:07:45 -- STEP: 290/406 -- GLOBAL_STEP: 34800\u001b[0m\n",
      "     | > loss: -0.1527796983718872  (-0.13131090972957948)\n",
      "     | > log_mle: -0.345977783203125  (-0.3251993191653286)\n",
      "     | > loss_dur: 0.1931980848312378  (0.19388840943574906)\n",
      "     | > amp_scaler: 8192.0  (6751.337931034481)\n",
      "     | > grad_norm: tensor(41.7484, device='cuda:0')  (tensor(23.6414, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.5935  (0.3887288274436161)\n",
      "     | > loader_time: 0.004  (0.003958761280980602)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:07:58 -- STEP: 315/406 -- GLOBAL_STEP: 34825\u001b[0m\n",
      "     | > loss: -0.14736144244670868  (-0.13121564194323534)\n",
      "     | > log_mle: -0.3459402322769165  (-0.3261763114777824)\n",
      "     | > loss_dur: 0.19857878983020782  (0.19496066953454697)\n",
      "     | > amp_scaler: 8192.0  (6865.676190476191)\n",
      "     | > grad_norm: tensor(31.3418, device='cuda:0')  (tensor(24.0787, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.5325  (0.4009386637854196)\n",
      "     | > loader_time: 0.005  (0.004016342617216563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:08:13 -- STEP: 340/406 -- GLOBAL_STEP: 34850\u001b[0m\n",
      "     | > loss: -0.11979636549949646  (-0.13102077955708788)\n",
      "     | > log_mle: -0.3206440210342407  (-0.3268940336564011)\n",
      "     | > loss_dur: 0.20084765553474426  (0.19587325409931294)\n",
      "     | > amp_scaler: 8192.0  (6963.2)\n",
      "     | > grad_norm: tensor(16.5902, device='cuda:0')  (tensor(23.8984, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.5145  (0.4127070973901186)\n",
      "     | > loader_time: 0.005  (0.004077225572922647)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:08:27 -- STEP: 365/406 -- GLOBAL_STEP: 34875\u001b[0m\n",
      "     | > loss: -0.138064906001091  (-0.13114487459398297)\n",
      "     | > log_mle: -0.3417121171951294  (-0.32790625226007764)\n",
      "     | > loss_dur: 0.2036472111940384  (0.19676137766609453)\n",
      "     | > amp_scaler: 8192.0  (7047.364383561644)\n",
      "     | > grad_norm: tensor(29.8162, device='cuda:0')  (tensor(24.5219, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.5645  (0.42398223093111204)\n",
      "     | > loader_time: 0.005  (0.004151712051809648)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:08:43 -- STEP: 390/406 -- GLOBAL_STEP: 34900\u001b[0m\n",
      "     | > loss: -0.13386963307857513  (-0.1312345251441002)\n",
      "     | > log_mle: -0.35079002380371094  (-0.3287803756885041)\n",
      "     | > loss_dur: 0.2169203907251358  (0.19754585054440377)\n",
      "     | > amp_scaler: 8192.0  (7120.738461538462)\n",
      "     | > grad_norm: tensor(18.0465, device='cuda:0')  (tensor(24.5294, device='cuda:0'))\n",
      "     | > current_lr: 2.125e-05 \n",
      "     | > step_time: 0.7106  (0.43719696326133517)\n",
      "     | > loader_time: 0.005  (0.004203816560598517)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09058251976966858 \u001b[0m(+0.0012579262256622314)\n",
      "     | > avg_loss:\u001b[91m -0.15897673927247524 \u001b[0m(+0.003412080928683281)\n",
      "     | > avg_log_mle:\u001b[91m -0.34913575649261475 \u001b[0m(+0.0005845874547958374)\n",
      "     | > avg_loss_dur:\u001b[91m 0.1901590172201395 \u001b[0m(+0.0028274934738874435)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 86/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:09:25) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:09:43 -- STEP: 9/406 -- GLOBAL_STEP: 34925\u001b[0m\n",
      "     | > loss: -0.1311529576778412  (-0.16625206172466278)\n",
      "     | > log_mle: -0.31208622455596924  (-0.3155936400095622)\n",
      "     | > loss_dur: 0.18093326687812805  (0.14934157828489938)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(28.2786, device='cuda:0')  (tensor(21.8325, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.2532  (0.2587902810838487)\n",
      "     | > loader_time: 0.001  (0.02513427204555935)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:09:50 -- STEP: 34/406 -- GLOBAL_STEP: 34950\u001b[0m\n",
      "     | > loss: -0.11746706068515778  (-0.1519162483951625)\n",
      "     | > log_mle: -0.2986154556274414  (-0.3135878794333514)\n",
      "     | > loss_dur: 0.18114839494228363  (0.16167163103818893)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(8.0602, device='cuda:0')  (tensor(19.7557, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.2662  (0.2636805632535149)\n",
      "     | > loader_time: 0.003  (0.008183808887706081)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:09:58 -- STEP: 59/406 -- GLOBAL_STEP: 34975\u001b[0m\n",
      "     | > loss: -0.13786056637763977  (-0.14307766167794247)\n",
      "     | > log_mle: -0.3231152296066284  (-0.31373167442063155)\n",
      "     | > loss_dur: 0.18525466322898865  (0.17065401274268907)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.2982, device='cuda:0')  (tensor(20.2459, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.3293  (0.2786089000055345)\n",
      "     | > loader_time: 0.003  (0.0057848348455914)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:10:06 -- STEP: 84/406 -- GLOBAL_STEP: 35000\u001b[0m\n",
      "     | > loss: -0.14063601195812225  (-0.13993685160364425)\n",
      "     | > log_mle: -0.3300420045852661  (-0.3158997836567106)\n",
      "     | > loss_dur: 0.18940599262714386  (0.17596293205306643)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(11.9035, device='cuda:0')  (tensor(21.1928, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.3043  (0.2918602597145806)\n",
      "     | > loader_time: 0.003  (0.0048972056025550475)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_35000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:10:18 -- STEP: 109/406 -- GLOBAL_STEP: 35025\u001b[0m\n",
      "     | > loss: -0.13871313631534576  (-0.13892679463285917)\n",
      "     | > log_mle: -0.33351457118988037  (-0.3184178564526619)\n",
      "     | > loss_dur: 0.1948014348745346  (0.17949106181980273)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(36.8895, device='cuda:0')  (tensor(22.6502, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.3924  (0.3076463401864426)\n",
      "     | > loader_time: 0.003  (0.004490250841193242)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:10:28 -- STEP: 134/406 -- GLOBAL_STEP: 35050\u001b[0m\n",
      "     | > loss: -0.1193966418504715  (-0.13772515997068205)\n",
      "     | > log_mle: -0.32599377632141113  (-0.3207470489971673)\n",
      "     | > loss_dur: 0.20659713447093964  (0.18302188902648528)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.2443, device='cuda:0')  (tensor(21.5768, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.4234  (0.32100789226702775)\n",
      "     | > loader_time: 0.004  (0.0042799835774435906)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:10:38 -- STEP: 159/406 -- GLOBAL_STEP: 35075\u001b[0m\n",
      "     | > loss: -0.13072657585144043  (-0.13626889134727935)\n",
      "     | > log_mle: -0.3275322914123535  (-0.3220624901213736)\n",
      "     | > loss_dur: 0.19680571556091309  (0.18579359877409427)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.6853, device='cuda:0')  (tensor(22.4532, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.3633  (0.3328871577040952)\n",
      "     | > loader_time: 0.003  (0.00419244676266076)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:10:48 -- STEP: 184/406 -- GLOBAL_STEP: 35100\u001b[0m\n",
      "     | > loss: -0.11992770433425903  (-0.13597222449986837)\n",
      "     | > log_mle: -0.3474428653717041  (-0.3237145705067595)\n",
      "     | > loss_dur: 0.22751516103744507  (0.187742346006891)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.2897, device='cuda:0')  (tensor(23.3700, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.3793  (0.34474778693655256)\n",
      "     | > loader_time: 0.004  (0.004134152246558143)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:10:59 -- STEP: 209/406 -- GLOBAL_STEP: 35125\u001b[0m\n",
      "     | > loss: -0.14925609529018402  (-0.13560770608876885)\n",
      "     | > log_mle: -0.3444058895111084  (-0.3251027878391687)\n",
      "     | > loss_dur: 0.19514979422092438  (0.18949508175039975)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.3867, device='cuda:0')  (tensor(23.7868, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.3944  (0.3558781169818348)\n",
      "     | > loader_time: 0.004  (0.004123330686651346)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:11:11 -- STEP: 234/406 -- GLOBAL_STEP: 35150\u001b[0m\n",
      "     | > loss: -0.13343872129917145  (-0.13563172519206998)\n",
      "     | > log_mle: -0.3445206880569458  (-0.3266908791330127)\n",
      "     | > loss_dur: 0.21108196675777435  (0.19105915394094256)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(34.0097, device='cuda:0')  (tensor(24.0089, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.5095  (0.3654813725724179)\n",
      "     | > loader_time: 0.004  (0.004119119073590658)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:11:23 -- STEP: 259/406 -- GLOBAL_STEP: 35175\u001b[0m\n",
      "     | > loss: -0.13121964037418365  (-0.13550448400403542)\n",
      "     | > log_mle: -0.3503764867782593  (-0.32775955540793295)\n",
      "     | > loss_dur: 0.21915684640407562  (0.19225507140389742)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(43.7004, device='cuda:0')  (tensor(25.1241, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.5289  (0.3770004220910974)\n",
      "     | > loader_time: 0.004  (0.004138894062705018)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:11:35 -- STEP: 284/406 -- GLOBAL_STEP: 35200\u001b[0m\n",
      "     | > loss: -0.12770794332027435  (-0.13560396789664952)\n",
      "     | > log_mle: -0.3446693420410156  (-0.32873341189303884)\n",
      "     | > loss_dur: 0.21696139872074127  (0.19312944399638915)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(35.8173, device='cuda:0')  (tensor(25.4540, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.5545  (0.38730495832335765)\n",
      "     | > loader_time: 0.005  (0.004162210813710384)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:11:49 -- STEP: 309/406 -- GLOBAL_STEP: 35225\u001b[0m\n",
      "     | > loss: -0.1370481550693512  (-0.13521427215110138)\n",
      "     | > log_mle: -0.34352922439575195  (-0.329479424698839)\n",
      "     | > loss_dur: 0.20648106932640076  (0.1942651525477375)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.9489, device='cuda:0')  (tensor(25.7714, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.6196  (0.3985908293801217)\n",
      "     | > loader_time: 0.004  (0.004197956288902502)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:12:02 -- STEP: 334/406 -- GLOBAL_STEP: 35250\u001b[0m\n",
      "     | > loss: -0.1381247639656067  (-0.13504177724529884)\n",
      "     | > log_mle: -0.3531932830810547  (-0.33012630268485244)\n",
      "     | > loss_dur: 0.215068519115448  (0.1950845254395536)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(31.8412, device='cuda:0')  (tensor(25.9033, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.6306  (0.40914615257057585)\n",
      "     | > loader_time: 0.005  (0.0042283499312258)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:12:17 -- STEP: 359/406 -- GLOBAL_STEP: 35275\u001b[0m\n",
      "     | > loss: -0.139685720205307  (-0.1348887167684215)\n",
      "     | > log_mle: -0.3374370336532593  (-0.3308736570698304)\n",
      "     | > loss_dur: 0.19775131344795227  (0.19598494030140898)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(40.9356, device='cuda:0')  (tensor(26.0765, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.5475  (0.4203029064082832)\n",
      "     | > loader_time: 0.005  (0.004271240287504482)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:12:32 -- STEP: 384/406 -- GLOBAL_STEP: 35300\u001b[0m\n",
      "     | > loss: -0.139077827334404  (-0.13494444153426843)\n",
      "     | > log_mle: -0.33604443073272705  (-0.33153235446661705)\n",
      "     | > loss_dur: 0.19696660339832306  (0.1965879129323487)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.8174, device='cuda:0')  (tensor(26.4798, device='cuda:0'))\n",
      "     | > current_lr: 2.15e-05 \n",
      "     | > step_time: 0.5775  (0.43243884295225127)\n",
      "     | > loader_time: 0.006  (0.004334604988495507)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08257561922073364 \u001b[0m(-0.008006900548934937)\n",
      "     | > avg_loss:\u001b[92m -0.1640575286000967 \u001b[0m(-0.00508078932762146)\n",
      "     | > avg_log_mle:\u001b[92m -0.3515957444906235 \u001b[0m(-0.002459987998008728)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18753821589052677 \u001b[0m(-0.002620801329612732)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_35322.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 87/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:13:17) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:13:34 -- STEP: 3/406 -- GLOBAL_STEP: 35325\u001b[0m\n",
      "     | > loss: -0.16873285174369812  (-0.18790918588638306)\n",
      "     | > log_mle: -0.3239123821258545  (-0.3247612714767456)\n",
      "     | > loss_dur: 0.15517953038215637  (0.1368520831068357)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.2315, device='cuda:0')  (tensor(22.7285, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.2482  (0.25856828689575195)\n",
      "     | > loader_time: 0.1842  (0.06272339820861816)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:13:41 -- STEP: 28/406 -- GLOBAL_STEP: 35350\u001b[0m\n",
      "     | > loss: -0.1358272135257721  (-0.1545336331639971)\n",
      "     | > log_mle: -0.31544017791748047  (-0.3149676365511759)\n",
      "     | > loss_dur: 0.17961296439170837  (0.16043400312108655)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.6428, device='cuda:0')  (tensor(16.4849, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.2763  (0.2585204924855914)\n",
      "     | > loader_time: 0.002  (0.008364549704960414)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:13:48 -- STEP: 53/406 -- GLOBAL_STEP: 35375\u001b[0m\n",
      "     | > loss: -0.1441248059272766  (-0.1445897038815157)\n",
      "     | > log_mle: -0.3124818801879883  (-0.31475024178343)\n",
      "     | > loss_dur: 0.16835707426071167  (0.1701605377613374)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.1666, device='cuda:0')  (tensor(17.9896, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.3113  (0.27049070934079733)\n",
      "     | > loader_time: 0.003  (0.005458004069778154)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:13:56 -- STEP: 78/406 -- GLOBAL_STEP: 35400\u001b[0m\n",
      "     | > loss: -0.13181957602500916  (-0.14227214723061296)\n",
      "     | > log_mle: -0.3155045509338379  (-0.31709053271856064)\n",
      "     | > loss_dur: 0.18368497490882874  (0.1748183853924275)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.7542, device='cuda:0')  (tensor(18.4494, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.3063  (0.283051759768755)\n",
      "     | > loader_time: 0.002  (0.004555543263753257)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:14:04 -- STEP: 103/406 -- GLOBAL_STEP: 35425\u001b[0m\n",
      "     | > loss: -0.1499287486076355  (-0.1406705765758904)\n",
      "     | > log_mle: -0.3482639789581299  (-0.31989938888734976)\n",
      "     | > loss_dur: 0.19833523035049438  (0.17922881223912385)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(37.8392, device='cuda:0')  (tensor(19.2621, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.3053  (0.2962495239035597)\n",
      "     | > loader_time: 0.004  (0.004198023416463616)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:14:13 -- STEP: 128/406 -- GLOBAL_STEP: 35450\u001b[0m\n",
      "     | > loss: -0.14016395807266235  (-0.14007763483095917)\n",
      "     | > log_mle: -0.3365582227706909  (-0.3221835102885961)\n",
      "     | > loss_dur: 0.19639426469802856  (0.1821058753994294)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.7510, device='cuda:0')  (tensor(19.6696, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.3954  (0.30838933028280724)\n",
      "     | > loader_time: 0.003  (0.003988046199083331)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:14:23 -- STEP: 153/406 -- GLOBAL_STEP: 35475\u001b[0m\n",
      "     | > loss: -0.13141250610351562  (-0.13909093762924474)\n",
      "     | > log_mle: -0.3261646032333374  (-0.3239142512963489)\n",
      "     | > loss_dur: 0.19475209712982178  (0.18482331361840762)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(42.7968, device='cuda:0')  (tensor(20.4853, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.3603  (0.31967583357119084)\n",
      "     | > loader_time: 0.003  (0.003912087359459573)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:14:33 -- STEP: 178/406 -- GLOBAL_STEP: 35500\u001b[0m\n",
      "     | > loss: -0.12370362877845764  (-0.13859048820613482)\n",
      "     | > log_mle: -0.31933867931365967  (-0.32524916295255163)\n",
      "     | > loss_dur: 0.19563505053520203  (0.18665867470455985)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.5701, device='cuda:0')  (tensor(21.6219, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.4574  (0.3326559870430591)\n",
      "     | > loader_time: 0.003  (0.0038911599791451794)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:14:44 -- STEP: 203/406 -- GLOBAL_STEP: 35525\u001b[0m\n",
      "     | > loss: -0.11198513209819794  (-0.1378456882655327)\n",
      "     | > log_mle: -0.32704174518585205  (-0.3266740955155472)\n",
      "     | > loss_dur: 0.2150566130876541  (0.18882840721331218)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.6730, device='cuda:0')  (tensor(22.2138, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.3904  (0.34396750468925874)\n",
      "     | > loader_time: 0.004  (0.00388528678217545)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:14:55 -- STEP: 228/406 -- GLOBAL_STEP: 35550\u001b[0m\n",
      "     | > loss: -0.14901308715343475  (-0.13773554177922115)\n",
      "     | > log_mle: -0.34808969497680664  (-0.32810843722862115)\n",
      "     | > loss_dur: 0.1990766078233719  (0.19037289541672206)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(49.4382, device='cuda:0')  (tensor(22.8341, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.5035  (0.35423392161988365)\n",
      "     | > loader_time: 0.004  (0.0038982807544239786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:15:07 -- STEP: 253/406 -- GLOBAL_STEP: 35575\u001b[0m\n",
      "     | > loss: -0.14437620341777802  (-0.13783339726123886)\n",
      "     | > log_mle: -0.3578530550003052  (-0.32947449627601116)\n",
      "     | > loss_dur: 0.21347685158252716  (0.19164109898532342)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.5137, device='cuda:0')  (tensor(23.6948, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.4284  (0.3659094096172467)\n",
      "     | > loader_time: 0.005  (0.003928454968297906)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:15:20 -- STEP: 278/406 -- GLOBAL_STEP: 35600\u001b[0m\n",
      "     | > loss: -0.13330531120300293  (-0.13805662540437505)\n",
      "     | > log_mle: -0.32374727725982666  (-0.33048108798994436)\n",
      "     | > loss_dur: 0.19044196605682373  (0.19242446255876874)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.7117, device='cuda:0')  (tensor(24.0647, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.5665  (0.3776775444154257)\n",
      "     | > loader_time: 0.005  (0.003992807093284115)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:15:33 -- STEP: 303/406 -- GLOBAL_STEP: 35625\u001b[0m\n",
      "     | > loss: -0.11745938658714294  (-0.13773775759703255)\n",
      "     | > log_mle: -0.337388277053833  (-0.33134521902984515)\n",
      "     | > loss_dur: 0.21992889046669006  (0.19360746140822335)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(66.1219, device='cuda:0')  (tensor(24.8621, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.4604  (0.3887094648757782)\n",
      "     | > loader_time: 0.005  (0.004059727042421649)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:15:47 -- STEP: 328/406 -- GLOBAL_STEP: 35650\u001b[0m\n",
      "     | > loss: -0.12624533474445343  (-0.13736765722676017)\n",
      "     | > log_mle: -0.34536802768707275  (-0.33193073839676074)\n",
      "     | > loss_dur: 0.21912269294261932  (0.19456308114728554)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.3796, device='cuda:0')  (tensor(25.4176, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.6096  (0.4006046790902206)\n",
      "     | > loader_time: 0.005  (0.004113404489145045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:16:01 -- STEP: 353/406 -- GLOBAL_STEP: 35675\u001b[0m\n",
      "     | > loss: -0.14318378269672394  (-0.1372020944066493)\n",
      "     | > log_mle: -0.35582590103149414  (-0.33269115345336214)\n",
      "     | > loss_dur: 0.2126421183347702  (0.19548905902560645)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.2836, device='cuda:0')  (tensor(25.6236, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.6626  (0.4122440848742259)\n",
      "     | > loader_time: 0.005  (0.0041594930816304596)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:16:16 -- STEP: 378/406 -- GLOBAL_STEP: 35700\u001b[0m\n",
      "     | > loss: -0.12294690310955048  (-0.137245421608289)\n",
      "     | > log_mle: -0.33761632442474365  (-0.3334434328886566)\n",
      "     | > loss_dur: 0.21466942131519318  (0.1961980112606571)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.1481, device='cuda:0')  (tensor(26.2296, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.6816  (0.4242715166990087)\n",
      "     | > loader_time: 0.005  (0.004233950029605282)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:16:32 -- STEP: 403/406 -- GLOBAL_STEP: 35725\u001b[0m\n",
      "     | > loss: -0.1454489380121231  (-0.13733599676979386)\n",
      "     | > log_mle: -0.3338247537612915  (-0.3340928172946863)\n",
      "     | > loss_dur: 0.1883758157491684  (0.19675682050640475)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.2708, device='cuda:0')  (tensor(26.3001, device='cuda:0'))\n",
      "     | > current_lr: 2.175e-05 \n",
      "     | > step_time: 0.7147  (0.43774507832586307)\n",
      "     | > loader_time: 0.004  (0.0042792774607466715)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.1046227514743805 \u001b[0m(+0.02204713225364685)\n",
      "     | > avg_loss:\u001b[92m -0.16519399918615818 \u001b[0m(-0.0011364705860614777)\n",
      "     | > avg_log_mle:\u001b[92m -0.35266445577144623 \u001b[0m(-0.001068711280822754)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18747045658528805 \u001b[0m(-6.775930523872375e-05)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_35728.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 88/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:17:05) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:17:27 -- STEP: 22/406 -- GLOBAL_STEP: 35750\u001b[0m\n",
      "     | > loss: -0.1341949850320816  (-0.1572772359306162)\n",
      "     | > log_mle: -0.300051212310791  (-0.3147160465067083)\n",
      "     | > loss_dur: 0.1658562272787094  (0.1574388105760921)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.2161, device='cuda:0')  (tensor(21.3240, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.2582  (0.25659670613028784)\n",
      "     | > loader_time: 0.002  (0.012693383476950905)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:17:34 -- STEP: 47/406 -- GLOBAL_STEP: 35775\u001b[0m\n",
      "     | > loss: -0.13271982967853546  (-0.14677704617064052)\n",
      "     | > log_mle: -0.3185621500015259  (-0.31329370559530056)\n",
      "     | > loss_dur: 0.18584232032299042  (0.1665166594246601)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.1847, device='cuda:0')  (tensor(18.4373, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.3013  (0.2665612241055103)\n",
      "     | > loader_time: 0.002  (0.007155575650803586)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:17:41 -- STEP: 72/406 -- GLOBAL_STEP: 35800\u001b[0m\n",
      "     | > loss: -0.14720773696899414  (-0.14247353147301414)\n",
      "     | > log_mle: -0.3139611482620239  (-0.3156586554315355)\n",
      "     | > loss_dur: 0.16675341129302979  (0.17318512395852143)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.4118, device='cuda:0')  (tensor(19.2372, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.2893  (0.27926754951477045)\n",
      "     | > loader_time: 0.003  (0.005616244342592026)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:17:50 -- STEP: 97/406 -- GLOBAL_STEP: 35825\u001b[0m\n",
      "     | > loss: -0.12397909164428711  (-0.1411799444365748)\n",
      "     | > log_mle: -0.318477988243103  (-0.3190628511389507)\n",
      "     | > loss_dur: 0.19449889659881592  (0.17788290670237591)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.9195, device='cuda:0')  (tensor(20.4584, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.3053  (0.2927297808460354)\n",
      "     | > loader_time: 0.002  (0.004891058833328718)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:17:59 -- STEP: 122/406 -- GLOBAL_STEP: 35850\u001b[0m\n",
      "     | > loss: -0.14639905095100403  (-0.14098902132178917)\n",
      "     | > log_mle: -0.31894397735595703  (-0.321756916945098)\n",
      "     | > loss_dur: 0.172544926404953  (0.18076789562330872)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.4971, device='cuda:0')  (tensor(21.2676, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.3924  (0.30531820703725343)\n",
      "     | > loader_time: 0.004  (0.004536951174501512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:18:08 -- STEP: 147/406 -- GLOBAL_STEP: 35875\u001b[0m\n",
      "     | > loss: -0.13183927536010742  (-0.14034234108973523)\n",
      "     | > log_mle: -0.3330214023590088  (-0.3239626219483461)\n",
      "     | > loss_dur: 0.20118212699890137  (0.18362028085861082)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.2140, device='cuda:0')  (tensor(21.7662, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.3413  (0.3162735935782089)\n",
      "     | > loader_time: 0.004  (0.004378125781104677)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:18:18 -- STEP: 172/406 -- GLOBAL_STEP: 35900\u001b[0m\n",
      "     | > loss: -0.13683146238327026  (-0.1396173181575398)\n",
      "     | > log_mle: -0.34002959728240967  (-0.32554181024085654)\n",
      "     | > loss_dur: 0.2031981348991394  (0.18592449208331663)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.5896, device='cuda:0')  (tensor(23.4394, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.4534  (0.3277569080508032)\n",
      "     | > loader_time: 0.004  (0.004277133664419485)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:18:29 -- STEP: 197/406 -- GLOBAL_STEP: 35925\u001b[0m\n",
      "     | > loss: -0.14507360756397247  (-0.13949277565866558)\n",
      "     | > log_mle: -0.34019172191619873  (-0.32728637838121605)\n",
      "     | > loss_dur: 0.19511811435222626  (0.1877936027225504)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(30.7250, device='cuda:0')  (tensor(24.1343, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.4634  (0.3401819630927844)\n",
      "     | > loader_time: 0.004  (0.00424242745801277)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:18:40 -- STEP: 222/406 -- GLOBAL_STEP: 35950\u001b[0m\n",
      "     | > loss: -0.14507006108760834  (-0.13952430015480202)\n",
      "     | > log_mle: -0.34442806243896484  (-0.32890029855676606)\n",
      "     | > loss_dur: 0.1993580013513565  (0.18937599840196404)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.8249, device='cuda:0')  (tensor(24.4518, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.5095  (0.35071490262005767)\n",
      "     | > loader_time: 0.004  (0.004210985458648958)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:18:52 -- STEP: 247/406 -- GLOBAL_STEP: 35975\u001b[0m\n",
      "     | > loss: -0.1307281255722046  (-0.13942111165899984)\n",
      "     | > log_mle: -0.3310120105743408  (-0.33017480518171183)\n",
      "     | > loss_dur: 0.20028388500213623  (0.190753693522712)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.3256, device='cuda:0')  (tensor(24.8239, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.5715  (0.36216696360815864)\n",
      "     | > loader_time: 0.005  (0.004206189259826413)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:19:04 -- STEP: 272/406 -- GLOBAL_STEP: 36000\u001b[0m\n",
      "     | > loss: -0.15314389765262604  (-0.13982179180225907)\n",
      "     | > log_mle: -0.35021233558654785  (-0.3313903401003165)\n",
      "     | > loss_dur: 0.19706843793392181  (0.19156854829805736)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.5533, device='cuda:0')  (tensor(25.5665, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.5405  (0.3741081392063813)\n",
      "     | > loader_time: 0.004  (0.00421699443284203)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_36000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:19:22 -- STEP: 297/406 -- GLOBAL_STEP: 36025\u001b[0m\n",
      "     | > loss: -0.1442115157842636  (-0.13988474478023213)\n",
      "     | > log_mle: -0.3419229984283447  (-0.3324369910590176)\n",
      "     | > loss_dur: 0.19771148264408112  (0.19255224627878523)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(20.1264, device='cuda:0')  (tensor(25.7982, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.4784  (0.38543754474883907)\n",
      "     | > loader_time: 0.004  (0.004236114546907468)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:19:36 -- STEP: 322/406 -- GLOBAL_STEP: 36050\u001b[0m\n",
      "     | > loss: -0.14566458761692047  (-0.13974155550417683)\n",
      "     | > log_mle: -0.3501952886581421  (-0.3333378793289944)\n",
      "     | > loss_dur: 0.20453070104122162  (0.1935963238248172)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.6657, device='cuda:0')  (tensor(26.2127, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.6035  (0.39788210540084346)\n",
      "     | > loader_time: 0.004  (0.004261584015366453)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:19:50 -- STEP: 347/406 -- GLOBAL_STEP: 36075\u001b[0m\n",
      "     | > loss: -0.14527077972888947  (-0.13958218792501711)\n",
      "     | > log_mle: -0.3565852642059326  (-0.3341023159301935)\n",
      "     | > loss_dur: 0.21131448447704315  (0.194520128005176)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(35.8095, device='cuda:0')  (tensor(26.3870, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.5365  (0.40918625053823493)\n",
      "     | > loader_time: 0.005  (0.004315104883067544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:20:04 -- STEP: 372/406 -- GLOBAL_STEP: 36100\u001b[0m\n",
      "     | > loss: -0.13507603108882904  (-0.13963936806045543)\n",
      "     | > log_mle: -0.3361475467681885  (-0.3348964882153338)\n",
      "     | > loss_dur: 0.20107151567935944  (0.195257120154878)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.7825, device='cuda:0')  (tensor(26.7258, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.6546  (0.42077378624229006)\n",
      "     | > loader_time: 0.005  (0.0043533482859211565)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:20:20 -- STEP: 397/406 -- GLOBAL_STEP: 36125\u001b[0m\n",
      "     | > loss: -0.15891912579536438  (-0.1399362368382494)\n",
      "     | > log_mle: -0.35171079635620117  (-0.3357631109223259)\n",
      "     | > loss_dur: 0.1927916705608368  (0.19582687408407615)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.5921, device='cuda:0')  (tensor(26.9295, device='cuda:0'))\n",
      "     | > current_lr: 2.2e-05 \n",
      "     | > step_time: 0.7347  (0.4341943630343419)\n",
      "     | > loader_time: 0.005  (0.004412003067939044)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08783003687858582 \u001b[0m(-0.016792714595794678)\n",
      "     | > avg_loss:\u001b[92m -0.1720072254538536 \u001b[0m(-0.006813226267695427)\n",
      "     | > avg_log_mle:\u001b[92m -0.3584034591913223 \u001b[0m(-0.005739003419876099)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18639623373746872 \u001b[0m(-0.0010742228478193283)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_36134.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 89/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:20:57) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:21:17 -- STEP: 16/406 -- GLOBAL_STEP: 36150\u001b[0m\n",
      "     | > loss: -0.15385419130325317  (-0.17176074907183647)\n",
      "     | > log_mle: -0.32359039783477783  (-0.3232506066560745)\n",
      "     | > loss_dur: 0.16973620653152466  (0.15148985758423805)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.3590, device='cuda:0')  (tensor(23.9704, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.2582  (0.25667059421539307)\n",
      "     | > loader_time: 0.002  (0.015013486146926878)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:21:24 -- STEP: 41/406 -- GLOBAL_STEP: 36175\u001b[0m\n",
      "     | > loss: -0.14634495973587036  (-0.15628719148112508)\n",
      "     | > log_mle: -0.3075026273727417  (-0.3188572685892989)\n",
      "     | > loss_dur: 0.16115766763687134  (0.16257007710817384)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(14.1835, device='cuda:0')  (tensor(19.2816, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.2642  (0.2638005396214927)\n",
      "     | > loader_time: 0.002  (0.0072259379596245)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:21:32 -- STEP: 66/406 -- GLOBAL_STEP: 36200\u001b[0m\n",
      "     | > loss: -0.12368026375770569  (-0.1495268288435358)\n",
      "     | > log_mle: -0.3212078809738159  (-0.3196361082972902)\n",
      "     | > loss_dur: 0.19752761721611023  (0.17010927945375445)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.9141, device='cuda:0')  (tensor(19.7867, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.2843  (0.2768726746241252)\n",
      "     | > loader_time: 0.002  (0.005368388060367469)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:21:40 -- STEP: 91/406 -- GLOBAL_STEP: 36225\u001b[0m\n",
      "     | > loss: -0.15349842607975006  (-0.14707211871723552)\n",
      "     | > log_mle: -0.3449380397796631  (-0.322070517382779)\n",
      "     | > loss_dur: 0.19143961369991302  (0.17499839866554337)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(43.6867, device='cuda:0')  (tensor(21.4275, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.3043  (0.2903296292483153)\n",
      "     | > loader_time: 0.003  (0.004652447752900177)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:21:49 -- STEP: 116/406 -- GLOBAL_STEP: 36250\u001b[0m\n",
      "     | > loss: -0.12302538752555847  (-0.14633226279040862)\n",
      "     | > log_mle: -0.3225986957550049  (-0.324967853981873)\n",
      "     | > loss_dur: 0.1995733082294464  (0.17863559119146438)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.5694, device='cuda:0')  (tensor(22.2140, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.3333  (0.30229182078920575)\n",
      "     | > loader_time: 0.003  (0.004314120473532841)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:21:58 -- STEP: 141/406 -- GLOBAL_STEP: 36275\u001b[0m\n",
      "     | > loss: -0.1367785781621933  (-0.1449570047094467)\n",
      "     | > log_mle: -0.33896851539611816  (-0.326990634837049)\n",
      "     | > loss_dur: 0.20218993723392487  (0.18203363012760237)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.1762, device='cuda:0')  (tensor(23.1656, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.4254  (0.3143776866561133)\n",
      "     | > loader_time: 0.003  (0.004138410514128123)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:22:08 -- STEP: 166/406 -- GLOBAL_STEP: 36300\u001b[0m\n",
      "     | > loss: -0.1621207445859909  (-0.14405160136969694)\n",
      "     | > log_mle: -0.34998929500579834  (-0.32835529295794924)\n",
      "     | > loss_dur: 0.18786855041980743  (0.1843036915882523)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(30.7548, device='cuda:0')  (tensor(23.3566, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.4414  (0.3253858347973193)\n",
      "     | > loader_time: 0.004  (0.004027678305844228)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:22:19 -- STEP: 191/406 -- GLOBAL_STEP: 36325\u001b[0m\n",
      "     | > loss: -0.14248058199882507  (-0.14376665355335352)\n",
      "     | > log_mle: -0.3423774242401123  (-0.32990976715587184)\n",
      "     | > loss_dur: 0.19989684224128723  (0.1861431136025183)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.4696, device='cuda:0')  (tensor(23.5011, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.4664  (0.33736914864385337)\n",
      "     | > loader_time: 0.004  (0.004003564724747425)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:22:30 -- STEP: 216/406 -- GLOBAL_STEP: 36350\u001b[0m\n",
      "     | > loss: -0.13834580779075623  (-0.14355684458105655)\n",
      "     | > log_mle: -0.3494683504104614  (-0.3312718879293512)\n",
      "     | > loss_dur: 0.2111225426197052  (0.1877150433482946)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.3220, device='cuda:0')  (tensor(23.8993, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.4884  (0.3487426428883166)\n",
      "     | > loader_time: 0.004  (0.003998909835462216)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:22:41 -- STEP: 241/406 -- GLOBAL_STEP: 36375\u001b[0m\n",
      "     | > loss: -0.13178271055221558  (-0.14323243498802185)\n",
      "     | > log_mle: -0.3336125612258911  (-0.33257800958957906)\n",
      "     | > loss_dur: 0.20182985067367554  (0.18934557460155715)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(28.8951, device='cuda:0')  (tensor(25.3126, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.4094  (0.3590730354499027)\n",
      "     | > loader_time: 0.004  (0.003999344046185125)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:22:54 -- STEP: 266/406 -- GLOBAL_STEP: 36400\u001b[0m\n",
      "     | > loss: -0.14268405735492706  (-0.1432347353127666)\n",
      "     | > log_mle: -0.3409222364425659  (-0.33362092918023123)\n",
      "     | > loss_dur: 0.19823817908763885  (0.19038619386746464)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(47.4877, device='cuda:0')  (tensor(25.3164, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.5445  (0.371886652215083)\n",
      "     | > loader_time: 0.005  (0.0040260445802731614)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:23:06 -- STEP: 291/406 -- GLOBAL_STEP: 36425\u001b[0m\n",
      "     | > loss: -0.13536296784877777  (-0.14331318663362785)\n",
      "     | > log_mle: -0.3328278064727783  (-0.33458173111132306)\n",
      "     | > loss_dur: 0.19746483862400055  (0.19126854447769537)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.3565, device='cuda:0')  (tensor(26.2240, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.4774  (0.38231977072778034)\n",
      "     | > loader_time: 0.005  (0.004075669750724871)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:23:20 -- STEP: 316/406 -- GLOBAL_STEP: 36450\u001b[0m\n",
      "     | > loss: -0.137422576546669  (-0.1431840249820601)\n",
      "     | > log_mle: -0.34409594535827637  (-0.33558801269229416)\n",
      "     | > loss_dur: 0.20667336881160736  (0.19240398771023443)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(36.0310, device='cuda:0')  (tensor(26.2767, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.6206  (0.39479846214946307)\n",
      "     | > loader_time: 0.006  (0.004120628290538547)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:23:34 -- STEP: 341/406 -- GLOBAL_STEP: 36475\u001b[0m\n",
      "     | > loss: -0.15095491707324982  (-0.14276842410263776)\n",
      "     | > log_mle: -0.3657665252685547  (-0.33608694894572466)\n",
      "     | > loss_dur: 0.21481160819530487  (0.1933185248430872)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(55.9330, device='cuda:0')  (tensor(27.0052, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.5365  (0.40603154006242054)\n",
      "     | > loader_time: 0.005  (0.004167806368069913)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:23:48 -- STEP: 366/406 -- GLOBAL_STEP: 36500\u001b[0m\n",
      "     | > loss: -0.15041352808475494  (-0.14276477828866155)\n",
      "     | > log_mle: -0.35821425914764404  (-0.33696765945257345)\n",
      "     | > loss_dur: 0.2078007310628891  (0.19420288116391232)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(52.9492, device='cuda:0')  (tensor(27.4199, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.5545  (0.4173982351855502)\n",
      "     | > loader_time: 0.005  (0.004227682540976933)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:24:04 -- STEP: 391/406 -- GLOBAL_STEP: 36525\u001b[0m\n",
      "     | > loss: -0.15968066453933716  (-0.14280163559614856)\n",
      "     | > log_mle: -0.35896384716033936  (-0.33769230434046943)\n",
      "     | > loss_dur: 0.1992831826210022  (0.1948906687443213)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.6360, device='cuda:0')  (tensor(27.5515, device='cuda:0'))\n",
      "     | > current_lr: 2.2250000000000002e-05 \n",
      "     | > step_time: 0.8067  (0.4311921450183215)\n",
      "     | > loader_time: 0.006  (0.004290131961598113)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.086809903383255 \u001b[0m(-0.0010201334953308105)\n",
      "     | > avg_loss:\u001b[92m -0.17278065904974937 \u001b[0m(-0.0007734335958957672)\n",
      "     | > avg_log_mle:\u001b[92m -0.35904473066329956 \u001b[0m(-0.0006412714719772339)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1862640716135502 \u001b[0m(-0.00013216212391853333)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_36540.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 90/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:24:46) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:25:05 -- STEP: 10/406 -- GLOBAL_STEP: 36550\u001b[0m\n",
      "     | > loss: -0.19391438364982605  (-0.1772139623761177)\n",
      "     | > log_mle: -0.32204127311706543  (-0.32238867282867434)\n",
      "     | > loss_dur: 0.12812688946723938  (0.14517471045255662)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(19.2897, device='cuda:0')  (tensor(18.6927, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.2532  (0.2597360610961914)\n",
      "     | > loader_time: 0.002  (0.03262937068939209)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:25:12 -- STEP: 35/406 -- GLOBAL_STEP: 36575\u001b[0m\n",
      "     | > loss: -0.1588226556777954  (-0.15875803317342485)\n",
      "     | > log_mle: -0.33568334579467773  (-0.3198237214769636)\n",
      "     | > loss_dur: 0.17686069011688232  (0.16106568830353873)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.5767, device='cuda:0')  (tensor(24.2514, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.2632  (0.26458314486912315)\n",
      "     | > loader_time: 0.002  (0.010781083788190567)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:25:19 -- STEP: 60/406 -- GLOBAL_STEP: 36600\u001b[0m\n",
      "     | > loss: -0.1481415033340454  (-0.15095427234967557)\n",
      "     | > log_mle: -0.3195117712020874  (-0.31983912388483676)\n",
      "     | > loss_dur: 0.171370267868042  (0.16888485153516133)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(29.6362, device='cuda:0')  (tensor(22.5505, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.2783  (0.2794204076131185)\n",
      "     | > loader_time: 0.003  (0.007289854685465496)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:25:27 -- STEP: 85/406 -- GLOBAL_STEP: 36625\u001b[0m\n",
      "     | > loss: -0.14649716019630432  (-0.14840290090617017)\n",
      "     | > log_mle: -0.34485065937042236  (-0.3227979141123154)\n",
      "     | > loss_dur: 0.19835349917411804  (0.1743950132061454)\n",
      "     | > amp_scaler: 16384.0  (9444.89411764706)\n",
      "     | > grad_norm: tensor(30.7180, device='cuda:0')  (tensor(23.0961, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.3053  (0.2923478519215304)\n",
      "     | > loader_time: 0.003  (0.00599357100094066)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:25:36 -- STEP: 110/406 -- GLOBAL_STEP: 36650\u001b[0m\n",
      "     | > loss: -0.15189918875694275  (-0.14796970500187448)\n",
      "     | > log_mle: -0.35320746898651123  (-0.325881721756675)\n",
      "     | > loss_dur: 0.20130828022956848  (0.1779120167548007)\n",
      "     | > amp_scaler: 16384.0  (11021.963636363633)\n",
      "     | > grad_norm: tensor(26.4295, device='cuda:0')  (tensor(23.3139, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.3413  (0.30625988136638316)\n",
      "     | > loader_time: 0.003  (0.005341135371815076)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:25:45 -- STEP: 135/406 -- GLOBAL_STEP: 36675\u001b[0m\n",
      "     | > loss: -0.129278764128685  (-0.1460559416700293)\n",
      "     | > log_mle: -0.3436298370361328  (-0.32743599591431793)\n",
      "     | > loss_dur: 0.21435107290744781  (0.18138005424428874)\n",
      "     | > amp_scaler: 4096.0  (10406.87407407407)\n",
      "     | > grad_norm: tensor(25.6353, device='cuda:0')  (tensor(25.6660, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.3393  (0.31652436256408706)\n",
      "     | > loader_time: 0.003  (0.0049526567812319166)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:25:55 -- STEP: 160/406 -- GLOBAL_STEP: 36700\u001b[0m\n",
      "     | > loss: -0.13308118283748627  (-0.14466752400621777)\n",
      "     | > log_mle: -0.34303581714630127  (-0.328781520575285)\n",
      "     | > loss_dur: 0.209954634308815  (0.1841139965690672)\n",
      "     | > amp_scaler: 4096.0  (9420.799999999992)\n",
      "     | > grad_norm: tensor(24.5842, device='cuda:0')  (tensor(25.7710, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.4334  (0.32869836539030073)\n",
      "     | > loader_time: 0.003  (0.004735535383224488)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:26:06 -- STEP: 185/406 -- GLOBAL_STEP: 36725\u001b[0m\n",
      "     | > loss: -0.13969853520393372  (-0.14452892437174522)\n",
      "     | > log_mle: -0.3446228504180908  (-0.33049683635299276)\n",
      "     | > loss_dur: 0.2049243152141571  (0.18596791198124757)\n",
      "     | > amp_scaler: 4096.0  (8701.232432432425)\n",
      "     | > grad_norm: tensor(24.3157, device='cuda:0')  (tensor(25.6326, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.4004  (0.34095814807994956)\n",
      "     | > loader_time: 0.003  (0.004598761893607473)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:26:17 -- STEP: 210/406 -- GLOBAL_STEP: 36750\u001b[0m\n",
      "     | > loss: -0.15401959419250488  (-0.14414569104001634)\n",
      "     | > log_mle: -0.3420102596282959  (-0.3318207076617651)\n",
      "     | > loss_dur: 0.18799066543579102  (0.1876750166217486)\n",
      "     | > amp_scaler: 4096.0  (8152.99047619047)\n",
      "     | > grad_norm: tensor(21.5652, device='cuda:0')  (tensor(26.3700, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.4034  (0.3524961868921917)\n",
      "     | > loader_time: 0.004  (0.0045374359403337755)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:26:29 -- STEP: 235/406 -- GLOBAL_STEP: 36775\u001b[0m\n",
      "     | > loss: -0.144000843167305  (-0.14413277722419576)\n",
      "     | > log_mle: -0.34512293338775635  (-0.3334089182792827)\n",
      "     | > loss_dur: 0.20112209022045135  (0.18927614105508683)\n",
      "     | > amp_scaler: 4096.0  (7721.395744680845)\n",
      "     | > grad_norm: tensor(24.0811, device='cuda:0')  (tensor(26.5644, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.4144  (0.3628996311350073)\n",
      "     | > loader_time: 0.004  (0.004510507177799307)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:26:41 -- STEP: 260/406 -- GLOBAL_STEP: 36800\u001b[0m\n",
      "     | > loss: -0.15466231107711792  (-0.14438407604510967)\n",
      "     | > log_mle: -0.3491325378417969  (-0.3347180792918573)\n",
      "     | > loss_dur: 0.19447022676467896  (0.19033400324674754)\n",
      "     | > amp_scaler: 4096.0  (7372.799999999995)\n",
      "     | > grad_norm: tensor(53.8112, device='cuda:0')  (tensor(26.9085, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.5395  (0.37609910323069656)\n",
      "     | > loader_time: 0.004  (0.004504118515894964)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:26:54 -- STEP: 285/406 -- GLOBAL_STEP: 36825\u001b[0m\n",
      "     | > loss: -0.14203447103500366  (-0.14426467951975366)\n",
      "     | > log_mle: -0.33782362937927246  (-0.3355531349516752)\n",
      "     | > loss_dur: 0.1957891583442688  (0.19128845543192144)\n",
      "     | > amp_scaler: 4096.0  (7085.361403508766)\n",
      "     | > grad_norm: tensor(18.3956, device='cuda:0')  (tensor(27.6440, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.4614  (0.386944229560986)\n",
      "     | > loader_time: 0.005  (0.004502362535710921)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:27:08 -- STEP: 310/406 -- GLOBAL_STEP: 36850\u001b[0m\n",
      "     | > loss: -0.14864109456539154  (-0.14420070686647965)\n",
      "     | > log_mle: -0.33802688121795654  (-0.3364591740792798)\n",
      "     | > loss_dur: 0.189385786652565  (0.19225846721280007)\n",
      "     | > amp_scaler: 4096.0  (6844.283870967736)\n",
      "     | > grad_norm: tensor(28.4608, device='cuda:0')  (tensor(27.2098, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.6236  (0.3993625210177515)\n",
      "     | > loader_time: 0.005  (0.0045105703415409225)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:27:21 -- STEP: 335/406 -- GLOBAL_STEP: 36875\u001b[0m\n",
      "     | > loss: -0.11421991884708405  (-0.143737928902925)\n",
      "     | > log_mle: -0.34039151668548584  (-0.33697908885443395)\n",
      "     | > loss_dur: 0.2261715978384018  (0.19324115995150892)\n",
      "     | > amp_scaler: 4096.0  (6639.188059701487)\n",
      "     | > grad_norm: tensor(26.1992, device='cuda:0')  (tensor(28.4203, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.4874  (0.410253015916739)\n",
      "     | > loader_time: 0.005  (0.004526520487087876)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:27:36 -- STEP: 360/406 -- GLOBAL_STEP: 36900\u001b[0m\n",
      "     | > loss: -0.15074503421783447  (-0.1435201112180948)\n",
      "     | > log_mle: -0.34718000888824463  (-0.33768085903591594)\n",
      "     | > loss_dur: 0.19643497467041016  (0.19416074781782097)\n",
      "     | > amp_scaler: 4096.0  (6462.577777777773)\n",
      "     | > grad_norm: tensor(60.6167, device='cuda:0')  (tensor(28.7663, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.5315  (0.42200252612431854)\n",
      "     | > loader_time: 0.005  (0.0045624997880723776)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:27:52 -- STEP: 385/406 -- GLOBAL_STEP: 36925\u001b[0m\n",
      "     | > loss: -0.1288667470216751  (-0.14353120973357902)\n",
      "     | > log_mle: -0.3465965986251831  (-0.3384628079154275)\n",
      "     | > loss_dur: 0.217729851603508  (0.1949315981818484)\n",
      "     | > amp_scaler: 4096.0  (6308.903896103891)\n",
      "     | > grad_norm: tensor(26.0308, device='cuda:0')  (tensor(28.8078, device='cuda:0'))\n",
      "     | > current_lr: 2.25e-05 \n",
      "     | > step_time: 0.7156  (0.43492727837005224)\n",
      "     | > loader_time: 0.005  (0.004606803051837083)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09546223282814026 \u001b[0m(+0.008652329444885254)\n",
      "     | > avg_loss:\u001b[91m -0.1724839899688959 \u001b[0m(+0.0002966690808534622)\n",
      "     | > avg_log_mle:\u001b[92m -0.3591248691082001 \u001b[0m(-8.01384449005127e-05)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18664087913930416 \u001b[0m(+0.0003768075257539749)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 91/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:28:37) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:28:54 -- STEP: 4/406 -- GLOBAL_STEP: 36950\u001b[0m\n",
      "     | > loss: -0.17178533971309662  (-0.19320793822407722)\n",
      "     | > log_mle: -0.3092077970504761  (-0.32812830805778503)\n",
      "     | > loss_dur: 0.13742245733737946  (0.13492036797106266)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.8246, device='cuda:0')  (tensor(24.8865, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.2652  (0.27324771881103516)\n",
      "     | > loader_time: 0.002  (0.07231587171554565)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:29:01 -- STEP: 29/406 -- GLOBAL_STEP: 36975\u001b[0m\n",
      "     | > loss: -0.17517182230949402  (-0.16771144599750124)\n",
      "     | > log_mle: -0.329024076461792  (-0.32473851072377174)\n",
      "     | > loss_dur: 0.15385225415229797  (0.1570270644693539)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(8.0136, device='cuda:0')  (tensor(21.5379, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.2783  (0.26472302140860726)\n",
      "     | > loader_time: 0.002  (0.011562330969448748)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:29:08 -- STEP: 54/406 -- GLOBAL_STEP: 37000\u001b[0m\n",
      "     | > loss: -0.1378263533115387  (-0.15780028507665353)\n",
      "     | > log_mle: -0.32547223567962646  (-0.3236600999478941)\n",
      "     | > loss_dur: 0.18764588236808777  (0.16585981473326677)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.0011, device='cuda:0')  (tensor(20.1560, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.2823  (0.2761395419085467)\n",
      "     | > loader_time: 0.002  (0.007265916577091928)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_37000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:29:19 -- STEP: 79/406 -- GLOBAL_STEP: 37025\u001b[0m\n",
      "     | > loss: -0.1355413943529129  (-0.15366404852535154)\n",
      "     | > log_mle: -0.33344507217407227  (-0.32494842402542695)\n",
      "     | > loss_dur: 0.19790367782115936  (0.17128437540576424)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.4461, device='cuda:0')  (tensor(23.1887, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.3743  (0.2932662390455415)\n",
      "     | > loader_time: 0.002  (0.005802776240095311)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:29:28 -- STEP: 104/406 -- GLOBAL_STEP: 37050\u001b[0m\n",
      "     | > loss: -0.14104275405406952  (-0.15163525981971848)\n",
      "     | > log_mle: -0.3291569948196411  (-0.32748499627296745)\n",
      "     | > loss_dur: 0.1881142407655716  (0.17584973638160864)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.6231, device='cuda:0')  (tensor(23.8565, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.4054  (0.30723080726770263)\n",
      "     | > loader_time: 0.003  (0.005139344013654271)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:29:37 -- STEP: 129/406 -- GLOBAL_STEP: 37075\u001b[0m\n",
      "     | > loss: -0.12687775492668152  (-0.15030287656673164)\n",
      "     | > log_mle: -0.3284868001937866  (-0.3295413209486378)\n",
      "     | > loss_dur: 0.2016090452671051  (0.1792384443241496)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.4110, device='cuda:0')  (tensor(24.1953, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.4124  (0.31890963399133027)\n",
      "     | > loader_time: 0.003  (0.0047640523245168305)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:29:47 -- STEP: 154/406 -- GLOBAL_STEP: 37100\u001b[0m\n",
      "     | > loss: -0.15050499141216278  (-0.149358234525501)\n",
      "     | > log_mle: -0.33081912994384766  (-0.3312031874408971)\n",
      "     | > loss_dur: 0.18031413853168488  (0.1818449528670156)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.5730, device='cuda:0')  (tensor(24.5333, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.4394  (0.32973439662487497)\n",
      "     | > loader_time: 0.003  (0.004562624089129561)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:29:58 -- STEP: 179/406 -- GLOBAL_STEP: 37125\u001b[0m\n",
      "     | > loss: -0.1493440717458725  (-0.14865447131282128)\n",
      "     | > log_mle: -0.3490755558013916  (-0.33244914249334945)\n",
      "     | > loss_dur: 0.1997314840555191  (0.18379467113890455)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.0226, device='cuda:0')  (tensor(25.1001, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.3823  (0.3407953824410893)\n",
      "     | > loader_time: 0.003  (0.0044621795249384895)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:30:09 -- STEP: 204/406 -- GLOBAL_STEP: 37150\u001b[0m\n",
      "     | > loss: -0.15091224014759064  (-0.14767064358673848)\n",
      "     | > log_mle: -0.34135568141937256  (-0.33363574158911624)\n",
      "     | > loss_dur: 0.19044344127178192  (0.18596509796585514)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.9903, device='cuda:0')  (tensor(26.8031, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.4034  (0.3525357094465519)\n",
      "     | > loader_time: 0.004  (0.0044059753417968785)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:30:20 -- STEP: 229/406 -- GLOBAL_STEP: 37175\u001b[0m\n",
      "     | > loss: -0.14979274570941925  (-0.14759671896305673)\n",
      "     | > log_mle: -0.3391035795211792  (-0.3351173468552303)\n",
      "     | > loss_dur: 0.18931083381175995  (0.1875206278596382)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(12.0842, device='cuda:0')  (tensor(26.4067, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.4174  (0.3629320740179205)\n",
      "     | > loader_time: 0.004  (0.004370800792910649)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:30:32 -- STEP: 254/406 -- GLOBAL_STEP: 37200\u001b[0m\n",
      "     | > loss: -0.14175951480865479  (-0.14753407263380341)\n",
      "     | > log_mle: -0.3340970277786255  (-0.3364281476013305)\n",
      "     | > loss_dur: 0.1923375129699707  (0.18889407493819396)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(52.3466, device='cuda:0')  (tensor(27.0170, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.5415  (0.3752895049222812)\n",
      "     | > loader_time: 0.004  (0.004385881536588896)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:30:45 -- STEP: 279/406 -- GLOBAL_STEP: 37225\u001b[0m\n",
      "     | > loss: -0.1220981627702713  (-0.1475329878189231)\n",
      "     | > log_mle: -0.33685004711151123  (-0.33731764063612973)\n",
      "     | > loss_dur: 0.21475188434123993  (0.18978465279050188)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.1915, device='cuda:0')  (tensor(28.3275, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.4484  (0.38686373071431274)\n",
      "     | > loader_time: 0.005  (0.004398273310780955)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:30:58 -- STEP: 304/406 -- GLOBAL_STEP: 37250\u001b[0m\n",
      "     | > loss: -0.14472609758377075  (-0.14750104309304768)\n",
      "     | > log_mle: -0.35387659072875977  (-0.3383870489503209)\n",
      "     | > loss_dur: 0.209150493144989  (0.19088600583276455)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.4150, device='cuda:0')  (tensor(28.3483, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.6136  (0.398381371247141)\n",
      "     | > loader_time: 0.005  (0.004415214846008703)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:31:13 -- STEP: 329/406 -- GLOBAL_STEP: 37275\u001b[0m\n",
      "     | > loss: -0.14782850444316864  (-0.1471172630968066)\n",
      "     | > log_mle: -0.33944177627563477  (-0.338919724736895)\n",
      "     | > loss_dur: 0.19161327183246613  (0.1918024616174421)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.2071, device='cuda:0')  (tensor(28.9729, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.7807  (0.41256208332838623)\n",
      "     | > loader_time: 0.005  (0.00449041465133157)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:31:28 -- STEP: 354/406 -- GLOBAL_STEP: 37300\u001b[0m\n",
      "     | > loss: -0.1419125646352768  (-0.1468628822578549)\n",
      "     | > log_mle: -0.34642958641052246  (-0.33964887210878303)\n",
      "     | > loss_dur: 0.20451702177524567  (0.19278598982988088)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.4831, device='cuda:0')  (tensor(28.9826, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.5385  (0.42535825637774277)\n",
      "     | > loader_time: 0.006  (0.004538017477692856)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:31:44 -- STEP: 379/406 -- GLOBAL_STEP: 37325\u001b[0m\n",
      "     | > loss: -0.16068673133850098  (-0.1470152620904364)\n",
      "     | > log_mle: -0.3552539348602295  (-0.3404790342325903)\n",
      "     | > loss_dur: 0.19456720352172852  (0.19346377212249494)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(42.5498, device='cuda:0')  (tensor(29.1874, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.6045  (0.4387258445367335)\n",
      "     | > loader_time: 0.005  (0.0045899061540185925)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:32:01 -- STEP: 404/406 -- GLOBAL_STEP: 37350\u001b[0m\n",
      "     | > loss: -0.1399156153202057  (-0.1469105254895616)\n",
      "     | > log_mle: -0.34731268882751465  (-0.3410301125875797)\n",
      "     | > loss_dur: 0.20739707350730896  (0.1941195870795756)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.5265, device='cuda:0')  (tensor(29.2527, device='cuda:0'))\n",
      "     | > current_lr: 2.275e-05 \n",
      "     | > step_time: 0.5698  (0.4528247637323814)\n",
      "     | > loader_time: 0.005  (0.004642808201289415)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09758901596069336 \u001b[0m(+0.0021267831325531006)\n",
      "     | > avg_loss:\u001b[91m -0.16664788126945496 \u001b[0m(+0.005836108699440956)\n",
      "     | > avg_log_mle:\u001b[91m -0.35499829053878784 \u001b[0m(+0.0041265785694122314)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18835040926933289 \u001b[0m(+0.0017095301300287247)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 92/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:32:34) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:32:58 -- STEP: 23/406 -- GLOBAL_STEP: 37375\u001b[0m\n",
      "     | > loss: -0.15726129710674286  (-0.17048594226007874)\n",
      "     | > log_mle: -0.319942831993103  (-0.3239338760790618)\n",
      "     | > loss_dur: 0.16268153488636017  (0.1534479341429213)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.6062, device='cuda:0')  (tensor(18.5706, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.2913  (0.27564153463944147)\n",
      "     | > loader_time: 0.003  (0.014970074529233183)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:33:05 -- STEP: 48/406 -- GLOBAL_STEP: 37400\u001b[0m\n",
      "     | > loss: -0.14407925307750702  (-0.16044862413158018)\n",
      "     | > log_mle: -0.32295894622802734  (-0.32272965709368395)\n",
      "     | > loss_dur: 0.17887969315052032  (0.16228103311732414)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.4813, device='cuda:0')  (tensor(19.8527, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.3233  (0.2873957554499309)\n",
      "     | > loader_time: 0.003  (0.008502850929896036)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:33:14 -- STEP: 73/406 -- GLOBAL_STEP: 37425\u001b[0m\n",
      "     | > loss: -0.15886914730072021  (-0.15544059341900968)\n",
      "     | > log_mle: -0.3471890687942505  (-0.3249613650857586)\n",
      "     | > loss_dur: 0.18831992149353027  (0.1695207717688116)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(14.3656, device='cuda:0')  (tensor(20.1201, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.3593  (0.30171930626647114)\n",
      "     | > loader_time: 0.003  (0.006660369977559129)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:33:23 -- STEP: 98/406 -- GLOBAL_STEP: 37450\u001b[0m\n",
      "     | > loss: -0.1317022740840912  (-0.15345479532772177)\n",
      "     | > log_mle: -0.32544147968292236  (-0.3278010171286913)\n",
      "     | > loss_dur: 0.19373920559883118  (0.17434622187699592)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.9006, device='cuda:0')  (tensor(20.4078, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.4004  (0.3164576681292788)\n",
      "     | > loader_time: 0.003  (0.005798768024055326)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:33:32 -- STEP: 123/406 -- GLOBAL_STEP: 37475\u001b[0m\n",
      "     | > loss: -0.13712675869464874  (-0.15299028364138875)\n",
      "     | > log_mle: -0.34575748443603516  (-0.33061518901731907)\n",
      "     | > loss_dur: 0.2086307257413864  (0.17762490543650417)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.9440, device='cuda:0')  (tensor(20.6405, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.3398  (0.32766405159864975)\n",
      "     | > loader_time: 0.005  (0.005336234240027947)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:33:42 -- STEP: 148/406 -- GLOBAL_STEP: 37500\u001b[0m\n",
      "     | > loss: -0.15227778255939484  (-0.15190229705862096)\n",
      "     | > log_mle: -0.35213136672973633  (-0.33240197558660767)\n",
      "     | > loss_dur: 0.1998535841703415  (0.18049967857832844)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.6332, device='cuda:0')  (tensor(22.0847, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.3703  (0.339686711092253)\n",
      "     | > loader_time: 0.004  (0.005098333229889741)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:33:53 -- STEP: 173/406 -- GLOBAL_STEP: 37525\u001b[0m\n",
      "     | > loss: -0.13655704259872437  (-0.15103811594103114)\n",
      "     | > log_mle: -0.33660101890563965  (-0.3337757621886412)\n",
      "     | > loss_dur: 0.20004397630691528  (0.18273764629067715)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(28.5685, device='cuda:0')  (tensor(22.1415, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.3783  (0.3513820626143086)\n",
      "     | > loader_time: 0.004  (0.004928554413635607)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:34:04 -- STEP: 198/406 -- GLOBAL_STEP: 37550\u001b[0m\n",
      "     | > loss: -0.15108628571033478  (-0.1501587773814346)\n",
      "     | > log_mle: -0.3449946641921997  (-0.3348328681907267)\n",
      "     | > loss_dur: 0.19390837848186493  (0.18467409084692146)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.7036, device='cuda:0')  (tensor(23.4268, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.4094  (0.3632859256532457)\n",
      "     | > loader_time: 0.004  (0.0048269093638718735)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:34:16 -- STEP: 223/406 -- GLOBAL_STEP: 37575\u001b[0m\n",
      "     | > loss: -0.15587620437145233  (-0.14963100857264258)\n",
      "     | > log_mle: -0.3407210111618042  (-0.33604431205800817)\n",
      "     | > loss_dur: 0.18484480679035187  (0.1864133035187764)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.3071, device='cuda:0')  (tensor(23.4598, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.4134  (0.37453234142252145)\n",
      "     | > loader_time: 0.004  (0.0047525600467562155)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:34:28 -- STEP: 248/406 -- GLOBAL_STEP: 37600\u001b[0m\n",
      "     | > loss: -0.15651267766952515  (-0.14948380768539443)\n",
      "     | > log_mle: -0.3454064130783081  (-0.3373661935329436)\n",
      "     | > loss_dur: 0.18889373540878296  (0.18788238587759196)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.5264, device='cuda:0')  (tensor(23.8020, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.5465  (0.3864553359247023)\n",
      "     | > loader_time: 0.004  (0.004713394949513098)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:34:41 -- STEP: 273/406 -- GLOBAL_STEP: 37625\u001b[0m\n",
      "     | > loss: -0.15181545913219452  (-0.14957647625998263)\n",
      "     | > log_mle: -0.358517050743103  (-0.33852619129222816)\n",
      "     | > loss_dur: 0.2067015916109085  (0.18894971505953714)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.9622, device='cuda:0')  (tensor(24.3064, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.4434  (0.39720276598528625)\n",
      "     | > loader_time: 0.004  (0.004692388541532524)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:34:54 -- STEP: 298/406 -- GLOBAL_STEP: 37650\u001b[0m\n",
      "     | > loss: -0.14876365661621094  (-0.14939468904029599)\n",
      "     | > log_mle: -0.33493947982788086  (-0.33930091529884593)\n",
      "     | > loss_dur: 0.18617582321166992  (0.18990622628355186)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.5245, device='cuda:0')  (tensor(24.5337, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.6516  (0.407775941311113)\n",
      "     | > loader_time: 0.005  (0.004705138654516847)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:35:09 -- STEP: 323/406 -- GLOBAL_STEP: 37675\u001b[0m\n",
      "     | > loss: -0.16212008893489838  (-0.14939401628616797)\n",
      "     | > log_mle: -0.3567308187484741  (-0.3402034937412747)\n",
      "     | > loss_dur: 0.19461072981357574  (0.19080947747817348)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.2493, device='cuda:0')  (tensor(25.0489, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.5055  (0.41994663657787784)\n",
      "     | > loader_time: 0.006  (0.0047190167217431795)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:35:24 -- STEP: 348/406 -- GLOBAL_STEP: 37700\u001b[0m\n",
      "     | > loss: -0.14549283683300018  (-0.1492004911361755)\n",
      "     | > log_mle: -0.3445429801940918  (-0.3409894584924325)\n",
      "     | > loss_dur: 0.1990501433610916  (0.19178896737766676)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.2715, device='cuda:0')  (tensor(25.4797, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.7006  (0.43233309874589415)\n",
      "     | > loader_time: 0.0055  (0.004752571555389757)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:35:39 -- STEP: 373/406 -- GLOBAL_STEP: 37725\u001b[0m\n",
      "     | > loss: -0.14955805242061615  (-0.14930307669390305)\n",
      "     | > log_mle: -0.3494812250137329  (-0.3418658175992582)\n",
      "     | > loss_dur: 0.19992317259311676  (0.19256274092532993)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(43.7579, device='cuda:0')  (tensor(25.7250, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.5905  (0.44506566006760173)\n",
      "     | > loader_time: 0.005  (0.0047989722551033944)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:35:57 -- STEP: 398/406 -- GLOBAL_STEP: 37750\u001b[0m\n",
      "     | > loss: -0.15216001868247986  (-0.14936691062084992)\n",
      "     | > log_mle: -0.358894944190979  (-0.34257252731514937)\n",
      "     | > loss_dur: 0.20673492550849915  (0.19320561671301947)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.0765, device='cuda:0')  (tensor(26.1961, device='cuda:0'))\n",
      "     | > current_lr: 2.3e-05 \n",
      "     | > step_time: 0.7957  (0.45985006986550947)\n",
      "     | > loader_time: 0.005  (0.004854632981458506)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.10722249746322632 \u001b[0m(+0.009633481502532959)\n",
      "     | > avg_loss:\u001b[92m -0.17922489903867245 \u001b[0m(-0.012577017769217491)\n",
      "     | > avg_log_mle:\u001b[92m -0.363592192530632 \u001b[0m(-0.008593901991844177)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18436729349195957 \u001b[0m(-0.003983115777373314)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_37758.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 93/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:36:36) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:36:58 -- STEP: 17/406 -- GLOBAL_STEP: 37775\u001b[0m\n",
      "     | > loss: -0.17758844792842865  (-0.17981327368932612)\n",
      "     | > log_mle: -0.3223857879638672  (-0.32893946591545553)\n",
      "     | > loss_dur: 0.14479734003543854  (0.14912619178785996)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.5504, device='cuda:0')  (tensor(18.1051, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.3273  (0.29023054066826315)\n",
      "     | > loader_time: 0.002  (0.025317093905280617)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:37:06 -- STEP: 42/406 -- GLOBAL_STEP: 37800\u001b[0m\n",
      "     | > loss: -0.1551610231399536  (-0.16495140216180254)\n",
      "     | > log_mle: -0.3292214870452881  (-0.32471552065440584)\n",
      "     | > loss_dur: 0.17406046390533447  (0.15976411831520854)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.3243, device='cuda:0')  (tensor(17.4630, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.3313  (0.2980445169267202)\n",
      "     | > loader_time: 0.002  (0.011844090053013396)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:37:14 -- STEP: 67/406 -- GLOBAL_STEP: 37825\u001b[0m\n",
      "     | > loss: -0.1467248499393463  (-0.15759326584303554)\n",
      "     | > log_mle: -0.339835524559021  (-0.32553176025846103)\n",
      "     | > loss_dur: 0.19311067461967468  (0.16793849430422284)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.7209, device='cuda:0')  (tensor(19.7298, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.3613  (0.3113450185576483)\n",
      "     | > loader_time: 0.003  (0.008515180046878646)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:37:24 -- STEP: 92/406 -- GLOBAL_STEP: 37850\u001b[0m\n",
      "     | > loss: -0.15136173367500305  (-0.1551378079406592)\n",
      "     | > log_mle: -0.35053551197052  (-0.32834718538367214)\n",
      "     | > loss_dur: 0.19917377829551697  (0.1732093773620284)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.9022, device='cuda:0')  (tensor(21.3715, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.3743  (0.3241764903068543)\n",
      "     | > loader_time: 0.003  (0.007091263066167418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:37:33 -- STEP: 117/406 -- GLOBAL_STEP: 37875\u001b[0m\n",
      "     | > loss: -0.1444605141878128  (-0.15449176410324547)\n",
      "     | > log_mle: -0.3433319330215454  (-0.3310977607710747)\n",
      "     | > loss_dur: 0.1988714188337326  (0.17660599660414916)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.1919, device='cuda:0')  (tensor(21.7743, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.4154  (0.33643079415345806)\n",
      "     | > loader_time: 0.003  (0.006397288069765793)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:37:43 -- STEP: 142/406 -- GLOBAL_STEP: 37900\u001b[0m\n",
      "     | > loss: -0.16502757370471954  (-0.15310985343137254)\n",
      "     | > log_mle: -0.3511533737182617  (-0.3333817451772554)\n",
      "     | > loss_dur: 0.18612580001354218  (0.18027189169341404)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.1969, device='cuda:0')  (tensor(22.5380, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.3433  (0.3462331026372776)\n",
      "     | > loader_time: 0.005  (0.005954645049404091)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:37:54 -- STEP: 167/406 -- GLOBAL_STEP: 37925\u001b[0m\n",
      "     | > loss: -0.15460921823978424  (-0.15193820240611802)\n",
      "     | > log_mle: -0.3461860418319702  (-0.3347463507852153)\n",
      "     | > loss_dur: 0.19157682359218597  (0.18280814833448308)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.7538, device='cuda:0')  (tensor(23.2476, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.3703  (0.35581533352058103)\n",
      "     | > loader_time: 0.004  (0.0056505774309535215)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:38:05 -- STEP: 192/406 -- GLOBAL_STEP: 37950\u001b[0m\n",
      "     | > loss: -0.15369682013988495  (-0.1517079463228584)\n",
      "     | > log_mle: -0.347947359085083  (-0.33630553446710093)\n",
      "     | > loss_dur: 0.19425053894519806  (0.18459758810543758)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.5378, device='cuda:0')  (tensor(23.7452, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.3984  (0.366144069780906)\n",
      "     | > loader_time: 0.004  (0.005430897076924641)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:38:16 -- STEP: 217/406 -- GLOBAL_STEP: 37975\u001b[0m\n",
      "     | > loss: -0.14467869699001312  (-0.15160371102221015)\n",
      "     | > log_mle: -0.3502340316772461  (-0.3376551674258323)\n",
      "     | > loss_dur: 0.20555533468723297  (0.18605145636928788)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.5786, device='cuda:0')  (tensor(24.1789, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.4504  (0.37661272589512135)\n",
      "     | > loader_time: 0.005  (0.005303363096878825)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:38:29 -- STEP: 242/406 -- GLOBAL_STEP: 38000\u001b[0m\n",
      "     | > loss: -0.16300712525844574  (-0.1512814720184351)\n",
      "     | > log_mle: -0.3637164831161499  (-0.33894375040511443)\n",
      "     | > loss_dur: 0.20070935785770416  (0.18766227835589197)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.1513, device='cuda:0')  (tensor(24.3781, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.5725  (0.3899515069220677)\n",
      "     | > loader_time: 0.004  (0.005280755768137529)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_38000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:38:47 -- STEP: 267/406 -- GLOBAL_STEP: 38025\u001b[0m\n",
      "     | > loss: -0.15733934938907623  (-0.15132352687446377)\n",
      "     | > log_mle: -0.3511009216308594  (-0.3399441072556855)\n",
      "     | > loss_dur: 0.19376157224178314  (0.18862058035331714)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.0828, device='cuda:0')  (tensor(24.6096, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.4844  (0.4043284230464407)\n",
      "     | > loader_time: 0.005  (0.005232388607125156)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:39:01 -- STEP: 292/406 -- GLOBAL_STEP: 38050\u001b[0m\n",
      "     | > loss: -0.14115142822265625  (-0.15140918749448382)\n",
      "     | > log_mle: -0.34649181365966797  (-0.3408661484718322)\n",
      "     | > loss_dur: 0.20534038543701172  (0.18945696095183273)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.9154, device='cuda:0')  (tensor(24.9456, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.5865  (0.4159287949130959)\n",
      "     | > loader_time: 0.005  (0.005219709383298272)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:39:16 -- STEP: 317/406 -- GLOBAL_STEP: 38075\u001b[0m\n",
      "     | > loss: -0.1472046822309494  (-0.1513031485140889)\n",
      "     | > log_mle: -0.3448526859283447  (-0.34173335337112376)\n",
      "     | > loss_dur: 0.19764800369739532  (0.19043020483353146)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.1338, device='cuda:0')  (tensor(25.1928, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.5185  (0.4283686052737551)\n",
      "     | > loader_time: 0.005  (0.005224819815121238)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:39:30 -- STEP: 342/406 -- GLOBAL_STEP: 38100\u001b[0m\n",
      "     | > loss: -0.1595076024532318  (-0.15115966865716632)\n",
      "     | > log_mle: -0.35684335231781006  (-0.3424458908058747)\n",
      "     | > loss_dur: 0.19733574986457825  (0.19128622212692295)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.6082, device='cuda:0')  (tensor(25.3670, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.6676  (0.43988175768601256)\n",
      "     | > loader_time: 0.005  (0.005232136151943987)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:39:46 -- STEP: 367/406 -- GLOBAL_STEP: 38125\u001b[0m\n",
      "     | > loss: -0.15086773037910461  (-0.15111591835437746)\n",
      "     | > log_mle: -0.34689033031463623  (-0.34329189396684107)\n",
      "     | > loss_dur: 0.19602259993553162  (0.1921759755921622)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.6258, device='cuda:0')  (tensor(25.7135, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.6756  (0.45066624441328745)\n",
      "     | > loader_time: 0.006  (0.005235158779965435)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:40:02 -- STEP: 392/406 -- GLOBAL_STEP: 38150\u001b[0m\n",
      "     | > loss: -0.16039735078811646  (-0.15121275650299323)\n",
      "     | > log_mle: -0.35645997524261475  (-0.3440276688458968)\n",
      "     | > loss_dur: 0.1960626244544983  (0.19281491232389683)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.1747, device='cuda:0')  (tensor(26.2936, device='cuda:0'))\n",
      "     | > current_lr: 2.3250000000000003e-05 \n",
      "     | > step_time: 0.5835  (0.4629211778543433)\n",
      "     | > loader_time: 0.006  (0.005256195457614198)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09633785486221313 \u001b[0m(-0.010884642601013184)\n",
      "     | > avg_loss:\u001b[92m -0.1801924742758274 \u001b[0m(-0.0009675752371549606)\n",
      "     | > avg_log_mle:\u001b[92m -0.36494749784469604 \u001b[0m(-0.0013553053140640259)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18475502356886864 \u001b[0m(+0.00038773007690906525)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_38164.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 94/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:40:45) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:41:05 -- STEP: 11/406 -- GLOBAL_STEP: 38175\u001b[0m\n",
      "     | > loss: -0.185500368475914  (-0.18633074245669626)\n",
      "     | > log_mle: -0.3308638334274292  (-0.3294708728790283)\n",
      "     | > loss_dur: 0.1453634649515152  (0.14314012974500656)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(13.0584, device='cuda:0')  (tensor(24.8444, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.2722  (0.27051821621981537)\n",
      "     | > loader_time: 0.001  (0.02138311212713068)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:41:12 -- STEP: 36/406 -- GLOBAL_STEP: 38200\u001b[0m\n",
      "     | > loss: -0.15051256120204926  (-0.1677462976011965)\n",
      "     | > log_mle: -0.3147308826446533  (-0.32667893171310425)\n",
      "     | > loss_dur: 0.16421832144260406  (0.15893263390494716)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.4434, device='cuda:0')  (tensor(20.3916, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.2973  (0.282978978421953)\n",
      "     | > loader_time: 0.002  (0.008229838477240669)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:41:20 -- STEP: 61/406 -- GLOBAL_STEP: 38225\u001b[0m\n",
      "     | > loss: -0.12807585299015045  (-0.1590905375167972)\n",
      "     | > log_mle: -0.32317280769348145  (-0.3261800261794543)\n",
      "     | > loss_dur: 0.195096954703331  (0.16708948854051653)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(22.9332, device='cuda:0')  (tensor(19.5048, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.2923  (0.2946773552503741)\n",
      "     | > loader_time: 0.003  (0.005939835407694832)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:41:29 -- STEP: 86/406 -- GLOBAL_STEP: 38250\u001b[0m\n",
      "     | > loss: -0.1499393880367279  (-0.1561687072349149)\n",
      "     | > log_mle: -0.32724857330322266  (-0.32805619683376563)\n",
      "     | > loss_dur: 0.17730918526649475  (0.1718874895122162)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.5279, device='cuda:0')  (tensor(22.0210, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.3833  (0.3084544303805329)\n",
      "     | > loader_time: 0.003  (0.005109312922455544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:41:38 -- STEP: 111/406 -- GLOBAL_STEP: 38275\u001b[0m\n",
      "     | > loss: -0.17054368555545807  (-0.1561561367801718)\n",
      "     | > log_mle: -0.3595550060272217  (-0.33146217062666594)\n",
      "     | > loss_dur: 0.1890113204717636  (0.17530603377937196)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.6322, device='cuda:0')  (tensor(21.5129, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.3403  (0.32115644162839596)\n",
      "     | > loader_time: 0.003  (0.004697980107487859)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:41:48 -- STEP: 136/406 -- GLOBAL_STEP: 38300\u001b[0m\n",
      "     | > loss: -0.14557546377182007  (-0.15544268850456266)\n",
      "     | > log_mle: -0.3532983064651489  (-0.33420342732878283)\n",
      "     | > loss_dur: 0.20772284269332886  (0.17876073876943657)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.7180, device='cuda:0')  (tensor(21.5799, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.4364  (0.331639356472913)\n",
      "     | > loader_time: 0.003  (0.0045261751202976)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:41:58 -- STEP: 161/406 -- GLOBAL_STEP: 38325\u001b[0m\n",
      "     | > loss: -0.14157775044441223  (-0.15453630796870826)\n",
      "     | > log_mle: -0.33246588706970215  (-0.33585782969220085)\n",
      "     | > loss_dur: 0.19088813662528992  (0.1813215216772156)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.4971, device='cuda:0')  (tensor(22.4957, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.3613  (0.3423667561193431)\n",
      "     | > loader_time: 0.004  (0.004420164949405266)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:42:09 -- STEP: 186/406 -- GLOBAL_STEP: 38350\u001b[0m\n",
      "     | > loss: -0.15398070216178894  (-0.1545739762725368)\n",
      "     | > log_mle: -0.3562706708908081  (-0.3377743382607735)\n",
      "     | > loss_dur: 0.20228996872901917  (0.18320036194817993)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(24.6650, device='cuda:0')  (tensor(22.6208, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.4894  (0.3563370730287285)\n",
      "     | > loader_time: 0.004  (0.0044072174256847745)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:42:21 -- STEP: 211/406 -- GLOBAL_STEP: 38375\u001b[0m\n",
      "     | > loss: -0.1626698076725006  (-0.15430121709950156)\n",
      "     | > log_mle: -0.3631983995437622  (-0.33919032320592063)\n",
      "     | > loss_dur: 0.2005285918712616  (0.18488910607110834)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.8780, device='cuda:0')  (tensor(23.2478, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.5225  (0.36773020622289576)\n",
      "     | > loader_time: 0.004  (0.004378401272669786)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:42:32 -- STEP: 236/406 -- GLOBAL_STEP: 38400\u001b[0m\n",
      "     | > loss: -0.13972584903240204  (-0.15425412697812252)\n",
      "     | > log_mle: -0.33877789974212646  (-0.340611406807172)\n",
      "     | > loss_dur: 0.19905205070972443  (0.18635727979747926)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.3369, device='cuda:0')  (tensor(23.6788, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.4364  (0.3778806854102571)\n",
      "     | > loader_time: 0.005  (0.004355696298308291)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:42:45 -- STEP: 261/406 -- GLOBAL_STEP: 38425\u001b[0m\n",
      "     | > loss: -0.16824744641780853  (-0.15449514671075384)\n",
      "     | > log_mle: -0.35400068759918213  (-0.34183560066296215)\n",
      "     | > loss_dur: 0.1857532411813736  (0.18734045392366205)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.7843, device='cuda:0')  (tensor(24.2796, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.4498  (0.39091786205540213)\n",
      "     | > loader_time: 0.004  (0.004375645027306802)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:42:58 -- STEP: 286/406 -- GLOBAL_STEP: 38450\u001b[0m\n",
      "     | > loss: -0.16308994591236115  (-0.15468121340850008)\n",
      "     | > log_mle: -0.35721516609191895  (-0.34289931292300446)\n",
      "     | > loss_dur: 0.1941252201795578  (0.18821809948845342)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.1902, device='cuda:0')  (tensor(24.4954, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.4894  (0.4016387821077467)\n",
      "     | > loader_time: 0.004  (0.004409613309206663)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:43:12 -- STEP: 311/406 -- GLOBAL_STEP: 38475\u001b[0m\n",
      "     | > loss: -0.1648559868335724  (-0.15466352305419953)\n",
      "     | > log_mle: -0.36431884765625  (-0.34393868032375713)\n",
      "     | > loss_dur: 0.1994628608226776  (0.18927515724560076)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.1066, device='cuda:0')  (tensor(24.9805, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.4874  (0.41372097803465424)\n",
      "     | > loader_time: 0.004  (0.004431673951470967)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:43:26 -- STEP: 336/406 -- GLOBAL_STEP: 38500\u001b[0m\n",
      "     | > loss: -0.13443678617477417  (-0.15440742631575885)\n",
      "     | > log_mle: -0.3408181667327881  (-0.34461527495157146)\n",
      "     | > loss_dur: 0.20638138055801392  (0.19020784861363832)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.7683, device='cuda:0')  (tensor(25.2595, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.6656  (0.4244282089528583)\n",
      "     | > loader_time: 0.005  (0.004456424996966407)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:43:41 -- STEP: 361/406 -- GLOBAL_STEP: 38525\u001b[0m\n",
      "     | > loss: -0.15249848365783691  (-0.1545252153995624)\n",
      "     | > log_mle: -0.3527541160583496  (-0.34554264287869363)\n",
      "     | > loss_dur: 0.2002556324005127  (0.19101742745849243)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(39.1507, device='cuda:0')  (tensor(25.7598, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.6856  (0.4356986247931821)\n",
      "     | > loader_time: 0.005  (0.004488822826057918)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:43:57 -- STEP: 386/406 -- GLOBAL_STEP: 38550\u001b[0m\n",
      "     | > loss: -0.16467425227165222  (-0.1546901730444146)\n",
      "     | > log_mle: -0.35816407203674316  (-0.3463504938263968)\n",
      "     | > loss_dur: 0.19348981976509094  (0.19166032076268005)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(19.7931, device='cuda:0')  (tensor(26.2995, device='cuda:0'))\n",
      "     | > current_lr: 2.3500000000000002e-05 \n",
      "     | > step_time: 0.7527  (0.44848075246563845)\n",
      "     | > loader_time: 0.006  (0.004530004886765552)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.09075245261192322 \u001b[0m(-0.005585402250289917)\n",
      "     | > avg_loss:\u001b[92m -0.1848727334290743 \u001b[0m(-0.00468025915324688)\n",
      "     | > avg_log_mle:\u001b[92m -0.3688107579946518 \u001b[0m(-0.0038632601499557495)\n",
      "     | > avg_loss_dur:\u001b[92m 0.1839380245655775 \u001b[0m(-0.0008169990032911301)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_38570.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 95/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:44:42) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:44:59 -- STEP: 5/406 -- GLOBAL_STEP: 38575\u001b[0m\n",
      "     | > loss: -0.16466763615608215  (-0.1953974574804306)\n",
      "     | > log_mle: -0.32122802734375  (-0.33380653858184817)\n",
      "     | > loss_dur: 0.15656039118766785  (0.13840908110141753)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.9077, device='cuda:0')  (tensor(22.7267, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.2582  (0.26083669662475584)\n",
      "     | > loader_time: 0.002  (0.02522311210632324)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:45:06 -- STEP: 30/406 -- GLOBAL_STEP: 38600\u001b[0m\n",
      "     | > loss: -0.16718004643917084  (-0.17555999308824535)\n",
      "     | > log_mle: -0.3304300308227539  (-0.33113228082656865)\n",
      "     | > loss_dur: 0.16324998438358307  (0.15557228773832316)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.9299, device='cuda:0')  (tensor(24.1042, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.2592  (0.26167074839274085)\n",
      "     | > loader_time: 0.003  (0.005905469258626302)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:45:13 -- STEP: 55/406 -- GLOBAL_STEP: 38625\u001b[0m\n",
      "     | > loss: -0.14693355560302734  (-0.16541011956605042)\n",
      "     | > log_mle: -0.3395533561706543  (-0.33002939440987333)\n",
      "     | > loss_dur: 0.19261980056762695  (0.16461927484382277)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.8517, device='cuda:0')  (tensor(22.9294, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.2783  (0.27269669446078215)\n",
      "     | > loader_time: 0.002  (0.004331285303289238)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:45:21 -- STEP: 80/406 -- GLOBAL_STEP: 38650\u001b[0m\n",
      "     | > loss: -0.1393752545118332  (-0.16205032095313068)\n",
      "     | > log_mle: -0.32313990592956543  (-0.33178164362907403)\n",
      "     | > loss_dur: 0.18376465141773224  (0.16973132267594335)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.5064, device='cuda:0')  (tensor(23.2992, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.2943  (0.2859809339046478)\n",
      "     | > loader_time: 0.002  (0.003828510642051696)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:45:30 -- STEP: 105/406 -- GLOBAL_STEP: 38675\u001b[0m\n",
      "     | > loss: -0.164698988199234  (-0.16079131818953016)\n",
      "     | > log_mle: -0.33241283893585205  (-0.3347089381445022)\n",
      "     | > loss_dur: 0.16771385073661804  (0.17391761995497199)\n",
      "     | > amp_scaler: 8192.0  (4603.1238095238095)\n",
      "     | > grad_norm: tensor(28.9070, device='cuda:0')  (tensor(24.9541, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.3333  (0.29852535611107245)\n",
      "     | > loader_time: 0.004  (0.0036700021652948285)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:45:39 -- STEP: 130/406 -- GLOBAL_STEP: 38700\u001b[0m\n",
      "     | > loss: -0.1684304177761078  (-0.15970333390511)\n",
      "     | > log_mle: -0.34874606132507324  (-0.33693340099774877)\n",
      "     | > loss_dur: 0.18031564354896545  (0.1772300670926387)\n",
      "     | > amp_scaler: 8192.0  (5293.292307692307)\n",
      "     | > grad_norm: tensor(24.7218, device='cuda:0')  (tensor(24.8565, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.3373  (0.310456552872291)\n",
      "     | > loader_time: 0.003  (0.0036032199859619136)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:45:49 -- STEP: 155/406 -- GLOBAL_STEP: 38725\u001b[0m\n",
      "     | > loss: -0.14037422835826874  (-0.1585132779613618)\n",
      "     | > log_mle: -0.33606040477752686  (-0.33845876186124735)\n",
      "     | > loss_dur: 0.19568617641925812  (0.17994548389988557)\n",
      "     | > amp_scaler: 8192.0  (5760.825806451611)\n",
      "     | > grad_norm: tensor(23.6308, device='cuda:0')  (tensor(24.6766, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.3533  (0.3211993940414921)\n",
      "     | > loader_time: 0.003  (0.003603244596912015)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:45:59 -- STEP: 180/406 -- GLOBAL_STEP: 38750\u001b[0m\n",
      "     | > loss: -0.15963703393936157  (-0.1582115651832687)\n",
      "     | > log_mle: -0.3544626235961914  (-0.3399816393852233)\n",
      "     | > loss_dur: 0.19482558965682983  (0.18177007420195473)\n",
      "     | > amp_scaler: 8192.0  (6098.488888888889)\n",
      "     | > grad_norm: tensor(21.0894, device='cuda:0')  (tensor(24.7908, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.4664  (0.33350116279390124)\n",
      "     | > loader_time: 0.004  (0.003608768516116672)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:46:10 -- STEP: 205/406 -- GLOBAL_STEP: 38775\u001b[0m\n",
      "     | > loss: -0.16310380399227142  (-0.1573815681585452)\n",
      "     | > log_mle: -0.3643224239349365  (-0.3412257008436248)\n",
      "     | > loss_dur: 0.2012186199426651  (0.18384413268507982)\n",
      "     | > amp_scaler: 8192.0  (6353.79512195122)\n",
      "     | > grad_norm: tensor(22.7636, device='cuda:0')  (tensor(25.9983, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.4794  (0.344960553471635)\n",
      "     | > loader_time: 0.004  (0.0036862047707162254)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:46:21 -- STEP: 230/406 -- GLOBAL_STEP: 38800\u001b[0m\n",
      "     | > loss: -0.16006594896316528  (-0.15730364782654727)\n",
      "     | > log_mle: -0.35839104652404785  (-0.3426379561424254)\n",
      "     | > loss_dur: 0.19832509756088257  (0.18533430831587833)\n",
      "     | > amp_scaler: 8192.0  (6553.6)\n",
      "     | > grad_norm: tensor(27.9135, device='cuda:0')  (tensor(25.7682, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.3994  (0.35463812765867814)\n",
      "     | > loader_time: 0.004  (0.0037555020788441534)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:46:33 -- STEP: 255/406 -- GLOBAL_STEP: 38825\u001b[0m\n",
      "     | > loss: -0.15605323016643524  (-0.15716175407755614)\n",
      "     | > log_mle: -0.3496701717376709  (-0.3438260947956757)\n",
      "     | > loss_dur: 0.19361694157123566  (0.18666434071811974)\n",
      "     | > amp_scaler: 8192.0  (6714.227450980392)\n",
      "     | > grad_norm: tensor(22.2500, device='cuda:0')  (tensor(26.5177, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.4224  (0.36666903682783536)\n",
      "     | > loader_time: 0.005  (0.0037955115823184744)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:46:45 -- STEP: 280/406 -- GLOBAL_STEP: 38850\u001b[0m\n",
      "     | > loss: -0.1593395620584488  (-0.1572362890200956)\n",
      "     | > log_mle: -0.36351466178894043  (-0.3447788770709718)\n",
      "     | > loss_dur: 0.20417509973049164  (0.18754258805087637)\n",
      "     | > amp_scaler: 8192.0  (6846.171428571429)\n",
      "     | > grad_norm: tensor(24.7779, device='cuda:0')  (tensor(26.6107, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.4594  (0.37821381262370524)\n",
      "     | > loader_time: 0.004  (0.0038569765431540354)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:46:59 -- STEP: 305/406 -- GLOBAL_STEP: 38875\u001b[0m\n",
      "     | > loss: -0.13976217806339264  (-0.15724618688958591)\n",
      "     | > log_mle: -0.35319793224334717  (-0.34583742266795675)\n",
      "     | > loss_dur: 0.21343575417995453  (0.18859123577837086)\n",
      "     | > amp_scaler: 8192.0  (6956.485245901641)\n",
      "     | > grad_norm: tensor(24.0334, device='cuda:0')  (tensor(26.5160, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.4714  (0.38961842099174127)\n",
      "     | > loader_time: 0.005  (0.003918195943363377)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:47:12 -- STEP: 330/406 -- GLOBAL_STEP: 38900\u001b[0m\n",
      "     | > loss: -0.1527775526046753  (-0.1571498626560876)\n",
      "     | > log_mle: -0.3646814823150635  (-0.34660811135263164)\n",
      "     | > loss_dur: 0.21190392971038818  (0.1894582486965439)\n",
      "     | > amp_scaler: 8192.0  (7050.08484848485)\n",
      "     | > grad_norm: tensor(32.4420, device='cuda:0')  (tensor(26.6941, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.4764  (0.4005082672292536)\n",
      "     | > loader_time: 0.005  (0.003985318270596591)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:47:26 -- STEP: 355/406 -- GLOBAL_STEP: 38925\u001b[0m\n",
      "     | > loss: -0.166394904255867  (-0.15692031635365025)\n",
      "     | > log_mle: -0.3672276735305786  (-0.3474299911042336)\n",
      "     | > loss_dur: 0.2008327692747116  (0.1905096747505832)\n",
      "     | > amp_scaler: 8192.0  (7130.501408450706)\n",
      "     | > grad_norm: tensor(22.9865, device='cuda:0')  (tensor(26.5999, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.5295  (0.41220449662544356)\n",
      "     | > loader_time: 0.006  (0.004065530400880623)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:47:41 -- STEP: 380/406 -- GLOBAL_STEP: 38950\u001b[0m\n",
      "     | > loss: -0.1595650166273117  (-0.15721682466958706)\n",
      "     | > log_mle: -0.3598754405975342  (-0.34836869961337064)\n",
      "     | > loss_dur: 0.20031042397022247  (0.19115187494378333)\n",
      "     | > amp_scaler: 8192.0  (7200.336842105265)\n",
      "     | > grad_norm: tensor(30.4463, device='cuda:0')  (tensor(26.6448, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.6626  (0.42427927318372227)\n",
      "     | > loader_time: 0.005  (0.0041351895583303325)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:47:57 -- STEP: 405/406 -- GLOBAL_STEP: 38975\u001b[0m\n",
      "     | > loss: -0.17370975017547607  (-0.15738978897347872)\n",
      "     | > log_mle: -0.3596618175506592  (-0.3491376305803843)\n",
      "     | > loss_dur: 0.1859520673751831  (0.19174784160690536)\n",
      "     | > amp_scaler: 8192.0  (7261.550617283951)\n",
      "     | > grad_norm: tensor(23.7060, device='cuda:0')  (tensor(27.5035, device='cuda:0'))\n",
      "     | > current_lr: 2.375e-05 \n",
      "     | > step_time: 0.3043  (0.4365886959028833)\n",
      "     | > loader_time: 0.002  (0.0041838940278983395)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09858947992324829 \u001b[0m(+0.007837027311325073)\n",
      "     | > avg_loss:\u001b[92m -0.18873136304318905 \u001b[0m(-0.0038586296141147614)\n",
      "     | > avg_log_mle:\u001b[92m -0.3724043369293213 \u001b[0m(-0.0035935789346694946)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18367297388613224 \u001b[0m(-0.0002650506794452667)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_38976.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 96/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:48:30) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:48:52 -- STEP: 24/406 -- GLOBAL_STEP: 39000\u001b[0m\n",
      "     | > loss: -0.1844131499528885  (-0.1811125942816337)\n",
      "     | > log_mle: -0.3429892063140869  (-0.33246027926603955)\n",
      "     | > loss_dur: 0.15857605636119843  (0.15134768498440584)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.1577, device='cuda:0')  (tensor(20.6341, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.2552  (0.2575255036354065)\n",
      "     | > loader_time: 0.002  (0.010050853093465168)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_39000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:49:01 -- STEP: 49/406 -- GLOBAL_STEP: 39025\u001b[0m\n",
      "     | > loss: -0.16534240543842316  (-0.17046131132816777)\n",
      "     | > log_mle: -0.332810640335083  (-0.3313400210166465)\n",
      "     | > loss_dur: 0.16746823489665985  (0.1608787096884786)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(16.9453, device='cuda:0')  (tensor(20.4252, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.2712  (0.27020449541053)\n",
      "     | > loader_time: 0.002  (0.006189341447791274)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:49:09 -- STEP: 74/406 -- GLOBAL_STEP: 39050\u001b[0m\n",
      "     | > loss: -0.15411479771137238  (-0.16670728797042692)\n",
      "     | > log_mle: -0.36068665981292725  (-0.3342741598954072)\n",
      "     | > loss_dur: 0.20657186210155487  (0.16756687192498027)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.8436, device='cuda:0')  (tensor(22.1765, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.2993  (0.28187752736581334)\n",
      "     | > loader_time: 0.003  (0.004991044869294037)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:49:18 -- STEP: 99/406 -- GLOBAL_STEP: 39075\u001b[0m\n",
      "     | > loss: -0.148847296833992  (-0.16438967711997762)\n",
      "     | > log_mle: -0.34119153022766113  (-0.33687375410638665)\n",
      "     | > loss_dur: 0.19234423339366913  (0.17248407698640913)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.1288, device='cuda:0')  (tensor(22.1870, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.3063  (0.2955308851569591)\n",
      "     | > loader_time: 0.003  (0.004499095858949601)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:49:27 -- STEP: 124/406 -- GLOBAL_STEP: 39100\u001b[0m\n",
      "     | > loss: -0.15608708560466766  (-0.16361890204491158)\n",
      "     | > log_mle: -0.3506876230239868  (-0.3395316927663741)\n",
      "     | > loss_dur: 0.19460053741931915  (0.17591279072146257)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.8049, device='cuda:0')  (tensor(23.6269, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.3984  (0.30799733054253364)\n",
      "     | > loader_time: 0.004  (0.004261951292714762)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:49:36 -- STEP: 149/406 -- GLOBAL_STEP: 39125\u001b[0m\n",
      "     | > loss: -0.15296553075313568  (-0.16291554872221595)\n",
      "     | > log_mle: -0.3559833765029907  (-0.34164775697976946)\n",
      "     | > loss_dur: 0.20301784574985504  (0.1787322082575535)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(50.4599, device='cuda:0')  (tensor(24.4368, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.4124  (0.318356128347)\n",
      "     | > loader_time: 0.004  (0.004144695781221323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:49:46 -- STEP: 174/406 -- GLOBAL_STEP: 39150\u001b[0m\n",
      "     | > loss: -0.14324428141117096  (-0.16186540787932518)\n",
      "     | > log_mle: -0.33750319480895996  (-0.3426999059216728)\n",
      "     | > loss_dur: 0.194258913397789  (0.18083449804234783)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(56.4062, device='cuda:0')  (tensor(26.4724, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.4344  (0.33060931200268623)\n",
      "     | > loader_time: 0.004  (0.004107208087526516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:49:57 -- STEP: 199/406 -- GLOBAL_STEP: 39175\u001b[0m\n",
      "     | > loss: -0.1382904052734375  (-0.16098961982894783)\n",
      "     | > log_mle: -0.34361255168914795  (-0.34392567255988193)\n",
      "     | > loss_dur: 0.20532214641571045  (0.18293605273093413)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(41.8830, device='cuda:0')  (tensor(26.8452, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.485  (0.3437963358720943)\n",
      "     | > loader_time: 0.004  (0.004084139014009252)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:50:08 -- STEP: 224/406 -- GLOBAL_STEP: 39200\u001b[0m\n",
      "     | > loss: -0.17101982235908508  (-0.1609321927784809)\n",
      "     | > log_mle: -0.3535645008087158  (-0.34536717193467276)\n",
      "     | > loss_dur: 0.18254467844963074  (0.1844349791561919)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(22.6070, device='cuda:0')  (tensor(27.6864, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.4344  (0.3543952533176968)\n",
      "     | > loader_time: 0.004  (0.004097472344126018)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:50:20 -- STEP: 249/406 -- GLOBAL_STEP: 39225\u001b[0m\n",
      "     | > loss: -0.14465045928955078  (-0.16068754551640477)\n",
      "     | > log_mle: -0.3458251953125  (-0.34662391622382477)\n",
      "     | > loss_dur: 0.20117473602294922  (0.18593637070742)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(36.8025, device='cuda:0')  (tensor(28.4103, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.4164  (0.3658856799803585)\n",
      "     | > loader_time: 0.004  (0.004112170882014386)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:50:33 -- STEP: 274/406 -- GLOBAL_STEP: 39250\u001b[0m\n",
      "     | > loss: -0.16430531442165375  (-0.16100041416004626)\n",
      "     | > log_mle: -0.35843026638031006  (-0.3477634865872181)\n",
      "     | > loss_dur: 0.1941249519586563  (0.18676307242717188)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.1129, device='cuda:0')  (tensor(28.9208, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.4444  (0.3773309584081609)\n",
      "     | > loader_time: 0.004  (0.004149764993765058)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:50:46 -- STEP: 299/406 -- GLOBAL_STEP: 39275\u001b[0m\n",
      "     | > loss: -0.17925184965133667  (-0.16093270600240767)\n",
      "     | > log_mle: -0.38452398777008057  (-0.3486835474154622)\n",
      "     | > loss_dur: 0.2052721381187439  (0.1877508414130546)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(35.2489, device='cuda:0')  (tensor(29.3034, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.6005  (0.38857960621250126)\n",
      "     | > loader_time: 0.004  (0.004171011041239354)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:50:59 -- STEP: 324/406 -- GLOBAL_STEP: 39300\u001b[0m\n",
      "     | > loss: -0.16634143888950348  (-0.16078999105059072)\n",
      "     | > log_mle: -0.3586314916610718  (-0.34948199288344667)\n",
      "     | > loss_dur: 0.1922900527715683  (0.18869200183285603)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.4875, device='cuda:0')  (tensor(29.5576, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.5135  (0.40018223612396797)\n",
      "     | > loader_time: 0.005  (0.004210594995522204)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:51:14 -- STEP: 349/406 -- GLOBAL_STEP: 39325\u001b[0m\n",
      "     | > loss: -0.1290208399295807  (-0.16050246733649068)\n",
      "     | > log_mle: -0.35550737380981445  (-0.35024925289318)\n",
      "     | > loss_dur: 0.22648653388023376  (0.18974678555668933)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(18.4872, device='cuda:0')  (tensor(29.6707, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.5055  (0.412997213680628)\n",
      "     | > loader_time: 0.004  (0.004287525712589818)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:51:29 -- STEP: 374/406 -- GLOBAL_STEP: 39350\u001b[0m\n",
      "     | > loss: -0.1600080132484436  (-0.1606206007819762)\n",
      "     | > log_mle: -0.3573645353317261  (-0.35110436786304805)\n",
      "     | > loss_dur: 0.19735652208328247  (0.19048376708107195)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(47.6263, device='cuda:0')  (tensor(29.9645, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.713  (0.4252715193651576)\n",
      "     | > loader_time: 0.005  (0.004346133553408044)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:51:46 -- STEP: 399/406 -- GLOBAL_STEP: 39375\u001b[0m\n",
      "     | > loss: -0.14245885610580444  (-0.1605483990041235)\n",
      "     | > log_mle: -0.3613547086715698  (-0.3518419059595666)\n",
      "     | > loss_dur: 0.21889585256576538  (0.19129350695544314)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(32.9378, device='cuda:0')  (tensor(30.3548, device='cuda:0'))\n",
      "     | > current_lr: 2.4e-05 \n",
      "     | > step_time: 0.5832  (0.43999957082265595)\n",
      "     | > loader_time: 0.005  (0.004418578064232539)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.1047200858592987 \u001b[0m(+0.006130605936050415)\n",
      "     | > avg_loss:\u001b[91m -0.18833850510418415 \u001b[0m(+0.00039285793900489807)\n",
      "     | > avg_log_mle:\u001b[92m -0.3727312535047531 \u001b[0m(-0.00032691657543182373)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18439274840056896 \u001b[0m(+0.0007197745144367218)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 97/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:52:22) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:52:44 -- STEP: 18/406 -- GLOBAL_STEP: 39400\u001b[0m\n",
      "     | > loss: -0.16478180885314941  (-0.1865539691514439)\n",
      "     | > log_mle: -0.320894718170166  (-0.3339442213376363)\n",
      "     | > loss_dur: 0.1561129093170166  (0.14739025260011354)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(17.9081, device='cuda:0')  (tensor(27.7760, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.2903  (0.296430508295695)\n",
      "     | > loader_time: 0.003  (0.010772466659545898)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:52:51 -- STEP: 43/406 -- GLOBAL_STEP: 39425\u001b[0m\n",
      "     | > loss: -0.1677660197019577  (-0.17457576754481294)\n",
      "     | > log_mle: -0.3220665454864502  (-0.3318577145421227)\n",
      "     | > loss_dur: 0.1543005257844925  (0.15728194717057914)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(27.9929, device='cuda:0')  (tensor(24.7882, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.3196  (0.2982074715370356)\n",
      "     | > loader_time: 0.003  (0.00588307269783907)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:53:00 -- STEP: 68/406 -- GLOBAL_STEP: 39450\u001b[0m\n",
      "     | > loss: -0.14680062234401703  (-0.168133331791443)\n",
      "     | > log_mle: -0.33985066413879395  (-0.33399260394713454)\n",
      "     | > loss_dur: 0.19305004179477692  (0.16585927226525896)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(23.1668, device='cuda:0')  (tensor(25.4157, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.3125  (0.30778590721242566)\n",
      "     | > loader_time: 0.003  (0.004750704064088708)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:53:09 -- STEP: 93/406 -- GLOBAL_STEP: 39475\u001b[0m\n",
      "     | > loss: -0.18158073723316193  (-0.16693980238770925)\n",
      "     | > log_mle: -0.36975395679473877  (-0.33746620660187093)\n",
      "     | > loss_dur: 0.18817321956157684  (0.1705264042942755)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.2806, device='cuda:0')  (tensor(24.8911, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.3153  (0.32103596964190073)\n",
      "     | > loader_time: 0.003  (0.004293349481398057)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:53:18 -- STEP: 118/406 -- GLOBAL_STEP: 39500\u001b[0m\n",
      "     | > loss: -0.15318897366523743  (-0.16550047291537462)\n",
      "     | > log_mle: -0.34652161598205566  (-0.33977058479341404)\n",
      "     | > loss_dur: 0.19333264231681824  (0.17427011194118003)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.1735, device='cuda:0')  (tensor(24.7129, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.3283  (0.32979096396494706)\n",
      "     | > loader_time: 0.003  (0.004130304869958907)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:53:28 -- STEP: 143/406 -- GLOBAL_STEP: 39525\u001b[0m\n",
      "     | > loss: -0.16972613334655762  (-0.1640551217369266)\n",
      "     | > log_mle: -0.3609408140182495  (-0.34176818307463097)\n",
      "     | > loss_dur: 0.1912146806716919  (0.1777130613898064)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(21.3753, device='cuda:0')  (tensor(26.5004, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.464  (0.33877554806795984)\n",
      "     | > loader_time: 0.005  (0.004017254689356662)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:53:38 -- STEP: 168/406 -- GLOBAL_STEP: 39550\u001b[0m\n",
      "     | > loss: -0.15483151376247406  (-0.1628653698911269)\n",
      "     | > log_mle: -0.34185004234313965  (-0.34293095128876816)\n",
      "     | > loss_dur: 0.1870185285806656  (0.18006558144199003)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(48.6049, device='cuda:0')  (tensor(27.2482, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.3773  (0.348205905585062)\n",
      "     | > loader_time: 0.003  (0.0039945230597541416)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:53:49 -- STEP: 193/406 -- GLOBAL_STEP: 39575\u001b[0m\n",
      "     | > loss: -0.16801923513412476  (-0.16265801529501384)\n",
      "     | > log_mle: -0.36683905124664307  (-0.34455518895480297)\n",
      "     | > loss_dur: 0.1988198161125183  (0.1818971736983932)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(25.7783, device='cuda:0')  (tensor(27.4645, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.4868  (0.3592973842522023)\n",
      "     | > loader_time: 0.004  (0.003990601999154358)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:54:00 -- STEP: 218/406 -- GLOBAL_STEP: 39600\u001b[0m\n",
      "     | > loss: -0.1555459350347519  (-0.16250973502430344)\n",
      "     | > log_mle: -0.3565540313720703  (-0.3458277823728159)\n",
      "     | > loss_dur: 0.20100809633731842  (0.18331804738268942)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(65.7366, device='cuda:0')  (tensor(28.2230, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.4154  (0.3695923068107815)\n",
      "     | > loader_time: 0.004  (0.004019697871776892)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:54:12 -- STEP: 243/406 -- GLOBAL_STEP: 39625\u001b[0m\n",
      "     | > loss: -0.17294913530349731  (-0.16252098597371525)\n",
      "     | > log_mle: -0.3786529302597046  (-0.3474175674925125)\n",
      "     | > loss_dur: 0.20570379495620728  (0.1848965815494581)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(26.3826, device='cuda:0')  (tensor(28.2327, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.5305  (0.37847320631207754)\n",
      "     | > loader_time: 0.004  (0.0040428010524545645)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:54:24 -- STEP: 268/406 -- GLOBAL_STEP: 39650\u001b[0m\n",
      "     | > loss: -0.17020972073078156  (-0.16243833881705555)\n",
      "     | > log_mle: -0.36624062061309814  (-0.3482747327035932)\n",
      "     | > loss_dur: 0.1960308998823166  (0.18583639391433834)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(24.8346, device='cuda:0')  (tensor(28.7993, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.5565  (0.38955697639664605)\n",
      "     | > loader_time: 0.005  (0.004102658869615239)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:54:37 -- STEP: 293/406 -- GLOBAL_STEP: 39675\u001b[0m\n",
      "     | > loss: -0.16664785146713257  (-0.1625151798485082)\n",
      "     | > log_mle: -0.36481189727783203  (-0.3492350114490391)\n",
      "     | > loss_dur: 0.19816404581069946  (0.18671983162595954)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(31.0995, device='cuda:0')  (tensor(29.1977, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.4684  (0.399230982256424)\n",
      "     | > loader_time: 0.004  (0.004169380298653556)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:54:51 -- STEP: 318/406 -- GLOBAL_STEP: 39700\u001b[0m\n",
      "     | > loss: -0.14946328103542328  (-0.1621318301127392)\n",
      "     | > log_mle: -0.3521122932434082  (-0.34997847994918324)\n",
      "     | > loss_dur: 0.20264901220798492  (0.18784664985987373)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(102.7987, device='cuda:0')  (tensor(29.9321, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.5205  (0.4103236790723021)\n",
      "     | > loader_time: 0.005  (0.004222471009260449)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:55:05 -- STEP: 343/406 -- GLOBAL_STEP: 39725\u001b[0m\n",
      "     | > loss: -0.15790492296218872  (-0.16179607413253008)\n",
      "     | > log_mle: -0.3733255863189697  (-0.350630192645437)\n",
      "     | > loss_dur: 0.215420663356781  (0.18883411853462898)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(28.9564, device='cuda:0')  (tensor(30.3199, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.5135  (0.42084404539436365)\n",
      "     | > loader_time: 0.006  (0.004270755167257679)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:55:19 -- STEP: 368/406 -- GLOBAL_STEP: 39750\u001b[0m\n",
      "     | > loss: -0.17474249005317688  (-0.1618602409068009)\n",
      "     | > log_mle: -0.3734675645828247  (-0.35159158577089716)\n",
      "     | > loss_dur: 0.19872507452964783  (0.1897313448843425)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(13.3020, device='cuda:0')  (tensor(30.1634, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.5425  (0.4313683924467667)\n",
      "     | > loader_time: 0.005  (0.0043260733718457406)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:55:36 -- STEP: 393/406 -- GLOBAL_STEP: 39775\u001b[0m\n",
      "     | > loss: -0.16268637776374817  (-0.1615905826555864)\n",
      "     | > log_mle: -0.3607754707336426  (-0.3521054321876312)\n",
      "     | > loss_dur: 0.1980890929698944  (0.19051484955100312)\n",
      "     | > amp_scaler: 8192.0  (8192.0)\n",
      "     | > grad_norm: tensor(43.3712, device='cuda:0')  (tensor(30.3673, device='cuda:0'))\n",
      "     | > current_lr: 2.425e-05 \n",
      "     | > step_time: 0.7297  (0.4449776037958742)\n",
      "     | > loader_time: 0.005  (0.004384534049580114)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.08132356405258179 \u001b[0m(-0.02339652180671692)\n",
      "     | > avg_loss:\u001b[91m -0.1850966066122055 \u001b[0m(+0.0032418984919786453)\n",
      "     | > avg_log_mle:\u001b[91m -0.37017427384853363 \u001b[0m(+0.0025569796562194824)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18507766723632812 \u001b[0m(+0.0006849188357591629)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 98/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 07:56:15) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:56:35 -- STEP: 12/406 -- GLOBAL_STEP: 39800\u001b[0m\n",
      "     | > loss: -0.1825990229845047  (-0.19766680027047792)\n",
      "     | > log_mle: -0.345455527305603  (-0.3399686614672343)\n",
      "     | > loss_dur: 0.16285650432109833  (0.14230186119675636)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(17.6115, device='cuda:0')  (tensor(24.2508, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.2652  (0.2563994725545247)\n",
      "     | > loader_time: 0.002  (0.02118573586146037)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:56:41 -- STEP: 37/406 -- GLOBAL_STEP: 39825\u001b[0m\n",
      "     | > loss: -0.16926178336143494  (-0.17886996228952665)\n",
      "     | > log_mle: -0.3307110071182251  (-0.33622179804621516)\n",
      "     | > loss_dur: 0.16144922375679016  (0.1573518357566885)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(10.9372, device='cuda:0')  (tensor(22.7053, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.2863  (0.2653490014978357)\n",
      "     | > loader_time: 0.002  (0.008358826508393159)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:56:49 -- STEP: 62/406 -- GLOBAL_STEP: 39850\u001b[0m\n",
      "     | > loss: -0.163819819688797  (-0.17131161088905028)\n",
      "     | > log_mle: -0.326180100440979  (-0.3364597981975925)\n",
      "     | > loss_dur: 0.162360280752182  (0.1651481873085422)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(29.0520, device='cuda:0')  (tensor(25.0920, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.3253  (0.2807388113391014)\n",
      "     | > loader_time: 0.003  (0.0061021697136663606)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:56:57 -- STEP: 87/406 -- GLOBAL_STEP: 39875\u001b[0m\n",
      "     | > loss: -0.1694205403327942  (-0.16882687396016607)\n",
      "     | > log_mle: -0.3682910203933716  (-0.33894113425550787)\n",
      "     | > loss_dur: 0.1988704800605774  (0.1701142602953418)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.6128, device='cuda:0')  (tensor(25.3358, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.3313  (0.2946353369745713)\n",
      "     | > loader_time: 0.003  (0.005200016087499157)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:57:07 -- STEP: 112/406 -- GLOBAL_STEP: 39900\u001b[0m\n",
      "     | > loss: -0.19289977848529816  (-0.16830183618835035)\n",
      "     | > log_mle: -0.36121559143066406  (-0.34176838185106007)\n",
      "     | > loss_dur: 0.1683158129453659  (0.17346654566270966)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(37.9517, device='cuda:0')  (tensor(26.1575, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.4024  (0.31267677673271715)\n",
      "     | > loader_time: 0.004  (0.004861459136009216)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:57:16 -- STEP: 137/406 -- GLOBAL_STEP: 39925\u001b[0m\n",
      "     | > loss: -0.14879292249679565  (-0.16655650941559863)\n",
      "     | > log_mle: -0.35173237323760986  (-0.34378739691128696)\n",
      "     | > loss_dur: 0.2029394507408142  (0.1772308874956883)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(27.6753, device='cuda:0')  (tensor(26.2593, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.3453  (0.32267284741366864)\n",
      "     | > loader_time: 0.004  (0.004639143491313406)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:57:26 -- STEP: 162/406 -- GLOBAL_STEP: 39950\u001b[0m\n",
      "     | > loss: -0.15628555417060852  (-0.1648688077190775)\n",
      "     | > log_mle: -0.3694429397583008  (-0.344871860963327)\n",
      "     | > loss_dur: 0.21315738558769226  (0.1800030532442494)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.7577, device='cuda:0')  (tensor(26.5370, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.4514  (0.3333136785177536)\n",
      "     | > loader_time: 0.003  (0.004485473220731007)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:57:37 -- STEP: 187/406 -- GLOBAL_STEP: 39975\u001b[0m\n",
      "     | > loss: -0.15542052686214447  (-0.1646275199989583)\n",
      "     | > log_mle: -0.35432517528533936  (-0.34619633207984163)\n",
      "     | > loss_dur: 0.19890464842319489  (0.18156881208088316)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(67.8498, device='cuda:0')  (tensor(27.6853, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.3763  (0.34488957195995956)\n",
      "     | > loader_time: 0.004  (0.004410357398782823)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:57:48 -- STEP: 212/406 -- GLOBAL_STEP: 40000\u001b[0m\n",
      "     | > loss: -0.15043948590755463  (-0.1639333860070075)\n",
      "     | > log_mle: -0.3565835952758789  (-0.34702955214482445)\n",
      "     | > loss_dur: 0.20614410936832428  (0.18309616613781685)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.1503, device='cuda:0')  (tensor(29.9189, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.4124  (0.355283905875008)\n",
      "     | > loader_time: 0.005  (0.004357628102572459)\n",
      "\n",
      "\n",
      " > CHECKPOINT : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\checkpoint_40000.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:58:05 -- STEP: 237/406 -- GLOBAL_STEP: 40025\u001b[0m\n",
      "     | > loss: -0.14878717064857483  (-0.16368052564592797)\n",
      "     | > log_mle: -0.3655691146850586  (-0.34837998921358143)\n",
      "     | > loss_dur: 0.21678194403648376  (0.18469946356765335)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.4024, device='cuda:0')  (tensor(29.4736, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.5765  (0.3693077433461378)\n",
      "     | > loader_time: 0.005  (0.004362510729439653)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:58:17 -- STEP: 262/406 -- GLOBAL_STEP: 40050\u001b[0m\n",
      "     | > loss: -0.14913353323936462  (-0.163503618640754)\n",
      "     | > log_mle: -0.3465021848678589  (-0.3491955354013517)\n",
      "     | > loss_dur: 0.19736865162849426  (0.18569191676059757)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(26.9313, device='cuda:0')  (tensor(30.9319, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.5355  (0.3808499902259302)\n",
      "     | > loader_time: 0.005  (0.004368216936824888)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:58:29 -- STEP: 287/406 -- GLOBAL_STEP: 40075\u001b[0m\n",
      "     | > loss: -0.13372613489627838  (-0.16346926182404622)\n",
      "     | > log_mle: -0.3499525785446167  (-0.3502262415370874)\n",
      "     | > loss_dur: 0.21622644364833832  (0.18675697971304125)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.6733, device='cuda:0')  (tensor(30.7006, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.5645  (0.3899885835547895)\n",
      "     | > loader_time: 0.005  (0.0043678383378617045)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:58:43 -- STEP: 312/406 -- GLOBAL_STEP: 40100\u001b[0m\n",
      "     | > loss: -0.15751655399799347  (-0.16331481881057597)\n",
      "     | > log_mle: -0.34735381603240967  (-0.350988678061045)\n",
      "     | > loss_dur: 0.1898372620344162  (0.18767385925046912)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.4967, device='cuda:0')  (tensor(31.2431, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.4794  (0.4005145820287556)\n",
      "     | > loader_time: 0.004  (0.0043771763642628985)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:58:56 -- STEP: 337/406 -- GLOBAL_STEP: 40125\u001b[0m\n",
      "     | > loss: -0.1752181351184845  (-0.16288978453913486)\n",
      "     | > log_mle: -0.36702871322631836  (-0.35153009983481553)\n",
      "     | > loss_dur: 0.19181057810783386  (0.1886403152956807)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.1194, device='cuda:0')  (tensor(30.9756, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.6286  (0.41098176194935243)\n",
      "     | > loader_time: 0.005  (0.004405893274867568)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:59:10 -- STEP: 362/406 -- GLOBAL_STEP: 40150\u001b[0m\n",
      "     | > loss: -0.16612541675567627  (-0.16280968351423397)\n",
      "     | > log_mle: -0.36874091625213623  (-0.3522759587066607)\n",
      "     | > loss_dur: 0.20261549949645996  (0.1894662751924267)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(33.5174, device='cuda:0')  (tensor(31.2828, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.5395  (0.42131751545226376)\n",
      "     | > loader_time: 0.005  (0.004444454256342257)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 07:59:26 -- STEP: 387/406 -- GLOBAL_STEP: 40175\u001b[0m\n",
      "     | > loss: -0.16367076337337494  (-0.16283011602030845)\n",
      "     | > log_mle: -0.3628194332122803  (-0.3529726935295478)\n",
      "     | > loss_dur: 0.19914866983890533  (0.19014257750923935)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(21.2593, device='cuda:0')  (tensor(31.3652, device='cuda:0'))\n",
      "     | > current_lr: 2.45e-05 \n",
      "     | > step_time: 0.5485  (0.43398605699070975)\n",
      "     | > loader_time: 0.005  (0.004493569834903844)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09068015217781067 \u001b[0m(+0.009356588125228882)\n",
      "     | > avg_loss:\u001b[92m -0.1942555084824562 \u001b[0m(-0.009158901870250702)\n",
      "     | > avg_log_mle:\u001b[92m -0.37575261294841766 \u001b[0m(-0.005578339099884033)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18149710446596146 \u001b[0m(-0.0035805627703666687)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_40194.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 99/100\u001b[0m\n",
      " --> tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\n",
      "\n",
      "\u001b[1m > TRAINING (2024-01-08 08:00:10) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:00:27 -- STEP: 6/406 -- GLOBAL_STEP: 40200\u001b[0m\n",
      "     | > loss: -0.21232163906097412  (-0.20556421826283136)\n",
      "     | > log_mle: -0.33589279651641846  (-0.34025683005650836)\n",
      "     | > loss_dur: 0.12357115745544434  (0.134692611793677)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(11.3006, device='cuda:0')  (tensor(22.0223, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.2502  (0.2517278989156087)\n",
      "     | > loader_time: 0.001  (0.04137126604715983)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:00:34 -- STEP: 31/406 -- GLOBAL_STEP: 40225\u001b[0m\n",
      "     | > loss: -0.1567494422197342  (-0.18516492795559666)\n",
      "     | > log_mle: -0.3309279680252075  (-0.3380730498221613)\n",
      "     | > loss_dur: 0.17417852580547333  (0.15290812162622328)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.0815, device='cuda:0')  (tensor(23.9234, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.2562  (0.2563294518378473)\n",
      "     | > loader_time: 0.002  (0.009557108725270918)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:00:41 -- STEP: 56/406 -- GLOBAL_STEP: 40250\u001b[0m\n",
      "     | > loss: -0.1675514578819275  (-0.17559120245277882)\n",
      "     | > log_mle: -0.3449373245239258  (-0.3377461774008615)\n",
      "     | > loss_dur: 0.1773858666419983  (0.16215497481503657)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(16.3887, device='cuda:0')  (tensor(21.9075, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.3153  (0.2690478776182446)\n",
      "     | > loader_time: 0.003  (0.0063450464180537635)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:00:49 -- STEP: 81/406 -- GLOBAL_STEP: 40275\u001b[0m\n",
      "     | > loss: -0.16930298507213593  (-0.1720269868771235)\n",
      "     | > log_mle: -0.35324931144714355  (-0.3391619126001994)\n",
      "     | > loss_dur: 0.18394632637500763  (0.16713492563109333)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(23.9777, device='cuda:0')  (tensor(23.3429, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.3553  (0.28202151369165473)\n",
      "     | > loader_time: 0.003  (0.005214579311417945)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:00:58 -- STEP: 106/406 -- GLOBAL_STEP: 40300\u001b[0m\n",
      "     | > loss: -0.16529959440231323  (-0.17037099473318965)\n",
      "     | > log_mle: -0.34502601623535156  (-0.34168125998299076)\n",
      "     | > loss_dur: 0.17972642183303833  (0.17131026517951256)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(15.5438, device='cuda:0')  (tensor(23.4900, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.3783  (0.29470152674980865)\n",
      "     | > loader_time: 0.003  (0.004674070286300947)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:01:07 -- STEP: 131/406 -- GLOBAL_STEP: 40325\u001b[0m\n",
      "     | > loss: -0.18229001760482788  (-0.16954777270327998)\n",
      "     | > log_mle: -0.3530539274215698  (-0.34413036044317347)\n",
      "     | > loss_dur: 0.17076390981674194  (0.1745825876830188)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(32.7036, device='cuda:0')  (tensor(24.5005, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.3283  (0.3061023450079764)\n",
      "     | > loader_time: 0.003  (0.0044085997661561455)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:01:16 -- STEP: 156/406 -- GLOBAL_STEP: 40350\u001b[0m\n",
      "     | > loss: -0.1682540774345398  (-0.16832790724360022)\n",
      "     | > log_mle: -0.35903942584991455  (-0.34571040593660785)\n",
      "     | > loss_dur: 0.19078534841537476  (0.17738249864524752)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(25.5703, device='cuda:0')  (tensor(24.8132, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.3513  (0.3171854294263398)\n",
      "     | > loader_time: 0.003  (0.004273125758537878)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:01:26 -- STEP: 181/406 -- GLOBAL_STEP: 40375\u001b[0m\n",
      "     | > loss: -0.15353944897651672  (-0.16799064598030794)\n",
      "     | > log_mle: -0.3582746982574463  (-0.34728803621471255)\n",
      "     | > loss_dur: 0.20473524928092957  (0.17929739019324104)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(18.4314, device='cuda:0')  (tensor(24.9675, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.4584  (0.3294925136460784)\n",
      "     | > loader_time: 0.004  (0.004219322573414163)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:01:37 -- STEP: 206/406 -- GLOBAL_STEP: 40400\u001b[0m\n",
      "     | > loss: -0.15371891856193542  (-0.1672590352522516)\n",
      "     | > log_mle: -0.3545210361480713  (-0.34846864973457115)\n",
      "     | > loss_dur: 0.20080211758613586  (0.18120961444615158)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(40.2397, device='cuda:0')  (tensor(26.3077, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.3833  (0.3404370129687115)\n",
      "     | > loader_time: 0.004  (0.004168881953341287)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:01:49 -- STEP: 231/406 -- GLOBAL_STEP: 40425\u001b[0m\n",
      "     | > loss: -0.1565645933151245  (-0.16731882746859542)\n",
      "     | > log_mle: -0.36234450340270996  (-0.34991740509545133)\n",
      "     | > loss_dur: 0.20577991008758545  (0.18259857759460224)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(38.8814, device='cuda:0')  (tensor(26.7238, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.5345  (0.35268895760243074)\n",
      "     | > loader_time: 0.004  (0.004172637865140839)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:02:01 -- STEP: 256/406 -- GLOBAL_STEP: 40450\u001b[0m\n",
      "     | > loss: -0.17836613953113556  (-0.16723987349541852)\n",
      "     | > log_mle: -0.3611741065979004  (-0.3511683791875839)\n",
      "     | > loss_dur: 0.18280796706676483  (0.1839285056630615)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(30.7282, device='cuda:0')  (tensor(27.5223, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.5545  (0.36602458264678717)\n",
      "     | > loader_time: 0.005  (0.004191294312477112)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:02:14 -- STEP: 281/406 -- GLOBAL_STEP: 40475\u001b[0m\n",
      "     | > loss: -0.1838204264640808  (-0.16718396438398392)\n",
      "     | > log_mle: -0.3801584243774414  (-0.3522531651093018)\n",
      "     | > loss_dur: 0.1963379979133606  (0.1850692006988033)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(34.4377, device='cuda:0')  (tensor(27.8407, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.5725  (0.37829344043528057)\n",
      "     | > loader_time: 0.006  (0.004224442078125434)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:02:27 -- STEP: 306/406 -- GLOBAL_STEP: 40500\u001b[0m\n",
      "     | > loss: -0.14740875363349915  (-0.16699550320315204)\n",
      "     | > log_mle: -0.3600144386291504  (-0.3532150750066719)\n",
      "     | > loss_dur: 0.21260568499565125  (0.18621957177917156)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(77.4117, device='cuda:0')  (tensor(28.5662, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.4804  (0.39022074805365675)\n",
      "     | > loader_time: 0.004  (0.0042652842266107695)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:02:41 -- STEP: 331/406 -- GLOBAL_STEP: 40525\u001b[0m\n",
      "     | > loss: -0.16142185032367706  (-0.1666485977857135)\n",
      "     | > log_mle: -0.3582109212875366  (-0.3536951502284254)\n",
      "     | > loss_dur: 0.19678907096385956  (0.18704655242020263)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(20.1874, device='cuda:0')  (tensor(29.9068, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.6306  (0.4024767990919039)\n",
      "     | > loader_time: 0.005  (0.004309014611373854)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:02:56 -- STEP: 356/406 -- GLOBAL_STEP: 40550\u001b[0m\n",
      "     | > loss: -0.15050679445266724  (-0.16608371765593472)\n",
      "     | > log_mle: -0.3721252679824829  (-0.35429097963183115)\n",
      "     | > loss_dur: 0.22161847352981567  (0.1882072619549678)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(31.3931, device='cuda:0')  (tensor(30.1619, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.6536  (0.41502810395165785)\n",
      "     | > loader_time: 0.005  (0.004349411873335246)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-01-08 08:03:11 -- STEP: 381/406 -- GLOBAL_STEP: 40575\u001b[0m\n",
      "     | > loss: -0.1570470929145813  (-0.16616775075907467)\n",
      "     | > log_mle: -0.35780882835388184  (-0.35499294505031714)\n",
      "     | > loss_dur: 0.20076173543930054  (0.18882519427168706)\n",
      "     | > amp_scaler: 4096.0  (4096.0)\n",
      "     | > grad_norm: tensor(36.4265, device='cuda:0')  (tensor(30.3842, device='cuda:0'))\n",
      "     | > current_lr: 2.475e-05 \n",
      "     | > step_time: 0.558  (0.4275548351718373)\n",
      "     | > loader_time: 0.0057  (0.004410057868857394)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 0.09408539533615112 \u001b[0m(+0.003405243158340454)\n",
      "     | > avg_loss:\u001b[92m -0.19673792831599712 \u001b[0m(-0.0024824198335409164)\n",
      "     | > avg_log_mle:\u001b[92m -0.37731917202472687 \u001b[0m(-0.001566559076309204)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18058124370872974 \u001b[0m(-0.0009158607572317123)\n",
      "\n",
      " > BEST MODEL : tts_train_dir\\run-January-08-2024_01+38AM-5dcc16d1\\best_model_40600.pth\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fada7a-592f-4a09-9369-e6f3d82de3a0",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6dd47ed5-da8e-4bf9-b524-d686630d6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "output_path = \"tts_train_dir\"\n",
    "# Get latest pth file and json config\n",
    "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
    "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])\n",
    "model_loc = ckpts[0]\n",
    "config_loc = configs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "71510884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: glow_tts\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Text: All those memories will be lost. Like tears in rain.\n",
      " > Text splitted to sentences.\n",
      "['All those memories will be lost.', 'Like tears in rain.']\n",
      " > Processing time: 1.8476781845092773\n",
      " > Real-time factor: 0.3842939176013957\n",
      " > Saving output to out.wav\n"
     ]
    }
   ],
   "source": [
    "!tts    --text \"All those memories will be lost. Like tears in rain.\" \\\n",
    "        --model_path $model_loc \\\n",
    "        --config_path $config_loc \\\n",
    "        --out_path \"out.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbcb3f-d952-469b-a0d8-8941cd7af670",
   "metadata": {},
   "source": [
    "Audio Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0000bd6-6763-4a10-a74d-911dd08ebcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"out.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c5533",
   "metadata": {},
   "source": [
    "## Output Comparison\n",
    "\n",
    "The output of this implemention is basic although within expectation considering the number of epochs and configuration of the model's parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d56614",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "This prototype produces a reasonable output for TTS use cases. The quality of the voice generated most certainly be improved with a few tweaks to the configuration of the model as well as an increase in the number of epochs which was this implementation was severely limited by due to it's computational and time requirements. Even with a 100 epochs, the model has taken over 6 hours to train thus an increase would present a significant amount of time. Despite this, the audio output from the model does reproduce the text provided concisely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
